toward
two-sided
fairness
framework
in
search
and
recommendation
jiqun
liu
jiqunliu@ou.edu
the
university
of
oklahoma
norman
ok
usa
abstract
as
artificial
intelligence
ai
assisted
search
and
recommender
sys
tems
have
become
ubiquitous
in
workplaces
and
everyday
lives
understanding
and
accounting
for
fairness
has
gained
increasing
attention
in
the
design
and
evaluation
of
such
systems
while
there
is
growing
body
of
computing
research
on
measuring
system
fairness
and
biases
associated
with
data
and
algorithms
the
impact
of
human
biases
that
go
beyond
traditional
machine
learning
ml
pipelines
still
remain
understudied
in
this
perspective
paper
we
seek
to
develop
two-sided
fairness
framework
that
not
only
charac
terizes
data
and
algorithmic
biases
but
also
highlights
the
cognitive
and
perceptual
biases
that
may
exacerbate
system
biases
and
lead
to
unfair
decisions
within
the
framework
we
also
analyze
the
interactions
between
human
and
system
biases
in
search
and
rec
ommendation
episodes
built
upon
the
two-sided
framework
our
research
synthesizes
intervention
and
intelligent
nudging
strategies
applied
in
cognitive
and
algorithmic
debiasing
and
also
proposes
novel
goals
and
measures
for
evaluating
the
performance
of
sys
tems
in
addressing
and
proactively
mitigating
the
risks
associated
with
biases
in
data
algorithms
and
bounded
rationality
this
pa
per
uniquely
integrates
the
insights
regarding
human
biases
and
system
biases
into
cohesive
framework
and
extends
the
concept
of
fairness
from
human-centered
perspective
the
extended
fair
ness
framework
better
reflects
the
challenges
and
opportunities
in
users
interactions
with
search
and
recommender
systems
of
vary
ing
modalities
adopting
the
two-sided
approach
in
information
system
design
has
the
potential
to
enhancing
both
the
effectiveness
in
online
debiasing
and
the
usefulness
to
boundedly
rational
users
engaging
in
information-intensive
decision-making
ccs
concepts
information
systems
users
and
interactive
retrieval
keywords
two-sided
fairness
human
bias
system
bias
information
retrieval
recommender
system
permission
to
make
digital
or
hard
copies
of
all
or
part
of
this
work
for
personal
or
classroom
use
is
granted
without
fee
provided
that
copies
are
not
made
or
distributed
for
profit
or
commercial
advantage
and
that
copies
bear
this
notice
and
the
full
citation
on
the
first
page
copyrights
for
components
of
this
work
owned
by
others
than
the
acm
reference
format
jiqun
liu
2023
toward
two-sided
fairness
framework
in
search
and
recommendation
in
acm
sigir
conference
on
human
information
inter
action
and
retrieval
chiir
23
march
19
23
2023
austin
tx
usa
acm
new
york
ny
usa
11
pages
https://doi.org/10.1145/3576840.3578332
introduction
artificial
intelligence
ai
assisted
search
and
recommender
systems
have
become
ubiquitous
in
workplaces
and
everyday
lives
and
play
significant
role
in
human
decision-making
activities
however
the
underlying
algorithms
and
data
could
be
unfair
and
skewed
toward
particular
community
or
group
of
people
leading
to
biased
judgments
and
problematic
decisions
for
instance
compas
software
used
by
the
courts
in
the
united
states
to
estimate
the
risk
of
person
to
recommit
another
crime
is
more
likely
to
have
higher
false
positive
rates
in
predicting
the
recidivism
of
african
american
offenders
also
ai
systems
built
upon
medical
and
usage
data
mainly
collected
from
men
could
falsely
underestimate
the
risk
of
heart
attack
faced
by
women
which
aggravates
gender
inequality
in
health
the
ai-assisted
retrieval
algorithms
bert
12
22
behind
web
search
engines
face
similar
problems
as
they
could
be
picking
up
on
biases
from
data
providers
algorithm
designers
and
users
in
the
way
child
mimics
the
bad
behavior
of
his
parents
given
these
sociotechnical
challenges
growing
body
of
computing
research
strives
to
measure
system-side
fairness
and
mitigate
the
risks
of
biases
embedded
in
algorithms
and
training
data
56
these
increasing
research
efforts
give
rise
to
series
of
relevant
workshops
grants
and
emerging
communities
acm
facct
1.1
biased
systems
and
boundedly
rational
users
while
existing
research
has
achieved
significant
progresses
in
mea
suring
and
mitigating
system
bias
in
broad
range
of
application
scenarios
the
impact
of
human
bias
that
goes
beyond
traditional
ma
chine
learning
ml
pipelines
still
remains
understudied
according
to
kahneman
39
human
bias
refers
to
the
systematic
deviations
of
human
behavior
from
the
predictions
of
rational
normative
models
in
contrast
to
the
assumptions
of
many
simulated
user
models
peo
ple
are
boundedly
rational
and
their
decisions
are
often
affected
by
series
of
biases
and
mental
shortcuts
72
thus
when
interacting
author
must
be
honored
abstracting
with
credit
is
permitted
to
copy
otherwise
or
republish
to
post
on
servers
or
to
redistribute
to
lists
requires
prior
specific
permission
and
or
fee
request
permissions
from
permissions@acm.org
chiir
23
march
19
23
2023
austin
tx
usa
2023
copyright
held
by
the
owner
author
publication
rights
licensed
to
acm
acm
isbn
979
4007
0035
23
03
15.00
https://doi.org/10.1145/3576840.3578332
https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-
sentencing
https://www.forbes.com/sites/carmenniethammer/2020/03/02/ai-bias-could-put-
womens-lives-at-riska-challenge-for-regulators
https://www.nytimes.com/2019/11/11/technology/artificial-intelligence-bias.html
https://facctconference.org/.
chiir
23
march
19
23
2023
austin
tx
usa
liu
with
search
and
recommender
systems
user
may
be
dispropor
tionately
impacted
by
the
retrieved
results
or
recommended
items
that
trigger
the
behavioral
impact
of
their
existing
cognitive
biases
and
heuristics
causing
unexpected
unfair
outcomes
for
example
users
who
have
certain
misleading
beliefs
regarding
vaccines
are
more
vulnerable
to
related
misinformation
presented
on
search
engine
result
pages
serps
leading
to
ill-informed
undesired
med
ical
decisions
online
shoppers
tend
to
quickly
accept
immediate
mediocre
recommendations
after
encountering
several
bad-quality
products
recommended
by
the
system
as
low
reference
levels
differing
from
data
and
algorithmic
biases
human
biases
tend
to
be
individualized
context-dependent
40
75
and
closely
associated
with
people
previous
similar
experiences
case-based
decision
making
29
however
both
system
bias
and
human
bias
could
result
in
unfair
decisions
and
negative
societal
impacts
how
to
identify
and
mitigate
the
risks
of
potential
biases
from
both
sides
is
fundamental
open
challenge
to
information
retrieval
ir
and
recommender
systems
rs
communities
1.2
two-sided
fairness
perspective
to
address
the
gap
above
we
re-conceptualize
fairness
in
ai
from
user-centered
perspective
and
propose
two-sided
fairness
frame
work
that
deconstructs
the
impact
of
both
system
bias
and
human
bias
in
interactive
search
recommendation
and
ai-assisted
de
cision
making
aligned
with
the
objectives
of
chiir
perspective
paper
track
our
work
seeks
to
present
novel
insights
and
iden
tify
open
questions
at
conceptual
methodological
and
evaluation
levels
we
extend
the
concept
of
fairness
to
cover
the
effects
and
measurements
of
both
human
bias
and
system
bias
embedded
in
data
and
algorithms
as
well
as
the
possible
interactions
between
them
we
propose
new
two-sided
evaluation
methods
that
can
examine
the
performance
of
search
and
recommender
systems
in
addressing
and
proactively
reducing
the
impacts
of
both
human
and
system
biases
we
synthesize
empirically
tested
re-ranking
interven
tion
and
nudging
techniques
that
could
potentially
miti
gate
the
risks
of
one
or
both
types
of
biases
through
accomplishing
the
above
goals
this
paper
makes
three
fold
contributions
it
integrates
the
interdisciplinary
insights
from
ir
and
recommendation
ai
fairness
and
cognitive
psychol
ogy
and
offers
more
balanced
psychologically
realistic
approach
to
measuring
and
evaluating
fairness
in
users
interactions
with
intelligent
information
systems
ii
it
highlights
the
available
tools
recommendation
and
re-ranking
system
intervention
intel
ligent
nudging
techniques
for
mitigating
the
risks
of
system
and
human
biases
in
information-intensive
tasks
iii
it
proposes
novel
evaluation
metrics
that
measure
the
performance
of
systems
in
re
ducing
both
system
and
human
biases
and
could
be
employed
and
tested
in
broader
scope
of
search
and
recommendation
scenarios
in
addition
this
paper
also
identifies
new
fundamental
and
em
pirical
issues
that
emerge
from
the
extended
fairness
concept
and
have
the
potential
to
inspire
substantive
discussions
and
significant
progresses
in
the
field
extending
the
scope
of
fairness
going
beyond
the
mainstream
studies
on
algorithmic
fairness
this
section
presents
an
extended
definition
of
fairness
that
sets
con
straints
on
both
system
bias
and
human
bias
in
users
interactions
with
systems
under
the
extended
concept
the
fairness
of
system
will
be
evaluated
based
on
not
only
its
performance
in
reducing
the
biases
inherited
from
data
and
algorithms
but
also
its
ability
in
protecting
users
from
the
risks
and
contextual
triggers
of
cognitive
and
perceptual
biases
our
two-sided
fairness
framework
incorporates
the
features
of
biases
from
both
sides
and
speaks
to
new
challenges
in
understanding
and
supporting
boundedly
rational
users
inter
acting
with
potentially
biased
systems
2.1
notions
of
system
fairness
search
and
recommender
systems
have
been
employed
by
grow
ing
user
population
as
the
main
channel
for
information
access
in
varying
tasks
including
the
ones
in
sensitive
environments
such
as
health
information
seeking
hiring
and
job
application
63
80
and
financial
decision
making
thus
the
underlying
biased
data
and
unfair
algorithm
would
not
only
affect
information
pre
sentation
but
also
lead
to
unfair
distributions
of
economic
and
socio-technical
resources
to
address
this
inspired
by
classic
research
on
fairness
from
psychology
and
philosophy
14
37
researchers
proposed
series
of
fairness
definitions
focusing
on
varying
levels
and
fac
tors
and
employed
them
as
constraints
to
mitigate
the
bias
and
discrimination
in
retrieval
and
recommendation
algorithms
ac
cording
to
56
the
existing
fairness
definitions
can
be
grouped
into
three
categories
individual
fairness
group
fairness
and
sub
group
fairness
individual
fairness
requires
that
systems
should
give
similar
predictions
to
individual
users
and
content
genera
tors
with
similar
characteristics
regardless
of
their
differences
in
protected
sensitive
attributes
such
as
gender
ethnicity
and
popu
larity
13
23
45
group
fairness
concept
focuses
on
the
potential
biases
against
sensitive
groups
or
communities
and
emphasizes
that
all
groups
should
be
treated
equally
23
24
45
subgroup
fair
ness
combines
the
features
of
both
fairness
concepts
above
and
measures
whether
fairness
constraint
holds
over
large
set
of
subgroups
41
42
existing
fairness
concepts
and
measures
seek
to
mitigate
and
prevent
varying
types
of
observable
unfairness
in
re
trieved
contents
and
recommended
items
especially
with
respect
to
certain
protected
attributes
however
the
potential
risks
of
implicit
unfairness
generated
through
the
combination
of
system
output
and
user
biases
still
remain
unclear
2.2
human
bias
and
bounded
rationality
differing
from
over
simplified
simulated
agents
seeking
maximized
utility
real-life
users
often
operates
under
the
impact
of
cognitive
and
perceptual
biases
and
attempt
to
satisfice
or
achieve
good
enough
results
rather
than
optimize
39
72
human
biases
and
satisficing
strategies
covered
under
the
theoretical
umbrella
of
bounded
rationality
could
drive
users
to
unconsciously
make
bi
ased
judgments
regarding
retrieved
information
and
recommended
items
and
unfair
decisions
in
sensitive
environments
current
fair
ness
metrics
and
constraints
focusing
on
the
biases
in
data
retrieval
algorithms
and
recommendation
mechanisms
are
widely
applied
toward
two-sided
fairness
framework
in
search
and
recommendation
chiir
23
march
19
23
2023
austin
tx
usa
in
standardized
offline
experiments
and
are
independent
from
user
characteristics
by
design
thus
extending
existing
fairness
con
cepts
to
cover
human
biases
would
be
essential
especially
for
the
scenarios
where
algorithmically
fair
systems
still
result
in
prac
tically
unfair
information
use
and
decisions
for
instance
users
may
click
and
save
search
results
that
are
consistent
with
their
pre-search
expectations
and
opinions
of
certain
cognitive
author
ities
despite
the
diverse
set
of
topics
perspectives
and
content
generators
included
on
the
serp
confirmation
bias
70
in
ad
dition
diverse
recommended
items
ranked
on
similar
positions
may
receive
significantly
different
amounts
of
actual
attention
due
to
the
divergence
in
users
remembered
experiences
with
similar
products
reference
dependence
51
given
this
challenge
it
is
critical
to
enrich
the
fairness
concept
with
user
dimensions
and
evaluate
the
performance
of
search
and
recommender
systems
in
identifying
preventing
and
mitigating
the
negative
effect
of
hu
man
bias
at
methodological
level
adopting
certain
intervention
and
nudging
techniques
for
cognitive
debiasing
may
not
only
ad
dress
immediate
biased
judgments
in
current
interactions
but
also
generate
sustained
impacts
on
future
information
searching
and
recommendation
assessments
52
53
87
2.3
interaction
between
human
bias
and
system
bias
human
bias
and
system
bias
can
interact
with
each
other
at
dif
ferent
stages
of
users
interactions
with
ir
and
recommender
sys
tems
such
as
search
initiation
and
query
reformulation
brows
ing
and
clicking
and
evaluation
of
information
items
and
products
for
instance
ge
et
al
28
studied
the
interactions
between
users
interests
as
anchoring
level
and
personalized
e-commerce
recom
mendations
in
particular
based
on
the
interaction
logs
gathered
from
alibaba
taobao
transactions
researchers
measured
the
self
reinforcement
effect
on
users
interests
caused
by
the
narrowed
exposure
of
recommended
product
types
this
mutual
reinforce
ment
between
users
initial
preferences
and
the
customized
rec
ommendations
tailored
according
to
in-situ
behaviors
could
lead
to
echo
chamber
effect
in
ir
evaluation
scholer
et
al
69
inves
tigated
the
dynamic
thresholds
in
external
assessors
document
judgments
and
their
associations
with
the
sequence
of
presenting
documents
of
varying
relevance
the
results
indicate
that
initially
encountered
high-quality
documents
may
heighten
user
refer
ence
level
of
relevance
leading
to
underestimated
relevance
levels
in
subsequent
document
judgments
in
addition
to
human-system
interactions
azzopardi
also
argues
that
information
searchers
may
experience
mixed
effects
of
multiple
cognitive
biases
in
search
and
evaluation
when
interacting
with
the
same
set
of
algorithmically
fair
re
sults
different
users
may
have
significantly
different
chances
of
making
biased
judgments
due
to
their
differences
in
pre-interaction
references
and
expectations
remembered
experiences
and
in-situ
perceived
gains
and
efforts
users
biases
and
system
biases
may
re
inforce
each
other
through
implicit
feedback
learning
to
rank
ltr
and
personalized
recommendation
processes
while
human
biases
are
difficult
to
observe
and
often
act
unconsciously
they
could
still
cause
unfair
decisions
and
tangible
consequences
for
people
with
different
beliefs
knowledge
bases
and
prior
experiences
to
figure
two-sided
bias
structure
in
users
interactions
with
search
and
recommender
systems
make
matter
worse
users
biases
are
often
purposely
exploited
for
increasing
engagements
and
profits
especially
in
online
shopping
social
media
feeds
and
marketing
promotions
33
77
86
leading
to
unseen
unfairness
compared
to
widely
discussed
protected
at
tributes
cf
18
factors
associated
with
human
biases
are
usually
hidden
in
fast
judgments
and
intuitive
decisions
and
are
closely
re
lated
to
local
contexts
search
intention
domain
knowledge
cog
nitive
load
and
individual
characteristics
short-term
memory
span
thus
understanding
and
achieving
human-centered
fairness
would
be
more
empirically
challenging
but
also
equally
important
to
reaching
system
fairness
especially
the
ai
machine
learning
components
19
in
an
era
of
information
ubiquity
two-sided
fairness
framework
built
upon
above
discussions
this
section
proposes
two-sided
fairness
framework
that
takes
into
consideration
the
features
ef
fects
and
measurements
of
both
human
bias
and
system
bias
the
extended
fairness
concept
can
inspire
and
inform
more
balanced
user-aware
approach
to
evaluating
the
fairness
of
search
and
rec
ommender
systems
figure
illustrates
the
biases
from
both
human
and
system
sides
that
may
operate
at
different
stages
of
user
interactions
given
that
the
mainstream
fairness
research
focusing
on
algorithmic
fairness
in
ai
ml
our
framework
presents
balanced
approach
to
addressing
two-sided
biases
at
different
stages
pre-interaction
interaction
post-interaction
with
an
emphasis
on
the
impacts
of
human
biases
note
that
our
work
discusses
the
major
types
of
human
and
system
biases
especially
the
ones
that
are
empirically
examined
in
search
and
recommendation
contexts
and
is
not
able
to
exhaust
all
possible
biases
more
comprehensive
list
of
human
bias
is
offered
by
benson
3.1
pre-interaction
stage
many
of
the
conditions
and
triggers
of
human
bias
and
system
bias
are
formed
long
before
users
interactions
with
systems
actually
occur
on
the
system
side
biases
in
the
data
employed
in
training
cognitive
bias
cheat
sheet
https://betterhumans.pub/cognitive-bias-cheat-sheet-
55a472476b18
chiir
23
march
19
23
2023
austin
tx
usa
liu
ml-based
algorithms
ltr
adaptive
recommendation
may
re
sult
in
biased
algorithmic
outcomes
the
biases
in
training
data
may
originate
from
the
biased
sampling
and
curation
processes
which
creates
non-representative
samples
as
well
as
the
existing
histori
cal
bias
and
socio-technical
problems
in
reality
74
data
bias
and
unfairness
may
also
occur
due
to
human
prejudice
and
stereotyping
based
upon
sensitive
attributes
56
in
addition
part
of
the
data
bias
could
result
from
biased
behaviors
during
interactions
across
varying
recommendation
platforms
and
search
interfaces
61
for
instance
users
may
spend
more
time
and
clicks
on
the
results
and
items
that
are
ranked
on
the
top
of
serps
or
consistent
with
their
expectations
which
could
generate
skewed
feedback
data
and
rein
force
existing
biases
in
relevance
and
usefulness
estimations
55
on
the
human
side
users
pre-search
expectations
interests
and
preferences
as
well
as
beliefs
and
knowledge
base
are
affected
by
their
remembered
prior
experiences
under
similar
scenarios
or
cases
in
cbdt
29
and
individual
characteristics
for
example
users
may
choose
to
avoid
certain
information
sources
or
vendors
due
to
previous
negative
experience
under
similar
scenarios
also
users
who
lack
certain
domain
knowledge
may
skip
unfamiliar
or
seemingly
ambiguous
results
on
serps
60
these
cognitive
factors
usually
shape
the
reference
levels
based
on
which
users
evaluate
available
options
during
interactions
such
as
retrieved
results
rec
ommended
queries
and
products
as
well
as
search
continuation
or
stopping
reference
dependence
bias
79
with
divergent
reference
levels
users
interacting
with
similar
result
lists
tend
to
perceive
and
evaluate
information
gains
and
search
efforts
differently
re
sulting
in
distinct
search
tactics
judgments
and
decision-making
strategies
15
51
in
addition
the
pre-interaction
factors
could
also
affect
the
extent
to
which
user
is
vulnerable
to
the
negative
impact
of
other
potential
biases
during
interactions
for
instance
medical
expert
may
be
less
likely
to
be
influenced
by
the
vac
cine
misinformation
ranked
on
top
positions
of
serps
compared
to
novice
searchers
in
the
field
computer
scientist
who
is
familar
with
personalized
recommendation
algorithms
may
possess
high
level
of
algorithm
awareness
cf
34
and
could
be
more
sensitive
to
biased
recommendations
from
over
personalized
systems
inves
tigating
pre-interaction
factors
and
associated
human
biases
will
allow
researchers
to
better
understand
why
users
with
different
backgrounds
and
prior
interaction
experiences
may
have
signifi
cantly
different
likelihood
of
achieving
optimal
utility
or
desired
outcomes
when
facing
similar
sets
of
information
and
recommen
dations
3.2
interaction
stage
on
the
system
side
biased
algorithmic
decision
music
recom
mendations
that
do
not
provide
fair
representation
of
new
artists
global
economy
search
results
that
mainly
focuses
on
small
set
of
developed
economies
could
happen
because
of
both
data
biases
inherited
through
training
and
built-in
biases
embedded
in
algo
rithms
56
in
existing
research
on
system
and
algorithmic
fairness
fairness
is
often
broadly
defined
as
the
absence
of
prejudice
or
fa
voritism
towards
an
individual
or
group
based
on
their
intrinsic
or
acquired
traits
in
the
context
of
decision-making
67
according
to
35
this
general
rule
of
fairness
can
be
written
as
where
represents
the
predicted
results
and
as
binary
variable
indicates
if
the
data
point
represents
protected
group
member
the
goal
of
this
equalized-odds
fairness
constraint
is
that
the
probability
of
an
item
in
the
positive
category
being
correctly
assigned
positive
label
and
the
probability
of
an
item
from
the
negative
class
being
incorrectly
put
into
positive
category
should
stay
the
same
regardless
of
the
protected
membership
labels
56
81
for
instance
with
the
same
level
of
actual
relevance
and
quality
the
contents
and
products
produced
by
both
popular
and
new
providers
should
obtain
equalized
likelihood
of
exposure
on
similar
rank
positions
also
when
searching
under
controversial
topic
users
should
have
access
to
fairly
distributed
information
sources
with
diverse
perspectives
the
equalized-odds
fairness
measure
has
also
been
adjusted
ac
cording
to
specific
application
scenarios
and
fairness
requirements
for
example
equalized-opportunity
fairness
focuses
on
the
positive
labels
and
requires
that
the
probability
of
an
item
in
positive
class
being
labeled
with
positive
outcome
should
be
equal
for
both
protected
and
unprotected
group
members
35
this
constraint
can
be
written
as
similar
rules
can
also
be
applied
to
group
and
subgroup
fairness
research
where
equal
true
positive
and
false
positive
rates
should
be
achieved
in
ml-based
predictions
for
groups
with
different
pro
tected
attribute
labels
mitigating
and
restricting
behind-the-scenes
algorithmic
biases
could
result
in
fairer
presentation
of
infor
mation
and
recommendations
accessed
by
users
apart
from
the
abstracted
biases
in
predictions
researchers
have
also
explored
potential
system
biases
in
interface
design
and
information
pre
sentation
60
68
that
could
trigger
some
users
misapplication
of
mental
shortcuts
and
heuristics
39
75
and
thereby
cause
obstacles
in
inferential
thinking
and
information
evaluation
differing
from
data
and
algorithmic
biases
for
which
external
la
beling
is
relatively
straightforward
human
biases
that
emerge
from
and
operate
in
interactions
are
often
difficult
to
measure
while
re
searchers
could
design
diverse
experimental
conditions
as
assigned
triggers
of
cognitive
biases
in
controlled
lab
settings
39
85
it
is
challenging
to
measure
biases
in
users
real-time
interactions
with
search
and
recommender
systems
under
ill-defined
complex
tasks
however
it
is
critical
to
study
human
bias
and
incite
discussions
on
human-side
fairness
as
some
users
may
end
up
in
implicitly
disadvantaged
positions
in
their
interactions
with
systems
due
to
their
cognitive
and
perceptual
biases
being
triggered
by
certain
contextual
factors
system
outputs
and
individual
traits
figure
presents
hypothetical
example
of
search
recommendation
iteration
under
query
or
question
to
illustrate
the
interrelated
hu
man
biases
that
operate
during
interaction
sessions
for
instance
when
interacting
with
retrieved
products
and
information
items
users
may
prefer
to
examine
and
click
the
ones
that
confirm
their
pre-interaction
expectations
and
beliefs
or
are
less
likely
to
chal
lenge
their
existing
status
quo
in
mind
confirmation
and
status
quo
bias
66
which
could
reduce
the
probability
of
cognitive
dis
sonance
47
or
knowledge
restructuring
in
addition
the
initially
toward
two-sided
fairness
framework
in
search
and
recommendation
chiir
23
march
19
23
2023
austin
tx
usa
figure
interrelated
human
biases
within
interactions
encountered
results
and
recommended
items
could
be
used
as
ref
erence
or
anchoring
points
in
users
evaluation
of
following
items
especially
in
terms
of
the
perceived
gains
and
costs
involved
in
browsing
and
examination
reference
dependence
thus
when
user
encounters
high-quality
item
at
the
beginning
of
the
iter
ation
highly
relevant
document
or
five-start
product
with
good
price
the
user
may
form
relatively
high
reference
level
or
in-situ
expectation
in
mind
as
result
slight
drop
in
item
qual
ity
or
small
increases
in
efforts
dwell
time
number
of
clicks
and
recommendations
examined
may
lead
to
major
decrease
of
interaction
satisfaction
in
following
browsing
and
clicking
activ
ities
loss
aversion
bias
and
threshold
priming
51
69
79
also
users
may
choose
to
avoid
the
search
results
that
are
framed
as
an
ambiguous
or
unfamiliar
risky
option
risk
aversion
and
framing
effect
43
54
62
however
when
the
user
starts
with
low
ref
erence
level
or
expectation
their
perceptions
and
evaluations
of
subsequent
items
may
change
completely
despite
that
the
nature
of
the
items
stay
the
same
decoy
effect
refers
to
the
scenarios
where
people
change
their
preference
between
two
existing
options
when
presented
with
third
option
the
decoy
that
is
asymmetrically
dominated
78
88
in
ir
and
crowdsourcing
labeling
eickhoff
25
examined
the
impact
of
decoy
document
on
users
thresholds
and
strategies
in
standard
relevance
judgments
for
instance
in
convenient
store
customer
may
find
it
difficult
to
decide
between
an
apple
and
banana
for
afternoon
snack
however
when
rotten
apple
the
decoy
is
placed
next
to
the
existing
apple
the
customer
may
find
the
apple
to
be
more
favorable
option
as
there
is
perceived
gain
compared
to
the
decoy
reference
as
figure
shows
it
may
be
difficult
to
predict
user
preference
between
document
and
document
as
they
are
associated
with
two
different
subtopics
and
respectively
however
when
symmetrically
dom
inated
document
is
presented
and
the
topic
is
similar
to
it
is
likely
that
the
user
will
give
higher
score
to
the
target
document
in
ir
user
may
compare
the
target
and
decoy
results
over
multiple
dimensions
such
as
relevance
usefulness
perceived
credibility
and
readability
the
essence
of
decoy
effect
is
that
person
preference
between
two
or
more
options
could
be
altered
completely
by
adding
decoy
option
without
changing
the
nature
of
existing
options
similar
impacts
of
decoy
has
also
been
empirically
confirmed
in
online
recommendation
and
e-commerce
settings
71
86
differing
from
the
human
biases
introduced
above
rank
position
bias
83
is
easier
to
observe
on
the
surface
of
interactions
and
has
been
discussed
in
wide
range
of
ir
particularly
unbiased
ltr
and
rs
experiments
20
32
the
knowledge
regarding
rank
position
bias
has
been
widely
applied
in
simulating
user
mod
els
underlying
offline
evaluation
metrics
where
users
attention
and
likelihood
of
clicking
and
examination
are
often
assumed
to
be
decreasing
by
rank
in
serp
and
recommendation
evaluations
17
58
however
the
actual
effect
of
rank
position
bias
may
be
moderated
by
the
form
and
modality
of
search
results
and
rec
ommendations
for
instance
researchers
found
that
compared
to
organic
search
results
vertical
results
and
recommendations
news
images
may
appear
to
be
more
visually
salient
and
reduce
the
impact
of
rank
positions
on
the
probability
of
examination
and
clicking
82
as
it
is
discussed
above
human
biases
could
be
triggered
by
series
of
pre-interaction
factors
and
within-interaction
factors
rank
position
decoy
items
initially
encountered
items
distance
and
similarity
between
results
once
triggered
human
biases
could
lead
to
significant
deviations
of
users
behaviors
and
judgments
from
optimal
or
desired
results
consequently
unfair
decisions
and
outcomes
may
occur
between
users
who
are
more
vulnerable
to
certain
biases
and
contextual
triggers
and
the
ones
who
are
not
by
extending
existing
fairness
concepts
our
two-sided
fairness
framework
seek
to
highlight
characterize
and
assess
this
human
side
unfairness
in
search
and
recommender
systems
3.3
post-interaction
stage
at
the
post-interaction
stage
the
mixed
effect
of
system
biases
and
human
biases
may
result
in
biased
information
evaluation
and
use
unfair
decisions
and
undesired
outcomes
on
the
system
side
bi
ased
algorithmic
decision
could
come
from
black-box
re-ranking
or
recommendation
model
where
the
training
data
generated
at
pre
and
within-interaction
stages
and
learning
algorithms
could
not
be
modified
or
scrutinized
on
the
human
side
in
addition
to
the
within-interaction
biases
users
may
subject
to
the
influence
of
other
whole-session
cognitive
biases
when
making
decisions
based
on
remembered
experiences
for
instance
when
evaluating
and
comparing
the
performances
of
multiple
queries
and
systems
users
are
heavily
influenced
by
the
peak
point
and
end
or
most-recent
point
of
experience
during
the
sessions
being
evaluated
and
are
not
sensitive
to
the
actual
time
duration
of
the
interaction
peak
end
rule
and
duration
neglect
36
51
64
these
memory-related
biases
may
lead
to
significant
divergence
between
users
retrospec
tive
satisfaction-based
judgments
and
the
assessment
from
system
designers
and
lead
to
unfair
evaluations
of
systems
and
interaction
experiences
from
whole-session
contexts
3.4
two-sided
fairness
goals
the
system-side
fairness
goal
can
be
adapted
from
current
fairness
objectives
in
ai
ml
fairness
as
it
is
indicated
in
sub-section
3.2
despite
the
difference
in
specific
measures
the
common
underlying
goal
is
to
achieve
equal
true
positive
and
false
positive
prediction
rates
for
both
protected
and
unprotected
group
members
identified
with
pre-defined
protected
attributes
the
prediction
results
are
chiir
23
march
19
23
2023
austin
tx
usa
liu
usually
associated
with
critical
decisions
and
societal
impacts
such
as
healthcare
hiring
and
house
mortgage
approval
48
56
regarding
human-side
fairness
we
can
adopt
similar
approach
and
write
it
as
where
represents
the
desired
or
accessible
optimal
outcome
for
an
individual
or
group
represents
the
set
of
attributes
and
contex
tual
features
that
are
not
associated
with
human
biases
indicates
if
the
user
belongs
to
the
protected
group
that
is
more
vulnerable
to
certain
cognitive
and
perceptual
biases
represents
the
actual
outcome
or
utility
of
information
use
and
decision-making
the
human-side
fairness
goal
is
that
users
with
similar
intentions
of
in
teracting
with
search
and
recommender
systems
and
backgrounds
should
have
similar
chance
of
obtaining
desired
outcomes
from
the
interaction
regardless
of
their
actual
vulnerability
to
the
human
biases
that
could
be
triggered
the
group
membership
variable
can
be
written
as
t1
predicting
desired
outcomes
or
estimating
optimal
out
comes
based
on
the
nature
of
tasks
and
problems
that
moti
vate
users
to
engage
with
systems
t2
estimating
the
real-time
risk
of
cognitive
and
perceptual
biases
for
individuals
and
groups
based
on
the
knowledge
of
user
characteristics
and
features
of
system
outputs
t3
learning
bias-aware
user
models
to
characterize
users
information
evaluation
use
and
decision-making
patterns
under
the
impact
of
biases
among
the
above
tasks
t1
will
offer
ground
truth
labels
for
eval
uating
the
fairness
in
the
probability
of
obtaining
desired
or
optimal
outcomes
in
well-structured
tasks
with
clearly-defined
goals
the
labels
could
also
be
extracted
from
users
annotations
of
their
task
goals
t2
will
generate
the
protected
attribute
labels
and
classify
individuals
into
multiple
categories
among
which
human-centered
fairness
needs
to
be
achieved
accomplishing
t2
and
developing
bias-aware
interventions
will
enhance
equal
access
to
quality
infor
mation
and
facilitate
unbiased
judgments
of
encountered
informa
tion
and
thereby
contribute
to
the
completion
of
t1
models
built
under
t3
will
allow
us
to
predict
potential
biased
judgments
and
de
cisions
based
on
the
estimated
risks
of
biases
individual
traits
and
where
represents
user
estimated
vulnerability
to
potential
human
bias
without
loss
of
generality
here
we
as
sume
that
every
is
binary
variable
the
probability
that
user
is
vulnerable
to
is
determined
by
the
function
of
three
variables
individual
characteristics
of
the
user
prior
experiences
expectations
and
beliefs
and
the
triggers
from
sys
tem
outputs
as
it
is
explained
in
previous
sub-sections
different
human
biases
may
involve
diverse
mechanisms
and
probabilities
of
being
triggered
39
and
thus
should
be
represented
with
separate
functions
in
addition
researchers
and
system
designers
should
also
explore
the
interplay
of
varying
biases
at
different
stages
and
inves
tigate
if
addressing
certain
human
biases
would
mitigate
or
increase
the
risk
of
encountering
other
biases
in
query
reformulation
judg
ment
of
results
and
recommendations
as
well
as
post-interaction
decision-making
3.5
two-sided
fairness
in
human-centered
system
evaluation
based
on
the
goals
defined
above
researchers
can
evaluate
the
performance
of
search
and
recommender
systems
in
fulfilling
as
sociated
fairness
constraints
27
81
84
regarding
system
fairness
the
predictions
and
output
ranked
results
customized
recommendations
of
systems
can
be
evaluated
according
to
the
measures
specified
in
sub-section
3.2
for
instance
when
making
algorithmic
decisions
on
music
recommendations
it
is
critical
to
assess
if
the
probabilities
and
rank
positions
of
recommending
rele
vant
musics
are
equal
across
artists
from
varying
backgrounds
57
in
addition
to
this
active
approach
the
system
fairness
constraint
may
also
be
achieved
through
unawareness
an
algorithm
can
be
considered
fair
if
no
protected
attribute
is
explicitly
adopted
in
making
decisions
31
on
the
human
side
the
evaluation
needs
to
be
built
upon
series
of
preparation
work
specifically
one
have
to
complete
following
tasks
before
assessing
human-centered
fairness
in-situ
contextual
triggers
with
these
models
researchers
could
proactively
identify
biased
behaviors
before
problematic
decisions
actually
occur
under
these
human-centered
fairness
constraints
when
evaluating
serps
and
ranked
list
of
recommended
items
we
should
not
only
measure
the
explicit
biases
associated
with
pro
tected
sensitive
attributes
but
also
estimate
the
risk
of
them
in
triggering
varying
types
of
human
biases
introduced
in
figure
depending
on
the
specific
systems
user
interacts
with
and
the
nature
of
motivating
tasks
the
weights
of
human-side
fairness
and
system-side
fairness
could
be
tailored
to
varying
evaluation
preferences
3.6
two-sided
fair
ranking
intervention
and
intelligent
nudging
in
previous
ir
ml
and
human-computer
interaction
hci
studies
series
of
re-ranking
intervention
and
nudging
techniques
have
been
developed
for
system
bias
mitigation
and
cognitive
debiasing
which
could
help
enhance
two-sided
fairness
on
the
system
and
algorithmic
side
most
bias
mitigation
methods
are
developed
in
ml
pipeline
and
can
be
grouped
into
three
categories
or
stages
pre
processing
in-processing
and
post-processing
56
pre-processing
category
covers
the
techniques
used
in
reducing
and
removing
bias
and
discrimination
in
datasets
employed
for
training
ranking
and
recommendation
algorithms
10
for
instance
researchers
can
apply
preferential
sampling
methods
to
address
discrimination
in
search
and
recommendation
logs
and
ensure
fair
representation
of
samples
from
diverse
communities
and
populations
before
training
rankers
in-processing
group
includes
the
techniques
for
modifying
learning
algorithms
and
removing
biases
during
interaction
and
model
training
processes
11
for
instance
ir
researchers
can
ad
just
ltr
algorithms
with
counterfactual
methods
and
mitigate
the
possible
biases
and
noise
learned
from
historical
data
and
user
behaviors
during
search
sessions
rank
position
bias
38
toward
two-sided
fairness
framework
in
search
and
recommendation
chiir
23
march
19
23
2023
austin
tx
usa
figure
enhancing
two-sided
fairness
post-processing
methods
are
applied
after
training
and
allow
sys
tems
to
reassign
labels
created
by
potentially
biased
black-box
models
21
on
human-centered
fairness
side
series
of
intelligent
interven
tion
and
nudging
techniques
have
been
proposed
and
empirically
tested
in
search
recommendation
and
diverse
set
of
hci
sce
narios
for
instance
systems
could
transform
digital
information
and
add
visual
aids
on
interfaces
to
reduce
the
perceived
ambiguity
and
increase
saliency
of
certain
information
16
73
also
effective
nudging
and
debiasing
could
be
achieved
through
changing
the
de
cision
structure
such
as
altering
the
starting
and
anchoring
options
proactively
adjust
the
ranking
structure
that
could
lead
to
negative
decoy
effects
and
re-arranging
evaluation
sequences
to
prevent
potential
priming
effects
and
reference
dependence
bias
16
69
76
in
addition
researchers
could
leverage
the
power
of
cognitive
au
thority
and
query
priming
techniques
in
designing
in-situ
inter
ventions
and
nudging
users
toward
more
effective
search
terms
and
paths
52
87
apart
from
individual-level
factors
researchers
have
also
explored
the
effect
of
social
factors
on
users
attitudes
and
behaviors
friends
and
colleagues
know
about
the
deci
sion
59
adding
and
changing
social
consequences
has
been
demonstrated
as
an
effective
technique
in
promoting
green
lifestyle
and
health
diet
30
46
and
may
also
be
leveraged
in
encouraging
critical
thinking
active
reflection
on
possible
biased
judgments
on
recommendations
and
the
acceptance
of
diverse
opinions
and
perspectives
due
to
the
diverse
nature
of
human
biases
the
spe
cific
intervention
and
nudging
methods
need
to
be
customized
and
adjusted
in
real-time
according
to
involved
user
characteristics
and
the
in-situ
estimated
risks
of
individual
biases
also
the
possible
interactions
and
mutual-reinforcements
between
multiple
biases
need
to
be
considered
in
designing
set
of
nudging
techniques
based
on
the
discussions
above
figure
summarizes
the
tasks
associated
with
enhancing
two-sided
fairness
similar
to
the
three
stage
structure
of
data
and
algorithmic
debiasing
human-side
fair
ness
can
also
be
achieved
and
enhanced
at
multiple
stages
specifi
cally
systems
could
proactively
estimate
the
potential
risks
of
biases
based
on
the
knowledge
about
users
learned
from
previous
interac
tion
data
and
the
structure
of
current
serp
and
recommendation
list
with
the
estimated
risk
levels
systems
can
decide
the
specific
actions
re-ranking
adaptive
intervention
digital
nudging
to
take
in
following
interactions
in
addition
when
biased
behaviors
and
judgments
occur
systems
can
adjust
the
ranking
algorithms
and
recommendation
strategies
accordingly
correct
the
biased
re
sults
and
remove
contextual
triggers
that
could
cause
other
biases
for
the
user
once
the
interaction
is
completed
the
system
may
still
provide
post-interaction
interventions
summarize
and
present
possible
biases
extracted
from
whole-session
interactions
and
im
plicit
feedback
in
order
to
at
least
partially
address
human
bias
in
decision-making
making
personal
health
decision
choosing
recommended
products
to
purchase
deciding
which
applicant
to
interview
or
hire
practical
applications
and
potential
challenges
when
interacting
with
information
systems
and
making
decisions
under
uncertainty
users
should
be
protected
from
the
bias
and
discrimination
that
emerge
from
both
system
biases
associated
with
sensitive
attributes
but
also
the
negative
impact
of
human
biases
triggered
by
both
individual
traits
and
contextual
factors
our
two-sided
fairness
framework
could
be
applied
in
broad
range
of
search
and
recommendation
interaction
scenarios
4.1
practical
applications
the
two-sided
fairness
concept
offers
new
perspective
for
evalu
ating
users
interactions
with
systems
of
varying
modalities
for
instance
when
evaluating
the
fairness
of
conversational
search
and
recommendation
systems
apart
from
the
observable
biases
in
system
responses
researchers
should
also
investigate
the
signals
of
cognitive
biases
in
utterances
and
interactions
in
addition
systems
can
predict
and
clarify
potential
biases
misleading
beliefs
and
unrealistic
expectations
regarding
certain
products
with
users
by
promoting
recommended
questions
asking
clarifying
questions
and
analyzing
users
reactions
once
potential
bias
is
identified
the
system
could
push
certain
reminders
or
alerts
to
the
user
before
an
unfair
decision
is
made
similarly
in
traditional
recommenda
tion
scenarios
systems
can
proactively
analyze
the
item
list
to
be
recommended
and
estimate
the
risk
of
cognitive
biases
being
triggered
by
an
individual
item
reference
dependence
confir
mation
and
status
quo
bias
or
combination
of
biases
loss
and
risk
aversion
decoy
effect
with
the
information
about
both
the
user
and
built-in
recommendation
algorithms
systems
can
develop
and
adaptively
adjust
the
models
that
predict
users
vulnerability
to
different
types
of
biases
and
provided
personalized
solutions
for
instance
system
could
apply
reinforcement
learning
rl
based
approach
that
can
offer
iteratively
optimized
ranking
and
recommendations
based
on
identified
bias
states
which
could
be
represented
as
varying
estimated
risks
of
biases
at
the
moment
similarly
the
two-sided
fairness
approach
could
also
be
em
ployed
in
measuring
and
mitigating
algorithmic
and
human
biases
in
social
media
platforms
for
instance
systems
should
include
the
affordance
and
components
that
allow
them
to
proactively
identify
the
triggered
cognitive
biases
that
may
increase
user
chance
of
receiving
and
accepting
certain
health
misinformation
predict
ing
and
identifying
biased
behavior
and
judgments
may
need
to
involve
two
models
global
model
that
captures
and
dismantles
the
structure
of
recommendations
triggering
biases
in
information
evaluation
identifying
and
removing
potential
decoy
results
that
could
trigger
the
acceptance
of
low-quality
or
irrelevant
infor
mation
personalized
model
that
covers
individual
character
istics
for
assessing
the
risk
of
human
bias
extracting
in-situ
reference
points
and
expectations
from
past
similar
experiences
chiir
23
march
19
23
2023
austin
tx
usa
liu
and
on-going
interactions
and
estimate
perceived
gains
and
costs
from
interactions
apart
from
system-initiated
intervention
and
intelligent
nudg
ing
addressing
two-sided
biases
particularly
human
biases
could
also
be
achieved
through
enhancing
users
algorithmic
literacy
and
awareness
44
65
for
instance
librarians
as
the
traditional
information
gatekeepers
can
design
and
implement
education
pro
grams
and
tools
for
community
members
who
are
not
familiar
with
search
and
recommendation
algorithms
or
are
vulnerable
to
the
bias
and
discrimination
emerging
from
both
system
and
human
biases
library
and
information
science
lis
professionals
may
provide
proactive
support
for
users
engaging
in
complex
black-box
recommender
systems
and
help
them
understand
the
decisions
of
algorithms
and
the
impacts
of
their
own
real-time
behaviors
and
feedback
on
the
scope
and
focus
of
recommendations
in
addition
incorporating
the
two-sided
fairness
framework
and
practices
into
information
search
education
could
improve
users
awareness
of
their
potential
biases
when
interacting
with
the
results
from
search
and
recommender
systems
and
facilitate
effective
fair
decision
making
4.2
potential
challenges
while
the
two-sided
fairness
framework
can
extend
the
scope
of
promoting
fairness
in
ir
rs
and
beyond
applying
the
approach
also
involves
additional
challenges
that
need
to
be
studied
and
addressed
many
of
the
potential
challenges
are
associated
with
the
preparation
tasks
to
be
completed
for
estimating
human
biases
see
section
3.5
specifically
regarding
t1
the
prediction
results
will
serve
as
the
ground
truth
label
for
measuring
the
fairness
of
equal
probabil
ity
in
achieving
desired
or
optimal
outcomes
this
is
challenging
mainly
for
three
reasons
predicting
desired
outcomes
requires
the
knowledge
about
user
intentions
and
the
nature
of
motivating
task
both
of
which
are
difficult
to
obtain
in
real-time
interactions
according
to
existing
relevant
research
49
in
some
scenarios
where
the
motivating
tasks
are
complex
and
ill-defined
users
them
selves
may
not
have
clear
goal
or
desired
outcome
leading
to
difficulty
for
evaluating
fairness
from
human
side
in
contrast
to
the
pre-defined
protected
attributes
and
fairness
goals
in
algorith
mic
side
users
intentions
and
desired
outcomes
may
change
over
time
which
calls
for
an
adaptive
context-dependent
approach
to
assessing
fairness
apart
from
the
technical
difficulties
predicting
desired
outcomes
and
estimating
the
risks
of
biases
t2
would
require
the
information
about
users
background
and
prior
expe
riences
under
similar
problems
which
may
lead
to
ethical
issues
and
privacy
concerns
to
address
this
challenge
system
designers
have
to
protect
and
restrict
the
usage
of
interaction
history
data
and
human
bias
data
in
model
training
and
fairness
evaluation
and
enable
users
to
be
aware
of
and
have
control
over
the
collec
tion
usage
and
processing
of
the
data
regarding
their
potential
cognitive
and
perceptual
biases
in
addition
certain
restrictions
and
regulations
should
be
implemented
for
better
managing
the
data
reuse
and
replication
experiments
in
human-centered
fairness
evaluation
with
respect
to
t3
learning
accurate
useful
bias-aware
user
models
may
require
data
regarding
user
behaviors
both
within
and
outside
interactive
information
systems
users
offline
purchase
decisions
in
supermarkets
under
the
effect
of
changing
reference
prices
and
decoy
options
users
existing
understanding
and
pref
erences
on
foreign
policy
topic
after
reading
political
science
textbook
in
addition
to
the
challenges
in
data
collection
users
themselves
may
have
difficulty
in
labeling
their
own
biased
behav
iors
in
naturalistic
settings
as
most
of
the
cognitive
biases
operate
unconsciously
in
information
evaluation
and
decision-making
sce
narios
causing
obstacles
for
training
and
testing
bias-aware
user
models
also
since
the
fairness
of
decisions
may
also
be
affected
by
the
factors
outside
search
and
recommendations
users
ex
isting
biases
and
beliefs
available
support
from
domain
experts
time
constraints
changing
ranking
algorithms
recommendation
mechanisms
and
interface
presentations
only
may
not
guarantee
successful
transition
of
information
fairness
to
the
tangible
fairness
in
task
performances
and
decision-making
new
questions
and
directions
under
the
two-sided
fairness
framework
we
propose
series
of
new
questions
and
directions
for
encouraging
discussions
on
related
problems
and
inspiring
future
research
on
user-centered
fairness
evaluation
5.1
understanding
biases
from
different
sources
as
the
basis
for
measuring
and
promoting
fairness
researchers
need
to
investigate
biases
from
varying
sources
and
characterize
the
implicit
interactions
among
them
we
can
start
with
addressing
following
research
questions
rqs
rq1
how
are
different
user
biases
triggered
by
their
previ
ous
experiences
system
outputs
and
individual
character
istics
in
users
interactions
with
search
and
recommender
systems
rq2
how
do
user
biases
interact
with
system
biases
at
dif
ferent
phases
of
interactions
such
as
query
reformulation
browsing
and
examination
of
search
results
and
recommen
dations
clicking
and
evaluation
rq3
to
what
extent
does
the
distribution
of
user
biases
vary
across
different
tasks
and
systems
addressing
the
first
three
rqs
would
require
researchers
to
con
duct
extensive
user
studies
and
carefully
examine
the
connections
of
individual
biases
to
users
tasks
and
systems
particularly
it
is
critical
to
differentiate
individual
biases
from
in-situ
natural
pref
erences
and
enhance
users
awarenss
of
potential
risks
without
intervening
their
tasks
this
could
be
challenging
especially
when
different
types
of
biases
are
correlated
with
each
other
generat
ing
mixed
effect
on
judgments
of
information
items
and
post
interaction
decision-making
knowledge
learned
under
these
rqs
will
offer
an
empirical
basis
for
estimating
the
risks
of
biases
in
real-time
interactions
5.2
evaluating
two-sided
fairness
on
human-sided
fairness
evaluation
our
work
defines
the
fairness
goal
without
specifying
individual
fairness
measures
determining
the
specific
measures
would
require
answers
to
at
least
two
rqs
toward
two-sided
fairness
framework
in
search
and
recommendation
chiir
23
march
19
23
2023
austin
tx
usa
rq4
how
do
different
user
biases
lead
to
biased
judgments
and
unfair
decisions
rq5
how
can
we
evaluate
system
fairness
in
addressing
the
negative
impact
of
human
biases
under
different
desired
outcomes
and
intentions
of
varying
types
differing
from
algorithmic
debiasing
where
the
goal
can
be
quan
tified
beforehand
once
the
protected
attributes
are
defined
different
human
biases
may
be
coupled
with
varying
types
of
behaviors
and
desired
outcomes
which
require
customized
fairness
measures
and
constraints
on
system
training
and
evaluation
therefore
rq4
and
rq5
highlight
the
connections
of
human
fairness
measures
to
user
behaviors
decisions
and
goals
of
interactions
aiming
to
clarify
the
role
of
human
biases
in
interaction
processes
findings
under
the
two
rqs
may
result
in
bias-aware
user
model
that
characterizes
user
search
behavior
and
decision-making
patterns
under
varying
biases
and
separate
fairness
metrics
for
evaluation
under
varying
intentions
and
desired
outcomes
5.3
enhancing
two-sided
fairness
moving
towards
enhancing
two-sided
fairness
researchers
need
to
examine
the
usefulness
and
appropriateness
of
the
available
tools
at
hand
aligned
with
the
discussions
presented
in
section
4.1
we
propose
following
two
rqs
as
starting
point
for
this
direction
of
research
rq6
how
can
we
enhance
two-sided
fairness
and
address
varying
types
of
biases
using
re-ranking
intervention
and
intelligent
nudging
techniques
rq7
how
can
we
we
enhance
two-sided
fairness
and
ad
dress
varying
types
of
biases
through
improving
users
algo
rithmic
literacy
and
awareness
of
human
and
system
biases
differing
from
previously
asked
causal-inference
questions
rq1
rq4
rq6
and
rq7
are
closely
related
to
application-oriented
practical
questions
and
may
yield
highly
contextual-dependent
answers
in
field
studies
for
instance
the
effectiveness
of
specific
interventions
nudging
techniques
and
algorithmic
literacy
ed
ucation
programs
may
vary
significantly
across
different
types
of
systems
and
populations
from
varying
background
therefore
studying
these
two
rqs
may
also
involve
fairness
issue
the
unique
traits
needs
and
challenges
of
different
community
members
and
groups
should
be
fully
considered
and
equally
represented
when
testing
intervention
tools
and
education
programs
also
in
practical
application
researchers
and
system
designers
should
balance
the
autonomy
of
users
and
the
role
of
recommendations
and
evaluate
broad
range
of
approaches
to
enhancing
two-sided
fairness
with
users
from
in-situ
reminders
of
possible
biased
judgments
and
suggestions
of
search
tactics
to
proactive
re-ranking
and
recom
mendations
based
on
estimated
risks
5.4
ethical
challenges
and
data
reusability
similar
to
other
user-centered
evaluation
studies
research
on
two
sided
fairness
will
involve
the
sensitive
expensive
and
time-consuming
process
of
collecting
labels
and
signals
regarding
user
features
in
this
case
human-side
biases
and
fairness
as
result
researchers
need
to
face
set
of
ethical
and
practical
challenges
the
exploration
on
this
problem
space
may
start
with
two
rqs
rq8
how
can
we
measure
and
promote
two-sided
fairness
and
also
protect
users
private
information
regarding
indi
vidual
biases
and
previous
experiences
rq9
how
can
we
effectively
reuse
the
data
regarding
two
sided
biases
and
fairness
and
amortizing
the
true
cost
of
user
experiments
rq8
could
be
address
by
adding
additional
privacy
protection
constraints
on
model
training
and
system
outputs
and
design
pun
ishments
significantly
reducing
the
evaluation
score
when
the
risk
of
bias
data
leakage
is
captured
regarding
rq9
researchers
need
to
develop
standard
framework
for
guiding
data
curation
and
sharing
and
assessing
the
reusability
of
behavior
and
annotation
datasets
collected
from
individual
user
studies
26
50
effective
data
reuse
would
allow
researchers
to
develop
and
meta-evaluate
the
effectiveness
of
two-sided
fairness
measures
across
varying
dtasets
systems
and
populations
5.5
from
user
to
people
interacting
with
information
apart
from
the
specific
rqs
and
new
directions
presented
above
our
long-term
vision
is
to
studying
users
as
people
interacting
with
information
rather
than
as
agents
operating
in
systems
discon
nected
from
specific
tasks
and
socio-technical
contexts
the
main
idea
behind
this
vision
is
that
we
cannot
expect
people
to
leave
their
specific
contexts
for
interacting
with
search
and
recommender
systems
and
act
as
users
in
the
way
we
assumed
instead
peo
ple
interactions
with
information
systems
should
be
characterized
and
evaluated
in
contexts
aligned
with
this
idea
our
two-sided
fairness
framework
goes
beyond
traditional
system
fairness
measures
that
sets
clear
bound
aries
between
algorithms
and
users
and
investigate
the
concept
of
human-centered
fairness
that
reconnect
users
and
their
biases
with
factors
from
their
contexts
and
problematic
situations
in
this
sense
studying
and
implementing
the
two-sided
fairness
evaluation
will
not
only
expand
the
scope
of
research
on
fairness
in
ir
rs
and
human-ai
interaction
in
general
but
also
contribute
to
the
general
efforts
on
bringing
users
interacting
with
information
and
systems
back
to
their
contexts
in
human-centered
computing
research
conclusion
as
artificial
intelligence
ai
assisted
search
and
recommender
sys
tems
have
become
ubiquitous
in
workplaces
and
everyday
lives
understanding
and
accounting
for
fairness
has
gained
increasing
attention
in
the
design
and
evaluation
of
such
systems
while
there
is
growing
body
of
computing
research
on
measuring
system
fairness
and
biases
associated
with
data
and
algorithms
the
im
pact
of
human
biases
that
go
beyond
traditional
machine
learning
ml
pipelines
still
remain
understudied
to
address
this
challenge
our
study
extends
the
concept
of
fairness
to
cover
the
effects
and
measurements
of
both
human
bias
and
system
bias
embedded
in
data
and
algorithms
as
well
as
the
possible
interactions
between
them
also
we
propose
new
two-sided
evaluation
goals
and
meth
ods
that
can
examine
the
performance
of
search
and
recommender
systems
in
addressing
and
proactively
reducing
the
impacts
of
both
human
and
system
biases
in
addition
our
paper
synthesizes
rele
vant
re-ranking
intervention
and
nudging
techniques
that
could
chiir
23
march
19
23
2023
austin
tx
usa
liu
potentially
mitigate
the
risks
of
one
or
both
types
of
biases
and
identifies
technical
and
ethical
challenges
as
well
as
new
directions
for
future
fairness-oriented
evaluation
research
in
ir
and
rs
we
hope
that
the
new
insights
perspectives
and
questions
we
presented
on
the
two-sided
fairness
problem
can
incite
fruitful
discussions
in
chiir
community
and
also
encourage
information
researchers
and
scientists
to
further
push
the
boundaries
of
fairness
evaluation
research
from
human-centered
perspective
acknowledgments
this
work
is
supported
by
the
national
science
foundation
nsf
award
iis-2106152
references
deena
abul-fottouh
melodie
yunju
song
and
anatoliy
gruzd
2020
examining
algorithmic
biases
in
youtube
recommendations
of
vaccine
videos
international
journal
of
medical
informatics
140
2020
104175
aman
agarwal
ivan
zaitsev
xuanhui
wang
cheng
li
marc
najork
and
thorsten
joachims
2019
estimating
position
bias
without
intrusive
interven
tions
in
proceedings
of
the
twelfth
acm
international
conference
on
web
search
and
data
mining
474
482
qingyao
ai
tao
yang
huazheng
wang
and
jiaxin
mao
2021
unbiased
learning
to
rank
online
or
offline
acm
transactions
on
information
systems
tois
39
2021
29
elliot
aronson
1969
the
theory
of
cognitive
dissonance
current
perspective
in
advances
in
experimental
social
psychology
vol
elsevier
34
alejandro
barredo
arrieta
natalia
díaz-rodríguez
javier
del
ser
adrien
ben
netot
siham
tabik
alberto
barbado
salvador
garcía
sergio
gil-lópez
daniel
molina
richard
benjamins
et
al
2020
explainable
artificial
intelligence
xai
concepts
taxonomies
opportunities
and
challenges
toward
responsible
ai
in
formation
fusion
58
2020
82
115
leif
azzopardi
2021
cognitive
biases
in
search
review
and
reflection
of
cognitive
biases
in
information
retrieval
in
proceedings
of
the
2021
conference
on
human
information
interaction
and
retrieval
27
37
aakriti
bajracharya
utsab
khakurel
barron
harvey
and
danda
rawat
2023
recent
advances
in
algorithmic
biases
and
fairness
in
financial
services
survey
in
proceedings
of
the
future
technologies
conference
springer
809
822
abigail
bakke
2020
everyday
googling
results
of
an
observational
study
and
applications
for
teaching
algorithmic
literacy
computers
and
composition
57
2020
102577
nicholas
belkin
2016
people
interacting
with
information
in
acm
sigir
forum
vol
49
acm
new
york
ny
usa
13
27
10
rachel
ke
bellamy
kuntal
dey
michael
hind
samuel
hoffman
stephanie
houde
kalapriya
kannan
pranay
lohia
jacquelyn
martino
sameep
mehta
aleksandra
mojsilovic
et
al
2019
ai
fairness
360
an
extensible
toolkit
for
de
tecting
and
mitigating
algorithmic
bias
ibm
journal
of
research
and
development
63
2019
11
richard
berk
hoda
heidari
shahin
jabbari
matthew
joseph
michael
kearns
jamie
morgenstern
seth
neel
and
aaron
roth
2017
convex
framework
for
fair
regression
arxiv
preprint
arxiv
1706.02409
2017
12
rishabh
bhardwaj
navonil
majumder
and
soujanya
poria
2021
investigating
gender
bias
in
bert
cognitive
computation
13
2021
1008
1018
13
asia
biega
krishna
gummadi
and
gerhard
weikum
2018
equity
of
attention
amortizing
individual
fairness
in
rankings
in
the
41st
international
acm
sigir
conference
on
research
development
in
information
retrieval
405
414
14
reuben
binns
2018
fairness
in
machine
learning
lessons
from
political
philoso
phy
in
conference
on
fairness
accountability
and
transparency
pmlr
149
159
15
tyler
brown
and
jiqun
liu
2022
reference
dependence
approach
to
enhancing
early
prediction
of
session
behavior
and
satisfaction
in
proceedings
of
the
22nd
acm
ieee
joint
conference
on
digital
libraries
16
ana
caraban
evangelos
karapanos
daniel
gonçalves
and
pedro
campos
2019
23
ways
to
nudge
review
of
technology-mediated
nudging
in
human-computer
interaction
in
proceedings
of
the
2019
chi
conference
on
human
factors
in
com
puting
systems
15
17
olivier
chapelle
donald
metlzer
ya
zhang
and
pierre
grinspan
2009
expected
reciprocal
rank
for
graded
relevance
in
proceedings
of
the
18th
acm
conference
on
information
and
knowledge
management
621
630
18
jiahao
chen
nathan
kallus
xiaojie
mao
geoffry
svacha
and
madeleine
udell
2019
fairness
under
unawareness
assessing
disparity
when
protected
class
is
unobserved
in
proceedings
of
the
conference
on
fairness
accountability
and
transparency
339
348
19
alexandra
chouldechova
and
aaron
roth
2020
snapshot
of
the
frontiers
of
fairness
in
machine
learning
commun
acm
63
2020
82
89
20
andrew
collins
dominika
tkaczyk
akiko
aizawa
and
joeran
beel
2018
posi
tion
bias
in
recommender
systems
for
digital
libraries
in
international
conference
on
information
springer
335
344
21
brian
alessandro
cathy
neil
and
tom
lagatta
2017
conscientious
classifi
cation
data
scientist
guide
to
discrimination-aware
classification
big
data
2017
120
134
22
jacob
devlin
ming-wei
chang
kenton
lee
and
kristina
toutanova
2018
bert
pre-training
of
deep
bidirectional
transformers
for
language
understanding
arxiv
preprint
arxiv
1810.04805
2018
23
cynthia
dwork
moritz
hardt
toniann
pitassi
omer
reingold
and
richard
zemel
2012
fairness
through
awareness
in
proceedings
of
the
3rd
innovations
in
theoretical
computer
science
conference
214
226
24
cynthia
dwork
and
christina
ilvento
2018
group
fairness
under
composition
in
proceedings
of
the
2018
conference
on
fairness
accountability
and
transparency
fat
2018
25
carsten
eickhoff
2018
cognitive
biases
in
crowdsourcing
in
proceedings
of
the
eleventh
acm
international
conference
on
web
search
and
data
mining
162
170
26
maria
gäde
marijn
koolen
mark
hall
toine
bogers
and
vivien
petras
2021
manifesto
on
resource
re-use
in
interactive
information
retrieval
in
proceedings
of
the
2021
conference
on
human
information
interaction
and
retrieval
141
149
27
ruoyuan
gao
yingqiang
ge
and
chirag
shah
2022
fair
fairness-aware
information
retrieval
evaluation
journal
of
the
association
for
information
science
and
technology
2022
28
yingqiang
ge
shuya
zhao
honglu
zhou
changhua
pei
fei
sun
wenwu
ou
and
yongfeng
zhang
2020
understanding
echo
chambers
in
e-commerce
recom
mender
systems
in
proceedings
of
the
43rd
international
acm
sigir
conference
on
research
and
development
in
information
retrieval
2261
2270
29
itzhak
gilboa
and
david
schmeidler
1995
case-based
decision
theory
the
quarterly
journal
of
economics
110
1995
605
639
30
diogo
gonçalves
pedro
coelho
luis
martinez
and
paulo
monteiro
2021
nudging
consumers
toward
healthier
food
choices
field
study
on
the
effect
of
social
norms
sustainability
13
2021
1660
31
nina
grgic-hlaca
muhammad
bilal
zafar
krishna
gummadi
and
adrian
weller
2016
the
case
for
process
fairness
in
learning
feature
selection
for
fair
decision
making
in
nips
symposium
on
machine
learning
and
the
law
vol
barcelona
spain
32
huifeng
guo
jinkai
yu
qing
liu
ruiming
tang
and
yuzhou
zhang
2019
pal
position-bias
aware
learning
framework
for
ctr
prediction
in
live
recommender
systems
in
proceedings
of
the
13th
acm
conference
on
recommender
systems
452
456
33
calin
gurau
2015
the
effect
of
marketing
promotions
on
customers
cogni
tive
biases
in
the
proceedings
of
the
international
conference
marketing-from
information
to
decision
babes
bolyai
university
48
34
kevin
hamilton
karrie
karahalios
christian
sandvig
and
motahhare
eslami
2014
path
to
understanding
the
effects
of
algorithm
awareness
in
chi
14
extended
abstracts
on
human
factors
in
computing
systems
631
642
35
moritz
hardt
eric
price
and
nati
srebro
2016
equality
of
opportunity
in
supervised
learning
advances
in
neural
information
processing
systems
29
2016
36
chia-fen
hsu
lee
propp
larissa
panetta
shane
martin
stella
dentakos
mag
gie
toplak
and
john
eastwood
2018
mental
effort
and
discomfort
testing
the
peak-end
effect
during
cognitively
demanding
task
plos
one
13
2018
e0191479
37
ben
hutchinson
and
margaret
mitchell
2019
50
years
of
test
un
fairness
lessons
for
machine
learning
in
proceedings
of
the
conference
on
fairness
ac
countability
and
transparency
49
58
38
rolf
jagerman
harrie
oosterhuis
and
maarten
de
rijke
2019
to
model
or
to
intervene
comparison
of
counterfactual
and
online
learning
to
rank
from
user
interactions
in
proceedings
of
the
42nd
international
acm
sigir
conference
on
research
and
development
in
information
retrieval
15
24
39
daniel
kahneman
2003
maps
of
bounded
rationality
psychology
for
behavioral
economics
american
economic
review
93
2003
1449
1475
40
daniel
kahneman
stewart
paul
slovic
paul
slovic
and
amos
tversky
1982
judgment
under
uncertainty
heuristics
and
biases
cambridge
university
press
41
michael
kearns
seth
neel
aaron
roth
and
zhiwei
steven
wu
2018
prevent
ing
fairness
gerrymandering
auditing
and
learning
for
subgroup
fairness
in
international
conference
on
machine
learning
pmlr
2564
2572
42
michael
kearns
seth
neel
aaron
roth
and
zhiwei
steven
wu
2019
an
empiri
cal
study
of
rich
subgroup
fairness
for
machine
learning
in
proceedings
of
the
conference
on
fairness
accountability
and
transparency
100
109
43
miles
kimball
1993
standard
risk
aversion
econometrica
journal
of
the
econometric
society
1993
589
611
44
abby
koenig
2020
the
algorithms
know
me
and
know
them
using
student
journals
to
uncover
algorithmic
literacy
awareness
computers
and
composition
58
2020
102611
45
matt
kusner
joshua
loftus
chris
russell
and
ricardo
silva
2017
counterfac
tual
fairness
advances
in
neural
information
processing
systems
30
2017
toward
two-sided
fairness
framework
in
search
and
recommendation
chiir
23
march
19
23
2023
austin
tx
usa
46
loni
ledderer
marianne
kjær
emilie
kirstine
madsen
jacob
busch
and
an
toinette
fage-butler
2020
nudging
in
public
health
lifestyle
interventions
systematic
literature
review
and
metasynthesis
health
education
behavior
47
2020
749
764
47
kwan
min
lee
younbo
jung
and
clifford
nass
2011
can
user
choice
alter
experimental
findings
in
human-computer
interaction
similarity
attraction
versus
cognitive
dissonance
in
social
responses
to
synthetic
speech
intl
journal
of
human-computer
interaction
27
2011
307
322
48
michelle
seng
ah
lee
and
luciano
floridi
2021
algorithmic
fairness
in
mortgage
lending
from
absolute
conditions
to
relational
trade-offs
minds
and
machines
31
2021
165
191
49
jiqun
liu
2021
deconstructing
search
tasks
in
interactive
information
retrieval
systematic
review
of
task
dimensions
and
predictors
information
processing
management
58
2021
102522
50
jiqun
liu
2022
toward
cranfield-inspired
reusability
assessment
in
interactive
information
retrieval
evaluation
information
processing
management
59
2022
103007
51
jiqun
liu
and
fangyuan
han
2020
investigating
reference
dependence
effects
on
user
search
interaction
and
satisfaction
behavioral
economics
perspective
in
proceedings
of
the
43rd
international
acm
sigir
conference
on
research
and
development
in
information
retrieval
1141
1150
52
jiqun
liu
yiwei
wang
soumik
mandal
and
chirag
shah
2019
exploring
the
immediate
and
short-term
effects
of
peer
advice
and
cognitive
authority
on
web
search
behavior
information
processing
management
56
2019
1010
1025
53
ramona
ludolph
and
peter
schulz
2018
debiasing
health-related
judgments
and
decision
making
systematic
review
medical
decision
making
38
2018
13
54
david
malenka
john
baron
sarah
johansen
jon
wahrenberger
and
jonathan
ross
1993
the
framing
effect
of
relative
and
absolute
risk
journal
of
general
internal
medicine
10
1993
543
548
55
jiaxin
mao
yiqun
liu
noriko
kando
cheng
luo
min
zhang
and
shaoping
ma
2018
investigating
result
usefulness
in
mobile
search
in
european
conference
on
information
retrieval
springer
223
236
56
ninareh
mehrabi
fred
morstatter
nripsuta
saxena
kristina
lerman
and
aram
galstyan
2021
survey
on
bias
and
fairness
in
machine
learning
acm
com
puting
surveys
csur
54
2021
35
57
alessandro
melchiorre
navid
rekabsaz
emilia
parada-cabaleiro
stefan
brandl
oleg
lesota
and
markus
schedl
2021
investigating
gender
fairness
of
recommen
dation
algorithms
in
the
music
domain
information
processing
management
58
2021
102666
58
alistair
moffat
and
justin
zobel
2008
rank-biased
precision
for
measurement
of
retrieval
effectiveness
acm
transactions
on
information
systems
tois
27
2008
27
59
robert
münscher
max
vetter
and
thomas
scheuerle
2016
review
and
taxon
omy
of
choice
architecture
techniques
journal
of
behavioral
decision
making
29
2016
511
524
60
alamir
novin
and
eric
meyers
2017
making
sense
of
conflicting
science
infor
mation
exploring
bias
in
the
search
engine
result
page
in
proceedings
of
the
2017
conference
on
conference
human
information
interaction
and
retrieval
175
184
61
alexandra
olteanu
carlos
castillo
fernando
diaz
and
emre
kiciman
2019
social
data
biases
methodological
pitfalls
and
ethical
boundaries
frontiers
in
big
data
2019
13
62
lihong
peng
yi
guo
and
dehua
hu
2021
information
framing
effect
on
public
intention
to
receive
the
covid-19
vaccination
in
china
vaccines
2021
995
63
manish
raghavan
solon
barocas
jon
kleinberg
and
karen
levy
2020
mitigating
bias
in
algorithmic
hiring
evaluating
claims
and
practices
in
proceedings
of
the
2020
conference
on
fairness
accountability
and
transparency
469
481
64
donald
redelmeier
joel
katz
and
daniel
kahneman
2003
memories
of
colonoscopy
randomized
trial
pain
104
2003
187
194
65
michael
ridley
and
danica
pawlick-potts
2021
algorithmic
literacy
and
the
role
for
libraries
information
technology
and
libraries
40
2021
66
william
samuelson
and
richard
zeckhauser
1988
status
quo
bias
in
decision
making
journal
of
risk
and
uncertainty
1988
59
67
nripsuta
ani
saxena
karen
huang
evan
defilippis
goran
radanovic
david
parkes
and
yang
liu
2019
how
do
fairness
definitions
fare
examining
public
attitudes
towards
algorithmic
definitions
of
fairness
in
proceedings
of
the
2019
aaai
acm
conference
on
ai
ethics
and
society
99
106
68
christoph
schneider
markus
weinmann
and
jan
vom
brocke
2018
digital
nudging
guiding
online
user
choices
through
interface
design
commun
acm
61
2018
67
73
69
falk
scholer
diane
kelly
wan-ching
wu
hanseul
lee
and
william
webber
2013
the
effect
of
threshold
priming
and
need
for
cognition
on
relevance
calibration
and
assessment
in
proceedings
of
the
36th
international
acm
sigir
conference
on
research
and
development
in
information
retrieval
623
632
70
christina
schwind
and
jürgen
buder
2012
reducing
confirmation
bias
and
evaluation
bias
when
are
preference-inconsistent
recommendations
effective
and
when
not
computers
in
human
behavior
28
2012
2280
2290
71
intan
sherlin
ferry
siswadhi
and
elex
sarmigi
2020
analysing
the
decoy
effect
on
online
product
purchasing
preference
an
experimental
study
in
6th
annual
international
conference
on
management
research
aicmar
2019
atlantis
press
125
130
72
herbert
simon
1955
behavioral
model
of
rational
choice
the
quarterly
journal
of
economics
69
1955
99
118
73
cass
sunstein
2016
the
council
of
psychological
advisers
annual
review
of
psychology
67
2016
713
737
74
harini
suresh
and
john
guttag
2019
framework
for
understanding
un
intended
consequences
of
machine
learning
arxiv
preprint
arxiv
1901.10002
2019
75
richard
thaler
2016
behavioral
economics
past
present
and
future
american
economic
review
106
2016
1577
1600
76
georgios
theocharous
jennifer
healey
sridhar
mahadevan
and
michele
saad
2019
personalizing
with
human
cognitive
biases
in
adjunct
publication
of
the
27th
conference
on
user
modeling
adaptation
and
personalization
13
17
77
samuel
trethewey
2019
medical
misinformation
on
social
media
cognitive
bias
pseudo-peer
review
and
the
good
intentions
hypothesis
circulation
140
14
2019
1131
1133
78
jennifer
trueblood
and
jonathan
pettibone
2017
the
phantom
decoy
effect
in
perceptual
decision
making
journal
of
behavioral
decision
making
30
2017
157
167
79
amos
tversky
and
daniel
kahneman
1991
loss
aversion
in
riskless
choice
reference-dependent
model
the
quarterly
journal
of
economics
106
1991
1039
1061
80
elmira
van
den
broek
anastasia
sergeeva
and
marleen
huysman
2019
hiring
algorithms
an
ethnography
of
fairness
in
practice
2019
81
sahil
verma
and
julia
rubin
2018
fairness
definitions
explained
in
2018
ieee
acm
international
workshop
on
software
fairness
fairware
ieee
82
chao
wang
yiqun
liu
min
zhang
shaoping
ma
meihong
zheng
jing
qian
and
kuo
zhang
2013
incorporating
vertical
results
into
search
click
models
in
proceedings
of
the
36th
international
acm
sigir
conference
on
research
and
development
in
information
retrieval
503
512
83
xuanhui
wang
nadav
golbandi
michael
bendersky
donald
metzler
and
marc
najork
2018
position
bias
estimation
for
unbiased
learning
to
rank
in
personal
search
in
proceedings
of
the
eleventh
acm
international
conference
on
web
search
and
data
mining
610
618
84
yifan
wang
weizhi
ma
min
zhang
yiqun
liu
and
shaoping
ma
2022
survey
on
the
fairness
of
recommender
systems
acm
journal
of
the
acm
jacm
2022
85
roberto
weber
and
colin
camerer
2006
behavioral
experiments
in
economics
experimental
economics
2006
187
86
chunhua
wu
and
koray
cosguner
2020
profiting
from
the
decoy
effect
case
study
of
an
online
diamond
retailer
marketing
science
39
2020
974
995
87
yusuke
yamamoto
and
takehiro
yamamoto
2018
query
priming
for
promoting
critical
thinking
in
web
search
in
proceedings
of
the
2018
conference
on
human
information
interaction
retrieval
12
21
88
tao
zhang
and
david
zhang
2007
agent-based
simulation
of
consumer
purchase
decision-making
and
the
decoy
effect
journal
of
business
research
60
2007
912
922