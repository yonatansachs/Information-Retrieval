session
3a
bias
and
fairness
sigir
20
july
25
30
2020
virtual
event
china
controlling
fairness
and
bias
in
dynamic
learning-to-rank
marco
morik
ashudeep
singh
m.morik@tu-berlin.de
ashudeep@cs.cornell.edu
technische
univerit√§t
berlin
cornell
university
berlin
germany
ithaca
ny
jessica
hong
thorsten
joachims
jwh296@cornell.edu
tj@cs.cornell.edu
cornell
university
cornell
university
ithaca
ny
ithaca
ny
abstract
introduction
rankings
are
the
primary
interface
through
which
many
online
we
consider
the
problem
of
dynamic
learning-to-rank
ltr
where
platforms
match
users
to
items
news
products
music
video
the
ranking
function
dynamically
adapts
based
on
the
feedback
in
these
two-sided
markets
not
only
the
users
draw
utility
from
that
users
provide
such
dynamic
ltr
problems
are
ubiquitous
in
the
rankings
but
the
rankings
also
determine
the
utility
ex
online
systems
news-feed
rankings
that
adapt
to
the
number
of
posure
revenue
for
the
item
providers
publishers
sellers
likes
an
article
receives
online
stores
that
adapt
to
the
number
of
artists
studios
it
has
already
been
noted
that
myopically
optimiz
positive
reviews
for
product
or
movie-recommendation
systems
ing
utility
to
the
users
as
done
by
virtually
all
learning-to-rank
that
adapt
to
who
has
watched
movie
in
all
of
these
systems
algorithms
can
be
unfair
to
the
item
providers
we
therefore
learning
and
prediction
are
dynamically
intertwined
where
past
present
learning-to-rank
approach
for
explicitly
enforcing
merit
feedback
influences
future
rankings
in
specific
form
of
online
based
fairness
guarantees
to
groups
of
items
articles
by
the
learning
with
partial-information
feedback
17
same
publisher
tracks
by
the
same
artist
in
particular
we
pro
while
dynamic
ltr
systems
are
in
widespread
use
and
unques
pose
learning
algorithm
that
ensures
notions
of
amortized
group
tionably
useful
there
are
at
least
two
issues
that
require
careful
fairness
while
simultaneously
learning
the
ranking
function
from
design
considerations
first
the
ranking
system
induces
bias
implicit
feedback
data
the
algorithm
takes
the
form
of
controller
through
the
rankings
it
presents
in
particular
items
ranked
highly
that
integrates
unbiased
estimators
for
both
fairness
and
utility
dy
are
more
likely
to
collect
additional
feedback
which
in
turn
can
namically
adapting
both
as
more
data
becomes
available
in
addition
influence
future
rankings
and
promote
misleading
rich-get-richer
to
its
rigorous
theoretical
foundation
and
convergence
guarantees
dynamics
31
32
39
second
the
ranking
system
is
the
arbiter
we
find
empirically
that
the
algorithm
is
highly
practical
and
robust
of
how
much
exposure
each
item
receives
where
exposure
directly
influences
opinion
ideological
orientation
of
presented
news
ccs
concepts
articles
or
economic
gain
revenue
from
product
sales
or
stream
information
systems
learning
to
rank
ing
for
the
provider
of
the
item
this
raises
fairness
considerations
about
how
exposure
should
be
allocated
based
on
the
merit
of
the
keywords
items
14
41
we
will
show
in
the
following
that
naive
dynamic
ltr
methods
that
are
oblivious
to
these
issues
can
lead
to
economic
ranking
learning-to-rank
fairness
bias
selection
bias
exposure
disparity
unfairness
and
polarization
acm
reference
format
in
this
paper
we
present
the
first
dynamic
ltr
algorithm
called
marco
morik
ashudeep
singh
jessica
hong
and
thorsten
joachims
2020
fairco
that
overcomes
rich-get-richer
dynamics
while
enforc
controlling
fairness
and
bias
in
dynamic
learning-to-rank
in
proceedings
ing
configurable
allocation-of-exposure
scheme
unlike
existing
of
the
43rd
international
acm
sigir
conference
on
research
and
development
in
information
retrieval
sigir
20
july
25
30
2020
virtual
event
china
fair
ltr
algorithms
14
41
42
47
fairco
explicitly
addresses
the
acm
new
york
ny
usa
10
pages
https://doi.org/10.1145/3397271.3401100
dynamic
nature
of
the
learning
problem
where
the
system
is
unbi
ased
and
fair
even
though
the
relevance
and
the
merit
of
items
are
equal
contribution
still
being
learned
at
the
core
of
our
approach
lies
merit-based
work
conducted
while
at
cornell
university
exposure-allocation
criterion
that
is
amortized
over
the
learning
permission
to
make
digital
or
hard
copies
of
all
or
part
of
this
work
for
personal
or
process
14
41
we
view
the
enforcement
of
this
merit-based
ex
classroom
use
is
granted
without
fee
provided
that
copies
are
not
made
or
distributed
posure
criterion
as
control
problem
and
derive
p-controller
that
for
profit
or
commercial
advantage
and
that
copies
bear
this
notice
and
the
full
citation
optimizes
both
the
fairness
of
exposure
as
well
as
the
quality
of
on
the
first
page
copyrights
for
components
of
this
work
owned
by
others
than
the
author
must
be
honored
abstracting
with
credit
is
permitted
to
copy
otherwise
or
the
rankings
crucial
component
of
the
controller
is
the
ability
republish
to
post
on
servers
or
to
redistribute
to
lists
requires
prior
specific
permission
to
estimate
merit
relevance
accurately
even
though
the
feed
and
or
fee
request
permissions
from
permissions@acm.org
back
is
only
revealed
incrementally
as
the
system
operates
and
sigir
20
july
25
30
2020
virtual
event
china
2020
copyright
held
by
the
owner
author
publication
rights
licensed
to
acm
the
feedback
is
biased
by
the
rankings
shown
in
the
process
31
acm
isbn
978
4503
8016
20
07
15.00
to
this
effect
fairco
includes
new
unbiased
cardinal
relevance
https://doi.org/10.1145/3397271.3401100
429
session
3a
bias
and
fairness
sigir
20
july
25
30
2020
virtual
event
china
estimator
as
opposed
to
existing
ordinal
methods
32
which
in
reverse
the
remaining
49
of
the
users
left-leaning
like
only
can
be
used
both
as
an
unbiased
merit
estimator
for
fairness
and
as
the
articles
in
left
ranking
articles
solely
by
their
true
average
ranking
criterion
relevance
puts
items
from
right
into
positions
10
and
the
items
in
addition
to
the
theoretical
justification
of
fairco
we
provide
from
left
in
positions
11
20
this
means
the
platform
gives
the
empirical
results
on
both
synthetic
news-feed
data
and
real-world
articles
in
left
vastly
less
exposure
than
those
in
right
we
argue
movie
recommendation
data
we
find
that
fairco
is
effective
at
that
this
can
be
considered
unfair
since
the
two
groups
receive
enforcing
fairness
while
providing
good
ranking
performance
fur
disproportionately
different
outcomes
despite
having
similar
merit
thermore
fairco
is
efficient
robust
and
easy
to
implement
relevance
here
difference
in
average
relevance
leads
to
much
larger
difference
in
exposure
between
the
groups
motivation
we
argue
that
these
two
deficiencies
namely
bias
and
unfair
consider
the
following
illustrative
example
of
dynamic
ltr
prob
ness
are
not
just
undesirable
in
themselves
but
that
they
have
lem
an
online
news-aggregation
platform
wants
to
present
rank
undesirable
consequences
for
example
biased
estimates
lead
to
ing
of
the
top
news
articles
on
its
front
page
through
some
external
poor
ranking
quality
and
unfairness
is
likely
to
alienate
the
left
mechanism
it
identifies
set
20
of
20
articles
at
the
leaning
users
in
our
example
driving
them
off
the
platform
and
beginning
of
each
day
but
it
is
left
with
the
learning
problem
of
encouraging
polarization
how
to
rank
these
20
articles
on
its
front
page
as
users
start
coming
furthermore
note
that
these
two
deficiencies
are
not
specific
to
the
platform
the
platform
uses
the
following
naive
algorithm
to
to
the
news
example
but
that
the
naive
algorithm
leads
to
anal
learn
the
ranking
ogous
problems
in
many
other
domains
for
example
consider
ranking
system
for
job
applicants
where
rich-get-richer
dynamics
and
exposure
allocation
may
perpetuate
and
even
amplify
existing
algorithm
naive
dynamic
ltr
algorithm
unfairness
disparity
between
male
and
female
applicants
sim
initialize
counters
for
each
ilarly
consider
an
online
marketplace
where
products
of
different
foreach
user
do
sellers
groups
are
ranked
here
rich-get-richer
dynamics
and
present
ranking
argsort
random
tiebreak
unfair
exposure
allocation
can
encourage
monopolies
and
drive
increment
for
the
articles
read
by
the
user
some
sellers
out
of
the
market
these
examples
illustrate
the
following
two
desiderata
that
less
naive
dynamic
ltr
algorithm
should
fulfill
executing
this
algorithm
at
the
beginning
of
day
the
platform
unbiasedness
the
algorithm
should
not
be
biased
or
subject
to
starts
by
presenting
the
20
articles
in
random
order
for
the
first
rich-get-richer
dynamics
user
it
may
then
observe
that
the
user
reads
the
article
in
position
fairness
the
algorithm
should
enforce
fair
allocation
of
expo
and
increments
the
counter
for
this
article
for
the
next
sure
based
on
merit
relevance
user
this
article
now
gets
ranked
first
and
the
counters
are
updated
based
on
what
the
second
user
reads
this
cycle
continues
for
each
with
these
two
desiderata
in
mind
this
paper
develops
alterna
subsequent
user
unfortunately
this
naive
algorithm
has
at
least
tives
to
the
naive
algorithm
in
particular
after
introducing
the
two
deficiencies
that
make
it
suboptimal
or
unsuitable
for
many
dynamic
learning-to-rank
setting
in
section
section
formalizes
ranking
applications
an
amortized
notion
of
merit-based
fairness
accounting
for
the
fact
the
first
deficiency
lies
in
the
choice
of
as
an
estimate
of
that
merit
itself
is
unknown
at
the
beginning
of
the
learning
process
average
relevance
for
each
article
namely
the
fraction
of
users
and
is
only
learned
throughout
section
then
addresses
the
bias
that
want
to
read
the
article
unfortunately
even
with
infinite
problem
providing
estimators
that
eliminate
the
presentation
bias
amounts
of
user
feedback
the
counters
are
not
consistent
for
both
global
and
personalized
ranking
policies
finally
section
estimators
of
average
relevance
31
32
39
in
particular
items
proposes
control-based
algorithm
that
is
designed
to
optimize
that
happened
to
get
more
reads
in
early
iterations
get
ranked
ranking
quality
while
dynamically
enforcing
fairness
highly
where
more
users
find
them
and
thus
have
the
opportunity
to
provide
more
positive
feedback
for
them
this
perpetuates
related
work
rich-get-richer
dynamic
where
the
feedback
count
recorded
ranking
algorithms
are
widely
recognized
for
their
potential
for
for
each
article
does
not
reflect
how
many
users
actually
wanted
to
societal
impact
as
they
form
the
core
of
many
online
systems
read
the
article
including
search
engines
recommendation
systems
news
feeds
the
second
deficiency
of
the
naive
algorithm
lies
in
the
ranking
and
online
voting
controlling
rich-get-richer
phenomena
in
rec
policy
itself
creating
source
of
unfairness
even
if
the
true
average
ommendations
and
rankings
has
been
studied
from
the
perspective
relevance
of
each
article
was
accurately
known
14
41
consider
of
both
optimizing
utility
through
exploration
as
well
as
ensur
the
following
omniscient
variant
of
the
naive
algorithm
that
ranks
ing
fairness
of
such
systems
40
48
there
are
several
adverse
the
articles
by
their
true
average
relevance
the
true
fraction
consequences
of
naive
ranking
systems
19
such
as
political
polar
of
users
who
want
to
read
each
article
how
can
this
ranking
be
ization
11
misinformation
45
unfair
allocation
of
exposure
42
unfair
let
us
assume
that
we
have
two
groups
of
articles
right
and
biased
judgment
through
phenomena
such
as
the
matthew
and
left
with
10
items
each
articles
from
politically
right
effect
23
viewing
such
ranking
problems
as
two-sided
markets
and
left-leaning
sources
51
of
the
users
right-leaning
want
to
of
users
and
items
that
each
derive
utility
from
the
ranking
system
read
the
articles
in
group
right
but
not
the
articles
in
group
left
brings
novel
perspective
to
tackling
such
problems
41
in
this
430
session
3a
bias
and
fairness
sigir
20
july
25
30
2020
virtual
event
china
work
we
take
inspiration
from
these
works
to
develop
methods
for
the
information
in
if
we
want
to
learn
single
global
ranking
mitigating
bias
and
unfairness
in
dynamic
setting
like
in
the
introductory
news
example
machine
learning
methods
underlie
most
ranking
algorithms
after
presenting
the
ranking
œÉt
the
system
receives
feedback
there
has
been
growing
concern
around
the
question
of
how
vector
ct
from
the
user
with
non-negative
value
ct
for
every
machine
learning
algorithms
can
be
unfair
especially
given
their
in
the
simplest
case
it
is
for
click
and
for
no
click
and
we
numerous
real-world
applications
10
there
have
been
several
will
use
the
word
click
as
placeholder
throughout
this
paper
for
definitions
proposed
for
fairness
in
the
binary
classification
setting
simplicity
but
the
feedback
may
take
many
other
forms
and
does
as
well
as
recently
in
the
domains
of
rankings
in
recommenda
not
have
to
be
binary
for
example
in
video
streaming
service
tions
and
information
retrieval
13
14
16
41
the
definitions
of
the
feedback
may
be
the
percentage
the
user
watched
of
each
video
fairness
in
ranking
span
from
ones
purely
based
on
the
composition
after
the
feedback
ct
was
received
the
dynamic
ltr
algorithm
of
the
top-k
16
to
relevance-based
definitions
such
as
fairness
of
now
updates
the
ranking
policy
and
produces
the
policy
œÄt
exposure
41
and
amortized
attention
equity
14
we
will
discuss
that
is
used
in
the
next
time
step
these
definitions
in
greater
detail
in
section
our
work
also
re
lates
to
the
recent
interest
in
studying
the
impact
of
fairness
when
œÄt
œÉ1
c1
œÉt
ct
learning
algorithms
are
applied
in
dynamic
settings
21
35
43
an
instance
of
such
dynamic
ltr
algorithm
is
the
naive
algorithm
in
information
retrieval
there
has
been
long-standing
interest
already
outlined
in
section
it
merely
computes
ct
to
produce
in
learning
to
rank
from
biased
click
data
as
already
argued
above
new
ranking
policy
for
here
global
ranking
independent
the
bias
in
logged
click
data
occurs
because
the
feedback
is
incom
of
plete
and
biased
by
the
presentation
numerous
approaches
based
on
preferences
25
30
click
models
18
and
random
ized
interventions
36
exist
most
recently
new
approach
4.1
partial
and
biased
feedback
for
de-biasing
feedback
data
using
techniques
from
causal
inference
key
challenge
of
dynamic
ltr
lies
in
the
fact
that
the
feedback
and
missing
data
analysis
was
proposed
to
provably
eliminate
se
ct
provides
meaningful
feedback
only
for
the
items
that
the
user
lection
biases
32
we
follow
this
approach
in
this
paper
extend
examined
following
large
body
of
work
on
click
models
18
we
it
to
the
dynamic
ranking
setting
and
propose
new
unbiased
model
this
as
censoring
process
specifically
for
binary
vector
regression
objective
in
section
et
indicating
which
items
were
examined
by
the
user
we
model
learning
in
our
dynamic
ranking
setting
is
related
to
the
con
the
relationship
between
ct
and
rt
as
follows
ventional
learning-to-rank
algorithms
such
as
lambdarank
lamb
if
et
damart
ranknet
softrank
etc
15
44
however
to
implement
ct
fairness
constraints
based
on
merit
we
need
to
explicitly
estimate
otherwise
relevance
to
the
user
as
measure
of
merit
while
the
scores
esti
coming
back
to
the
running
example
of
news
ranking
rt
contains
mated
by
these
methods
don
necessarily
have
meaning
our
the
full
information
about
which
articles
the
user
is
interested
setting
is
also
closely
related
to
online
learning
to
rank
for
top-k
in
reading
while
ct
reveals
this
information
only
for
the
articles
ranking
where
feedback
is
observed
only
on
the
top-k
items
and
examined
by
the
user
et
analogously
in
the
job
hence
exploration
interventions
are
necessary
to
ensure
conver
placement
application
rt
indicates
for
all
candidates
whether
gence
26
34
37
49
these
algorithms
are
designed
with
respect
they
are
qualified
to
receive
an
interview
call
but
ct
reveals
this
to
click-model
assumption
49
or
learning
in
the
presence
of
information
only
for
those
candidates
examined
by
the
employer
document
features
34
key
difference
in
our
method
is
that
second
challenge
lies
in
the
fact
that
the
examination
vector
we
do
not
consider
exploration
through
explicit
interventions
but
et
cannot
be
observed
this
implies
that
feedback
value
of
ct
merely
exploit
user-driven
exploration
however
explicit
explo
is
ambiguous
it
may
either
indicate
lack
of
examination
ration
could
also
be
incorporated
into
our
algorithms
to
improve
et
or
negative
feedback
rt
this
would
not
the
convergence
rate
of
our
methods
be
problematic
if
et
was
uniformly
random
but
which
items
get
examined
is
strongly
biased
by
the
ranking
œÉt
presented
to
the
dynamic
learning-to-rank
user
in
the
current
iteration
specifically
users
are
more
likely
to
we
begin
by
formally
defining
the
dynamic
ltr
problem
given
is
look
at
an
item
high
in
the
ranking
than
at
one
that
is
lower
down
set
of
items
that
needs
to
be
ranked
in
response
to
incoming
31
we
model
this
position
bias
as
probability
distribution
on
requests
at
each
time
step
request
the
examination
vector
rt
et
œÉt
rt
arrives
at
the
ranking
system
each
request
consists
of
feature
most
click
models
can
be
brought
into
this
form
18
for
the
sim
vector
describing
the
user
information
need
query
user
plicity
of
this
paper
we
merely
use
the
position-based
model
pbm
profile
and
the
user
vector
of
true
relevance
ratings
rt
for
all
20
it
assumes
that
the
marginal
probability
of
examination
pt
items
in
the
collection
only
the
feature
vector
is
visible
to
for
each
item
depends
only
on
the
rank
rank
of
in
the
the
system
while
the
true
relevance
ratings
rt
are
hidden
based
on
presented
ranking
despite
its
simplicity
it
was
found
that
the
the
information
in
ranking
policy
œÄt
produces
ranking
pbm
can
capture
the
main
effect
of
position
bias
accurately
enough
œÉt
that
is
presented
to
the
user
note
that
the
policy
may
ignore
to
be
reliable
in
practice
32
46
431
session
3a
bias
and
fairness
sigir
20
july
25
30
2020
virtual
event
china
4.2
evaluating
ranking
performance
candidate
we
discuss
in
section
how
to
estimate
pt
taking
we
measure
the
quality
of
ranking
policy
by
its
utility
to
the
group-based
approach
to
fairness
we
aggregate
exposure
by
groups
users
virtually
all
ranking
metrics
used
in
information
retrieval
de
gm
fine
the
utility
of
ranking
as
function
of
the
relevances
of
the
individual
items
in
our
case
these
item-based
relevances
exp
pt
represent
which
articles
the
user
likes
to
read
or
which
candidates
are
qualified
for
an
interview
commonly
used
utility
measure
is
these
groups
can
be
legally
protected
groups
gender
race
the
dcg
29
reflect
some
other
structure
items
sold
by
particular
seller
dcg
or
simply
put
each
item
in
its
own
group
individual
fairness
log2
rank
in
order
to
formulate
fairness
criteria
that
relate
exposure
to
merit
we
define
the
merit
of
an
item
as
its
expected
average
rele
or
the
ndcg
when
normalized
by
the
dcg
of
the
optimal
ranking
vance
and
again
aggregate
over
groups
over
distribution
of
requests
ranking
policy
is
evaluated
by
its
expected
utility
merit
in
section
we
will
discuss
how
to
get
unbiased
estimates
of
4.3
optimizing
ranking
performance
merit
using
the
biased
feedback
data
ct
with
these
definitions
in
hand
we
can
address
the
types
of
dis
the
user-facing
goal
of
dynamic
ltr
is
to
converge
to
the
policy
parities
identified
in
section
specifically
we
extend
the
disparity
argmaxœÄ
that
maximizes
utility
even
if
we
solve
the
of
treatment
criterion
of
41
to
the
dynamic
ranking
problem
problem
of
estimating
despite
our
lack
of
knowledge
of
this
using
an
amortized
notion
of
fairness
as
in
14
in
particular
for
maximization
problem
could
be
computationally
challenging
since
any
two
groups
and
the
disparity
the
space
of
ranking
policies
is
exponential
even
when
learning
just
single
global
ranking
fortunately
it
is
easy
to
show
38
that
√≠œÑ
exp
√≠œÑ
exp
sorting-based
policies
dœÑe
10
merit
merit
argsort
measures
in
how
far
amortized
exposure
over
time
steps
was
where
fulfilled
this
exposure-based
fairness
disparity
expresses
in
how
far
averaged
over
all
time
steps
each
group
of
items
got
exposure
proportional
to
its
relevance
the
further
the
disparity
is
from
zero
the
greater
is
the
violation
of
fairness
note
that
other
are
optimal
for
virtually
all
commonly
used
in
ir
dcg
allocation
strategies
beyond
proportionality
could
be
implemented
so
the
problem
lies
in
estimating
the
expected
relevance
as
well
by
using
alternate
definitions
of
disparity
41
of
each
item
conditioned
on
when
learning
single
global
exposure
can
also
be
allocated
based
on
other
fairness
criteria
ranking
this
further
simplifies
to
estimating
the
expected
average
for
example
disparity
of
impact
that
specific
exposure
allocation
relevance
for
each
item
the
global
ranking
implies
41
if
we
consider
the
feedback
ct
clicks
purchases
can
then
be
derived
via
votes
as
measure
of
impact
argsort
imp
ct
11
in
section
we
will
use
techniques
from
causal
inference
and
missing-data
analysis
to
design
unbiased
and
consistent
estimators
then
keeping
the
following
disparity
close
to
zero
controls
how
for
and
that
only
require
access
to
the
observed
feedback
exposure
is
allocated
to
make
impact
proportional
to
relevance
ct
√≠œÑ
imp
√≠œÑ
imp
fairness
in
dynamic
ltr
dœÑ
12
merit
merit
while
sorting
by
or
for
global
rankings
may
provide
optimal
utility
to
the
user
the
introductory
example
has
already
we
refer
to
this
as
the
impact-based
fairness
disparity
in
sec
illustrated
that
this
ranking
can
be
unfair
there
is
growing
body
tion
we
will
derive
controller
that
drives
such
exposure
and
of
literature
to
address
this
unfairness
in
ranking
and
we
now
impact
disparities
to
zero
extend
merit-based
fairness
14
41
to
the
dynamic
ltr
setting
the
key
scarce
resource
that
ranking
policy
allocates
among
unbiased
estimators
the
items
is
exposure
based
on
the
model
introduced
in
the
pre
to
be
able
to
implement
the
ranking
policies
in
equation
and
vious
section
we
define
the
exposure
of
an
item
as
the
mar
the
fairness
disparities
in
equations
10
and
12
we
need
accu
ginal
probability
of
examination
pt
et
œÉt
rt
rate
estimates
of
the
position
bias
pt
the
expected
conditional
it
is
the
probability
that
the
user
will
see
and
thus
have
the
op
relevances
and
the
expected
average
relevances
we
portunity
to
read
that
article
buy
that
product
or
interview
that
consider
these
estimation
problems
in
the
following
432
session
3a
bias
and
fairness
sigir
20
july
25
30
2020
virtual
event
china
6.1
estimating
the
position
bias
that
uses
the
unobserved
true
relevances
r1
rœÑ
learning
model
for
pt
is
not
part
of
our
dynamic
ltr
problem
as
the
position-bias
model
is
merely
an
input
to
our
dynamic
ltr
ee
algorithms
fortunately
several
techniques
for
estimating
position
bias
models
already
exist
in
the
literature
22
32
46
and
we
√µ√µ
ct
are
agnostic
to
which
of
these
is
used
in
the
simplest
case
the
ct
2r
et
œÉt
examination
probabilities
pt
only
depend
on
the
rank
of
the
pt
et
item
in
analogous
to
position-based
click
model
20
with
fixed
probability
for
each
rank
it
was
shown
in
32
46
how
rt
rt
2r
pt
these
position-based
probabilities
can
be
estimated
from
explicit
pt
and
implicit
swap
interventions
furthermore
it
was
shown
in
22
how
the
contextual
features
about
the
users
and
query
can
be
rt
rt
incorporated
in
neural-network
based
propensity
model
allow
ing
it
to
capture
that
certain
users
may
explore
further
down
the
ranking
for
some
queries
once
any
of
these
propensity
models
are
rt
learned
they
can
be
applied
to
predict
pt
for
any
new
query
and
ranking
œÉt
6.2
estimating
conditional
relevances
the
key
challenge
in
estimating
from
equation
lies
in
line
formulates
the
expectation
in
terms
of
the
marginal
exposure
our
inability
to
directly
observe
the
true
relevances
rt
instead
probabilities
et
œÉt
which
decomposes
the
expectation
the
only
data
we
have
is
the
partial
and
biased
feedback
ct
to
as
the
objective
is
additive
in
note
that
et
œÉt
is
overcome
this
problem
we
take
an
approach
inspired
by
32
and
therefore
equal
to
pt
under
our
exposure
model
line
sub
extend
it
to
the
dynamic
ranking
setting
the
key
idea
is
to
correct
stitutes
ct
et
rt
and
simplifies
the
expression
since
for
the
selection
bias
with
which
relevance
labels
are
observed
in
et
rt
whenever
the
user
is
not
exposed
to
an
item
note
ct
using
techniques
from
survey
sampling
and
causal
inference
that
the
propensities
pt
for
the
exposed
items
now
cancel
as
27
28
however
unlike
the
ordinal
estimators
proposed
in
32
long
as
they
are
bounded
away
from
zero
meaning
that
all
items
we
need
cardinal
relevance
estimates
since
our
fairness
disparities
have
some
probability
of
being
found
by
the
user
in
case
users
are
cardinal
in
nature
we
therefore
propose
the
following
cardinal
do
not
naturally
explore
low
enough
in
the
ranking
active
inter
relevance
estimator
ventions
can
be
used
to
stochastically
promote
items
in
order
to
the
key
idea
behind
this
estimator
lies
in
training
objective
that
ensure
non-zero
examination
propensities
26
note
that
un
only
uses
ct
but
that
in
expectation
is
equivalent
to
least-squares
biasedness
holds
for
any
sequence
of
r1
œÉ1
xt
rt
œÉt
no
objective
that
has
access
to
rt
to
start
the
derivation
let
consider
matter
how
complex
the
dependencies
between
the
rankings
œÉt
how
we
would
estimate
if
we
had
access
to
the
relevance
are
labels
r1
rœÑ
of
the
previous
time
steps
straightforward
beyond
this
proof
of
unbiasedness
it
is
possible
to
use
stan
solution
would
be
to
solve
the
following
least-squares
objective
for
dard
concentration
inequalities
to
show
that
converges
to
given
regression
model
neural
network
where
as
the
size
of
the
training
sequence
increases
thus
un
are
the
parameters
of
the
model
der
standard
conditions
on
the
capacity
for
uniform
convergence
it
is
possible
to
show
convergence
of
the
minimizer
of
to
the
least-squares
regressor
as
the
size
of
the
training
sequence
rt
13
increases
we
will
use
this
regression
objective
to
learn
neural
network
rankers
in
section
8.2
the
minimum
of
this
objective
is
the
least-squares
regression
estimator
of
since
the
r1
rœÑ
are
not
available
we
de
6.3
estimating
average
relevances
fine
an
asymptotically
equivalent
objective
that
merely
uses
the
the
conditional
relevances
are
used
in
the
ranking
policies
biased
feedback
c1
cœÑ
the
new
objective
corrects
for
the
po
from
equation
but
when
defining
merit
in
equation
for
the
sition
bias
using
inverse
propensity
score
ips
weighting
27
28
fairness
disparities
the
average
relevance
is
needed
further
where
the
position
bias
p1
pœÑ
takes
the
role
of
the
missingness
more
serves
as
the
ranking
criterion
for
global
rankings
in
model
equation
while
we
could
marginalize
over
to
derive
we
argue
that
the
following
is
more
direct
way
to
get
an
ct
ct
2r
14
unbiased
estimate
pt
we
denote
the
regression
estimator
defined
by
the
minimum
of
this
objective
as
reg
the
regression
objective
in
14
is
unbiased
ct
ips
15
meaning
that
its
expectation
is
equal
to
the
regression
objective
pt
433
session
3a
bias
and
fairness
sigir
20
july
25
30
2020
virtual
event
china
the
following
shows
that
this
estimator
is
unbiased
as
long
as
the
we
are
now
in
position
to
state
the
fairco
ranking
policy
as
propensities
are
bounded
away
from
zero
fairco
œÉœÑ
argsort
errœÑ
17
1√µ
et
rt
ee
ips
et
œÉt
pt
when
the
exposure-based
disparity
œÑe
is
used
in
the
error
et
term
we
refer
to
this
policy
as
fairco
exp
if
the
impact-based
rt
disparity
œÑi
is
used
we
refer
to
it
as
fairco
imp
pt
like
the
policies
in
section
4.3
fairco
is
sort-based
policy
however
the
sorting
criterion
is
combination
of
relevance
1√µ
rt
and
an
error
term
representing
the
fairness
violation
the
idea
behind
fairco
is
that
the
error
term
pushes
the
items
from
the
underexposed
groups
upwards
in
the
ranking
the
parameter
can
be
chosen
to
be
any
positive
constant
while
any
choice
of
in
the
following
experiments
we
will
use
this
estimator
whenever
leads
to
asymptotic
convergence
as
shown
by
the
theorem
below
direct
estimate
of
is
needed
for
the
fairness
disparities
or
as
for
exposure
fairness
suitable
choice
of
can
have
influence
global
ranking
criterion
on
the
finite-sample
behavior
of
fairco
higher
can
lead
to
an
oscillating
behavior
while
smaller
makes
the
convergence
dynamically
controlling
fairness
smoother
but
slower
we
explore
the
role
of
in
the
experiments
given
the
formalization
of
the
dynamic
ltr
problem
our
defini
but
find
that
keeping
it
fixed
at
0.01
works
well
across
all
of
tion
of
fairness
and
our
derivation
of
estimators
for
all
relevant
our
experiments
another
key
quality
of
fairco
is
that
it
is
agnostic
parameters
we
are
now
in
the
position
to
tackle
the
problem
of
to
the
choice
of
error
metric
and
we
conjecture
that
it
can
easily
ranking
while
enforcing
the
fairness
conditions
we
view
this
as
be
adapted
to
other
types
of
fairness
disparities
furthermore
it
is
control
problem
since
we
need
to
be
robust
to
the
uncertainty
easy
to
implement
and
it
is
very
efficient
making
it
well
suited
for
practical
applications
in
the
estimates
and
at
the
beginning
of
the
learning
to
illustrate
the
theoretical
properties
of
fairco
we
now
ana
process
specifically
we
propose
controller
that
is
able
to
make
lyze
its
convergence
for
the
case
of
exposure-based
fairness
to
up
for
the
initial
uncertainty
as
these
estimates
converge
during
the
learning
process
disentangle
the
convergence
of
the
estimator
for
merit
from
the
following
our
pairwise
definitions
of
amortized
fairness
from
convergence
of
fairco
consider
time
point
œÑ0
where
merit
is
section
we
quantify
by
how
much
fairness
between
all
classes
is
already
close
to
merit
for
all
we
can
thus
focus
on
the
violated
using
the
following
overall
disparity
metric
question
whether
fairco
can
drive
to
zero
starting
from
any
unfairness
that
may
have
persisted
at
time
œÑ0
to
make
this
prob
lem
well-posed
we
need
to
assume
that
exposure
is
not
available
dœÑ
dœÑ
16
in
overabundance
otherwise
it
may
be
unavoidable
to
give
some
groups
more
exposure
than
they
deserve
even
if
they
are
put
at
this
metric
can
be
instantiated
with
the
disparity
dœÑe
from
the
bottom
of
the
ranking
sufficient
condition
for
excluding
this
equation
10
for
exposure-based
fairness
or
dœÑi
from
equa
case
is
to
only
consider
problems
for
which
the
following
is
true
tion
12
for
impact-based
fairness
since
optimal
fairness
is
achieved
for
all
pairs
of
groups
if
is
ranked
entirely
above
at
any
time
point
then
for
we
seek
to
minimize
to
this
end
we
now
derive
method
we
call
fairco
which
exp
exp
18
takes
the
form
of
proportional
controller
p-controller
merit
merit
12
p-controller
is
widely
used
control-loop
mechanism
that
intuitively
the
condition
states
that
ranking
ahead
of
reduces
applies
feedback
through
correction
term
that
is
proportional
to
the
disparity
if
has
been
underexposed
in
the
past
we
can
now
the
error
in
our
application
the
error
corresponds
to
the
violation
state
the
following
theorem
of
our
amortized
fairness
disparity
from
equations
10
and
12
specifically
for
any
set
of
disjoint
groups
gm
the
theorem
7.1
for
any
set
of
disjoint
groups
gm
error
term
of
the
controller
for
any
item
is
defined
as
with
any
fixed
target
merits
merit
that
fulfill
18
any
relevance
model
any
exposure
model
pt
with
errœÑ
max
pt
pmax
and
any
value
running
fairco
exp
from
gi
time
œÑ0
will
always
ensure
that
the
overall
disparity
with
respect
the
error
term
errœÑ
is
zero
for
the
group
that
already
has
the
to
the
target
merits
converges
to
zero
at
rate
of
œÑ1
no
matter
how
unfair
the
exposures
œÑ10
œÑt
exp
up
to
œÑ0
have
been
maximum
exposure
impact
its
merit
for
items
in
the
other
groups
the
error
term
grows
with
increasing
disparity
note
that
the
disparity
in
the
error
term
uses
the
es
the
proof
of
the
theorem
is
included
in
the
full
version
of
timated
merit
from
equation
15
which
converges
to
merit
the
paper
on
arxiv
note
that
this
theorem
holds
for
any
time
as
the
sample
size
increases
to
avoid
division
by
zero
merit
point
œÑ0
even
if
the
estimated
merits
change
substantially
up
to
œÑ0
can
be
set
to
some
minimum
constant
so
once
the
estimated
merits
have
converged
to
the
true
merits
434
session
3a
bias
and
fairness
sigir
20
july
25
30
2020
virtual
event
china
fairco
exp
will
ensure
that
the
amortized
disparity
converges
in
all
news
experiments
we
learn
global
ranking
and
compare
to
zero
as
well
the
following
methods
naive
rank
by
the
sum
of
the
observed
feedback
ct
empirical
evaluation
d-ultr
glob
dynamic
ltr
by
sorting
via
the
unbiased
esti
in
addition
to
the
theoretical
justification
of
our
approach
we
also
mates
ips
from
eq
15
conducted
an
empirical
evaluation1
we
first
present
experiments
fairco
imp
fairness
controller
from
eq
17
for
impact
fairness
on
semi-synthetic
news
dataset
to
investigate
different
aspects
of
the
proposed
methods
under
controlled
conditions
after
that
0.750
0.20
avg
cumulative
ndcg
we
evaluate
the
methods
on
real-world
movie
preference
data
for
naive
impact
unfairness
external
validity
0.725
0.15
d-ultr
glob
0.700
0.10
fairco
imp
8.1
robustness
analysis
on
news
data
to
be
able
to
evaluate
the
methods
in
variety
of
specifically
de
0.675
0.05
signed
test
settings
we
created
the
following
simulation
environ
0.650
0.00
1000
2000
3000
1000
2000
3000
ment
from
articles
in
the
ad
fontes
media
bias
dataset2
it
simulates
users
users
dynamic
ranking
problem
on
set
of
news
articles
belonging
to
two
groups
left
and
right
left-leaning
and
right-leaning
news
figure
convergence
of
ndcg
left
and
unfairness
right
articles
as
the
number
of
users
increases
100
trials
in
each
trial
we
sample
set
of
30
news
articles
for
each
article
the
dataset
contains
polarity
value
that
we
rescale
to
the
8.1
can
fairco
reduce
unfairness
while
maintaining
good
rank
interval
between
and
while
the
user
polarities
are
simulated
ing
quality
this
is
the
key
question
in
evaluating
fairco
and
each
user
has
polarity
that
is
drawn
from
mixture
of
two
normal
figure
shows
how
ndcg
and
unfairness
converge
for
naive
distributions
clipped
to
ultr
glob
and
fairco
imp
the
plots
show
that
naive
achieves
ut
clip
pne–¥
0.5
0.2
pne–¥
0.5
0.2
19
the
lowest
ndcg
and
that
its
unfairness
remains
high
as
the
where
pne–¥
is
the
probability
of
the
user
to
be
left-leaning
mean
0.5
number
of
user
interactions
increases
d-ultr
glob
achieve
the
we
use
pne–¥
0.5
unless
specified
in
addition
each
user
has
an
best
ndcg
as
predicted
by
the
theory
but
its
unfairness
is
only
openness
parameter
out
0.05
0.55
indicating
on
the
breadth
marginally
better
than
that
of
naive
only
fairco
manages
to
sub
of
interest
outside
their
polarity
based
on
the
polarities
of
the
user
stantially
reduce
unfairness
and
this
comes
only
at
small
decrease
ut
and
the
item
the
true
relevance
is
drawn
from
the
bernoulli
in
ndcg
compared
to
d-ultr
glob
distribution
the
following
questions
will
provide
further
insight
into
these
results
evaluating
the
components
of
the
fairco
and
exploring
its
ut
rt
bernoulli
exp
robustness
out
as
the
model
of
user
behavior
we
use
the
position-based
click
0.3
average
model
pbm
18
where
the
marginal
probability
that
user
ut
examines
an
article
only
depends
only
on
its
position
we
choose
0.2
naive
an
exposure
drop-off
analogous
to
the
gain
function
in
dcg
as
ip
0.1
pt
20
log2
rank
œÉt
0.0
500
1000
1500
2000
2500
3000
the
remainder
of
the
simulation
follows
the
dynamic
ranking
users
setup
at
each
time
step
user
ut
arrives
to
the
system
the
algorithm
presents
an
unpersonalized
ranking
œÉt
and
the
user
figure
error
of
relevance
estimators
as
the
number
of
provides
feedback
ct
according
to
pt
and
rt
the
algorithm
only
users
increases
30
10
trials
observes
ct
and
not
rt
to
investigate
group-fairness
we
group
the
items
according
to
their
polarity
where
items
with
polarity
belong
to
8.1
do
the
unbiased
estimates
converge
to
the
true
relevances
the
left-leaning
group
left
and
items
with
polarity
the
first
component
of
fairco
we
evaluate
is
the
unbiased
ips
belong
to
the
right-leaning
group
right
estimator
ips
from
equation
15
figure
shows
the
absolute
we
measure
ranking
quality
by
the
average
cumulative
ndcg
difference
between
the
estimated
global
relevance
and
true
global
√≠œÑ
dcg
over
all
the
users
up
to
time
we
measure
relevance
for
ips
and
the
estimator
used
in
the
naive
while
the
error
for
naive
stagnates
at
around
0.25
the
estimation
error
exposure
unfairness
via
and
impact
unfairness
via
as
de
of
ips
approaches
zero
as
the
number
of
users
increases
this
fined
in
equation
16
verifies
that
ips
eliminates
the
effect
of
position
bias
and
learns
the
implementation
is
available
at
https://github.com/marcomorik/dynamic-fairness.
accurate
estimates
of
the
true
expected
relevance
for
each
news
https://www.adfontesmedia.com/interactive-media-bias-chart/
article
so
that
we
can
use
them
for
the
fairness
and
ranking
criteria
435
session
3a
bias
and
fairness
sigir
20
july
25
30
2020
virtual
event
china
0.2
naive
see
that
their
solutions
are
unfair
as
increases
both
methods
impact
unfairness
d-ultr
glob
start
enforcing
fairness
at
the
expense
of
ndcg
in
these
and
other
fairco
imp
experiments
we
found
no
evidence
that
the
linprog
baseline
is
su
0.1
perior
to
fairco
however
linprog
is
substantially
more
expensive
to
compute
which
makes
fairco
preferable
in
practice
0.0
50
100
150
200
250
300
350
400
number
of
right-leaning
users
in
the
beginning
naive
impact
unfairness
0.75
0.3
d-ultr
glob
figure
the
effect
of
block
of
right-leaning
users
on
the
ndcg
0.2
fairco
imp
unfairness
of
impact
50
trials
3000
users
0.70
0.1
0.65
8.1
does
fairco
overcome
the
rich-get-richer
dynamic
the
il
0.0
0.2
0.4
0.2
0.4
lustrating
example
in
section
argues
that
naively
ranking
items
proportion
of
left-leaning
items
proportion
of
left-leaning
items
is
highly
sensitive
to
the
initial
conditions
which
items
get
the
first
clicks
leading
to
rich-get-richer
dynamic
we
now
test
figure
ndcg
left
and
unfairness
right
for
varying
pro
whether
fairco
overcomes
this
problem
in
particular
we
adver
portion
of
left
20
trials
3000
users
sarially
modify
the
user
distribution
so
that
the
first
users
are
right-leaning
pne–¥
followed
by
left-leaning
users
pne–¥
8.1
is
fairco
effective
for
different
group
sizes
in
this
experi
before
we
continue
with
balanced
user
distribution
pne–¥
0.5
ment
we
vary
asymmetry
of
the
polarity
within
the
set
of
30
news
figure
shows
the
unfairness
after
3000
user
interactions
as
ex
articles
ranging
from
left
to
left
15
news
articles
for
each
pected
naive
is
the
most
sensitive
to
the
head-start
that
the
right
group
size
we
run
20
trials
for
3000
users
each
figure
shows
leaning
articles
are
getting
d-ultr
glob
fares
better
and
its
un
that
regardless
of
the
group
ratio
fairco
reduces
unfairness
for
fairness
remains
constant
but
high
independent
of
the
initial
user
the
whole
range
while
maintaining
ndcg
this
is
in
contrast
to
distribution
since
the
unbiased
estimator
ips
corrects
for
the
naive
and
d-ultr
glob
which
suffer
from
high
unfairness
presentation
bias
so
that
the
estimates
still
converge
to
the
true
rel
evance
fairco
inherits
this
robustness
to
initial
conditions
since
it
uses
the
same
ips
estimator
and
its
active
control
for
unfairness
0.4
naive
impact
unfairness
makes
it
the
only
method
that
achieves
low
unfairness
across
the
0.8
d-ultr
glob
whole
range
ndcg
fairco
imp
0.2
0.74
0.7
linprog
impact
unfairness
0.15
0.72
fairco
imp
0.0
0.2
0.4
0.6
0.8
0.2
0.4
0.6
0.8
ndcg
0.10
proportion
of
left-leaning
users
proportion
of
left-leaning
users
0.70
0.05
0.68
figure
ndcg
left
and
unfairness
right
with
varying
0.00
user
distributions
20
trials
3000
users
10
10
10
10
10
10
10
10
10
10
10
100
101
102
8.1
is
fairco
effective
for
different
user
distributions
finally
to
figure
comparing
the
lp
baseline
and
the
p-controller
examine
the
robustness
to
varying
user
distributions
we
control
the
in
terms
of
ndcg
left
and
unfairness
right
for
different
polarity
distribution
of
the
users
by
varying
pne–¥
in
equation
19
values
of
15
trials
3000
users
we
run
20
trials
each
on
3000
users
in
figure
observe
that
naive
and
d-ultr
glob
suffer
from
high
unfairness
when
there
is
8.1
how
effective
is
the
fairco
compared
to
more
expensive
large
imbalance
between
the
minority
and
the
majority
group
linear-programming
baseline
as
baseline
we
adapt
the
linear
while
fairco
is
able
to
control
the
unfairness
in
all
settings
programming
method
from
41
to
the
dynamic
ltr
setting
to
minimize
the
amortized
fairness
disparities
that
we
consider
in
8.2
evaluation
on
real-world
preference
data
this
work
the
method
uses
the
current
relevance
and
disparity
to
evaluate
our
method
on
real-world
preference
data
we
adopt
estimates
to
solve
linear
programming
problem
whose
solution
is
the
ml-20m
dataset
24
we
select
the
five
production
companies
stochastic
ranking
policy
that
satisfies
the
fairness
constraints
in
with
the
most
movies
in
the
dataset
mgm
warner
bros
para
expectation
at
each
the
details
of
this
method
are
described
in
mount
20th
century
fox
columbia
these
production
companies
the
full
version
of
the
paper
on
arxiv
figure
shows
ndcg
and
form
the
groups
for
which
we
aim
to
ensure
fairness
of
exposure
impact
unfairness
after
3000
users
averaged
over
15
trials
for
both
to
exclude
movies
with
only
few
ratings
and
have
diverse
user
linprog
and
fairco
for
different
values
of
their
hyperparameter
population
from
the
set
of
300
most
rated
movies
by
these
produc
for
both
methods
reduce
to
d-ultr
glob
and
we
can
tion
companies
we
select
100
movies
with
the
highest
standard
436
session
3a
bias
and
fairness
sigir
20
july
25
30
2020
virtual
event
china
0.9
0.4
avg
cumulative
ndcg
deviation
in
the
rating
across
users
for
the
users
we
select
104
exposure
unfairness
naive
users
who
have
rated
the
most
number
of
the
chosen
movies
this
0.3
d-ultr
glob
leaves
us
with
partially
filled
ratings
matrix
with
104
users
and
0.8
0.2
d-ultr
100
movies
to
avoid
missing
data
for
the
ease
of
evaluation
we
use
fairco
exp
an
off-the-shelf
matrix
factorization
algorithm3
to
fill
in
the
missing
0.1
entries
we
then
normalize
the
ratings
to
by
apply
sigmoid
function
centered
at
rating
with
slope
10
these
serve
0.7
2000
4000
6000
0.0
2000
4000
6000
as
relevance
probabilities
where
higher
star
ratings
correspond
to
users
users
higher
likelihood
of
positive
feedback
finally
for
each
trial
we
obtain
binary
relevance
matrix
by
drawing
bernoulli
sample
figure
ndcg
left
and
exposure
unfairness
right
on
the
for
each
user
and
movie
pair
with
these
probabilities
we
use
the
movie
data
as
the
number
of
user
interactions
increases
10
user
embeddings
from
the
matrix
factorization
model
as
the
user
trials
features
0.9
0.20
avg
cumulative
ndcg
in
the
following
experiments
we
use
fairco
to
learn
sequence
naive
impact
unfairness
of
ranking
policies
œÄt
that
are
personalized
based
on
the
goal
0.15
d-ultr
glob
is
to
maximize
ndcg
while
providing
fairness
of
exposure
to
the
0.8
0.10
d-ultr
production
companies
user
interactions
are
simulated
analogously
fairco
imp
to
the
previous
experiments
at
each
time
step
we
sample
user
0.05
and
the
ranking
algorithm
presents
ranking
of
the
100
movies
0.7
0.00
the
user
follows
the
position-based
model
from
equation
20
and
2000
4000
6000
2000
4000
6000
users
users
reveal
ct
accordingly
for
the
conditional
relevance
model
reg
used
by
fairco
and
figure
ndcg
left
and
impact
unfairness
right
on
the
d-ultr
we
use
one
hidden-layer
neural
network
that
consists
of
movie
data
as
the
number
of
user
interactions
increases
10
50
input
nodes
fully
connected
to
64
nodes
in
the
hidden
layer
trials
with
relu
activation
which
is
connected
to
100
output
nodes
with
sigmoid
to
output
the
predicted
probability
of
relevance
of
each
movie
since
training
this
network
with
less
than
100
observations
is
only
has
access
to
the
partial
feedback
ct
it
tracks
the
performance
unreliable
we
use
the
global
ranker
d-ultr
glob
for
the
first
100
of
skyline
as
predicted
by
the
theory
they
appear
to
converge
users
we
then
train
the
network
at
100
users
and
then
update
asymptotically
the
network
after
every
10
users
on
all
previously
collected
feedback
8.2
can
fairco
reduce
unfairness
figure
shows
that
fairco
exp
c1
cœÑ
using
the
unbiased
regression
objective
from
can
effectively
control
exposure
unfairness
unlike
the
other
meth
eq
14
with
the
adam
optimizer
33
ods
that
do
not
actively
consider
fairness
similarly
figure
shows
that
fairco
imp
is
effective
at
controlling
impact
unfairness
as
ex
1.0
avg
cumulative
ndcg
pected
the
improvement
in
fairness
comes
at
reduction
in
ndcg
naive
d-ultr
but
this
reduction
is
small
0.9
d-ultr
glob
skyline
0.20
0.20
exposure
unfairness
0.8
d-ultr
impact
unfairness
0.15
0.15
fairco
imp
0.7
0.10
0.10
fairco
exp
1000
2000
3000
4000
5000
6000
users
0.05
0.05
0.00
0.00
figure
comparing
the
ndcg
of
personalized
and
non
2000
4000
6000
2000
4000
6000
users
users
personalized
rankings
on
the
movie
data
10
trials
8.2
does
personalization
via
unbiased
objective
improve
ndcg
figure
10
unfairness
of
exposure
left
and
unfairness
of
we
first
evaluate
whether
training
personalized
model
using
the
impact
right
for
the
personalized
controller
optimized
for
de-biased
reg
regression
estimator
improves
ranking
perfor
either
exposure
or
impact
10
trials
mance
over
non-personalized
model
figure
shows
that
ranking
by
reg
d-ultr
provides
substantially
higher
ndcg
than
8.2
how
different
are
exposure
and
impact
fairness
figure
10
the
unbiased
global
ranking
d-ultr
glob
and
the
naive
ranking
evaluates
how
an
algorithm
that
optimizes
exposure
fairness
per
to
get
an
upper
bound
on
the
performance
of
the
personalization
forms
in
terms
of
impact
fairness
and
vice
versa
the
plots
show
models
we
also
train
skyline
model
using
the
in
practice
un
that
the
two
criteria
achieve
different
goals
and
that
they
are
sub
observed
true
relevances
rt
with
the
least-squares
objective
from
stantially
different
in
fact
optimizing
for
fairness
in
impact
can
eq
13
even
though
the
unbiased
regression
estimator
reg
even
increase
the
unfairness
in
exposure
illustrating
that
the
choice
of
criterion
needs
to
be
grounded
in
the
requirements
of
the
appli
surprise
library
http://surpriselib.com/)
for
svd
with
biased
false
and
50
cation
437
session
3a
bias
and
fairness
sigir
20
july
25
30
2020
virtual
event
china
conclusions
20
nick
craswell
onno
zoeter
michael
taylor
and
bill
ramsey
2008
an
experi
mental
comparison
of
click
position-bias
models
in
wsdm
we
identify
how
biased
feedback
and
uncontrolled
exposure
alloca
21
danielle
ensign
sorelle
friedler
scott
neville
carlos
scheidegger
and
suresh
tion
can
lead
to
unfairness
and
undesirable
behavior
in
dynamic
venkatasubramanian
2018
runaway
feedback
loops
in
predictive
policing
in
conference
of
fairness
accountability
and
transparency
ltr
to
address
this
problem
we
propose
fairco
which
is
able
22
zhichong
fang
agarwal
and
joachims
2019
intervention
harvesting
for
to
adaptively
enforce
amortized
merit-based
fairness
constraints
context-dependent
examination-bias
estimation
in
sigir
even
though
their
underlying
relevances
are
still
being
learned
the
23
fabrizio
germano
vicen√ß
g√≥mez
and
ga√´l
le
mens
2019
the
few-get
richer
surprising
consequence
of
popularity-based
rankings
arxiv
preprint
algorithm
is
robust
to
presentation
bias
and
thus
does
not
exhibit
arxiv
1902.02580
2019
rich-get-richer
dynamics
finally
fairco
is
easy
to
implement
and
24
maxwell
harper
and
joseph
konstan
2015
the
movielens
datasets
history
and
context
acm
tiis
2015
computationally
efficient
which
makes
it
well
suited
for
practical
25
herbrich
graepel
and
obermayer
2000
large
margin
ranking
boundaries
for
applications
ordinal
regression
in
advances
in
large
margin
classifiers
26
katja
hofmann
shimon
whiteson
and
maarten
de
rijke
2013
balancing
ex
ploration
and
exploitation
in
listwise
and
pairwise
online
learning
to
rank
for
acknowledgments
information
retrieval
information
retrieval
2013
this
research
was
supported
in
part
by
nsf
awards
iis-1901168
27
daniel
horvitz
and
donovan
thompson
1952
generalization
of
sampling
without
replacement
from
finite
universe
journal
of
the
american
statistical
and
gift
from
workday
all
content
represents
the
opinion
of
association
1952
the
authors
which
is
not
necessarily
shared
or
endorsed
by
their
28
guido
imbens
and
donald
rubin
2015
causal
inference
in
statistics
social
respective
employers
and
or
sponsors
and
biomedical
sciences
cambridge
university
press
29
kalervo
j√§rvelin
and
jaana
kek√§l√§inen
2002
cumulated
gain-based
evaluation
of
ir
techniques
tois
2002
references
30
joachims
2002
optimizing
search
engines
using
clickthrough
data
in
acm
himan
abdollahpouri
gediminas
adomavicius
robin
burke
ido
guy
dietmar
sigkdd
conference
on
knowledge
discovery
and
data
mining
kdd
133
142
jannach
toshihiro
kamishima
jan
krasnodebski
and
luiz
pizzato
2019
beyond
31
joachims
granka
bing
pan
hembrooke
radlinski
and
gay
2007
personalization
research
directions
in
multistakeholder
recommendation
arxiv
evaluating
the
accuracy
of
implicit
feedback
from
clicks
and
query
reformula
preprint
arxiv
1905.01986
2019
tions
in
web
search
acm
tois
2007
himan
abdollahpouri
robin
burke
and
bamshad
mobasher
2017
controlling
32
joachims
swaminathan
and
schnabel
2017
unbiased
learning-to-rank
popularity
bias
in
learning-to-rank
recommendation
in
acm
recsys
with
biased
feedback
in
wsdm
lada
adamic
and
bernardo
huberman
2000
power-law
distribution
of
the
33
diederik
kingma
and
jimmy
ba
2014
adam
method
for
stochastic
opti
world
wide
web
science
2000
mization
arxiv
preprint
arxiv
1412.6980
2014
agarwal
takatsu
zaitsev
and
joachims
2019
general
framework
34
shuai
li
tor
lattimore
and
csaba
szepesv√°ri
2018
online
learning
to
rank
for
counterfactual
learning-to-rank
in
sigir
with
features
arxiv
preprint
arxiv
1810.02567
2018
agarwal
zaitsev
xuanhui
wang
cheng
li
najork
and
joachims
35
lydia
liu
sarah
dean
esther
rolf
max
simchowitz
and
moritz
hardt
2018
2019
estimating
position
bias
without
intrusive
interventions
in
wsdm
delayed
impact
of
fair
machine
learning
in
icml
qingyao
ai
keping
bi
cheng
luo
jiafeng
guo
and
bruce
croft
2018
unbi
36
radlinski
and
joachims
2006
minimally
invasive
randomization
for
col
ased
learning
to
rank
with
unbiased
propensity
estimation
in
sigir
lecting
unbiased
preferences
from
clickthrough
logs
in
aaai
1406
1412
michael
ekstrand
sebastian
kohlmeier
asia
biega
fernando
diaz
2019
trec
37
radlinski
kleinberg
and
joachims
2008
learning
diverse
rankings
fair
ranking
track
https://fair-trec.github.io/
online
accessed
08
14
2019
with
multi-armed
bandits
in
icml
ricardo
baeza-yates
2018
bias
on
the
web
commun
acm
2018
38
stephen
robertson
1977
the
probability
ranking
principle
in
ir
journal
of
solon
barocas
moritz
hardt
and
arvind
narayanan
2018
fairness
and
machine
documentation
1977
learning
2018
39
salganik
sheridan
dodds
and
watts
2006
experimental
study
of
10
solon
barocas
and
andrew
selbst
2016
big
data
disparate
impact
calif
inequality
and
unpredictability
in
an
artificial
cultural
market
science
2006
rev
2016
40
tobias
schnabel
adith
swaminathan
ashudeep
singh
navin
chandak
and
11
michael
beam
2014
automating
the
news
how
personalized
news
recom
thorsten
joachims
2016
recommendations
as
treatments
debiasing
learning
mender
system
design
choices
impact
news
reception
communication
research
and
evaluation
in
icml
2014
41
ashudeep
singh
and
thorsten
joachims
2018
fairness
of
exposure
in
rankings
12
wayne
bequette
2003
process
control
modeling
design
and
simulation
prentice
in
acm
sigkdd
hall
professional
42
ashudeep
singh
and
thorsten
joachims
2019
policy
learning
for
fairness
in
13
alex
beutel
jilin
chen
tulsee
doshi
hai
qian
li
wei
yi
wu
lukasz
heldt
ranking
in
neurips
zhe
zhao
lichan
hong
ed
chi
and
cristos
goodrow
2019
fairness
in
43
behzad
tabibian
vicen√ß
g√≥mez
abir
de
bernhard
sch√∂lkopf
and
recommendation
ranking
through
pairwise
comparisons
in
acm
sigkdd
manuel
gomez
rodriguez
2019
consequential
ranking
algorithms
and
14
asia
biega
krishna
gummadi
and
gerhard
weikum
2018
equity
of
attention
long-term
welfare
arxiv
preprint
arxiv
1905.05305
2019
amortizing
individual
fairness
in
rankings
in
sigir
44
michael
taylor
john
guiver
stephen
robertson
and
tom
minka
2008
softrank
15
christopher
jc
burges
2010
from
ranknet
to
lambdarank
to
lambdamart
an
optimizing
non-smooth
rank
metrics
in
wsdm
acm
overview
learning
2010
45
soroush
vosoughi
deb
roy
and
sinan
aral
2018
the
spread
of
true
and
false
16
elisa
celis
damian
straszak
and
nisheeth
vishnoi
2017
ranking
with
news
online
science
2018
fairness
constraints
arxiv
preprint
arxiv
1704.06840
2017
46
xuanhui
wang
nadav
golbandi
michael
bendersky
donald
metzler
and
marc
17
nicol√≤
cesa-bianchi
and
g√°bor
lugosi
2006
prediction
learning
and
games
najork
2018
position
bias
estimation
for
unbiased
learning
to
rank
in
personal
cambridge
university
press
search
in
wsdm
acm
18
aleksandr
chuklin
ilya
markov
and
maarten
de
rijke
2015
click
models
for
47
himank
yadav
zhengxiao
du
and
thorsten
joachims
2019
fair
learning-to
web
search
synthesis
lectures
on
information
concepts
retrieval
and
services
rank
from
implicit
feedback
arxiv
cs
lg
1911.08054
2015
48
hongzhi
yin
bin
cui
jing
li
junjie
yao
and
chen
chen
2012
challenging
the
19
giovanni
luca
ciampaglia
azadeh
nematzadeh
filippo
menczer
and
alessandro
long
tail
recommendation
vldb
2012
flammini
2018
how
algorithmic
popularity
bias
hinders
or
promotes
quality
49
masrour
zoghi
tomas
tunys
mohammad
ghavamzadeh
branislav
kveton
scientific
reports
2018
csaba
szepesvari
and
zheng
wen
2017
online
learning
to
rank
in
stochastic
click
models
in
icml
438