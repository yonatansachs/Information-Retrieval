Exploring the Effect of Search Engine
Personalization on Politically Biased Search Results
Author: Mario Martinovic
University of Twente
P.O. Box 217, 7500AE Enschede
The Netherlands

ABSTRACT
The internet has become a widespread tool for people to find political information. As a result
of this, the neutrality of the results shown by search engines has been of increasing concern for
the democratic ways of many countries. With the introduction of personalized search results,
the so-called ‘’filter bubble effect’’ could result in users potentially getting results which only
portrays one political side. We have used the results from 89 students who filled out our survey.
We have found out that on Google’s search engine, more than 25% the participants had search
results which were to some extent politically biased. However, no clear connection was found
between personalization and politically biased results. Moreover, we discovered that
DuckDuckGo isn’t as reliable as previously thought. DuckDuckGo states that if multiple users
type in the same query, they should get the same results. Furthermore, DuckDuckGo should be
clear of any political biases due to the fact that is provides results based on the semantics of a
query and it doesn’t collect any data of the user. Nonetheless, over 67% of the results, for one
of our queries used in the survey, turned out be politically biased. One should be well aware of
the potential biases it may encounter in search engines, as the biases are not only existent in
personalized search engines, they may also well be found in search engines which don’t
personalize their results.

Graduation Committee members:
Wijnhoven, Fons, dr.
de Visser, Matthias, dr.
Keywords
Google; Search Engine; User Profile; Search Engine Manipulation; Personalization; Political Bias; DuckDuckGo
Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise,
or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
11th IBA Bachelor Thesis Conference, July 10th, 2018, Enschede, The Netherlands.
Copyright 2018, University of Twente, The Faculty of Behavioural, Management and Social sciences.

1. INTRODUCTION
There is a lot of information being stored on the
Web which makes it nearly impossible to sort them
all out [8]. Due to this, there is a need for search
engines to use certain tools to provide its users with
the relevant data that they are actually looking for.
This can be achieved through the so-called
personalization of search engines. Google
implemented personalized search for the first time in
2005 in order to improve the user experience. This
was based on the knowledge Google has gained from
past searches, clicks and interactions [17]. In the
beginning, this service was only available to users
who had a Google account, but in 2009, it was made
accessible to everyone who uses the Google search
engine. It provides customized search results through
the use of an anonymous cookie placed in your
browser which collects data of a period of up to 180
days [11]. An example of this personalization put to
practice can be seen in the following example. If a
small boy, who is a fan of the animated movie named
Cars, types in ‘’Cars’’ in the search engine of Google,
it is highly likely that the results will be mostly from
the animated movie ‘’cars’’ instead of actual cars.
While on the other hand, if someone else who never
heard of the movie before, types in ‘’cars’’ in
Google’s search engine, the results will most
probably be about actual cars. This is the result of
personalization.
Personalization anticipates the user’s needs and
it does so through constant monitoring of the
interactions that happen while browsing the Web.
With all the data that Google has collected, it creates
a specific profile for the user, also called the eprofile. This profile contains everything that Google
knows about you, such as whether you are male or
female, your approximate age, your location as well
as your major interests [8]. It uses this profile to
maximize the user experience and to give you the
best personalized search results. However, with all
this personalization happening, a question arises of
whether the search results might be biased, or even
manipulative. When we talk about manipulation we
mean ‘’the action of influencing or controlling
someone or something to your advantage, often
without anyone knowing it’’ [15]. The goal of this
paper is to find out whether personalized search
engines provide results which are politically biased
and to what extent are these results caused by
personalization. Moreover, we want to find out
whether one-sided results have an influence on the
user’s decision making. The main research question
for this research is:
To what extent do personalized search engines
manipulate user’s decision making by providing onesided views based on their political preference?
Moreover, in this research we will use the
search engine called ‘’DuckDuckGo’’ as a
benchmark to compare with Google to find out
whether the results on Google are a result of
personalization. This search engine states that it
doesn’t collect any information about the user, this is
to avoid having biased results due to the ‘’filter
bubble’’ effect.

Furthermore, we will test whether the results on
DuckDuckGo are biased towards either the left-wing
or right-wing political ideology. A sub question for
this research will be:
Do the results from DuckDuckGo contain any
political bias?

2. THEORY
Algorithms are inventions created by humans,
as a result of this, the algorithms for the Google
search engine will be created with certain beliefs and
biases which might affect the design and function of
the algorithm [1,5]. This means that a certain
developer who worked on Google’s search engine
algorithm, could knowingly or unknowingly, have
left a digital footprint of his political views in the
algorithm. This raises the question whether there is
any inherent bias within the algorithm from Google.

2.1 Filter bubble
Although personalization has been proven to
provide higher user satisfaction amongst its users,
there are a few potential drawbacks. One of them is
the ‘’filter bubble’’ effect, which was explained by
Nguyen et al as a ‘’self-reinforcing pattern of
narrowing exposure that reduces user creativity,
learning and connection’’ [16]. This is the result of
personalization, the results shown are being filtered
so that they match the user’s interests and preferences
[16]. As a result of this, the user might not be able to
discover new topics or different views. Furthermore,
personalization doesn’t only limit the user of finding
new ideas, it could also possibly result in providing
one-sided views based on their preference.
Moreover, the results may become biased and the socalled ‘’manipulation effect’’ might occur. The effect
of this was shown by Epstein and Robertson in 2015,
where they found out that the manipulation of search
engine rankings based on queries which are electionrelated could change the voting preference of the user
by 20% after a single search [19].

2.2 DuckDuckGo
Due to the filter bubble and even some questions
regarding privacy violation, other search engines
such as DuckDuckGo, which doesn’t collect any data
from the user, has seen an increase in popularity.
DuckDuckGo is a search engine which aims to
protect the user’s privacy as well as avoiding the
filter bubble effect due to personalized search results
[4]. DuckDuckGo provides results based on the
semantics of the query and can be seen as an expert
oriented search engine [22]. One of the reasons why
someone might want to use the DuckDuckGo search
engine is that there is no, so-called, ‘’search
leakage’’. This happens when you search for
something which is private, by unknowingly sharing
the data of what you actually searched, not only with
the search engine you’re using, but also with the sites
that you visited as a result of that search. This
information can be used to identify who the person
who visited these websites is [6].

Another reason to use DuckDuckGo is that it doesn’t
save your search history after you close it. Other
search engines who do save the search history, they
also save other information such as your IP address,
the User agent and a unique identifier which is
usually stored in a browser cookie [6]. However,
DuckDuckGo only has a 0.68% market share,
compared to Google which holds 86.95% [22].

2.3 Left-wing vs Right-wing
In most democratic countries, we will find that
there are mostly two different sides in politics,
namely the ‘’Left’’ and the ‘’Right’’. According to
the Oxford dictionary the definition of the ‘’left
wing’’ is ‘’the radical, reforming, or socialist section
of a political party or system.’’ [14]. While the
definition of the ‘’Right wing’’ is ‘’the conservative
or reactionary section of a political party or system.’’
[20]. Furthermore, the political left wing tends to be
more liberal, focussing on moving forward, while the
political right wing tends to be more conservative and
traditional in nature. However, most of the people
don’t see themselves as fully left-wing supporters or
fully right-wing supporters. Most probably, they
support some ideas from the left and some ideas from
the right.
We expect that quite a bit of people might have
neutral views about certain topics. For example, there
might be people who aren’t living in Europe and have
neutral views about the refugee crisis in Europe.
For this research we will be looking whether a
person’s political preference, which is anywhere
from left to right, will influence the results on the
search engine and in particular if it will provide onesided views based on that political preference.

2.4 Related work
According to a study conducted by CanIRank,
which collected the results from over 1,200 URLs on
queries which are politically-charged, such as
‘’abortion’’ and ‘’gun control’’, they found out that
there is a 40% chance that the results will be more in
favour of liberal or ‘’left’’ politics rather than their
‘’right wing’’ counterpart [7].

They did this by looking at a few ranking factors such
as: keyword usage in title, related term usage,
relevancy of indexed pages, relevancy of home page
and more. They concluded however that there was no
clear evidence to prove that there is any ‘’inherent
bias within Google’s algorithm’’ [7].
Another study which was conducted by Epstein
Robertson in 2015, found out that the rankings of the
search results have a 20% can influence undecided
voters to vote for a certain political option [19]. In
general, the U.S. Presidential elections have been
won by margins which were less than 7.6% [13]. Due
to the fact that elections are often won by small vote
margins, the search ranking manipulation might have
a huge impact on the democratic way of voting.
Hannak et al. measured and identified which
kind of factors caused personalization such as
gender, location etc. They found out that most
personalization happens when a user is logged in to
their Google account. Their experiments showed that
only 11.7% of the differences in search results were
caused due to personalization [9]. This proves that
personalization does not have a great impact on the
results, but only slightly.
According to research conducted in the year
2000 by Introna and Nissenbaum, they suggest that
search engines can systematically exclude specific
websites [23]. They state that especially those
powerful, popular and rich websites have a higher
possibility of appearing on the search results at the
expense of other websites which are less popular or
powerful. This can be seen as an attack to the
democratic ways of the World Wide Web. As a result
of this, people looking for certain information online
might be susceptible to getting biased results.

2.5 Relevance
Although previously conducted research proved
the existence of the ‘’search engine manipulation
effect’’ also known as ‘’SEME’’, there was no prior
research conducted to find out whether the results
shown on Google could be manipulating the user
based on their political preference due to
personalization.
The practical relevance of this research is that it
will shed light on the fact whether personalization
affects the results to be politically biased. It will also
create awareness of how reliable DuckDuckGo
actually is. Reliability can be defined as ‘’the extent
to which an experiment, test, or measuring procedure
yields the same results on repeated trials’’ [18].

3. METHODOLOGY

Figure 1. CanIRank.com [7]
As one can see in figure 1, there is a 33% chance to
come across left-wing views in the first 5 search
results, as opposed to the 20% of coming across
results which contain right-wing views. Furthermore,
CanIrank wanted to find out whether Google’s
algorithm contains any political bias.

In order to do find out whether the users of the
Google search engine are in fact being manipulated
due to them getting one-sided results because of
personalization, we will conduct a survey. The
survey is going to be obtrusive, which means that the
subjects are aware that they are being monitored and
that their responses will be used for this research. We
acknowledge the fact that this could influence their
responses in the survey. ‘’The unit of observation is
the who about which data is collected in a survey’’
[21]. For this research, the unit of observation will be
students who are 18 years or older. The students can

be from any country in the world. The unit of analysis
can be defined as the major entity which is being
analyzed [2]. Our unit of analysis is going to be the
two search engines, namely Google and
DuckDuckGo.
First, we need to define what we wish to find out
with our survey. The goal for this survey is to find
out whether our survey respondents are being
manipulated through the search results that they will
provide to us during the survey. In this paper we will
define manipulation as the search results only
showing information from one point of view as a
result of one’s political view. We also want to find
out whether DuckDuckGo contains any political bias
in its search results.

3.1 Participants
As mentioned earlier, all our participants have
to be students and at least 18 years of age in order for
them to be used in our research. They should
currently be studying or have finished their studies,
because that way we can prevent any biases that
could be caused by differences in educational levels.
They can reside in any country of the world.
However, we anticipate that most of our respondents
will be from Europe. All of the participants shouldn’t
have deleted their cookies in the past one month. This
is to make sure that the participant will receive results
which are personalized. A cookie can be defined as
‘’a small piece of data that a server sends to the user’s
web browser, which the browser may sort and sent it
back with the next request to the same server’’ [12].
The main search engine of the participants should be
Google, but they can also have used other search
engines from time to time. All of the participants
have to complete the survey on their own personal
laptop or PC (personal computer). This is because
only then will their searches personalized due to their
online profiles. Any surveys which are completed
elsewhere such as a phone or a public computer
won’t be used for this study.

3.2 Procedure
We will compare the results from two different
queries with Google and DuckDuckGo. The
participants will make a screenshot of the first six
organic results, which means that we don’t include
results which are paid advertisements from both
Google and DuckDuckGo. They will do this for the
both search queries which are ‘’how is trump doing
overall’’ and ‘’European refugee crisis result’’.
Which we will respectively shorten in this report as
‘’query #1’’ and ‘’query #2’’. We will look at the first
six results and find out whether the majority of the
results shown are biased towards the left-wing or the
right-wing ideology. If it turns out that the results
aren’t politically biased for a specific participant, we
will call the results to be neutral.
These two queries were chosen due to the fact
that at the moment of writing this paper, both Trump
and the European refugee crisis have been in the
news quite a bit and there has been an ongoing debate
about the positive and negative sides. The queries
themselves are neutral in nature and should be clear
of any political bias. The query about Trump is
asking how Trump is doing overall, so the results

should be mostly facts about the progress he made
and what he has achieved so far. The second query
about the European refugee crisis specifically asks
what the result of this crisis has been. We expect
results which should show what kind of impact the
European refugee crises has had on Europe.
However, there are people who like the things Trump
did and there are people who are criticizing his
achievements. There’s also a lot of mixed feelings
about the European refugee crisis. One part of the
people think that the European country should help
out the refugees and that this as a result increases the
multicultural diversity, while on the other hand, there
are people who are against the refugees and are
saying that they take away the culture and values of
the European countries.
To find out whether the respondents of the
survey are more ‘’leftist’’, ‘’rightist’’ or ‘’neutral’’,
they will be asked two questions near the end of the
survey which are ‘’what is your opinion about
Trump?’’ and ‘’what is your opinion about the
refugees in Europe?’’. These questions have five
different multiple-choice answers which are: ‘’Very
positive’’; ‘’Positive’’; ‘’Neutral’’; ‘’Negative’’;
‘’Very negative’’. Based on the answers the
respondents give on these questions, we can
approximately put them in a group of being, either
‘’leftist’’, ‘’rightist’’ or ‘’neutral’’. This information
will be used to see whether the user is indeed being
manipulated by the search engine by getting onesided search results.
Based on the results from the survey, we will put
every respondent in two different groups. The first
group is going to consist of respondents who viewed
themselves as either a ‘’leftist’’ or ‘’rightist’’ for one
of the search queries, while the other group will
consist of those who see themselves as ‘’neutral’’.
This will be done for both queries as we don’t expect
that all our participants will have the same views on
both topics.

3.3 Web page classification
In order to find out whether the results shown
on Google and DuckDuckGo contain any political
bias, we will have to classify the results. This will
firstly be done by looking at the title. Example of a
left-wing title from one of our participants is:’’
Trump Is a Hothead Who Is Doing a Bad Job’’.
Another example of a right-wing title is:’’ Here’s
why Donald Trump is doing so well’’. As one can see
there is a clear difference between the two articles
based on the title. We consider an article to be neutral
if it points out facts instead of having subjective
statements. An example of this is ‘’How is Donald
Trump actually doing?’’. If it is unclear from the title
what kind of sentiment the article contains, we will
look at the article to find out whether it has any
politically biased views or not. After looking at all
the 6 results from a specific participant, if there are 2
or more articles which are left-wing or right-wing we
consider this person to have politically biased results
for either left-wing or right-wing views. If it doesn’t
have 2 or more politically biased views it will be seen
as neutral.

3.4 Expectations
In theory, we expect that if a person is more
leaning towards the right-wing ideology, he should
be given search results which are against the
immigration of the refugees in Europe. Those who
are supporters of the left-wing ideology should have
search results which put the refugees in Europe in a
much more positive light, such as listing the benefits
of having them in Europe.
The same goes with the query about Trump, the
people who identify themselves as a supporter of the
‘’right’’, should get results praising Trump while the
people who identify themselves as a supporter of the
‘’left’’, should get the opposite results, which are
predominantly criticizing Trump.

4. RESULTS
In this chapter we will discuss the research
results. First, we will elaborate on the demographic
characteristics of the sample. After this, we will go
more in depth into the actual search engine results
and we will discuss whether there is any sign of
manipulation existent due to the personalization of
search engines.

4.1 Demographic characteristics
Our sample consists out of a total of 89
participants. All of these have stated that they didn’t
remove their cookies in at least one month. This is
important so that the search engine will give the
respondents personalized search results. 48 of these
participants are male while the other 42 are female.
The age of all our participants is between 18 and 29
with the average age being 22. We have participants
from 8 different countries. However, most of them
reside currently in the Netherlands.

4.2 DuckDuckGo results
First, we will look at the results from
DuckDuckGo and find out whether the results are
politically biased in any way. According to the
creators of DuckDuckGo, if multiple people type in
the same query in the search bar, they should receive
the same results [6]. However, based on the results
from our research we found this not to be correct.

Figure 2. Participant #5 search results for query #1
on DuckDuckGo

Figure 3. Participant #16 search results for query #1
on DuckDuckGo
As one can see in the two figures above, figure
2 has results which contain more left-wing views. In
fact, the results shown are biased against Trump. In
figure 3 this is not the case and it even has two
different results which have right-wing views and are
praising Trump of how well he actually is doing so
far. According to the results from our survey, we
found out that for the query ‘’how is Trump doing
overall’’, 46% of the results where leftist, 33% of the
results were neutral while the remaining 23% were
rightist. For the second query however, ‘’European
refugee crisis result’’, we found out that 25% of the
results contained left-wing views, while 75%
contained neutral results. There was no significant
bias in the second query.
Query #1

Query #2

Left-wing
views

46% (N=41)

25% (N=22)

Neutral views

33% (N=29)

75% (N=67)

Right-wing
views

21% (N=19)

0%

Figure 4. Query results on DuckDuckGo

4.3 Google results
Looking at the results from the first search
query, ‘’How is trump doing overall’’, we found out
that 80% of the respondents had left-wing views,
which were views opposing Trump. 18% of the
respondents were neutral, which means they weren’t
either in favor or opposing Trump. The remaining
2% have right-wing views, which means that they are
supporters of Trump. Political views changed
slightly for the second query, ‘’european refugee
crisis result’’. There we found out that 38% of the
respondents had left-wing views, 48% of them had
neutral views and 14% had right-wing views.

As one can see from figure 6, the article which
is called ‘’Donald Trump Is the Most Successful
First-Year President of All Time’’ is not shown for
participant #13, as can be seen in figure 7.

80
60
40
20
0
1
Left-wing

2
Neutral

For the second query, ‘’European refugee crisis
result’’, the results were rather similar to the first
query. 12% of the participants received results which
were more right-wing, showing results from charities
and as well as articles which are saying that Europe
isn’t doing enough to help the refugees in Europe.

Right-wing

Figure 5. Political views of the respondents (N=89)
For the first query, ‘’how is Trump doing
overall’’, we found out that only 2% of the results
were biased towards left-wing ideology. 76% of the
results were neutral and showed predominantly facts
instead of having views which were left-wing or
right-wing, in other words, against Trump or
supporting Trump. The last 22% of the results
contained a slightly more right-wing view of Trump,
showing articles such as ‘’Donald Trump Is the Most
Successful First-Year President of All Time’’.
Figure 8. Participant #61 Left-wing results for query
#2 on Google

Figure 6. Participant #57 Right-wing results for
query #1 on Google

The figure above shows results which are rather
left-wing in nature as there is one article which is
blaming Europe for the refugee crisis. 67% of the
participants had results which were mostly neutral,
giving facts and other data which is not biased in a
political view. The remaining 21% of the respondents
of our survey had results which were more leaning
towards the right-wing ideology. One of the main
articles those people had was ‘’How is the migrant
crisis dividing EU countries?’’. This article explains
the negative effects the refugees have on European
countries.

Figure 9. Participant #4 Right-wing results for query
#2 on Google

Figure 7. Participant #13 Neutral results for query
#1 on Google

Query #1

Query #2

Left-wing
views

2% (N=2)

12% (N=11)

Neutral views

76% (N=68)

67% (N=60)

Right-wing
views

22% (N=19)

21% (N=17)

Figure 10. Query results on Google

4.3.1

Google
Search
Manipulation Results

Engine

In order to find out whether Google could
possibly be manipulating its users, we will look at our
participants whose results were biased towards either
left-wing or right-wing views. Those participants
who had neutral results won’t be used for this part of
the research.
For query #1, which is ‘’how is Trump doing
overall’’, there were a total of 21 respondents who
had results which were biased towards either leftwing or right-wing views. Out of those people, 14%
had their views enforced. In example, people who are
against Trump got left-wing results and those that
support Trump got right-wing results in only 14% of
the cases. The remaining 86% showed no sign of
manipulation, because they didn’t have their views
enforced based on the given results.
For query #2, which is ‘’European refugee crisis
result’’, there were 28 respondents who had biased
results in favor of either political side. Here 36% of
them had their views enforced while the other 64%
didn’t.
Views
enforced
Views
enforced

not

Query #1

Query #2

14% (N=3)

36% (N=10)

86% (N=18)

64% (N=18)

Figure 11. Results of political views enforced on
Google

5. DISCUSSION
In this study, we questioned how many of our
respondents used Google as their main search engine.
We found that 100% of our participants stated that
Google was their main search engine. Out of these
people, only 5% weren’t aware of the fact that
Google personalized its results for each user. We
have discovered that the results from Google had a
chance of over 25% to be politically biased.
However, we found no clear connection between
personalization and the results being politically
biased. Most of the participants which received
politically biased results, didn’t have their views
enforced, namely 86% of them in the first query and
64% in the second query. In general, the participants
which stated in the survey that they had negative
thoughts about Trump didn’t get more results which
were left-wing than the ones who had positive
thoughts about him. Same goes for the query about
the European refugee crisis, the people who have
positive thoughts about it didn’t receive more leftwing articles than those who have negative thoughts.

As such, we can’t proof that Google provides onesided results based on one’s political preference
because there is no explicit evidence.
Furthermore, we focused on DuckDuckGo to
find out whether the search results could potentially
be biased. Contrary to the believe that DuckDuckGo
should provide the same results if different people
type in the same query, we discovered this not to be
true. We have found that different people had
different results. This discovery wasn’t very strange
due to the fact that we had participants from different
countries. However, we were surprised by the fact
that the search results on DuckDuckGo were, for at
least the query about Trump, to some extent
politically biased. We found out that for the first
query, 46% of the results were biased towards the
leftist political ideology while 21% contained results
which were mostly rightist. The remaining 33%
contained neutral results. This result was unexpected
due to the fact that DuckDuckGo doesn’t collect any
data and thus shouldn’t have results which might
have been a result of the so-called ‘’filter bubble’’.
For the second query, which was about the European
refugee crisis, there was a slightly smaller bias
visible compared to the first query. Only 25% of the
results were leaning more towards the leftist
ideology. While, on the other hand, 75% of the
results were considered to be neutral. It is worth
noting that out of the 89 participants used for the
survey, 76% of them were from the Netherlands. Due
to this, there is a 24% possibility that the different
results on DuckDuckGo can be explained due to the
other participants residing in another country instead
of the Netherlands. It’s also worth noting that the
participants took our survey in a time span of 2
weeks, so this might have some effect for the results
of DuckDuckGo.

5.1 Conclusion
There have been numerous debates on whether
search engines, especially Google are giving
politically biased search results. The primary concern
in this paper was to find out whether people could get
manipulated by the search engines due to
personalized results, however based on the findings
of this research there is no evidence to prove this. As
this research has shown, search engines which claim
to not collect any data about its users such as
DuckDuckGo still can provide politically biased
results. Even though it seems like personalization
does not directly manipulate its users by enforcing
their views, it can still happen. Moreover, people
should be aware when looking up information on the
internet and they shouldn’t settle for the first results
they see, but instead dig deeper to avoid stumbling
upon possible biases.

5.2 Limitations
There were several limitations in this study.
First, even though we originally had over 120
participants who conducted our survey, we could
only use 89 of them since others didn’t fit all our
criteria. Second, we have no way of finding out
whether the participants which have been used for
this survey actually didn’t delete their cookies in a
month. They might have deleted them by accident or
they forgot that they deleted them in the first place.

As a result of this, their search results might not be
that personalized after all. Lastly, for the first query,
‘’how is Trump doing overall’’, more than 80% of
our survey respondents stated that their opinion about
Trump is ‘’negative’’ or ‘’very negative’’. However,
considering the fact that our participants knew that
their results would be used for the research, they
could have not stated their true opinion about him.
Lastly, the web page classification is conducted by
ourselves instead of the participants. This means that
the results could unintentionally be biased.

6. ACKNOWLEDGEMENTS
We would like to thank Fons Wijnhoven for his
guidance throughout this research as well as Jeanna
van Haren and Rebeca Schafer for their help in
finding participants for the survey.

7. REFERENCES
[1] Aylin Caliskan, Joanna J Bryson, and Arvind
Narayanan.
2017.
Semantics
derived
automatically from language corpora contain
human-like biases. Science 356, 6334 (2017),
183–186.
[2] A. Nuri Yurdusev, ‘Level of Analysis and Unit
of Analysis: A Case for Distinction’,
Millennium: Journal of International Studies
(Vol.22, No.1, Spring 1993), 77–88
[3] Burger, V., Hirth, M., Hoûfeld, T., & Tran-Gia,
P. (2016). Principles of Information Neutrality
and counter measures against biased
information. Paper presented at the Lecture
Notes in Informatics (LNI), Proceedings Series of the Gesellschaft fur Informatik (GI).
[4] Buys, Jon (July 10, 2010). "DuckDuckGo: A
New Search Engine Built from Open Source".
GigaOM OStatic blog.
[5] Christian Sandvig, Kevin Hamilton, Karrie
Karahalios, and Cedric Langbort. 2014.
Auditing algorithms: Research methods for
detecting discrimination on internet platforms.
In Proceedings of “Data and Discrimination:
Converting Critical Concerns into Productive
Inquiry”, a Productivereconference at the 64th
Annual Meeting of the International
Communication Association
[6] DuckDuckGo Privacy. (n.d.). Retrieved from
https://duckduckgo.com/privacy
[7] Google liberal bias: Study shows 40% of search
results lean left | CanIRank. (2017, August 13).
Retrieved
from
http://www.canirank.com/blog/analysis-ofpolitical-bias-in-internet-search-engine-results/
[8] Google Privacy | Why data protection matters.
(n.d.).
https://privacy.google.com/yourdata.html

[9] Hannak, A. Sapiezynski, P. Kakhki, A.M.
Krishnamurthy, B. Lazer, D. Mislove, A. and
Wilson, C. 2013. Measuring Personalization of
Web Search. In Proceedings of the 22nd
international conference on World Wide Web
(Rio de Janeiro, Brazil, May 13-17, 2013),
International World Wide Web Conferences
Steering Committee Republic and Canton of
Geneva, Switzerland, 527-538.
[10] Helberger, N., Karppinen, K., & D’Acunto, L.
(2018). Exposure diversity as a design principle
for recommender systems. Information
Communication and Society, 21(2), 191-207.
doi:10.1080/1369118X.2016.1271900
[11] Horling, B and Kulick, M. Personalized Search
for Everyone. Google Official Blog, 2009.
http://bit.ly/71RcmJ.
[12] HTTP cookies. (n.d.). Retrieved June 2, 2018,
from
https://developer.mozilla.org/enUS/docs/Web/HTTP/Cookies
[13] Leip D (2012) Dave Leip’s atlas of U.S.
presidential elections. Available at perma.cc/
G9YF-6CPE. Accessed June 30, 2015.
[14] Left wing | Definition of left wing in English by
Oxford Dictionaries. (n.d.). Retrieved June 2,
2018,
from
https://en.oxforddictionaries.com/definition/left
_wing
[15] Manipulation. (n.d.). Retrieved June 01, 2018,
from
https://dictionary.cambridge.org/dictionary/eng
lish/manipulation
[16] Nguyen, T. T., Hui, P.-M., Harper, F. M.,
Terveen, L., & Konstan, J. A. (2014). Exploring
the filter bubble: the effect of using
recommender systems on content diversity.
Paper presented at the Proceedings of the 23rd
international conference on World wide web,
Seoul, Korea.
[17] Personalized Search Graduates from Google
Labs. News from Google Blog, 2005.
http://bit.ly/Tndpgf.
[18] Reliability. (n.d.). Retrieved June 16, 2018,
from
https://www.merriamwebster.com/dictionary/reliability
[19] Robert Epstein and Ronald E Robertson. 2015.
The search engine manipulation effect (SEME)
and its possible impact on the outcomes of
elections. Proceedings of the National Academy
of Sciences 112, 33 (2015), E4512–E4521.
[20] Right wing | Definition of right wing in English
by Oxford Dictionaries. (n.d.). Retrieved June 2,
2018,
from
https://en.oxforddictionaries.com/definition/rig
ht_wing
[21] Unit of Observation. (n.d.). Retrieved June 2,
2018,
from
https://dimewiki.worldbank.org/wiki/Unit_of_
Observation
[21] Wijnhoven, F. (2017). Filter Bubble: Deception
or Convenience.

[22] Search Engine Market Share United States Of
America. (n.d.). Retrieved June 18, 2018, from
http://gs.statcounter.com/search-enginemarket-share/all/united-states-of-america
[23] Lucas D. Introna, Helen Nissenbaum (2000)
Shaping the Web: Why the Politics of Search
Engines Matters, The Information Society,
16:3, 169-185, DOI:
10.1080/01972240050133634

