stability
and
multigroup
fairness
in
ranking
with
uncertain
predictions
aleksandra
korolova
princeton
university
korolova@princeton.edu
arxiv
2402
09326v1
cs
lg
14
feb
2024
siddartha
devic
university
of
southern
california
devic@usc.edu
david
kempe
university
of
southern
california
david.m.kempe@gmail.com
vatsal
sharan
university
of
southern
california
vsharan@usc.edu
abstract
rankings
are
ubiquitous
across
many
applications
from
search
engines
to
hiring
committees
in
practice
many
rankings
are
derived
from
the
output
of
predictors
however
when
predictors
trained
for
classification
tasks
have
intrinsic
uncertainty
it
is
not
obvious
how
this
uncertainty
should
be
represented
in
the
derived
rankings
our
work
considers
ranking
functions
maps
from
individual
predictions
for
classification
task
to
distributions
over
rankings
we
focus
on
two
aspects
of
ranking
functions
stability
to
perturbations
in
predictions
and
fairness
towards
both
individuals
and
subgroups
not
only
is
stability
an
important
requirement
for
its
own
sake
but
as
we
show
it
composes
harmoniously
with
individual
fairness
in
the
sense
of
dwork
et
al
2012
while
deterministic
ranking
functions
cannot
be
stable
aside
from
trivial
scenarios
we
show
that
the
recently
proposed
uncertainty
aware
ua
ranking
functions
of
singh
et
al
2021
are
stable
our
main
result
is
that
ua
rankings
also
achieve
multigroup
fairness
through
successful
composition
with
multiaccurate
or
multicalibrated
predictors
our
work
demonstrates
that
ua
rankings
naturally
interpolate
between
group
and
individual
level
fairness
guarantees
while
simultaneously
satisfying
stability
guarantees
important
whenever
machine-learned
predictions
are
used
introduction
rankings
underpin
many
modern
systems
companies
rank
job
applications
geyik
et
al
2019
turbohire
2023
ad
marketplaces
rank
ads
to
serve
to
user
google
2023
and
social
media
platforms
and
feeds
rank
content
meta
2023
rankings
are
also
used
to
partially
automate
decision
making
in
settings
with
limited
resources
or
attention
span
such
as
job
candidate
interview
selections
or
ad
delivery
rankings
are
often
derived
from
predictions
generated
by
machine
learning
models
designed
and
deployed
on
relevant
classification
tasks
for
example
job
advertisement
platform
may
use
model
which
predicts
an
individual
relevance
score
for
each
job
they
apply
to
say
on
scale
from
to
corresponding
to
irrelevant
suitable
or
extremely
relevant
this
score
is
then
factored
into
the
platform
ranking
of
job
applicants
shown
to
company
recruiter
with
limited
time
budget
in
practice
machine
learning
models
often
predict
distributions
over
classes
instead
of
single
class
this
is
because
predictions
correspond
to
belief
about
what
the
future
may
possibly
hold
but
not
certainty
about
what
the
future
will
look
like
plethora
of
recent
research
in
model
calibration
guo
et
al
2017
gupta
and
ramdas
2022
minderer
et
al
2021
conformal
prediction
bastani
et
al
2022
jung
et
al
2023
and
uncertainty
quantification
angelopoulos
and
bates
2021
has
tackled
the
issue
of
ensuring
that
equal
contribution
the
order
of
these
authors
was
randomized
with
https://www.random.org/.
the
uncertainty
estimates
output
by
model
are
meaningful
rather
than
artifacts
of
any
particular
training
regime
with
uncertainty
inherent
in
predictions
we
argue
that
it
is
essential
to
revisit
the
question
of
how
to
meaningfully
convert
predictions
made
in
the
form
of
distributions
over
classes
into
rankings
without
any
uncertainty
for
example
if
one
had
access
to
an
oracle
for
the
future
it
would
usually
be
clear
what
ranking
should
look
like
meritocracy
would
suggest
that
one
always
places
the
more
suitable
candidates
higher
in
the
ranking
however
when
given
only
predictions
about
suitability
merit
with
intrinsic
uncertainty
the
approach
for
generating
meaningful
ranking
is
less
clear
after
all
one
must
choose
ranking
over
candidates
in
order
to
make
an
interview
decision
before
witnessing
the
exact
suitability
of
each
candidate
which
is
generally
only
observable
after
an
individual
works
in
the
job
for
months
or
even
years
since
an
uncertain
prediction
can
be
considered
prior
and
typically
imperfect
belief
on
the
qualifications
or
performance
of
any
given
individual
the
fundamental
task
of
designing
meaningful
ranking
algorithm
utilizing
these
predictions
must
be
reexamined
for
meaningful
derivation
of
rankings
from
predictors
we
consider
the
following
two
properties
to
be
essential
requirements
anonymity
all
individuals
must
be
treated
symmetrically
priori
if
the
predictions
are
permuted
then
the
ranking
is
permuted
according
to
the
same
permutation
stability
if
the
predictor
distribution
over
classes
changes
only
slightly
in
total
variation
distance
then
the
corresponding
induced
ranking
should
only
change
slightly
the
reason
for
requiring
anonymity
is
self-evident
it
rules
out
discrimination
on
the
basis
of
the
identity
of
individuals
stability
is
more
nuanced
it
articulates
desire
to
have
rankings
which
are
agnostic
to
small
amounts
of
noise
in
the
predictions
for
each
individual
in
deployed
applications
small
amount
of
variation
injected
by
seeded
training
test
data
set
split
or
randomized
training
procedure
can
introduce
noise
at
the
level
of
individual
predictions
ganesh
et
al
2023
furthermore
there
will
also
always
be
at
least
some
additional
noise
due
to
incomplete
data
entries
mistaken
inputs
etc
nettleton
et
al
2010
rankings
should
be
generally
agnostic
to
these
sources
of
noise
if
minute
noise
in
predictions
can
induce
large
changes
in
the
derived
ranking
the
ranking
cannot
be
very
meaningful
or
fair
to
begin
with
stability
can
therefore
be
interpreted
as
way
to
combat
micro-arbitrariness
of
rankings
induced
by
learned
predictors
cooper
et
al
2024
for
stability
to
be
meaningful
we
will
need
to
shift
our
focus
to
distributions
over
rankings
utilizing
randomness
to
deal
with
uncertainty
will
be
key
in
achieving
stability
anonymity
can
be
construed
as
fairness
notion
but
it
is
very
minimal
one
fairness
in
stronger
sense
has
been
the
focus
of
much
recent
work
both
in
the
context
of
ranking
see
singh
and
joachims
2018
2019
and
in
the
context
of
classifiers
predictors
see
awasthi
et
al
2020
caton
and
haas
2020
dwork
et
al
2012
hardt
et
al
2016
as
ml-based
predictors
are
often
used
in
order
to
ultimately
produce
rankings
wang
and
chen
2012
it
is
natural
desideratum
that
the
ranking
function
preserve
fairness
guarantees
of
the
underlying
predictor
this
ensures
that
no
additional
unfairness
is
introduced
in
post-processing
the
classifier
output
as
we
will
see
not
all
ranking
functions
satisfy
such
fairness
composition
properties
1.1
our
contributions
we
focus
on
scenarios
in
which
individuals
scored
by
predictor
must
be
presented
to
decision
maker
in
linear
order
or
ranking
we
assume
that
the
predictions
take
the
form
of
distributions
over
classes
modeling
inherent
uncertainty
in
the
underlying
ground
truth
or
data
in
section
we
define
ranking
function
as
map
from
such
probabilistic
predictions
to
distribution
over
rankings
figure
illustrates
this
setting
with
an
example
our
first
and
very
immediate
see
section
3.1
result
is
that
stability
naturally
composes
with
individual
fairness
dwork
et
al
2012
if
the
predictor
is
individually
fair
and
the
ranking
function
is
stable
then
the
coding
work
history
ability
3.0
excellent
applicable
3.5
poor
not
applicable
4.0
excellent
applicable
rank
student
gpa
observations
rank
prob
ml
algorithm
irrelevant
suitable
extremely
relevant
candidate
relevance
classes
uncertain
predictions
ranking
function
this
work
rank
prob
0.6
0.3
0.07
0.03
distribution
over
rankings
figure
an
overview
of
our
setting
using
students
being
ranked
by
an
employer
for
potential
interviews
observations
given
by
the
students
resume
and
coding
abilities
are
fed
into
machine
learning
algorithm
which
produces
distributions
over
the
relevance
classes
irrelevant
suitable
extremely
relevant
for
each
candidate
then
ranking
function
takes
as
input
these
uncertain
predictions
to
produce
distribution
over
rankings
of
the
three
candidates
although
it
may
appear
that
x3
is
the
most
qualified
or
relevant
due
to
inherent
uncertainty
in
observations
ranking
function
may
place
x1
or
x2
at
rank
one
with
non-zero
probability
composition
satisfies
natural
generalization
of
individual
fairness
to
rankings
this
result
further
confirms
that
stability
is
desirable
property
for
ranking
function
in
light
of
the
desirability
of
stability
we
next
investigate
which
ranking
functions
are
stable
deterministic
ranking
functions
are
natural
and
popular
unfortunately
we
show
section
3.2
that
the
only
stable
deterministic
ranking
functions
are
constant
trivial
functions
that
output
the
same
ranking
regardless
of
the
predictions
further
deterministic
ranking
functions
cannot
be
anonymous
thus
one
must
choose
between
stability
anonymity
and
determinism
providing
significant
evidence
in
favor
of
randomization
with
randomization
stability
and
anonymity
both
become
achievable
we
show
section
3.3
that
natural
adaptation
of
the
uncertainty
aware
ua
ranking
functions
of
devic
et
al
2023
singh
et
al
2021
to
the
case
of
multiclass
predictions
of
the
classifier
is
indeed
anonymous
and
stable
we
then
investigate
the
fairness
guarantees
of
ua
ranking
in
more
depth
and
prove
section
our
main
result
ua
ranking
naturally
preserves
multiaccuracy
and
multicalibration
guarantees1
he
bert-johnson
et
al
2018
kim
et
al
2019
we
show
that
when
the
predictor
is
multiaccurate
or
multicalibrated
then
the
ranking
distribution
output
by
ua
ranking
satisfies
natural
generalization
of
multiaccuracy
resp
multicalibration
towards
the
same
groups
this
result
can
be
interpreted
as
an
interpolation
between
individual
and
group
fairness
notions
for
ranking
as
the
set
of
subgroups
the
predictor
is
multicalibrated
against
becomes
more
refined
the
ua
ranking
for
predictions
more
accurately
reflects
the
ua
ranking
induced
by
the
unknown
ground
truth
classes
of
individuals
to
investigate
the
tradeoff
between
fairness
stability
and
utility
in
section
we
introduce
standard
ranking
utility
model
and
show
that
the
utility
optimal
ranking
function
cannot
hope
to
achieve
stability
or
fairness
guarantees
similar
to
ua
we
also
investigate
ranking
function
which
provides
guaranteed
tradeoff
between
stability
fairness
and
utility
we
believe
that
this
will
be
useful
to
practitioners
interested
in
employing
stable
rankings
in
practice
finally
in
section
we
corroborate
our
theoretical
results
with
experimental
evidence
while
various
notions
of
stability
in
rankings
have
been
proposed
before
see
asudeh
et
al
2018
our
framework
is
unique
in
that
it
frames
the
rankings
as
induced
by
predictions
of
some
machine
learning
algorithm
this
ties
our
work
more
closely
to
modern
applications
another
benefit
of
our
definition
of
stability
is
that
it
makes
progress
towards
the
broader
goal
of
rankings
which
compose
with
fair
predictors
multiaccuracy
requires
that
the
uncertainty
estimates
of
predictor
are
unbiased
over
set
of
subgroups
combating
discrimination
between
groups
multicalibration
guarantees
that
the
estimates
are
also
calibrated
over
subgroups
combating
discrimination
between
and
within
groups
these
are
arguably
the
most
popular
notions
of
fairness
in
settings
with
uncertain
predictions
where
predictors
output
uncertainty
estimates
since
obtaining
meaningful
or
accurate
estimates
at
the
level
of
individuals
is
usually
computationally
and
statistically
infeasible
1.2
related
work
fairness
in
ranking
by
far
the
most
relevant
related
work
is
of
dwork
et
al
2019
who
are
also
interested
in
fair
rankings
induced
by
predictors
but
importantly
restrict
their
focus
to
only
deterministic
rankings
where
better
prediction
means
that
an
individual
will
always
receive
higher
rank
induced
by
probabilistic
binary
predictors
indeed
their
motivating
example
is
setting
in
which
small
perturbations
to
predictor
can
massively
impact
an
induced
ranking
by
requiring
stability
of
ranking
functions
we
approach
this
problem
fundamentally
differently
we
allow
and
indeed
require
non-deterministic
rankings
the
multiaccuracy
and
multicalibration
guarantees
of
dwork
et
al
2019
for
induced
rankings
from
predictors
are
similar
in
flavor
to
ours
however
fundamental
difference
is
that
we
show
this
guarantee
to
be
compatible
with
stability
and
furthermore
that
our
guarantees
hold
for
each
position
in
the
ranking
at
the
intersection
of
group
and
individually
fair
rankings
the
work
of
gorantla
et
al
2023
is
most
similar
to
ours
they
show
that
one
can
sample
from
distribution
over
rankings
which
is
simultaneously
individually
and
group
fair
in
proportional
representation
sense
for
laminar
groups
in
contrast
our
group
fairness
hinges
on
the
group-level
statistical
constraints
of
multicalibration
imposed
on
the
underlying
predictor
which
instead
allow
for
potentially
arbitrarily
overlapping
groups
garcı
a-soriano
and
bonchi
2021
also
work
at
the
intersection
of
group
and
individual
fairness
in
rankings
although
their
group
fairness
constraints
require
that
certain
groups
get
representation
amongst
the
top-k
positions
in
the
ranking
for
all
both
of
these
works
and
ours
more
broadly
explore
the
interplay
between
group
and
individual
fairness
constraints
there
is
far
too
rich
literature
on
group
and
individually
fair
rankings
to
cover
here
so
we
restrict
attention
to
only
works
related
to
uncertainty
and
fairness
for
more
comprehensive
overview
the
interested
reader
is
referred
to
the
survey
of
zehlike
et
al
2021
uncertainty
in
rankings
rastogi
and
joachims
2023
investigate
fairness
in
uncertainty
aware
rankings
when
the
uncertainty
estimates
themselves
may
be
biased
for
different
subgroups
we
work
in
the
simpler
setting
in
which
we
assume
that
uncertainty
estimates
are
themselves
unbiased
mehrotra
and
celis
2021
and
mehrotra
and
vishnoi
2022
investigate
uncertain
protected
attributes
in
the
settings
of
subset
selection
and
ranking
respectively
we
do
not
assume
that
anything
is
known
about
individuals
protected
attributes
instead
we
only
require
utilizing
the
output
of
group-fair
multiaccurate
predictor
in
section
training
such
predictor
however
will
require
certain
knowledge
of
protected
attributes
see
kim
et
al
2019
independently
of
the
line
of
work
on
ua
rankings
devic
et
al
2023
singh
et
al
2021
shen
et
al
2023
propose
ranked
proportionality
which
shares
similar
definition
their
work
is
in
the
more
general
setting
of
the
assignment
problem
with
uncertain
priorities
and
they
focus
on
algorithmic
approaches
for
achieving
variety
of
fairness
notions
simultaneously
tang
et
al
2023
also
consider
the
fair
assignment
problem
and
its
connections
with
calibration
our
work
is
instead
focused
on
proving
certain
properties
of
rankings
induced
by
predictors
predictors
which
when
stated
in
the
language
of
shen
et
al
2023
may
induce
uncertain
priorities
more
generally
in
fairness
in
uncertain
decision
making
tahir
et
al
2023
consider
how
different
sources
of
uncertainty
can
impact
fairness
guo
et
al
2023
utilize
conformal
prediction
techniques
to
feasibly
train
fair
learn-to-rank
models
and
are
also
partially
interested
in
similar
notion
of
stability
as
ours
cohen
et
al
2021
guiver
and
snelson
2008
penha
and
hauff
2021
soliman
and
ilyas
2009
yang
et
al
2022
all
also
work
in
the
area
of
ranking
with
uncertain
scores
or
preferences
in
contrast
to
these
works
we
simultaneously
consider
uncertainty
fairness
and
stability
of
rankings
heuss
et
al
2023
also
model
uncertainty
with
bayesian
framework
that
allows
them
to
apply
their
method
post-hoc
to
arbitrary
retrieval
models
in
hopes
of
reducing
bias
perhaps
most
relevant
is
the
work
of
yang
et
al
2023
who
examine
rankings
utility
fairness
and
uncertainty
simultaneously
they
find
that
modeling
uncertainty
can
actually
improve
utility
in
some
cases
relative
to
other
fair
ranking
metrics
calibration
and
ranking
in
section
we
work
with
multi
calibrated
predictors
within
the
ranking
community
there
has
been
some
investigation
into
the
impact
of
calibration
of
ranking
models
menon
et
al
2012
initiated
this
study
attempting
to
obtain
predicted
probabilities
based
on
the
score
output
of
ranking
model
kweon
et
al
2022
work
in
similar
setting
but
refine
the
method
of
obtaining
predicted
probabilities
yan
et
al
2022
work
in
the
score-and-sort
model
where
scoring
function
is
learned
to
score
each
individual
and
ranking
function
is
derived
by
sorting
the
individuals
according
to
their
scores
yan
et
al
2022
aim
to
ensure
that
the
scoring
model
is
calibrated
with
respect
to
some
external
property
these
works
all
attempt
to
infer
uncertainty
from
the
scoring
function
whereas
we
assume
that
uncertainty
is
given
in
the
form
of
machine-learned
predictions
busa-fekete
et
al
2011
show
that
calibration
for
ranking
functions
can
help
increase
diversity
of
rankings
more
recently
diciccio
et
al
2023
show
that
conditional
predictive
parity
notion
which
appears
to
be
related
to
multicalibration
can
help
decrease
bias
in
rankings
these
works
all
highlight
the
benefits
of
using
calibrated
predictive
models
for
ranking
outside
of
the
guarantees
that
we
provide
korevaar
et
al
2023
relate
calibration
and
exposure
in
rankings
by
comparing
the
rankings
attained
by
subgroups
with
similar
score
distributions
stability
in
rankings
in
the
information
retrieval
literature
asudeh
et
al
2018
also
study
the
notion
of
stability
for
rankings
they
work
in
setting
where
score
is
calculated
based
on
weighted
sum
of
features
of
each
item
and
stability
is
then
with
respect
to
small
changes
of
these
weights
however
their
notion
of
stability
is
based
on
geometric
intuition
for
their
scoring
function
and
its
dual
and
only
holds
for
any
fixed
data
set
they
furthermore
state
that
stability
is
not
property
of
their
scoring
function
particular
weighted
sum
over
features
in
contrast
we
are
explicitly
defining
stability
as
property
of
our
ranking
function
which
maps
from
any
set
of
predictions
data
set
to
randomized
ranking
oh
et
al
2022
also
study
the
sensitivity
of
rankings
however
their
context
is
slightly
different
they
examine
stability
with
respect
to
user
interactions
with
recommendation
system
in
very
recent
followup
work
oh
et
al
2024
the
same
authors
also
provide
an
algorithm
to
empirically
achieve
stability
in
that
setting
bruch
et
al
2020
provide
experimental
evidence
showing
that
randomization
can
help
stability
which
they
define
as
robustness
during
the
training
of
learning-to-rank
models
our
theoretical
results
are
complementary
and
corroborate
the
empirical
evidence
of
bruch
et
al
2020
that
randomized
rankings
are
more
robust
to
noise
than
deterministic
ones
finally
in
terms
of
the
interplay
between
prediction
systems
and
rankings
the
work
of
narasimhan
et
al
2020
is
perhaps
most
relevant
they
show
that
the
ranking
problem
can
be
considered
as
pairwise
binary
classification
problem
between
items
to
determine
which
item
should
be
placed
at
higher
rank
notation
and
preliminaries
we
write
vectors
in
boldface
we
use
the
standard
notation
to
denote
the
vector
with
the
ith
coordinate
removed
for
random
event
we
write
1e
for
the
indicator
function
which
is
if
happens
and
otherwise
the
total
variation
distance
of
two
measures
is
defined
as
the
maximum
difference
in
probability
for
any
event
under
the
two
measures
dtv
maxe
we
will
use
the
entry-wise
matrix
norms
mi
and
maxi
mi
denotes
set
of
individuals
it
contains
humans
ads
service
requests
or
other
entities
towards
whom
fairness
is
desired
the
elements
of
can
be
labeled
with
labels
from
the
label
set
we
work
in
the
multiclass
ordinal
classification
setting
where
the
labels
are
sorted
from
most
to
least
preferred
as
this
notation
corresponds
with
the
intuition
that
possessing
higher
merit
score
class
is
valued
more
by
decision
maker
common
special
case
is
binary
labels
where
label
might
represent
irrelevant
unsuitable
while
label
represents
relevant
suitable
2.1
predictors
we
focus
on
predictors
in
the
multiclass
setting
which
output
distributions
over
labels
let
denote
the
set
of
all
distributions
on
probabilistic
predictor
is
function
mapping
data
points
to
distributions
over
labels
we
let
denote
the
vector
of
probabilities
that
the
predictor
assigns
rather
than
induced
norms
which
are
typically
described
by
the
same
notation
to
individual
for
any
class
pℓ
denotes
the
probability
of
that
class
as
an
example
for
probabilistic
binary
predictor
in
the
context
of
determining
whether
candidate
is
qualified
for
job
p2
would
capture
the
probability
that
the
individual
is
qualified
while
p1
p2
is
the
probability
that
is
unqualified
rankings
involve
multiple
individuals
and
hence
multiple
predictions
prediction
for
individuals
is
an
matrix
where
each
row
corresponds
to
the
distribution
over
labels
for
particular
individual
we
define
pn
to
be
the
set
of
all
predictions
for
individuals
the
set
of
all
matrices
where
each
row
is
distribution
we
will
frequently
consider
the
case
in
which
predictor
for
single
individuals
is
applied
to
each
of
individuals
separately
for
vector
x1
xn
of
individuals
we
write
x1
xn
for
the
matrix
of
predictions
for
all
of
the
individuals
we
use
the
random
variable
λx
to
denote
the
random
label
of
individual
when
pwe
specifically
consider
an
individual
xi
in
vector
of
individuals
we
abbreviate
λi
λxi
we
write
1λi
for
the
random
variable
that
is
the
number
of
individuals
with
label
when
we
use
this
notation
the
domain
of
will
be
pl
clear
from
the
context
we
extend
this
notation
to
write
for
the
number
of
individuals
with
label
or
better
and
similarly
pfor
we
will
sometimes
restrict
the
count
to
individuals
in
particular
set
and
then
write
ns
1λi
and
similarly
for
the
derived
notation
in
particular
we
use
the
notation
for
the
number
of
individuals
other
than
with
particular
label
2.2
rankings
and
ranking
functions
principal
would
like
to
use
predictions
provided
by
predictor
to
output
distribution
over
rankings
as
examples
consider
site
or
service
such
as
linkedin
providing
an
employer
with
ranked
list
of
applicants
to
interview
geyik
et
al
2019
or
an
online
platform
deciding
on
the
order
in
which
to
display
ads
or
vendors
to
visitor
in
these
settings
because
attention
is
limited
resource
common
approach
would
have
the
principal
rank
the
items
in
question
based
on
some
function
of
the
predictions
ranking
is
total
order
on
individuals
randomized
ranking
is
distribution
over
rankings
let
mn
ds
denote
the
set
of
all
doubly
stochastic
matrices
each
matrix
mds
represents
randomized
ranking
over
individuals
where
mi
is
the
probability
with
which
individual
is
ranked
in
position
when
reasoning
about
random
rankings
we
use
ri
to
denote
the
random
event
that
individual
receives
position
in
the
ranking
we
refer
to
mappings
from
predictions
to
randomized
rankings
as
ranking
functions
definition
ranking
function
pn
mn
ds
maps
predictions
over
labels
on
data
set
of
individuals
to
randomized
ranking
of
those
individuals
by
focusing
on
ranking
functions
we
implicitly
state
that
the
principal
interacts
with
the
data
set
only
through
the
predictions
over
labels
that
is
we
do
not
consider
listwise
learning-to-rank
schemes
such
as
cao
et
al
2007
xu
and
li
2007
in
which
the
principal
directly
learns
function
mapping
data
sets
of
individuals
features
to
rankings
2.3
desiderata
of
ranking
functions
while
ranking
functions
could
be
very
general
there
are
natural
requirements
that
make
them
reasonable
to
be
used
in
particular
we
focus
on
the
following
basic
properties
definition
anonymity
ranking
function
pn
mn
ds
is
anonymous
if
every
permutation
of
the
predictions
for
individuals
results
in
an
identical
permutation
of
the
individuals
ranks
anonymity
states
that
the
outcome
for
an
individual
depends
only
on
their
and
everyone
else
prediction
but
not
on
the
index
at
which
the
individual
appeared
in
the
data
set
on
their
identity
as
such
it
is
an
essential
fairness
requirement
in
virtually
all
settings
more
precisely
it
represents
the
marginal
probabilities
of
the
distribution
which
can
typically
be
implemented
by
many
different
distributions
over
rankings
we
assume
that
individuals
care
only
about
the
probabilities
with
which
they
are
ranked
in
each
position
in
which
case
marginal
distributions
sufficiently
capture
fairness
second
essential
property
of
ranking
functions
is
stability
that
small
changes
in
the
predictions
only
lead
to
small
changes
in
the
rankings
definition
stability
fix
and
ranking
function
pn
mn
ds
is
γ-stable
if
for
all
predictions
pn
this
is
particularly
important
when
the
predictions
are
the
result
of
ml-based
training
methods
which
will
always
contain
non-trivial
amounts
of
noise
indeed
the
lack
of
stability
is
well-documented
and
problematic
aspect
of
many
ml-systems
and
has
been
shown
not
only
within
the
fairness
literature
cooper
et
al
2024
but
has
long
been
concern
for
image
classification
models
goodfellow
et
al
2015
and
more
recently
also
llms
zou
et
al
2023
predictions
and
rankings
we
first
show
useful
fairness
consequences
of
stability
combining
stable
ranking
function
with
an
individually
fair
predictor
results
in
fair
ranking
outcomes
we
then
show
that
stability
and
anonymity
are
fundamentally
at
odds
with
determinism
only
constant
deterministic
ranking
functions
are
stable
and
no
deterministic
ranking
function
is
anonymous
this
establishes
that
randomization
is
inherently
necessary
for
ranking
function
to
be
meaningful
anonymous
and
stable
we
then
present
our
adaptation
of
the
ua
ranking
function
of
singh
et
al
2021
and
show
that
it
is
anonymous
and
stable
3.1
consequences
of
stability
stability
implies
that
small
changes
in
predictions
do
not
change
the
distribution
over
rankings
much
this
has
two
immediate
but
noteworthy
consequences
if
the
predictions
are
made
by
an
individually
fair
predictor
then
similar
individuals
will
be
ranked
similarly
and
as
the
predictions
approach
ground
truth
the
ranking
distribution
produced
by
the
ranking
function
approaches
the
rankings
under
the
ground
truth
to
formalize
the
first
claim
we
recall
the
seminal
definition
of
an
individually
fair
predictor
dwork
et
al
2012
this
notion
assumes
metric
defined
on
capturing
relevant
measure
of
similarity
between
individuals
for
probabilistic
predictor
is
individually
fair
if
for
all
proposition
let
be
individually
fair
predictor
and
pn
mn
ds
an
anonymous
and
γ-stable
ranking
function
given
data
set
of
individuals
xi
and
their
associated
predictions
xi
pn
let
be
the
ith
and
th
rows
of
respectively
then
2βγ
xi
xj
proof
the
proof
is
straightforward
application
of
γ-stability
with
respect
to
the
given
prediction
matrix
and
matrix
where
is
exactly
but
with
rows
and
swapped
requiring
the
anonymity
condition
this
combined
with
the
definition
of
individual
fairness
for
completes
the
proof
the
result
can
be
interpreted
as
composition
guarantee
for
anonymous
and
stable
rankings
with
individually
fair
predictors
if
are
simultaneously
in
data
set
the
difference
in
their
distributions
over
rankings
can
be
at
most
proportional
to
their
dissimilarity
under
the
metric
another
interpretation
is
the
following
stability
and
individual
fairness
are
both
lipschitz
conditions
and
composition
of
lipschitzness
implies
that
an
individually
fair
predictor
combined
with
stable
ranking
will
induce
an
individually
fair
ranking
another
very
straightforward
but
desirable
consequence
of
stability
is
obtained
by
considering
one
prediction
to
be
ground
truth
and
the
other
obtained
from
learned
classifier
corollary
let
be
the
ground
truth
label
distribution
for
individual
and
the
learned
predictor
assume
that
is
ϵ-accurate
satisfying
that
for
all
then
any
γ-stable
ranking
function
guarantees
that
nϵ
for
all
put
differently
for
any
stable
ranking
function
accurate
individual
level
uncertainty
estimates
relative
to
ground
truth
will
induce
accurate
individual
level
rankings
although
somewhat
obvious
we
highlight
this
property
of
stability
since
the
ground
truth
approach
is
often
central
assumption
in
the
study
of
machine
learned
predictors
shalev-shwartz
and
ben-david
2014
3.2
stability
and
determinism
are
incompatible
third
property
which
most
rankings
used
in
practice
possess
and
which
is
often
considered
desirable
by
practitioners
is
determinism
that
for
given
inputs
only
one
ranking
rather
than
distribution
over
rankings
can
result
definition
determinism
ranking
function
pn
mn
ds
is
deterministic
iff
for
all
pn
the
resulting
distribution
over
rankings
has
only
entries
in
perhaps
the
most
well-known
deterministic
ranking
function
is
given
by
the
probability
ranking
principle
prp
of
robertson
1977
in
the
setting
with
binary
predictions
this
ranking
function
sorts
individuals
by
decreasing
probability
of
belonging
to
class
being
qualified
naturally
one
may
ask
whether
deterministic
ranking
function
like
the
prp
can
be
stable
or
anonymous
unfortunately
neither
is
possible
as
captured
by
the
following
proposition
no
deterministic
ranking
function
pn
mn
ds
is
anonymous
furthermore
any
deterministic
and
stable
ranking
function
must
be
constant
in
the
sense
that
im
the
ranking
function
outputs
the
same
ranking
for
all
input
predictions
proof
to
prove
the
impossibility
of
anonymity
consider
any
prediction
matrix
with
identical
predictions
for
each
individual
then
any
deterministic
ranking
function
must
order
the
individuals
based
only
on
their
indices
in
since
they
all
have
identical
predictions
for
any
permutation
let
pσ
represent
applying
permutation
to
the
rows
of
since
the
ranking
function
can
only
depend
on
the
input
matrix
and
is
deterministic
we
have
that
pσ
however
by
the
definition
of
anonymity
definition
the
permutation
on
the
rows
of
should
produce
the
permutation
on
the
individuals
in
the
resulting
ranking
which
is
contradiction
therefore
is
not
anonymous
to
prove
the
instability
result
we
prove
the
contrapositive
let
be
deterministic
and
non-constant
we
will
show
that
is
not
stable
because
is
non-constant
there
exist
pn
with
consider
the
straight
line
βp
for
because
pn
is
convex
pn
for
all
let
inf
is
well-defined
because
by
definition
for
all
and
if
then
on
the
other
hand
by
the
definition
of
the
infimum
for
every
there
is
with
thus
we
obtain
arbitrarily
close
pairs
with
because
is
deterministic
all
entries
of
and
are
in
implying
that
on
the
other
hand
2δ
as
this
implies
that
is
not
stable
completing
the
proof
we
remark
that
the
instability
portion
of
the
proof
did
not
rely
on
considering
straight
line
by
considering
any
path
curve
in
rn
connecting
and
its
parametrization
by
the
exact
same
proof
still
works
this
shows
that
even
if
we
consider
only
subset
of
possible
predictions
so
long
as
the
subset
is
path-connected4
deterministic
stable
ranking
function
must
be
constant
this
extends
the
proposition
to
settings
where
prediction
strategies
may
output
only
certain
path-connected
subsets
of
predictions
due
to
for
example
intrinsic
preferences
or
implicit
bias
of
particular
learning
algorithm
proposition
formalizes
the
intuition
that
randomness
is
required
to
achieve
stability
indeed
the
main
results
of
our
work
also
show
that
randomization
and
the
resulting
stability
are
crucial
for
achieving
desirable
fairness
guarantees
recall
that
set
is
path-connected
if
for
every
pair
of
elements
there
exists
continuous
path
between
and
which
is
entirely
contained
within
3.3
uncertainty
aware
rankings
meaningful
deterministic
ranking
functions
cannot
be
stable
in
fact
it
is
not
immediate
that
there
exist
non-constant
stable
ranking
functions
we
now
show
that
uncertainty
aware
ua
rankings
introduced
by
singh
et
al
2021
are
anonymous
and
stable
ua
rankings
were
originally
introduced
via
an
axiomatization
of
when
probabilistic
ranking
should
be
considered
fair
for
given
merit
distributions
devic
et
al
2023
further
refined
this
axiomatization
by
combining
notions
of
meritocracy
and
lifting
deterministic
decision
making
to
decision
making
under
uncertainty
the
definition
of
singh
et
al
2021
assumed
that
merit
distributions
were
continuous
and
ties
occurred
with
probability
motivated
by
predictors
which
output
distributions
over
discrete
label
sets
such
as
or
irrelevant
suitable
extremely
relevant
with
corresponding
total
order
we
adapt
the
definition
of
ua
rankings
definition
uncertainty
awareness
singh
et
al
2021
randomized
ranking
mn
ds
is
uncertainty
aware
for
prediction
pn
if
for
each
individual
and
position
the
entry
mi
is
the
probability
that
has
the
th
highest
label
if
all
labels
λi
pi
are
sampled
independently
from
the
respective
distributions
pi
and
ties
are
broken
uniformly
formally
conditioned
on
the
drawn
labels
λi
of
all
individuals
which
entail
the
counts
for
all
labels
the
probability
for
individual
to
obtain
rank
is
if
ri
λi
otherwise
ranking
function
pn
mn
ds
is
uncertainty
aware
if
is
uncertainty
aware
for
all
pn
because
the
definition
of
uncertainty
awareness
fully
prescribes
the
ranking
distribution
for
given
prediction
as
shown
in
lemma
4.2
of
singh
et
al
2021
there
is
unique
uncertainty
aware
ranking
function
for
any
given
we
henceforth
denote
it
by
rua
intuitively
the
fairness
of
ua
can
be
interpreted
through
possible
futures
viewpoint
given
two
individuals
if
has
more
merit
than
in
60
of
futures
when
the
merits
labels
of
both
and
are
sampled
from
their
respective
distributions
then
ua
implements
the
requirement
that
the
allocation
in
the
present
should
respect
this
uncertainty
and
give
the
better
rank
at
least
60
of
the
time
and
at
least
40
of
the
time
this
entails
the
need
for
randomization
we
refer
the
reader
to
devic
et
al
2023
singh
et
al
2021
for
formal
argument
on
the
fairness
of
ua
ranking
our
first
key
insight
for
proving
properties
of
ua
rankings
is
that
by
taking
into
account
the
randomness
of
the
draws
of
labels
and
the
tie
breaking
the
rank
distribution
produced
by
ua
ranking
can
be
summarized
as
follows
proposition
let
pn
be
prediction
and
rua
the
ranking
distribution
produced
by
rua
for
then
the
probability
of
individual
being
ranked
in
position
is
pp
and
prua
ri
pi
prua
ri
λi
prua
ri
λi
proof
for
the
first
part
we
observe
that
the
probability
of
ri
in
depends
only
on
and
by
considering
all
the
possible
values
of
for
which
gives
non-zero
probability
we
obtain
that
prua
ri
λi
pp
and
λi
the
result
is
then
obtained
by
noticing
that
conditioned
on
λi
we
have
and
for
all
the
second
part
of
the
proposition
simply
states
the
law
of
total
probability
we
also
remark
that
the
definition
of
singh
et
al
2021
in
contrast
to
definition
did
not
require
the
labels
merits
of
different
individuals
to
be
sampled
independently
from
their
respective
distributions
pi
we
add
this
independence
requirement
to
facilitate
connections
with
learning
algorithms
for
predictors
an
added
benefit
of
the
independence
assumption
is
that
it
makes
it
possible
to
explicitly
compute
rua
in
polynomial
time
as
captured
by
the
following
proposition
note
that
this
is
in
contrast
to
the
case
of
possibly
correlated
labels
merits
from
previous
work
devic
et
al
2023
singh
et
al
2021
indeed
main
technical
contribution
of
these
works
was
analyzing
the
loss
in
fairness
utility
incurred
due
to
imperfectly
approximating
rua
via
sampling
proposition
10
there
exists
an
algorithm
which
given
pn
exactly
computes
rua
in
time
n4
n3
proof
the
two
parts
of
proposition
combined
imply
that
in
order
to
compute
row
of
rua
it
is
sufficient
to
compute
pp
and
for
all
pairs
this
is
accomplished
by
dynamic
program
similar
to
standard
undergraduate
exercise
which
is
to
compute
poisson
binomial
distribution
explicitly
for
notational
convenience
assume
that
this
is
solely
to
avoid
special
case
in
the
recurrence
and
also
without
loss
of
generality
by
anonymity
of
the
ua
rule
for
any
let
pp
and
be
the
probability
that
among
the
first
individuals
exactly
have
label
and
exactly
have
label
strictly
better
than
from
these
values
we
can
then
construct
the
necessary
quantities
as
pp
and
we
give
the
recurrence
relationship
for
the
the
base
cases
are
that
if
because
with
no
individuals
the
only
possible
numbers
of
individuals
with
given
labels
is
now
consider
for
with
probability
pt
individual
has
label
in
which
case
the
desired
event
happens
when
pindividuals
among
the
first
have
label
and
have
labels
strictly
better
than
with
probability
pt
individual
has
label
strictly
better
than
in
which
case
the
desired
event
happens
when
individuals
pamong
the
first
have
label
and
have
labels
strictly
better
than
finally
with
probability
pt
individual
has
label
strictly
worse
than
in
which
case
the
desired
event
happens
when
individuals
among
the
first
have
label
and
have
labels
strictly
better
than
these
three
cases
disjointly
cover
all
possibilities
for
the
label
of
so
we
have
derived
the
following
recurrence
pt
pt
pt
here
to
avoid
case
distinctions
for
whether
and
or
are
we
treat
whenever
or
are
negative
notice
that
for
any
fixed
all
values
pt
being
prefix
sums
can
be
pre-computed
in
time
thus
for
all
the
precomputation
can
be
performed
in
time
nl
then
any
one
entry
can
be
computed
in
constant
time
from
previously
computed
values
because
the
table
has
size
n3
the
total
computation
takes
time
n3
summing
over
all
possible
values
of
the
total
time
to
compute
the
entire
ranking
distribution
rua
is
n4
n2
finally
the
post-processing
of
computing
the
pp
and
for
all
for
fixed
can
be
implemented
in
time
by
using
differences
of
prefix
sums
thus
all
values
can
be
computed
in
time
n3
this
gives
total
time
of
n4
n3
10
while
the
notion
and
use
of
uncertainty
aware
rankings
may
appear
to
be
of
primarily
theoretical
interest
it
is
in
fact
used
in
practice
for
example
the
nba
draft
lottery
can
be
understood
through
the
lens
of
uncertainty
aware
rankings
the
merit
of
team
is
its
need
for
better
choice
picks
which
can
be
imperfectly
inferred
from
the
team
performance
in
the
previous
season
the
draft
order
is
then
obtained
by
weighted
lottery
based
on
these
uncertain
merits
we
now
present
the
central
result
of
this
section
that
the
uncertainty
aware
ranking
function
is
anonymous
and
stable
theorem
11
let
rua
pn
mn
ds
be
the
ua
ranking
function
for
individuals
and
labels
rua
is
anonymous
and
stable
the
following
lemma
is
key
part
of
the
proof
of
stability
it
bounds
how
different
the
probabilities
for
individual
obtaining
rank
can
be
under
two
different
prediction
matrices
as
function
of
how
similar
these
matrices
are
lemma
12
let
pn
be
two
different
prediction
matrices
for
any
individual
let
pi
qi
be
the
ith
rows
of
respectively
the
label
distributions
of
individual
under
the
two
predictions
let
be
an
individual
position
and
label
then
prua
ri
λi
prua
ri
λi
dtv
pi
qi
we
defer
the
proof
of
lemma
12
to
appendix
proof
of
theorem
11
first
the
ua
ranking
rule
is
obviously
anonymous
simply
by
its
symmetric
definition
which
treats
all
indices
identically
thus
we
focus
on
proving
stability
now
let
any
individual
and
rank
be
given
by
equation
in
the
second
part
of
proposition
ri
pi
ri
λi
now
consider
two
different
predictors
we
bound
the
difference
in
probabilities
for
to
be
ranked
in
position
as
follows
prua
ri
prua
ri
pi
prua
ri
λi
qi
prua
ri
λi
pi
qi
prua
ri
λi
qi
prua
ri
λi
prua
ri
λi
pi
qi
qi
prua
ri
λi
prua
ri
λi
by
lemma
12
we
can
bound
prua
ri
λi
prua
ri
λi
dtv
pi
qi
substituting
this
bound
back
into
we
now
obtain
that
prua
ri
prua
ri
pi
qi
qi
dtv
pi
qi
dtv
pi
qi
dtv
pi
qi
in
the
final
step
we
absorbed
the
total
variation
distance
for
into
the
sum
for
which
has
larger
coefficient
and
used
that
the
norm
is
exactly
twice
the
total
variation
distance
as
the
number
of
labels
increases
the
predictor
can
provide
the
ranking
function
with
more
fine-grained
information
which
should
allow
the
ua
ranking
function
to
produce
wider
class
of
distributions
over
rankings
the
next
proposition
shows
that
this
is
indeed
the
case
11
proposition
13
the
expressivity
of
uncertainty
aware
ranking
functions
is
strictly
increasing
in
more
formally
let
and
rua
pn
mds
rua
pn
mn
ds
be
the
corresponding
ua
ranking
functions
then
rua
pn
rua
pn
proof
first
to
see
monotonicity
notice
that
adding
column
of
all
entries
an
unused
label
does
not
change
the
behavior
of
rua
for
any
pn
writing
pn
for
this
matrix
we
have
rua
rua
implying
that
rua
pn
rua
pn
to
prove
strictness
of
inclusion
consider
prediction
jn
over
individuals
here
jn
is
the
row-reversed
identity
matrix
with
ones
along
the
anti-diagonal
so
individual
is
deterministically
known
to
have
label
then
rua
in
for
the
identity
matrix
in
individual
is
ranked
deterministically
in
position
and
we
have
proved
that
in
rua
pn
note
that
due
to
the
tie
breaking
of
rua
to
achieve
deterministic
ranking
no
two
individuals
must
ever
have
the
same
label
the
supports
of
the
rows
of
any
prediction
matrix
yielding
rua
in
must
be
disjoint
this
implies
that
must
have
at
least
columns
in
rua
pn
completing
the
proof
of
strictness
of
inclusion
using
proposition
13
we
can
show
that
our
stability
analysis
is
essentially
tight
up
to
factor
of
ruling
out
the
possibility
of
for
example
n1
stability
for
ua
rankings
proposition
14
for
any
and
rua
is
not
γ-stable
for
any
21
proof
let
be
given
we
only
consider
for
any
it
suffices
by
proposition
13
to
embed
the
following
instance
and
ignore
the
extra
labels
consider
the
prediction
matrix
with
individual
having
prediction
p1
and
individuals
through
having
prediction
p2
similarly
the
prediction
matrix
will
have
individual
with
prediction
and
individuals
through
with
prediction
p2
that
is
and
are
identical
except
for
individual
let
rua
rua
be
the
resulting
probabilities
for
placing
individuals
in
specific
positions
since
all
individuals
except
individual
have
deterministic
qualifications
under
there
is
50
probability
that
individual
is
ranked
last
so
m1
whereas
m1
therefore
we
have
the
following
rua
rua
m1
m1
thus
rua
cannot
be
γ-stable
for
any
multigroup
fairness
guarantees
we
now
present
our
main
result
ua
rankings
naturally
compose
with
multiaccurate
and
multicalibrated
predictors
we
have
shown
that
ua
rankings
are
stable
and
furthermore
that
stable
rankings
compose
harmoniously
with
individually
fair
predictors
corollary
demonstrates
that
an
accurate
predictor
at
the
individual
level
can
combine
with
stable
ranking
function
such
as
ua
to
induce
ranking
which
is
close
to
that
of
the
underlying
ground
truth
in
practice
however
obtaining
accurate
uncertainty
estimates
at
the
individual
level
is
too
strong
of
an
assumption
for
arbitrary
data
sets
of
individuals
this
is
because
such
requirement
is
equivalent
to
learning
the
bayes
optimal
predictor
the
true
distribution
over
the
labels
conditioned
on
the
features
of
an
individual
shalev-shwartz
and
ben-david
2014
section
3.2
which
generally
requires
the
number
of
samples
or
running
time
to
be
exponential
in
the
dimensionality
of
the
features
used
for
prediction
which
can
be
statistically
or
computationally
infeasible
instead
we
focus
on
obtaining
coarser
guarantee
for
ua
rankings
at
the
level
of
subgroups
of
the
domain
for
data
sets
sampled
from
distribution
over
individuals
instead
of
arbitrary
data
sets
the
assumption
is
standard
setting
for
machine
learning
and
has
proven
useful
in
many
practical
settings
our
contributions
are
tightly
connected
to
the
statistical
group-fairness
conditions
of
multiaccuracy
and
multicalibration
he
bert-johnson
et
al
2018
kim
et
al
2019
our
guarantees
will
be
meaningful
since
they
directly
imply
that
relative
to
an
underlying
ground
truth
unbiased
predictors
will
induce
unbiased
rankings
12
4.1
group-wise
accuracy
guarantees
we
first
recall
the
definitions
of
multiaccuracy
and
multicalibration
from
the
fair
machine
learning
literature
then
we
state
our
result
on
the
average
accuracy
of
rankings
induced
by
multiaccurate
and
multicalibrated
predictors
when
compared
to
rankings
induced
from
nature
definition
15
multiaccuracy
multicalibration
he
bert-johnson
et
al
2018
kim
et
al
2019
let
be
distribution
over
individuals
let
be
the
ground
truth
distribution
of
labels
is
the
true
distribution
of
labels
for
individual
while
is
the
predictor
so
is
the
predicted
label
distribution
let
be
collection
of
sets
for
which
the
predictor
is
to
be
multiaccurate
multcalibrated
let
be
parameter
for
how
far
from
fully
accurate
calibrated
the
predictor
is
allowed
to
be
when
writing
for
vector-valued
quantity
we
mean
the
coordinate-wise
expectations
then
we
have
that
is
multiaccurate
if
for
every
set
ex
1x
that
is
for
each
of
the
given
groups
and
each
label
the
expected
probability
mass
on
that
label
is
approximately
the
same
for
the
predictor
as
for
the
ground
truth
let
some
interval
width
be
given
such
that
is
an
integer
is
multicalibrated
if
for
every
set
and
vector
j1
j2
jl
ex
1x
jℓ
jℓ
that
is
in
addition
to
fixing
group
even
if
we
also
fix
rough
interval
within
which
the
predicted
probability
mass
must
lie
the
predictor
still
has
to
be
close
to
the
ground
truth
for
each
possible
label
each
set
represents
protected
group
of
import
in
the
underlying
population
the
sets
in
can
be
complex
overlapping
nested
laminar
etc
since
both
multiaccuracy
and
multicalibration
with
respect
to
are
in
contrast
to
other
notions
of
group
fairness
in
supervised
learning
such
as
equalized
odds
awasthi
et
al
2020
or
equality
of
opportunity
hardt
et
al
2016
statistically
sound
in
that
they
are
consistent
with
the
underlying
ground
truth
there
are
variety
of
learning
and
post-processing
algorithms
which
in
terms
of
sample
and
time
complexity
efficiently
achieve
multiaccuracy
multicalibration
gopalan
et
al
2022
haghtalab
et
al
2023
he
bert-johnson
et
al
2018
kim
et
al
2019
we
now
present
the
central
contribution
of
this
section
multicalibration
and
multiaccuracy
for
predictor
guarantee
that
on
per
group
basis
ua
rankings
derived
from
will
be
close
to
ua
rankings
derived
from
the
ground
truth
theorem
16
let
be
distribution
over
individuals
let
be
the
ground
truth
distribution
of
labels
and
predictor
for
any
let
dn
be
the
distribution
obtained
from
drawing
vector
of
samples
from
let
be
collection
of
sets
with
the
sets
of
individuals
for
which
the
predictor
will
be
assumed
to
be
multiaccurate
multcalibrated
let
be
parameter
for
how
far
from
fully
accurate
calibrated
the
predictor
is
allowed
to
be
then
we
have
that
if
is
multiaccurate
then
the
following
holds
for
all
sets
and
ex
dn
unif
1xi
prua
ri
prua
ri
lnα
let
some
interval
width
be
given
such
that
is
an
integer
if
is
multicalibrated
and
multiaccurate
then
for
every
set
vector
j1
j2
jl
and
ex
dn
unif
1xi
1f
xi
jℓ
jℓ
for
all
prua
ri
prua
ri
lnα
13
proof
fix
set
and
position
the
proofs
of
both
parts
of
the
theorem
are
essentially
identical
with
only
minor
practically
syntactic
changes
and
we
will
give
both
proofs
simultaneously
pointing
out
the
few
places
where
differences
occur
for
the
proof
of
the
second
part
of
the
theorem
for
the
case
of
multi-calibrated
predictor
let
be
given
such
that
is
an
integer
and
fix
vector
j1
j2
jl
we
use
the
notation
to
denote
1x
for
the
proof
under
multiaccurate
predictor
and
to
denote
1x
1f
jℓ
jℓ
for
all
for
the
proof
under
multicalibrated
predictor
first
we
observe
that
we
can
simplify
notation
by
using
that
all
draws
of
the
xj
are
and
we
can
apply
the
law
of
total
probability
ex
dn
unif
xi
prua
ri
prua
ri
ex
dn
xn
prua
rn
prua
rn
exn
xn
ex
dn
prua
xn
rn
prua
xn
rn
next
we
sum
over
all
possible
labels
λn
condition
on
those
labels
for
individual
and
then
omit
from
the
probabilities
those
random
variables
that
do
not
affect
the
probability
to
rewrite
the
preceding
expression
as
exn
xn
ex
dn
pf
xn
λn
prua
xn
rn
λn
pf
xn
λn
prua
xn
rn
λn
exn
xn
ex
dn
pf
xn
λn
prua
rn
λn
pf
xn
λn
prua
rn
λn
exn
xn
ex
dn
pf
xn
λn
pf
xn
λn
prua
rn
λn
exn
xn
ex
dn
pf
xn
λn
prua
rn
λn
prua
rn
λn
exn
xn
pf
xn
λn
pf
xn
λn
ex
dn
prua
rn
λn
exn
xn
pf
xn
λn
ex
dn
prua
rn
λn
prua
rn
λn
we
bound
the
two
sums
separately
for
the
first
sum
we
simply
bound
exn
xn
pf
xn
λn
pf
xn
λn
in
the
final
step
we
applied
the
multi-accuracy
guarantee
for
for
every
label
under
the
sum
for
the
first
part
of
the
theorem
and
the
multi-calibration
guarantee
for
and
j1
jl
for
every
label
for
the
second
part
of
the
theorem
14
for
the
second
term
we
apply
the
triangle
inequality
and
bound
exn
pf
xn
λn
ex
dn
prua
rn
λn
prua
rn
λn
first
by
equation
in
the
first
part
of
proposition
ex
dn
prua
rn
λn
ex
dn
pf
and
because
the
label
of
under
is
drawn
by
first
drawing
xi
then
drawing
λi
xi
the
label
distribution
of
under
is
exactly
ex
where
we
again
take
expectation
of
vectors
componentwise
writing
pn
for
the
matrix
in
which
each
of
the
rows
is
pi
we
can
therefore
write
ex
dn
prua
rn
λn
pp
and
prua
rn
λn
an
identical
argument
applies
for
instead
of
writing
ex
and
pn
for
the
matrix
in
which
each
of
the
rows
is
qi
we
can
write
ex
dn
prua
rn
λn
prua
rn
λn
combining
both
of
these
calculations
then
applying
lemma
12
we
can
bound
ex
dn
prua
rn
λn
prua
rn
λn
prua
rn
λn
prua
rn
λn
dtv
pi
qi
dtv
pℓ
qℓ
ex
if
is
multiaccurate
because
we
bound
ex
ex
1x
the
identical
bound
holds
for
the
second
part
of
the
theorem
because
we
assumed
to
also
be
multiaccurate
finally
we
combine
all
of
these
bounds
to
obtain
that
exn
1xn
pf
xn
λn
pf
xn
λn
ex
dn
prua
rn
λn
exn
1xn
pf
xn
λn
ex
dn
prua
rn
λn
prua
rn
λn
exn
pf
xn
λn
nlα
completing
the
proof
15
theorem
16
can
intuitively
be
thought
of
as
the
following
predictor
which
is
unbiased
on
average
over
collection
of
subgroups
will
induce
an
uncertainty
aware
ranking
which
for
those
subgroups
has
similar
outcome
to
the
usually
inaccessible
uncertainty
aware
ranking
induced
by
the
ground
truth
label
distribution
the
multicalibration
guarantee
refines
this
to
hold
for
not
only
subgroups
but
intervals
of
predictions
of
the
predictor
within
that
subgroup
part
of
theorem
16
requires
be
simultaneously
multicalibrated
and
multiaccurate
that
is
is
unbiased
on
average
across
individuals
sampled
from
this
combination
of
properties
can
be
achieved
by
the
algorithm
of
gopalan
et
al
2022
4.2
multicalibration
as
interpolating
between
group
and
individual
fairness
in
contrast
to
learning
accurate
individual-level
estimates
the
bayes
optimal
predictor
multiaccuracy
multicalibration
can
be
achieved
in
time
and
samples
polynomial
in
the
number
of
sets
in
or
more
generally
polynomial
in
measures
of
complexity
of
such
as
its
vc-dimension
gopalan
et
al
2022
he
bert-johnson
et
al
2018
notice
that
if
we
define
cbayes
to
be
the
set
of
all
singleton
groups
then
cbayes
multiaccuracy
guarantees
increasingly
accurate
predictions
for
all
individuals
as
and
recovers
the
bayes
optimal
classifier
the
ground
truth
by
varying
the
level
of
granularity
of
the
collection
the
learned
multiaccurate
or
multicalibrated
predictor
represents
finer
or
coarser
approximation
of
the
bayes
optimal
classifier
thus
theorem
16
guarantees
that
the
induced
ranking
effectively
interpolates
between
individual
and
group-level
fair
rankings
at
the
granularity
defined
by
nonetheless
as
previously
noted
it
is
usually
unreasonable
to
expect
multiaccuracy
or
multicalibration
at
the
level
of
cbayes
as
this
is
due
to
information
and
computational
constraints
multicalibration
algorithms
must
use
poly
samples
to
learn
multiaccurate
multicalibrated
predictor
shabat
et
al
2020
in
addition
to
the
sample
complexity
requirements
the
class
must
be
agnostic
pac
learnable
shalev-shwartz
and
ben-david
2014
section
3.2
this
is
stringent
requirement
which
rarely
holds
for
complex
collections
such
as
cbayes
in
practice
we
envision
theorem
16
to
be
used
with
sufficiently
simple
classes
such
as
conjunctions
of
categorical
features
and
intervals
of
numeric
features
women
in
the
age
range
45
65
working
at
this
level
of
granularity
not
only
permits
efficient
algorithms
for
obtaining
multiaccurate
multicalibrated
predictors
but
also
guarantees
that
the
derived
rankings
will
be
unbiased
for
meaningful
protected
groups
of
individuals
ranking
functions
and
utility
most
online
marketplaces
utilizing
rankings
and
ranking
functions
are
also
concerned
with
utility
or
revenue
in
this
section
we
introduce
natural
class
of
utility
models
inspired
by
the
literature
standard
taylor
et
al
2008
and
prove
that
the
optimal
utility
ranking
function
cannot
achieve
the
stability
or
group
fairness
guarantees
that
ua
rankings
enjoy
we
then
show
that
simple
ranking
function
rmix
which
is
randomization
between
the
utility-optimal
and
ua
ranking
function
satisfies
an
approximate
notion
of
stability
and
fairness
while
simultaneously
retaining
utility
guarantee
this
may
be
of
use
to
practitioners
more
broadly
definition
17
utility
model
let
w1
w2
wn
be
position
weights
and
function
we
call
the
class
utility
map
which
determines
how
predictions
are
mapped
to
utilities
the
utility
of
prediction
matrix
pn
under
ranking
function
is
eσ
wk
pσ
wk
pi
pl
particularly
natural
and
common
type
of
class
utility
map
is
the
expected
utility
vℓ
pℓ
where
vl
vl
v1
are
the
utilities
for
labels
combined
with
the
weights
wk
log2
this
class
captures
dcg
ja
rvelin
and
keka
la
inen
2002
for
example
16
the
ranking
function
which
achieves
optimal
utility
will
clearly
depend
on
we
denote
it
by
ropt
it
can
be
simply
described
as
the
ranking
function
which
deterministically
orders
the
individuals
by
decreasing
values
pi
recall
that
pi
is
the
ith
row
of
pn
we
now
show
that
in
general
ropt
is
not
stable
which
demonstrates
necessity
to
trade
off
notions
of
utility
and
stability
proposition
18
even
for
binary
labels
and
expected
utility
map
the
utility-maximizing
map
ropt
is
unstable
proof
the
example
is
standard
in
the
literature
assume
that
v2
v1
for
any
12
define
12
pϵ
21
then
ropt
pϵ
deterministically
ranks
ahead
of
while
ropt
pϵ
deterministically
ranks
ahead
of
as
result
ropt
pϵ
ropt
pϵ
while
pϵ
pϵ
8ϵ
as
this
proves
instability
of
ropt
next
we
show
that
for
an
extremely
simple
class
of
instances
namely
when
there
are
two
types
of
individuals
with
uniform
distribution
binary
labels
identical
uniform
ground
truth
distribution
over
the
two
labels
for
both
types
and
groups
which
are
just
the
two
singleton
types
the
utility-maximizing
ranking
function
ropt
cannot
approach
optimal
multigroup
fairness
never
mind
how
close
to
perfectly
multiaccurate
the
predictor
gets
proposition
19
let
be
domain
of
two
types
of
individuals
let
be
the
uniform
distribution
over
those
two
types
let
we
consider
binary
labels
and
the
ground
truth
label
distribution
is
12
12
for
both
under
the
ground
truth
both
types
are
equally
likely
to
be
good
and
bad
let
be
the
collection
of
singleton
subgroups
for
any
12
let
fα
be
the
predictor
with
predictions
fα
12
12
and
fα
12
12
that
is
fα
slightly
overestimates
the
quality
of
type
and
slightly
underestimates
the
quality
of
type
let
be
any
utility
map
strictly
preferring
higher
labels
any
utility
map
with
12
12
12
21
let
ropt
be
any
utility-maximizing
ranking
function
for
the
utility
map
then
fα
is
multiaccurate
yet
for
every
number
of
individuals
the
group
fairness
under
ropt
towards
the
group
for
assignment
to
the
top
most
valuable
position
in
the
ranking
is
the
following
ex
dn
unif
1xi
ri
pr
ri
propt
opt
in
particular
for
any
fixed
the
quantity
stays
bounded
away
from
even
as
the
intuition
for
proposition
19
is
similar
to
that
for
proposition
for
the
utility-maximizing
ranking
function
an
arbitrarily
small
but
non-zero
predictive
mistake
can
induce
large
variations
in
the
resulting
ranking
distribution
preventing
it
from
preserving
group
fairness
of
its
predictor
proof
we
first
verify
that
fα
is
multiaccurate
for
or
we
have
that
ex
1x
fα
max
the
rest
of
the
proof
focuses
on
the
group
fairness
analysis
proving
equation
we
first
consider
the
ri
first
observe
that
under
the
ground
truth
classifier
we
have
that
term
propt
1n
for
all
here
1n
denotes
the
all-ones
matrix
under
this
input
matrix
ropt
must
have
some
distribution
q1
qn
over
which
individual
is
assigned
the
top
rank
crucially
for
our
analysis
because
the
ranking
function
only
observes
this
matrix
12
1n
it
must
use
the
same
distribution
for
all
type
vectors
ri
qi
for
all
type
vectors
we
thus
conclude
that
propt
ri
focus
on
any
type
vector
vector
next
we
consider
the
term
propt
that
has
at
least
one
individual
of
type
because
fα
fα
and
ropt
is
utility-maximizing
for
the
17
utility
map
ropt
fα
must
rank
all
individuals
pn
of
type
of
whom
there
is
at
least
one
ahead
of
all
ri
for
all
individuals
of
type
from
this
we
obtain
that
1xi
propt
next
we
write
out
the
expectation
from
equation
we
use
that
the
terms
1xi
for
all
when
which
allows
us
to
drop
this
term
from
the
sum
we
then
use
that
each
under
the
uniform
type
distribution
is
drawn
with
probability
and
substitute
our
preceding
calculations
for
the
probabilities
this
gives
us
the
following
ri
pr
ri
ex
dn
unif
1xi
propt
opt
xx
ri
pr
ri
1xi
propt
opt
ri
1xi
qi
1xi
propt
pr
qi
1xi
qi
1xi
2n
qi
2n
2n
2n
in
the
step
labeled
we
used
that
there
are
exactly
2n
vectors
with
xi
the
following
step
used
that
the
qi
defining
probability
distribution
sum
to
this
completes
the
proof
5.1
utility-stability
tradeoffs
in
both
theory
and
practice
it
is
often
necessary
to
trade
off
utility
against
other
desiderata
such
as
fairness
or
stability
see
for
example
pitoura
et
al
2022
singh
and
joachims
2019
if
achieving
fairness
stability
comes
at
huge
price
in
utility
it
may
become
economically
infeasible
to
implement
fair
or
stable
rankings
in
this
section
we
introduce
and
discuss
class
rmix
of
ranking
functions
which
provide
quantifiable
tradeoff
between
the
objectives
rmix
linearly
interpolates
between
rua
and
ropt
with
trade-off
parameter
chosen
by
the
ranking
mechanism
designer
we
show
that
this
interpolation
naturally
leads
to
rmix
satisfying
approximate
stability
and
fairness
while
providing
lower-bound
guarantees
on
the
utility
while
the
proofs
are
relatively
straightforward
we
believe
that
practitioners
may
find
this
class
of
ranking
functions
useful
in
practical
applications
where
the
stringent
requirement
of
stability
may
not
be
necessary
the
interested
reader
is
referred
to
singh
et
al
2021
for
additional
discussion
on
how
to
choose
appropriately5
we
first
formally
define
the
notion
of
approximate
stability
definition
20
fix
and
ranking
function
pn
mn
ds
is
approximately
stable
if
for
all
predictions
pn
5we
note
that
our
approximate
fairness
guarantee
in
proposition
22
on
multiaccuracy
multicalibration
with
an
additive
slack
is
different
from
the
ϕ-approximate
fairness
of
singh
et
al
2021
which
is
multiplicative
notion
indeed
both
hold
simultaneously
for
rmix
18
notice
that
approximate
stability
recovers
our
stability
notion
from
definition
approximate
stability
is
relaxation
which
allows
for
additive
slack
in
the
dependence
on
an
additive
slack
relaxation
is
natural
and
akin
to
for
example
differential
privacy
when
compared
to
pure
differential
privacy
we
show
that
simple
mixture
of
ua
and
the
optimal
utility
ranking
satisfies
the
following
approximate
stability
and
utility
guarantee
proposition
21
fix
utility
map
let
rmix
be
the
ranking
function
which
randomizes
between
rua
with
probability
and
ropt
with
probability
then
rmix
is
approximately
stable
furthermore
for
any
pn
we
have
that
rmix
rua
ropt
proof
we
first
show
approximate
stability
for
any
pn
we
have
the
following
rmix
rmix
ϕrua
ropt
ϕrua
ropt
rua
rua
ropt
ropt
the
last
line
used
the
stability
of
rua
proved
in
theorem
11
as
well
as
the
fact
that
the
norm
difference
of
doubly
stochastic
matrices
is
at
most
the
claim
about
utility
is
simply
linearity
of
expectations
it
is
straightforward
to
show
that
similar
approximate
fairness
guarantee
holds
for
rmix
again
due
to
its
linearity
proposition
22
let
be
distribution
over
individuals
let
be
the
ground
truth
distribution
of
labels
and
predictor
for
any
let
dn
be
the
distribution
obtained
from
drawing
vector
of
samples
from
let
be
collection
of
sets
with
the
sets
of
individuals
for
which
the
predictor
will
be
assumed
to
be
multiaccurate
multcalibrated
let
be
parameter
for
how
far
from
fully
accurate
calibrated
the
predictor
is
allowed
to
be
if
is
multiaccurate
then
the
following
holds
for
all
sets
and
ex
dn
unif
1xi
prϕ
ri
prϕ
ri
ϕlnα
mix
mix
let
some
interval
width
be
given
such
that
is
an
integer
if
is
multicalibrated
and
multiaccurate
then
for
every
set
vector
j1
j2
jl
and
ex
dn
unif
1xi
1f
xi
jℓ
jℓ
for
all
prua
ri
prua
ri
ϕlnα
proof
the
proof
follows
from
the
following
computation
due
to
linearity
of
rmix
prmix
ri
prmix
ri
prua
ri
propt
ri
ri
prua
ri
propt
applying
this
decomposition
then
applying
linearity
of
expectation
applying
the
triangle
inequality
and
then
using
theorem
16
completes
the
proof
of
both
parts
19
experiments
on
stability
and
utility
we
ran
experiments
on
the
us
census
data
set
acs
curated
by
ding
et
al
2021
and
the
student
dropout
task
enrollment
introduced
by
martins
et
al
2021
in
the
uci
data
set
repository
in
our
experiments
we
demonstrate
empirically
that
the
stability
guarantees
of
ua
rankings
hold
when
using
multiclass
predictions
furthermore
we
find
that
in
practice
the
stability
guarantees
offered
by
ua
ranking
may
be
much
better
than
stability
or
the
stability
worst-case
lower
bound
in
proposition
14
and
show
that
the
utility
loss
suffered
by
rua
is
reasonable
although
our
experiments
are
relatively
simplistic
and
are
not
the
main
focus
of
our
work
they
demonstrate
that
ua
rankings
have
relatively
good
performance
in
terms
of
utility
they
outperform
not
only
uniformly
random
baseline
ranking
but
even
the
plackett-luce
distribution
at
the
same
time
they
also
retain
the
provable
fairness
and
stability
properties
related
experiments
previous
work
devic
et
al
2023
singh
et
al
2021
also
contain
experiments
demonstrating
the
utility
and
utility-fairness
tradeoff
of
ua
ranking
functions
this
past
work
assumed
real-valued
predictions
as
opposed
to
the
multiclass
predictions
in
our
work
singh
et
al
2021
actually
deployed
paper
recommendation
system
at
large
computer
science
conference
using
ua
rankings
to
demonstrate
the
viability
of
the
method
in
practice
furthermore
their
experiments
on
the
movielens
data
set
harper
and
konstan
2015
demonstrate
that
ua
ranking
corresponding
to
fairness
parameter
of
in
their
work
can
achieve
nearly
99
of
the
optimal
utility
given
by
ropt
in
some
applications
devic
et
al
2023
show
the
viability
of
ua
rankings
in
matching
setting
running
experiments
on
an
online
dating
data
set
6.1
stability
against
sgd
noise
in
neural
network
training
given
our
focus
on
the
combination
of
ranking
functions
with
noisy
predictions
derived
from
ml-based
classifiers
we
first
investigate
experimentally
the
stability
of
ua
and
utility-maximizing
rankings
under
natural
model
of
prediction
noise
in
particular
one
of
the
most
common
sources
of
noise
in
predictions
is
the
randomness
in
the
training
procedure
such
as
sgd
we
designed
natural
experiment
by
comparing
the
behavior
of
ranking
functions
under
predictors
learned
with
different
randomly
seeded
sgd
training
runs
our
focus
is
on
understanding
if
or
to
what
extent
the
stability
of
ua
and
other
ranking
functions
will
exceed
the
worst-case
theoretical
guarantees
in
such
quasi-realistic
settings
first
we
describe
the
data
sets
in
acs
the
prediction
target
is
the
binary
variable
of
whether
person
is
employed
or
not
after
filtering
to
individuals
in
the
age
range
16
90
for
computational
reasons
we
restrict
our
experiments
to
subset
of
the
data
for
california
with
parameters
survey
year
2018
horizon
1year
and
survey
person
these
parameters
are
standard
when
using
acs
for
testing
algorithmic
fairness
methods
due
to
the
large
amount
of
available
data
see
the
github
repository
of
ding
et
al
2021
we
are
left
with
378
817
entries
and
use
an
80
20
train
test
split
in
enrollment
the
target
is
multiclass
variable
for
whether
an
individual
is
an
enrolled
graduated
or
dropout
student
after
cleaning
the
data
we
are
left
with
424
entries
on
which
we
use
an
80
20
train
test
split
since
we
want
to
compare
the
stability
of
rua
against
that
of
ropt
we
next
define
simple
and
natural
utilities
for
acs
we
take
class
to
correspond
to
employment
and
class
to
correspond
to
unemployment
class
class
we
define
p2
the
probability
of
employment
for
enrollment
we
take
class
to
be
that
the
student
has
dropped
out
class
to
be
enrolled
and
class
to
be
graduated
class
class
class
and
define
p1
p2
p3
we
train
30
simple
three-layer
mlp
neural
networks
on
the
acs
data
set
which
we
divide
into
15
pairs
of
networks
each
pair
of
networks
is
initialized
with
the
same
random
weight
matrix
then
trained
separately
with
sgd
this
introduces
noise
into
the
final
trained
neural
network
weights
and
consequently
the
predictions
that
is
each
pair
of
networks
has
similar
test
accuracy
but
will
output
different
probabilities
on
some
or
all
individuals
on
acs
all
networks
achieve
between
75
80
train
and
test
accuracy
we
perform
the
identical
procedure
for
the
enrollment
data
set
where
the
networks
all
achieve
between
70
75
train
and
test
accuracy
due
to
less
data
being
available
20
let
fi
gi
for
15
be
the
classifiers
corresponding
to
given
pair
of
networks
trained
from
the
same
initialization
but
with
different
noise
due
to
sgd
to
test
the
stability
of
the
ranking
functions
rua
and
ropt
for
each
pair
fi
gi
we
randomly
select
30
individuals
from
the
test
set
as
the
data
set
of
individuals
and
obtain
the
probabilistic
predictions
fi
and
gi
we
then
run
ropt
and
rua
on
these
two
prediction
matrices
logging
the
deviations
of
the
rankings
and
the
resulting
value
of
for
each
pair
of
networks
fi
gi
we
repeat
this
procedure
10
times
with
different
randomly
selected
subsets
of
individuals
in
table
we
report
the
average
and
standard
deviation
of
this
experiment
quantity
acs
enrollment
rua
rua
ropt
ropt
0.011
0.002
0.947
0.224
0.971
0.582
0.012
0.002
0.680
0.466
0.653
0.453
table
measured
stability
over
30
neural
network
training
runs
15
pairs
of
networks
for
10
data
sets
of
30
individuals
each
norm
of
ua
deviation
being
bounded
above
by
confirms
stability
of
ua
theorem
11
instability
of
the
ranking
ropt
is
also
demonstrated
proposition
18
the
results
in
table
demonstrate
that
dominates
the
value
of
rua
rua
this
behavior
persisted
through
all
of
our
many
training
runs
we
conclude
that
ua
rankings
are
extremely
stable
in
the
face
of
noise
introduced
during
the
learning
of
predictor
drastically
surpassing
our
stability
bound
our
results
also
confirm
that
instability
of
the
optimal
ranking
function
ropt
is
not
only
theoretical
possibility
but
prevalent
when
working
with
real
data
to
see
this
notice
that
the
mean
value
of
ropt
ropt
is
two
orders
of
magnitude
larger
than
for
rua
for
the
enrollment
data
set
it
even
exceeds
the
mean
value
of
implying
that
is
impossible
for
the
acs
data
set
the
norms
are
very
comparable
meaning
that
is
impossible
in
fact
consistent
with
the
large
standard
deviations
there
are
multiple
instances
illustrating
that
must
be
significantly
larger
than
for
both
data
sets
6.2
utility
next
we
measure
the
utility
attained
by
the
different
ranking
functions
the
utility
map
for
both
data
sets
is
the
same
one
as
in
section
6.1
in
addition
to
the
two
rankings
functions
of
primary
interest
we
also
consider
the
following
two
baselines
runif
the
ranking
function
which
places
the
individuals
in
uniformly
random
order
and
rpl
the
plackett-luce
pl
ranking
defined
by
luce
axiom
luce
1959
plackett
1975
the
pl
model
similar
to
ua
defines
distribution
over
rankings
at
high
level
in
each
iteration
the
item
for
the
ith
position
is
sampled
based
on
softmax
mapping
of
all
remaining
items
relevance
scores
more
precisely
in
each
iteration
let
mt
be
the
set
of
individuals
not
yet
placed
in
the
ranking
with
m1
in
the
first
iteration
then
in
each
iteration
individual
mt
is
placed
in
position
with
probability
exp
pi
ri
mt
exp
pj
to
efficiently
compute
the
pl
ranking
we
use
the
now
standard
gumbel
trick
from
bruch
et
al
2020
that
is
to
sample
one
ranking
from
the
pl
ranking
distribution
rpl
we
sort
the
individuals
in
decreasing
order
of
pi
γi
where
each
γi
gumbel
independently
we
average
over
100k
samples
from
the
pl
ranking
distribution
to
compute
rpl
to
measure
utility
we
use
the
dcg
position
weights
wk
log2
in
order
to
make
the
scales
of
the
utilities
more
meaningful
in
our
comparisons
we
normalize
all
utilities
to
lie
in
thereto
let
rmin
be
the
worst-utility
ranking
obtained
by
ordering
the
individuals
by
increasing
relevance
score
the
individual
of
lowest
utility
is
deterministically
placed
first
for
ranking
function
we
compute
the
21
normalized
utility
score
as
follows
rmin
ropt
min
in
table
we
report
the
mean
and
standard
deviation
over
30
neural
network
training
runs
of
the
normalized
utility
for
each
of
the
ranking
functions
discussed
above
for
each
neural
network
and
associated
prediction
function
we
randomly
sample
20
40
and
60
individuals
from
the
test
set
then
we
construct
the
prediction
matrix
xi
and
report
for
each
ranking
function
we
find
that
ua
ranking
outperforms
the
uniform
and
pl
ranking
in
each
experimental
instance
however
ua
ranking
is
not
guaranteed
to
always
outperform
the
uniform
ranking
one
can
carefully
construct
instances
in
which
the
safe
bet
individual
provides
more
utility
than
an
individual
who
has
low
probability
of
being
moonshot
candidate
further
discussed
in
singh
et
al
2021
such
an
instance
crucially
depends
on
the
specific
choice
of
20
40
60
rua
rpl
runif
0.726
0.027
0.616
0.038
0.540
0.043
0.724
0.027
0.621
0.028
0.548
0.029
0.727
0.020
0.624
0.023
0.550
0.030
rua
rpl
runif
0.852
0.030
0.755
0.041
0.552
0.052
0.860
0.023
0.767
0.027
0.561
0.037
0.857
0.018
0.767
0.025
0.562
0.033
table
normalized
utility
achieved
by
rua
runif
and
rpl
for
20
40
and
60
random
individuals
from
the
test
set
of
acs
top
rows
and
enrollment
bottom
rows
mean
std
taken
across
30
neural
network
training
runs
ua
outperforms
the
uniform
and
pl
ranking
conclusions
and
future
work
stability
of
ranking
functions
is
natural
desideratum
to
prevent
large
deviations
arising
in
rankings
from
noise
in
learned
classifiers
combined
with
individually
fair
predictions
it
results
in
fair
rankings
stability
is
achieved
by
the
natural
uncertainty
aware
ranking
functions
which
also
preserve
multigroup
fairness
guarantees
of
their
underlying
classifiers
an
interesting
direction
for
future
work
is
to
find
more
general
sufficient
condition
for
ranking
functions
which
allows
them
to
inherit
properties
of
multiaccurate
multicalibrated
predictors
in
the
proof
of
theorem
16
we
crucially
make
use
of
the
fact
that
an
individual
when
competing
against
sampled
dataset
can
be
thought
of
as
competing
against
other
individuals
sampled
from
single
conditional
distribution
we
call
this
property
individual
interpolation
since
it
allows
for
the
linear
properties
of
multiaccuracy
and
multicalibration
noarov
and
roth
2023
to
compose
with
the
ranking
function
it
would
be
desirable
to
characterize
which
other
ranking
functions
satisfy
individual
interpolation
and
whether
the
property
is
necessary
for
guarantees
in
the
vein
of
theorem
16
another
important
extension
is
to
consider
correlations
between
the
sampled
labels
of
different
individuals
and
whether
analogous
individual
group
fairness
guarantees
can
still
be
provided
in
this
case
in
practice
predictors
used
in
rankings
in
applications
such
as
linkedin
are
trained
using
highly
correlated
data
due
to
consumer
click-through
behavior
diciccio
et
al
2023
investigating
ways
to
train
group-fair
predictors
in
the
multiaccurate
sense
while
only
relying
on
non-i
examples
and
furthermore
applying
these
predictors
in
rankings
with
correlated
merit
distributions
is
an
important
avenue
for
future
work
22
acknowledgements
sd
was
supported
by
the
department
of
defense
dod
through
the
national
defense
science
engineering
graduate
ndseg
fellowship
program
this
work
was
also
funded
in
part
by
nsf
awards
1916153
2333448
1956435
1943584
2344925
and
2239265
and
an
amazon
research
award
references
angelopoulos
and
bates
gentle
introduction
to
conformal
prediction
and
distribution-free
uncertainty
quantification
preprint
2021
asudeh
jagadish
miklau
and
stoyanovich
on
obtaining
stable
rankings
in
proc
44th
intl
conf
on
very
large
data
bases
volume
12
pages
237
250
2018
awasthi
kleindessner
and
morgenstern
equalized
odds
postprocessing
under
imperfect
group
information
in
proc
23rd
intl
conf
on
artificial
intelligence
and
statistics
pages
1770
1780
pmlr
2020
13
bastani
gupta
jung
noarov
ramalingam
and
roth
practical
adversarial
multivalid
conformal
prediction
in
proc
36th
advances
in
neural
information
processing
systems
2022
bruch
han
bendersky
and
najork
stochastic
treatment
of
learning
to
rank
scoring
functions
in
proc
13th
acm
intl
conf
on
web
search
and
data
mining
pages
61
69
2020
21
busa-fekete
ke
gl
lteto
and
szarvas
ranking
by
calibrated
adaboost
in
proceedings
of
the
learning
to
rank
challenge
pages
37
48
pmlr
2011
cao
qin
liu
tsai
and
li
learning
to
rank
from
pairwise
approach
to
listwise
approach
in
proc
24th
intl
conf
on
machine
learning
pages
129
136
2007
caton
and
haas
fairness
in
machine
learning
survey
acm
computing
surveys
2020
cohen
mitra
lesota
rekabsaz
and
eickhoff
not
all
relevance
scores
are
equal
efficient
uncertainty
and
calibration
modeling
for
deep
retrieval
models
in
proc
44th
intl
conf
on
research
and
development
in
information
retrieval
sigir
pages
654
664
2021
cooper
lee
barocas
de
sa
sen
and
zhang
is
my
prediction
arbitrary
measuring
self-consistency
in
fair
classification
in
proc
38th
aaai
conf
on
artificial
intelligence
2024
devic
kempe
sharan
and
korolova
fairness
in
matching
under
uncertainty
in
proc
40th
intl
conf
on
machine
learning
volume
202
pages
7775
7794
2023
10
20
diciccio
hsu
yu
nandy
and
basu
detection
and
mitigation
of
algorithmic
bias
via
predictive
parity
in
proceedings
of
the
2023
acm
conference
on
fairness
accountability
and
transparency
pages
1801
1816
2023
22
ding
hardt
miller
and
schmidt
retiring
adult
new
datasets
for
fair
machine
learning
in
proc
35th
advances
in
neural
information
processing
systems
2021
20
dwork
hardt
pitassi
reingold
and
zemel
fairness
through
awareness
in
proc
3rd
innovations
in
theoretical
computer
science
pages
214
226
2012
dwork
kim
reingold
rothblum
and
yona
learning
from
outcomes
evidence-based
rankings
in
proc
60th
ieee
symp
on
foundations
of
computer
science
pages
106
125
ieee
2019
23
ganesh
chang
strobel
and
shokri
on
the
impact
of
machine
learning
randomness
on
group
fairness
in
proceedings
of
the
2023
acm
conference
on
fairness
accountability
and
transparency
pages
1789
1800
2023
garcı
a-soriano
and
bonchi
maxmin-fair
ranking
individual
fairness
under
group-fairness
constraints
in
proceedings
of
the
27th
acm
sigkdd
conference
on
knowledge
discovery
data
mining
pages
436
446
2021
geyik
ambler
and
kenthapadi
fairness-aware
ranking
in
search
recommendation
systems
with
application
to
linkedin
talent
search
in
proc
25th
intl
conf
on
knowledge
discovery
and
data
mining
pages
2221
2231
2019
goodfellow
shlens
and
szegedy
explaining
and
harnessing
adversarial
examples
in
bengio
and
lecun
editors
3rd
international
conference
on
learning
representations
iclr
2015
san
diego
ca
usa
may
2015
2015
url
http://arxiv.org/abs/1412.6572.
google
ads
help
about
ad
rank
2023
url
https://support.google.com/google-ads/answer/
1722122
hl
en
accessed
2023
09
28
gopalan
kim
singhal
and
zhao
low-degree
multicalibration
in
proc
35th
conference
on
learning
theory
pages
3193
3234
pmlr
2022
13
16
gorantla
mehrotra
deshpande
and
louis
sampling
individually-fair
rankings
that
are
always
group
fair
in
rossi
das
davis
firth-butterfield
and
john
editors
proceedings
of
the
2023
aaai
acm
conference
on
ai
ethics
and
society
aies
2023
pages
205
216
acm
2023
guiver
and
snelson
learning
to
rank
with
softrank
and
gaussian
processes
in
proc
31st
intl
conf
on
research
and
development
in
information
retrieval
sigir
pages
259
266
2008
guo
pleiss
sun
and
weinberger
on
calibration
of
modern
neural
networks
in
proc
34th
intl
conf
on
machine
learning
pages
1321
1330
pmlr
2017
guo
ton
and
liu
fair
learning
to
rank
with
distribution-free
risk
control
preprint
2023
gupta
and
ramdas
top-label
calibration
and
multiclass-to-binary
reductions
in
the
tenth
international
conference
on
learning
representations
iclr
2022
virtual
event
april
25
29
2022
openreview
.net
2022
url
https://openreview.net/forum?id=wqobaaphs-.
gutie
rrez
perez-ortiz
sanchez-monedero
fernandez-navarro
and
hervas-martinez
ordinal
regression
methods
survey
and
experimental
study
ieee
transactions
on
knowledge
and
data
engineering
28
127
146
2015
haghtalab
jordan
and
zhao
unifying
perspective
on
multi-calibration
unleashing
game
dynamics
for
multi-objective
learning
proc
37th
advances
in
neural
information
processing
systems
36
2023
13
hardt
price
and
srebro
equality
of
opportunity
in
supervised
learning
proc
30th
advances
in
neural
information
processing
systems
29
2016
13
harper
and
konstan
the
movielens
datasets
history
and
context
acm
trans
interact
intell
syst
2015
20
he
bert-johnson
kim
reingold
and
rothblum
multicalibration
calibration
for
the
computationally-identifiable
masses
in
proc
35th
intl
conf
on
machine
learning
pages
1939
1948
pmlr
2018
12
13
16
24
heuss
cohen
mansoury
rijke
and
eickhoff
predictive
uncertainty-based
bias
mitigation
in
ranking
in
proceedings
of
the
32nd
acm
international
conference
on
information
and
knowledge
management
pages
762
772
2023
ja
rvelin
and
keka
la
inen
cumulated
gain-based
evaluation
of
ir
techniques
acm
transactions
on
information
systems
tois
20
422
446
2002
16
jung
noarov
ramalingam
and
roth
batch
multivalid
conformal
prediction
in
the
eleventh
international
conference
on
learning
representations
iclr
2023
kigali
rwanda
may
2023
2023
kim
ghorbani
and
zou
multiaccuracy
black-box
post-processing
for
fairness
in
classification
in
proceedings
of
the
2019
aaai
acm
conference
on
ai
ethics
and
society
pages
247
254
2019
12
13
korevaar
mcconnell
tong
brinkman
shine
abbas
metevier
corbett-davies
and
el-arini
matched
pair
calibration
for
ranking
fairness
arxiv
preprint
arxiv
2306.03775
2023
kweon
kang
and
yu
obtaining
calibrated
probabilities
with
personalized
ranking
models
in
proc
36th
aaai
conf
on
artificial
intelligence
volume
36
pages
4083
4091
2022
luce
individual
choice
behavior
courier
corporation
1959
21
martins
tolledo
machado
baptista
and
realinho
early
prediction
of
student
performance
in
higher
education
case
study
in
trends
and
applications
in
information
systems
and
technologies
volume
pages
166
175
springer
2021
20
mehrotra
and
celis
mitigating
bias
in
set
selection
with
noisy
protected
attributes
in
proceedings
of
the
2021
acm
conference
on
fairness
accountability
and
transparency
pages
237
248
2021
mehrotra
and
vishnoi
fair
ranking
with
noisy
protected
attributes
proc
36th
advances
in
neural
information
processing
systems
35
31711
31725
2022
menon
jiang
vembu
elkan
and
ohno-machado
predicting
accurate
probabilities
with
ranking
loss
in
proc
29th
intl
conf
on
machine
learning
volume
2012
page
703
2012
meta
our
approach
to
facebook
feed
ranking
2023
url
https://transparency.fb.com/features/
ranking-and-content
accessed
2023
09
28
minderer
djolonga
romijnders
hubis
zhai
houlsby
tran
and
lucic
revisiting
the
calibration
of
modern
neural
networks
proc
35th
advances
in
neural
information
processing
systems
34
15682
15694
2021
narasimhan
cotter
gupta
and
wang
pairwise
fairness
for
ranking
and
regression
in
proc
34th
aaai
conf
on
artificial
intelligence
volume
34
pages
5248
5255
2020
nettleton
orriols-puig
and
fornells
study
of
the
effect
of
different
types
of
noise
on
the
precision
of
supervised
learning
techniques
artificial
intelligence
review
33
275
306
2010
noarov
and
roth
the
statistical
scope
of
multicalibration
in
proc
40th
intl
conf
on
machine
learning
volume
202
pages
26283
26310
2023
22
oh
ustun
mcauley
and
kumar
rank
list
sensitivity
of
recommender
systems
to
interaction
perturbations
in
proceedings
of
the
31st
acm
international
conference
on
information
knowledge
management
pages
1584
1594
2022
oh
ustun
mcauley
and
kumar
finest
stabilizing
recommendations
by
rank-preserving
fine-tuning
arxiv
preprint
arxiv
2402.03481
2024
25
penha
and
hauff
on
the
calibration
and
uncertainty
of
neural
learning
to
rank
models
for
conversational
search
in
proceedings
of
the
16th
conference
of
the
european
chapter
of
the
association
for
computational
linguistics
main
volume
pages
160
170
2021
pitoura
stefanidis
and
koutrika
fairness
in
rankings
and
recommendations
an
overview
in
proc
48th
intl
conf
on
very
large
data
bases
2022
18
plackett
the
analysis
of
permutations
journal
of
the
royal
statistical
society
series
applied
statistics
24
193
202
1975
21
rastogi
and
joachims
fair
ranking
under
disparate
uncertainty
preprint
2023
robertson
the
probability
ranking
principle
in
ir
journal
of
documentation
33
294
304
1977
shabat
cohen
and
mansour
sample
complexity
of
uniform
convergence
for
multicalibration
proc
34th
advances
in
neural
information
processing
systems
33
13331
13340
2020
16
shalev-shwartz
and
ben-david
understanding
machine
learning
from
theory
to
algorithms
cambridge
university
press
2014
12
16
shen
wang
zhu
fain
and
munagala
fairness
in
the
assignment
problem
with
uncertain
priorities
in
proc
22nd
intl
conf
on
autonomous
agents
and
multiagent
systems
page
188
196
2023
singh
and
joachims
fairness
of
exposure
in
rankings
in
proceedings
of
the
24th
acm
sigkdd
international
conference
on
knowledge
discovery
data
mining
pages
2219
2228
2018
singh
and
joachims
policy
learning
for
fairness
in
ranking
proc
33rd
advances
in
neural
information
processing
systems
32
2019
18
singh
kempe
and
joachims
fairness
in
ranking
under
uncertainty
in
proc
35th
advances
in
neural
information
processing
systems
pages
11896
11908
2021
10
18
20
22
soliman
and
ilyas
ranking
with
uncertain
scores
in
2009
ieee
25th
international
conference
on
data
engineering
pages
317
328
ieee
2009
tahir
cheng
and
liu
fairness
through
aleatoric
uncertainty
preprint
2023
tang
koc
yig
it
rice
and
vayanos
learning
optimal
and
fair
policies
for
online
allocation
of
scarce
societal
resources
from
data
collected
in
deployment
arxiv
preprint
arxiv
2311.13765
2023
taylor
guiver
robertson
and
minka
softrank
optimizing
non-smooth
rank
metrics
in
proc
1st
acm
intl
conf
on
web
search
and
data
mining
pages
77
86
2008
16
turbohire
unleashing
the
power
of
ai
automation
to
effortlessly
discover
the
best
talent
2023
url
https://turbohire.co/features/talent-screening/#candidate-scoring.
accessed
2023
10
09
wang
and
chen
learning
to
predict
the
cost-per-click
for
your
ad
words
in
proceedings
of
the
21st
acm
international
conference
on
information
and
knowledge
management
pages
2291
2294
2012
xu
and
li
adarank
boosting
algorithm
for
information
retrieval
in
proc
30th
intl
conf
on
research
and
development
in
information
retrieval
sigir
pages
391
398
2007
yan
qin
wang
bendersky
and
najork
scale
calibration
of
deep
ranking
models
in
proceedings
of
the
28th
acm
sigkdd
conference
on
knowledge
discovery
and
data
mining
pages
4300
4309
2022
yang
luo
lu
gupta
yin
and
ai
can
clicks
be
both
labels
and
features
unbiased
behavior
feature
collection
and
uncertainty-aware
learning
to
rank
in
proc
45th
intl
conf
on
research
and
development
in
information
retrieval
sigir
pages
17
2022
26
yang
xu
wang
tran
and
ai
marginal-certainty-aware
fair
ranking
algorithm
in
proc
16th
acm
intl
conf
on
web
search
and
data
mining
pages
24
32
2023
zehlike
yang
and
stoyanovich
fairness
in
ranking
survey
preprint
2021
url
https
arxiv
org
abs
2103.14000
zou
wang
kolter
and
fredrikson
universal
and
transferable
adversarial
attacks
on
aligned
language
models
preprint
2023
27
proof
of
key
lemma
for
uncertainty
aware
ranking
the
proof
of
lemma
12
uses
the
following
lemma
bounding
the
total
variation
distance
of
sums
of
random
variables
in
terms
of
the
total
variation
distances
of
the
individual
variables
lemma
23
let
and
pn
pn
xi
pi
yi
qi
for
be
independent
categorical
random
variables
pn
let
be
the
respective
distributions
of
then
tv
tv
pi
qi
proof
consider
maximal
coupling
between
each
xi
and
the
corresponding
yi
by
the
coupling
lemma
we
then
have
that
xi
yi
dtv
pi
qi
and
dtv
now
by
union
bound
over
all
we
obtain
that
dtv
xi
yi
dtv
pi
qi
completing
the
proof
proof
of
lemma
12
first
by
equation
in
the
first
part
of
proposition
ri
λi
and
let
pp
and
pq
and
note
that
is
not
random
variable
but
simply
determined
by
the
distributions
we
substitute
the
characterization
for
both
and
and
use
the
triangle
inequality
as
well
as
the
fact
that
to
give
us
that
prua
ri
λi
prua
ri
λi
pp
and
pq
and
pp
and
pq
and
pq
and
pp
and
pp
and
pq
and
pq
and
pp
and
pp
and
pq
and
pp
and
pq
and
consider
the
vector-valued
random
variable
and
let
denote
its
distribution
under
respectively
because
and
and
and
are
events
that
can
be
expressed
in
terms
of
this
random
variable
the
definition
of
total
variation
distance
implies
that
pp
and
pq
and
dtv
pp
and
pq
and
dtv
28
to
bound
dtv
associate
with
each
individual
the
dimensional
random
vector
vi
1λi
1λi
then
vi
for
fixed
consider
the
distribution
of
vi
under
pi
and
qi
the
total
variation
distance
between
these
distributions
is
at
most
dtv
pi
qi
because
the
vectors
can
differ
only
when
the
labels
of
differ
by
lemma
23
we
thus
obtain
that
dtv
dtv
pi
qi
substituting
this
bound
back
into
we
now
obtain
that
prua
ri
λi
prua
ri
λi
dtv
pi
qi
completing
the
proof
29