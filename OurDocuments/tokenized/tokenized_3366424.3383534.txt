fairsearch
tool
for
fairness
in
ranked
search
results
meike
zehlike
tom
sühr
humboldt
universität
zu
berlin
technische
universität
berlin
max
planck
inst
for
software
systems
tom.suehr@googlemail.com
meikezehlike@mpi-sws.org
carlos
castillo
ivan
kitanovski
universitat
pompeu
fabra
faculty
of
computer
science
and
engineering
chato@acm.org
university
saint
cyril
and
methodius
ivan.kitanovski@finki.ukim.mk
abstract
relevant
content
ranking
algorithms
automatically
score
and
sort
ranked
search
results
and
recommendations
have
become
the
main
these
contents
for
us
typically
by
decreasing
probability
of
an
mechanism
by
which
we
find
content
products
places
and
people
item
being
relevant
therefore
more
often
than
not
algorithms
online
with
hiring
selecting
purchasing
and
dating
being
increas
choose
not
only
the
products
we
are
offered
and
the
news
we
ingly
mediated
by
algorithms
rankings
may
determine
business
read
but
also
the
people
we
meet
or
whether
we
get
loan
or
an
opportunities
education
access
to
benefits
and
even
social
success
invitation
to
job
interview
with
hiring
selecting
purchasing
and
it
is
therefore
of
societal
and
ethical
importance
to
ask
whether
dating
being
increasingly
mediated
by
algorithms
rankings
may
search
results
can
demote
marginalize
or
exclude
individuals
of
determine
business
opportunities
education
access
to
benefits
and
unprivileged
groups
or
promote
products
with
undesired
features
even
social
success
it
is
therefore
of
societal
and
ethical
importance
in
this
paper
we
present
fairsearch
the
first
fair
open
source
to
ask
whether
search
algorithms
produce
results
that
can
demote
search
api
to
provide
fairness
notions
in
ranked
search
results
we
marginalize
or
exclude
individuals
of
unprivileged
groups
implement
two
well-known
algorithms
from
the
literature
namely
racial
or
gender
discrimination
or
promote
products
with
undesired
fa
ir
zehlike
et
al
2017
and
deltr
zehlike
and
castillo
2018
features
gendered
books
and
provide
them
as
stand-alone
libraries
in
python
and
java
ad
this
paper
operates
on
the
concept
of
historically
and
currently
ditionally
we
implement
interfaces
to
elasticsearch
for
both
algo
disadvantaged
protected
group
and
the
concern
of
disparate
impact
rithms
well-known
search
engine
api
based
on
apache
lucene
loss
of
opportunity
for
said
group
independently
of
whether
the
interfaces
use
the
aforementioned
java
libraries
and
enable
they
are
treated
differently
in
rankings
disparate
impact
translates
search
engine
developers
who
wish
to
ensure
fair
search
results
into
differences
in
exposure
or
inequality
of
attention
across
of
different
styles
to
easily
integrate
deltr
and
fa
ir
into
their
groups
which
are
to
be
understood
as
systematic
differences
in
existing
elasticsearch
environment
access
to
economic
or
social
opportunities
in
this
paper
we
present
fairsearch
the
first
fair
open
source
ccs
concepts
search
api
that
implements
two
well-known
methods
from
the
literature
namely
fa
ir
and
deltr
10
for
both
algorithms
information
systems
learning
to
rank
applied
com
the
implementation
is
provided
as
stand-alone
java
and
python
puting
law
social
and
behavioral
sciences
library
as
well
as
interfaces
for
elasticsearch
popular
well
tested
search
engine
which
is
used
by
many
big
brands
such
as
keywords
amazon
netflix
and
facebook
our
goal
with
fairsearch
is
to
pro
ranking
algorithmic
fairness
disparate
impact
vide
various
approaches
for
fair
ranking
algorithms
with
broad
acm
reference
format
spectrum
of
justice
definitions
to
satisfy
many
possible
fairness
meike
zehlike
tom
sühr
carlos
castillo
and
ivan
kitanovski
2020
fairsearch
policies
in
various
business
situations
by
providing
the
algorithms
tool
for
fairness
in
ranked
search
results
in
companion
proceedings
of
as
stand-alone
libraries
in
python
and
java
and
for
elasticsearch
the
web
conference
2020
www
20
companion
april
20
24
2020
taipei
we
make
the
on-going
research
on
fair
machine
learning
accessible
taiwan
acm
new
york
ny
usa
pages
https://doi.org/10.1145/3366424.
and
ready-to-use
for
broad
community
of
professional
developers
3383534
and
researchers
particularly
those
working
in
the
realm
of
human
introduction
centric
and
socio-technical
systems
as
well
as
sharing
economy
platforms
with
the
volume
of
information
increasing
at
frenetic
pace
ranked
search
results
have
become
the
main
mechanism
by
which
we
find
theoretical
background
this
section
explains
the
math
behind
fa
ir
and
deltr
and
gives
this
paper
is
published
under
the
creative
commons
attribution
4.0
international
cc
by
4.0
license
authors
reserve
their
rights
to
disseminate
the
work
on
their
examples
for
their
application
domain
deltr
10
constitutes
so
personal
and
corporate
web
sites
with
the
appropriate
attribution
called
in-processing
approach
that
incorporates
fairness
term
into
www
20
companion
april
20
24
2020
taipei
taiwan
its
learning
objective
this
way
it
can
learn
to
ignore
the
protected
2020
iw3c2
international
world
wide
web
conference
committee
published
under
creative
commons
cc
by
4.0
license
feature
as
well
as
non-protected
ones
that
serve
as
proxies
such
as
acm
isbn
978
4503
7024
20
04
https://doi.org/10.1145/3366424.3383534
https://www.elastic.co/
172
www
20
companion
april
20
24
2020
taipei
taiwan
zehlike
et
al
aa
aa
10
11
12
0.1
0.3
0.5
case
where
all
non-protected
elements
appear
first
in
the
training
set
0.7
table
example
values
of
the
minimum
number
of
pro
tected
items
that
must
appear
in
the
top
positions
to
pass
the
ranked
group
fairness
test
with
0.1
we
call
this
an
mtable
table
from
given
ranking
of
length
the
ratio
of
protected
items
does
not
fall
far
below
given
at
any
ranking
position
fa
ir
translates
case
where
all
protected
elements
appear
first
in
the
training
set
figure
depiction
of
test
results
using
synthetic
data
top
this
constraint
into
statistical
significance
test
using
the
binomial
deltr
reduces
disparate
exposure
bottom
asymmetry
in
cumulative
distribution
function
with
parameters
and
and
deltr
which
does
not
change
rankings
if
protected
ele
declares
ranking
as
fairly
representing
the
protected
group
if
for
ments
already
appear
in
the
first
positions
each
the
following
constraint
holds
zip
code
fa
ir
belongs
to
the
class
of
post-processing
proce
τp
dures
and
re-ranks
given
search
engine
result
to
meet
predefined
where
τp
is
the
actual
number
of
protected
items
in
the
ranking
fairness
constraints
under
test
this
constraint
can
now
be
used
to
calculate
the
min
imum
number
of
protected
items
at
each
ranking
position
such
2.1
deltr
learning-to-rank
approach
that
the
constraint
holds
see
table
with
different
examples
of
in
traditional
learning-to-rank
ltr
systems
ranking
function
as
an
example
consider
the
ranking
in
table
that
corresponds
is
learned
by
minimizing
loss
function
that
measures
the
error
to
job
candidate
search
for
an
economist
in
the
xing
dataset
between
predictions
made
by
and
the
training
judgments
for
used
in
we
observe
that
the
proportion
of
male
and
female
deltr
the
loss
function
of
listnet
well-known
ltr
algorithm
is
extended
by
term
which
measures
the
unfairness
of
position
top
10
top
10
top
40
top
40
predicted
ranking
this
way
new
loss
function
deltr
10
male
female
male
female
γu
simultaneously
optimizes
for
relevance
and
fairness
is
90
10
73
27
defined
to
be
measure
of
disparate
exposure
across
different
social
groups
in
probabilistic
ranking
py
this
means
discrepancies
in
table
example
of
non-uniformity
of
the
top-10
vs
the
top
the
probability
to
appear
at
the
top
position
received
by
items
of
40
results
for
query
economist
in
xing
jan
2017
table
the
protected
group
vs
items
of
the
non-protected
group
are
from
measured
candidates
keeps
changing
throughout
the
top
positions
which
in
max
exposure
py
exposure
py
this
case
disadvantages
women
by
preferring
men
at
the
top-10
po
sitions
suppose
that
the
required
proportion
of
female
candidates
figure
shows
how
deltr
works
on
synthetic
dataset
which
is
0.3
this
translates
into
having
at
least
one
female
candidate
has
total
size
of
50
items
and
each
item
is
represented
by
in
the
top-10
positions
hence
the
ranking
in
table
will
be
ac
two
features
their
protection
status
and
score
between
and
cepted
as
fair
however
if
the
required
proportion
is
0.5
this
the
attribute
is
if
the
item
belongs
to
the
translates
into
needing
at
least
one
female
candidate
in
the
top-4
protected
group
and
otherwise
the
scores
are
distributed
two
in
the
top-7
and
three
in
the
top-9
positions
in
this
case
the
uniformly
at
random
over
two
non-overlapping
intervals
training
ranking
will
be
reordered
by
fa
ir
to
meet
the
fairness
constraints
documents
are
ordered
by
decreasing
scores
hence
the
top
element
furthermore
our
library
implements
the
best
possible
adjustment
is
the
one
that
has
the
highest
score
of
the
desired
significance
level
this
is
necessary
because
the
we
first
consider
scenario
in
which
all
protected
elements
have
test
for
representation
like
in
table
is
multi-hypothesis
test
strictly
smaller
scores
than
all
non-protected
ones
figure
1a
standard
learning
to
rank
algorithm
in
this
case
places
all
non
fairsearch
the
deltr
plugin
protected
elements
above
all
protected
elements
giving
them
for
the
integration
of
deltr
into
elasticsearch
we
use
the
elas
larger
exposure
instead
deltr
with
increasing
values
of
reduces
ticsearch
learning
to
rank
ltr-es
plugin
the
integration
ar
the
disparate
exposure
while
still
considering
the
discrepancy
in
chitecture
is
depicted
on
figure
the
logic
consists
of
two
phases
the
score
values
figure
1b
shows
the
asymmetry
of
the
method
if
training
and
ranking
the
protected
elements
already
receive
larger
predicted
exposure
training
to
apply
deltr
at
run-time
for
retrieval
ltr-es
needs
than
the
non-protected
by
ranker
deltr
will
behave
like
previously
trained
model
that
is
uploaded
into
its
model
storage
standard
ltr
approach
since
training
models
is
very
cpu
intensive
task
that
involves
2.2
fa
ir
re-ranking
approach
lot
of
supervision
and
verification
it
happens
offline
in
deltr
being
post-processing
method
fa
ir
assumes
that
ranking
wrapper
which
calls
our
stand-alone
deltr
python
library
to
function
has
already
been
trained
and
ranked
search
result
is
train
ltr-es
suitable
model
the
wrapper
has
to
be
provided
available
its
ranked
group
fairness
constraint
guarantees
that
in
https://elasticsearch-learning-to-rank.readthedocs.io/en/latest/
173
fairsearch
tool
for
fairness
in
ranked
search
results
www
20
companion
april
20
24
2020
taipei
taiwan
architecture
of
the
fa
ir
elasticsearch
plugin
demo
application
figure
architecture
of
the
fa
ir
elasticsearch
plugin
and
demo
webapp
with
the
fa
ir
elasticsearh
plugin
red
indicates
protected
items
with
training
set
the
training
parameters
and
name
for
the
interface
which
it
applies
our
previously
learned
weights
to
the
model
after
training
the
wrapper
calls
the
ltr-es
upload
api
document
features
of
the
top
results
to
produce
the
final
ranking
which
stores
the
serialized
model
inside
elasticsearch
ltr
plugin
in
the
rescorer
we
have
to
specify
two
key
parameters
making
it
available
for
up-coming
retrieval
tasks
upon
upload
the
window_size
the
number
of
elements
to
re-score
usually
wrapper
specifies
model_name
type
always
deltr
the
model
itself
and
the
feature_set
it
was
trained
against
feature_set
model
the
model
name
specifies
query-dependent
features
that
tell
ltr-es
which
docu
ment
features
to
use
when
applying
the
model
post
ranking
elasticsearch
ranks
retrieved
documents
by
applying
query
match
re-scoring
methods
because
executing
query
on
the
entire
elas
snow
ticsearch
cluster
is
very
expensive
the
system
first
executes
rescore
baseline
relevance
query
on
the
entire
index
and
returns
the
top
window_size
1000
results
the
rescorer
then
modifies
the
scores
for
the
top
results
query
and
returns
the
new
list
deltr
implements
elastic
rescorer
rescore_query
sltr
params
keywords
snow
model
the
above
code
constitutes
sample
rescore
query
using
deltr
in
which
we
limit
the
result
set
to
documents
that
match
jon
snow
all
results
are
scored
based
on
elasticsearch
default
similarity
bm25
on
top
of
those
already
somewhat
relevant
results
we
apply
our
deltr
model
to
get
the
best
and
fairest
ranking
of
the
top
1000
documents
fairsearch
the
fa
ir
plugin
the
fa
ir
plugin
enables
elasticsearch
to
process
search
query
and
re-rank
the
result
using
fa
ir
with
parameters
and
it
extends
the
elasticsearch
api
by
two
new
endpoints
and
fair
rescorer
json
object
that
contains
the
parameters
for
fa
ir
the
two
new
endpoints
create
new
or
request
an
existing
mtable
an
integer
array
that
implements
table
once
generated
mtables
are
persisted
within
elasticsearch
for
further
usage
to
avoid
additional
computational
costs
at
search
time
figure
2a
shows
the
control
figure
architecture
of
the
elasticsearch
plugin
integra
flow
inside
the
plugin
fa
ir
query
is
passed
to
elasticsearch
and
tion
for
deltr
174
www
20
companion
april
20
24
2020
taipei
taiwan
zehlike
et
al
algorithm
construct
mtable
input
ranking
size
minimum
proportion
significance
output
mtable
nk
0k
αc
adjustalpha
for
to
do
mi
inversecdf
αc
end
return
elastic
returns
the
standard
result
ranking
to
the
plugin
the
plugin
figure
re-ranking
an
elasticsearch
result
according
to
then
re-ranks
the
result
according
to
the
respective
mtable
that
mtable
shields
indicate
protected
items
matches
the
input
parameters
and
note
that
the
execution
of
an
unaware
search
query
with
all
built-in
features
is
still
possible
demonstration
all
libraries
and
plugins
are
available
at
https://github.com/fair-search.
post
our
demo
will
consist
of
two
main
parts
first
we
will
explain
the
from
size
architecture
of
fa
ir
and
deltr
by
use
of
the
figures
in
this
paper
match
body
next
we
will
have
live
coding
session
for
fa
ir
we
will
code
rescore
mini
example
that
is
going
to
setup
the
algorithm
in
an
elastic
window_size
search
instance
it
will
show
how
to
integrate
the
parameters
fair_rescorer
and
and
how
to
further
interact
with
the
elasticsearch
plugin
via
protected_key
gender
search
queries
an
introduction
into
the
fa
ir
python
library
and
protected_value
elasticsearch
plugin
is
available
on
youtube
11
for
deltr
we
alpha
will
use
the
synthetic
dataset
from
section
2.1
to
train
fair
model
min_proportion_protected
we
will
show
how
to
upload
this
model
into
elasticsearch
using
the
deltr-wrapper
and
how
it
is
used
when
issuing
search
query
the
components
communicate
via
rest
api
for
http
requests
second
using
the
results
from
the
live
coding
session
we
will
and
the
above
code
represents
http
request
to
the
plugin
with
observe
how
the
algorithms
influence
ranking
results
on
demo
this
elasticsearch
executes
regular
search
using
the
specified
website
figure
2b
for
job
candidate
search
which
operates
on
query
object
the
match
object
and
query
terms
the
result
is
resume
dataset
lastly
we
will
demonstrate
how
different
input
re-ranked
by
the
plugin
using
fa
ir
if
the
fairness
constraints
parameters
for
deltr
and
fa
ir
will
affect
the
results
and
give
named
in
and
are
not
met
first
the
mtable
handler
will
intuition
on
best
practice
choices
for
the
parameters
these
two
check
if
mtable
for
parameters
already
exists
right
side
parts
are
also
shown
in
the
youtube
tutorial
of
figure
2a
if
not
the
plugin
calls
the
mtable
generator
to
we
require
large
screen
so
that
attendees
will
be
able
to
follow
create
it
using
algorithm
and
stores
it
to
mtable
storage
as
the
coding
examples
from
distance
key-value
pairs
with
key
we
note
that
the
mtable
handler
in
figure
2a
is
simplification
of
java
classes
and
interfaces
for
the
references
purpose
of
presentation
the
fa
ir
ranker
figure
2a
re-ranks
the
2018
resumes
dataset
with
labels
2018
https://www.kaggle.com/
iammhaseeb
resumes-dataset-with-labels
accessed
2018
11
02
elasticsearch
results
according
to
the
requested
mtable
figure
toon
calders
and
indre
žliobaite
2013
why
unbiased
computational
processes
and
returns
them
through
http
response
in
json
format
like
can
lead
to
discriminative
decision
procedures
in
discrimination
and
privacy
in
the
information
society
springer
43
57
standard
elasticsearch
result
zhe
cao
tao
qin
tie-yan
liu
ming-feng
tsai
and
hang
li
2007
learning
to
rank
from
pairwise
approach
to
listwise
approach
in
proceedings
of
the
24th
conclusion
international
conference
on
machine
learning
acm
129
136
in
this
paper
we
presented
fairsearch
the
first
open
source
api
cynthia
dwork
moritz
hardt
toniann
pitassi
omer
reingold
and
richard
zemel
2012
fairness
through
awareness
in
proc
of
itcs
acm
press
214
226
for
search
engines
to
provide
fair
search
results
we
implemented
moritz
hardt
2014
how
big
data
is
unfair
understanding
sources
of
unfairness
our
previously
published
methods
as
stand-alone
libraries
in
python
in
data
driven
decision
making
2014
stephen
robertson
1977
the
probability
ranking
principle
in
ir
journal
of
and
java
and
embedded
those
into
plugins
for
elasticsearch
while
documentation
33
1977
294
304
the
plugins
are
intended
to
be
off-the-shelf
implementations
for
ashudeep
singh
and
thorsten
joachims
2018
fairness
of
exposure
in
rankings
elasticsearch
engineers
the
stand-alone
libraries
allow
great
flexi
in
proceedings
of
the
24th
acm
sigkdd
international
conference
on
knowledge
discovery
data
mining
acm
2219
2228
bility
for
those
who
use
other
technology
such
as
solr
this
way
latanya
sweeney
2013
discrimination
in
online
ad
delivery
queue
11
2013
we
hope
that
fairness-aware
algorithms
will
make
their
way
faster
10
into
productive
code
and
business
environments
to
avoid
bad
social
meike
zehlike
francesco
bonchi
carlos
castillo
sara
hajian
mohamed
mega
hed
and
ricardo
baeza-yates
2017
fa
ir
fair
top-k
ranking
algorithm
in
consequences
such
as
discrimination
in
search
results
proc
of
the
2017
acm
on
conference
on
information
and
knowledge
management
acm
1569
1578
acknowledgments
this
project
was
realized
with
research
10
meike
zehlike
and
carlos
castillo
2018
reducing
disparate
exposure
in
ranking
grant
from
data
transparency
lab
castillo
is
partially
funded
learning
to
rank
approach
arxiv
preprint
arxiv
1805.08716
2018
by
la
caixa
project
lcf
pr
pr16
11110009
zehlike
is
funded
by
11
meike
zehlike
and
tom
sühr
2019
fa
ir
in
fairsearch
tutorial
05
01
2019
https://youtu.be/uxxtijlb5sy
the
mpi-sws
175