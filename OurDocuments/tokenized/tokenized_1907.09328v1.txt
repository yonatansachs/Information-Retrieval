arxiv
1907
09328v1
cs
ir
22
jul
2019
conceptual
framework
for
evaluating
fairness
in
search
anubrata
das
matthew
lease
anubrata@utexas.edu
university
of
texas
at
austin
austin
texas
usa
ml@utexas.edu
university
of
texas
at
austin
austin
texas
usa
abstract
while
search
efficacy
has
been
evaluated
traditionally
on
the
basis
of
result
relevance
fairness
of
search
has
attracted
recent
attention
in
this
work
we
define
notion
of
distributional
fairness
and
provide
conceptual
framework
for
evaluating
search
results
based
on
it
as
part
of
this
we
formulate
set
of
axioms
which
an
ideal
evaluation
framework
should
satisfy
for
distributional
fairness
we
show
how
existing
trec
test
collections
can
be
repurposed
to
study
fairness
and
we
measure
potential
data
bias
to
inform
test
collection
design
for
fair
search
set
of
analyses
show
metric
divergence
between
relevance
and
fairness
and
we
describe
simple
but
flexible
interpolation
strategy
for
integrating
relevance
and
fairness
into
single
metric
for
optimization
and
evaluation
ir
systems
face
existing
societal
bias
such
as
gender
and
racial
14
inequality
application
areas
such
as
resume-search
19
and
political
news-search
10
demonstrate
this
two
types
of
fairness
are
individual
fairness
and
group
fairness
group
fairness
ensures
that
all
protected
groups
are
treated
equally
while
individual
fairness
ensures
that
all
individuals
are
treated
equally1
researchers
have
proposed
different
methods
to
tackle
the
bias
in
ir
systems
18
20
these
approaches
include
new
ranking
algorithms
taking
fairness
constraints
into
account
postprocessing
method
for
re-ranking
existing
systems
considering
both
individual
and
group
fairness
19
and
evaluation
of
ranking
systems
in
terms
of
fairness
18
from
group
fairness
perspective
ibm-3602
is
an
industry
standard
for
evaluating
fairness
in
machine
learning
algorithms
and
datasets
however
it
does
not
include
measurements
for
ranking
systems
recent
work
such
as
sapiezynski
et
al
15
yang
and
stoyanovich
18
has
begun
to
explore
evaluating
search
fairness
keywords
information
retrieval
fairness
evaluation
introduction
algorithmic
fairness
is
now
receiving
significant
attention
and
with
search
systems
increasingly
mediating
human
information
access
it
is
recognized
that
search
systems
must
be
fair
as
well
as
accurate
however
while
the
idea
of
fairness
is
intuitive
there
are
many
competing
definitions
of
how
to
operationalize
it
in
practice
there
is
also
increasing
recognition
today
that
dataset
bias
imbalance
can
lead
to
biased
training
or
evaluation
for
example
while
one
might
desire
balanced
search
results
an
imbalanced
dataset
distribution
can
make
this
goal
more
difficult
to
achieve
in
practice
to
the
extent
relevant
information
is
more
scarce
for
some
perspectives
or
categories
imbalance
in
relevant
information
may
lead
to
imbalance
in
retrieved
results
when
relevant
information
for
given
category
is
scarce
or
completely
absent
it
may
be
difficult
or
impossible
for
ir
systems
to
find
any
relevant
results
from
that
category
to
retrieve
diversity
thus
plays
role
in
test
collection
design
and
decisions
must
be
made
as
to
which
categories
it
will
be
important
to
ensure
diversity
in
terms
of
documents
included
in
the
collection
and
relevance
annotation
in
this
work
we
define
notion
of
distributional
fairness
and
provide
conceptual
framework
for
evaluating
search
results
based
on
it
section
section
formulates
set
of
axioms
which
an
ideal
evaluation
framework
should
satisfy
for
distributional
fairness
in
section
we
show
how
existing
trec
test
collections
can
be
repurposed
to
study
fairness
and
section
5.1
measures
potential
data
bias
to
inform
test
collection
design
for
fair
search
set
of
analyses
presented
in
section
show
metric
divergence
between
relevance
and
fairness
and
simple
but
flexible
interpolation
strategy
for
integrating
relevance
and
fairness
into
single
metric
for
optimization
and
evaluation
we
first
provide
brief
background
related
work
evaluation
desiderata
motivated
by
lioma
et
al
11
we
propose
desiderata
for
evaluating
ranking
systems
that
are
both
fair
and
relevant
we
also
include
the
notion
of
authoritativeness
especially
keeping
in
mind
modern
challenges
such
as
polarization
and
misinformation
d1
fairness
ranking
system
should
return
set
of
documents
that
fairly
represent
different
types
of
contents
fairness
can
have
different
definitions
two
of
them
are
described
below
d1
equality
ranking
system
should
return
documents
from
different
types
in
equal
proportion
regardless
of
the
distribution
of
content
d1
equity
ranking
system
should
return
documents
from
different
types
where
the
frequency
of
documents
reflects
the
distribution
of
contents
in
real
world
d2
exposure
bias
in
the
ranking
output
there
should
not
be
any
presentation
bias
for
relevant
documents
across
different
types
certain
types
of
document
should
not
always
appear
before
the
other
types
16
d2
the
property
of
fair
exposure
should
hold
across
any
number
of
arbitrary
queries
d3
relevance
system
should
always
return
document
that
is
more
relevant
above
less
relevant
document
d4
generalizability
at
any
k-th
intersection
of
ranking
documents
should
be
both
relevant
and
fairly
represented
d5
authoritativeness
for
some
specific
topics
ranking
system
can
have
deliberate
authoritative
bias
imposed
on
type
of
information
to
avoid
misinformation
fairness-measures
http://www.fairness-measures.org/
https://aif360.mybluemix.net/
july
2019
approach
in
this
section
we
describe
our
conceptual
framework
for
evaluating
fairness
in
search
results
the
key
tenet
of
our
approach
is
that
documents
can
be
organized
into
categories
and
that
ir
systems
should
ensure
some
degree
of
balanced
coverage
over
these
categories
in
search
results
key
concepts
include
document
categories
we
assume
single
set
of
static
document
categories
topical
news
vs
sports
documents
irrespective
of
topic
at
evaluation
we
know
the
number
of
categories
and
labels
for
each
document
results
distribution
the
actual
distribution
of
documents
over
categories
in
search
results
notated
as
the
results
distribution
as
estimated
over
categories
target
distribution
the
desired
distribution
of
documents
over
categories
in
search
results
the
target
distribution
may
be
arbitrarily
specified
uniform
reflect
distributional
prior
or
be
empirically-derived
dataset
distribution
we
assume
in
this
work
that
the
target
distribution
is
constant
across
search
topics
we
denote
the
target
distribution
as
qt
where
denotes
the
target
distribution
type
estimation
each
of
the
above
distributions
may
be
estimated
from
observed
data
simply
by
relative
frequency
maximum
likelihood
or
with
some
form
of
regulation
or
smoothing
in
this
work
we
apply
simple
add-1
laplacian
smoothing3
when
estimating
empirical
results
and
dataset
distributions
distributional
fairness
we
define
fairness
by
distributional
similarity
how
closely
the
results
distribution
matches
the
target
distribution
we
must
specify
distributional
similarity
integrative
measures
beyond
measuring
relevance
and
fairness
as
distinct
aspects
of
system
performance
it
can
be
useful
to
integrate
them
into
single
measure
this
requires
specifying
how
metrics
can
be
combined
the
target
distribution
what
distribution
should
be
targeted
all
things
being
equal
lacking
prior
information
uniform
distribution
targets
balanced
equal
coverage
and
respecting
the
principle
of
maximum
entropy4
however
given
prior
information
one
may
specify
non-uniform
target
distribution
for
example
we
may
expect
search
results
to
respect
some
prior
distribution
for
given
dataset
we
might
observe
given
population
distribution
perhaps
65
of
documents
are
written
in
english
and
want
search
results
to
be
representative
of
this
larger
population
fairness
as
noted
above
we
define
fairness
by
distributional
similarity
between
results
and
target
qt
distributions
specifically
we
compute
kl-divergence5
as
discussed
in
the
next
subsection
it
is
useful
to
have
relevance
and
fairness
on
the
same
scale
before
combining
them
into
single
measure
we
thus
apply
min-max
normalization6
this
produces
score
but
with
as
most
fair
no
distributional
divergence
and
as
least
fair
for
ease
of
interpretation
and
consistency
with
relevance
metrics
we
reverse
the
scale
so
is
most
fair
given
target
distribution
we
thus
compute
fairness
ft
kl
qt
https://en.wikipedia.org/wiki/additive_smoothing
https://en.wikipedia.org/wiki/principle_of_maximum_entropy
https://en.wikipedia.org/wiki/kullback-leibler_divergence
https://en.wikipedia.org/wiki/feature_scaling#rescaling_(min-max_normalization)
das
and
lease
combining
relevance
and
fairness
regardless
of
how
relevance
and
fairness
are
measured
it
may
be
useful
to
integrate
these
into
single
measure
for
example
f-measure
interpolates
between
precision
and
recall
via
the
harmonic
mean
in
this
work
we
apply
arithmetic
and
geometric
means
as
simple
interpolation
methods
between
normalized
fairness
and
relevance
scores
13
as
with
map
vs
gmap
the
arithmetic
mean
is
more
tolerant
to
imbalance
in
inputs
whereas
the
geometric
mean
more
heavily
penalizes
such
imbalance
in
general
one
can
specify
smoothing
parameter
to
weight
the
mixture
f-measure
lets
one
weight
precision
vs
recall
though
simple
unweighted
f-1
is
typically
used
we
leave
such
parameterized
interpolation
for
future
work
but
note
the
flexibility
exists
for
balancing
and
as
noted
above
we
apply
min-max
normalization
to
define
fairness
in
range
while
relevance
measures
are
typically
also
defined
in
that
same
interval
we
apply
consistent
normalization
to
as
well
so
both
and
fully
span
before
they
are
mixed
axiomatic
analysis
our
approach
to
measuring
fairness
is
grounded
in
the
idea
of
diversity
for
example
intent-aware
evaluation
metrics
originally
developed
for
topical
diversity
could
be
adapted
to
evaluating
over
protected
attributes
for
diversity
the
general
connection
between
topical
diversity
and
fairness
has
also
been
noticed
elsewhere
ekstrand
et
al
our
framework
incorporates
two
different
aspects
of
the
proposed
evaluation
desiderata
d1
and
d3
the
notion
of
distributional
fairness
can
satisfy
different
definitions
of
fairness
as
well
as
long
as
target
distribution
can
be
estimated
based
on
particular
definition
of
fairness
our
approach
can
be
used
to
score
search
system
the
idea
of
generalizability
d4
of
metrics
is
also
incorporated
in
our
approach
our
method
can
provide
insight
on
the
fairness
aspect
as
well
as
the
relevance
aspect
of
search
results
at
any
k-th
intersection
our
combined
metric
gmean
also
enforces
that
system
needs
to
perform
well
both
in
terms
of
relevance
and
fairness
there
is
an
implicit
sense
of
authoritativeness
d5
incorporated
into
our
approach
since
one
of
the
ways
we
measure
fairness
is
to
compare
with
the
dataset
distribution
test-collection
with
authoritative
stands
for
some
topics
encourages
systems
to
retrieve
more
results
from
some
perspectives
vs
others
however
since
we
do
not
consider
rank
order
here
in
calculating
fairness
system
performing
well
on
our
fairness
metrics
can
still
have
exposure
bias
as
defined
in
d2
experiments
evaluation
seeks
to
understand
two
over-arching
questions
how
system
performance
varies
under
relevance
vs
fairness
or
combined
metrics
and
how
well
these
metrics
meet
evaluation
desiderata
proposed
in
section
datasets
blogs07
and
trec-8
adhoc
we
first
describe
how
we
adapt
two
existing
trec
test
collections
to
study
fairness
trec-8
adhoc
17
considers
topics
401
450
with
binary
relevance
judgments
for
four
newswire
sources
financial
times
los
angeles
times
foreign
broadcast
information
service
and
federal
register
129
participant
rankings
were
obtained
from
trec
this
track
also
did
not
consider
fairness
and
we
re-interpret
system
performance
here
with
new
assumption
that
fair
ranking
should
provide
diverse
coverage
across
these
different
four
news
sources
conceptual
framework
for
evaluating
fairness
in
search
trec-8
adhoc
distribution
over
newswire
sources
foreign
broadcast
info
service
fed
register
financial
times
and
la
times
july
2019
trec
blogs07
distribution
over
categories
of
opinionated
content
no
opinion
negative
mixed
and
positive
figure
distribution
of
relevant
documents
across
topics
by
category
for
two
test
collections
r-precision
vs
fairness
scores
and
in
trec-8
system
runs
r-precision
vs
fairness
scores
and
in
blogs07
system
runs
figure
correlation
in
system
scores
by
metrics
for
relevance
vs
fairness
for
uniform
vs
dataset
target
distributions
the
blogs07
12
opinion
retrieval
task
had
participant
ranking
systems
retrieve
relevant
blog
posts
with
given
opinion
for
50
topics
the
collection
contains
binary
relevance
judgments
and
four
opinion
labels
no
opinion
negative
mixed
and
positive
104
participant
rankings
were
obtained
from
trec7
while
the
track
did
not
consider
fairness
we
re-interpret
performance
of
those
systems
under
new
assumption
that
fair
ranking
should
ensure
diverse
coverage
across
the
four
opinion
categories
5.1
identifying
potential
test
collection
bias
our
first
analysis
explores
whether
the
underlying
test
collections
are
balanced
or
imbalanced
across
categories
as
discussed
earlier
more
or
less
balance
in
relevant
information
across
categories
in
an
underlying
test
collection
will
likely
lead
to
more
or
less
balanced
coverage
of
categories
distributional
fairness
in
search
results
note
that
since
we
are
repurposing
existing
datasets
to
study
this
notion
of
distributional
fairness
we
are
not
disputing
anything
about
the
particular
test
collections
under
consideration
but
rather
describing
method
by
which
one
could
design
or
assess
test
collection
over
actual
categories
of
interest
for
ensuring
fairness
figures
1a
and
1b
present
the
distribution
of
relevant
documents
across
topics
by
category
for
each
collection
as
noted
above
trec8
categories
are
the
four
newswire
sources
while
for
blogs07
we
have
four
categories
of
opinion
we
see
that
relevant
information
for
some
categories
is
more
scarce
fr
for
trec-8
or
abundant
no
http://trec.nist.gov/results/
opinion
for
blogs07
so
there
is
potential
for
imbalance
in
relevant
information
that
could
lead
to
imbalance
in
retrieved
results
5.2
score
correlation
relevance
vs
fairness
we
next
aim
to
understand
the
degree
to
which
relevance
and
fairness
for
uniform
or
dataset
target
distributions
are
correlated
we
hypothesize
low
correlation
which
would
motivate
measuring
both
metrics
and
potentially
optimizing
retrieval
results
for
some
combination
thereof
we
measure
r-precision
as
our
relevance
metric
due
to
its
robustness
when
there
are
few
relevant
documents
for
given
category
per
the
previous
analysis
figure
shows
r-precision
vs
fairness
scores
for
participating
systems
in
trec-8
and
blogs07
tracks
system
scores
are
sorted
by
decreasing
r-prec
shown
as
green
bars
with
scores
measured
on
the
left
y-axis
for
each
system
we
also
see
corresponding
fairness
scores
for
two
target
distributions
uniform
blue
and
dataset
population
cyan
as
measured
on
the
right
y-axis
the
figures
confirm
that
systems
indeed
perform
differently
for
fairness
and
relevance
metrics
we
see
that
r-precision
scores
of
systems
and
the
uniform
target
fairness
scores
are
inversely
correlated
however
when
we
compare
the
r-precision
scores
with
the
dataset
population
target
distribution
scores
are
more
correlated
random
sample
of
relevant
documents
would
tend
to
be
representative
of
the
population
distribution
in
the
test
collection
the
more
imbalanced
relevant
documents
are
by
category
in
the
collection
the
more
population
and
uniform
will
diverge
we
also
infer
that
ranking
systems
are
usually
optimized
to
reflect
on
the
july
2019
distribution
of
documents
in
the
test
collection
itself
figures
and
suggest
that
to
build
fair
ranking
systems
we
should
also
focus
on
developing
fair
test-collections
as
well
5.3
top
systems
relevance
vs
fairness
another
way
to
look
at
the
relationship
between
relevance
and
fairness
is
to
look
at
which
systems
perform
best
for
each
metric
tables
and
report
the
top-3
systems
for
each
metric
as
well
as
for
arithmetic
and
geometric
means
which
integrate
both
measures
we
see
that
the
highest
performing
systems
for
r-precision
have
very
low
fairness
scores
and
vice
versa
naturally
this
inverse
relationship
between
relevance
and
fairness
also
influences
both
arithmetic
and
geometric
means
for
both
tracks
we
see
that
the
top
systems
for
relevance
are
largely
also
the
top
systems
for
the
arithmetic
mean
but
the
geometric
mean
penalizes
low
fairness
more
heavily
and
so
tends
to
select
systems
that
are
more
balanced
across
relevance
and
fairness
recalling
our
high-level
evaluation
desiderata
section
rprecision
does
not
tell
us
much
beyond
d3
relevance
similarly
fairness
does
not
inform
us
about
any
other
evaluation
criteria
except
for
d1
fairness
however
the
interpolation
of
fairnessrelevance
scores
helps
incorporate
all
of
d1
d3
and
d4
systems
r-prec
fair
mean
gmean
sn1
1.0000
0.1158
0.5579
0.3403
sn2
0.8800
0.1578
0.5189
0.3727
sn3
0.8552
0.1638
0.5095
0.3743
sn129
0.0000
1.0000
0.5000
0.0000
sn127
0.0536
0.7306
0.3921
0.1979
sn125
0.0868
0.6916
0.3892
0.2450
sn1
see
sn1
above
sn2
see
sn2
above
sn4
0.8472
0.1766
0.5119
0.3868
sn56
0.6000
0.2514
0.4257
0.3884
sn4
see
sn4
above
sn15
0.6854
0.2112
0.4482
0.3805
table
the
top-3
scoring
systems
for
trec8
for
each
of
metrics
relevance
r-precision
fairness
section
and
r-f
arithmetic
and
geometric
means
indicates
min-max
normalized
scores
as
discussed
earlier
we
name
systems
by
rank
order
under
r-prec
sn1
achieves
best
r-prec
on
trec8
newswire
followed
by
sn2
etc
the
top
score
for
each
metric
is
underlined
systems
r-prec
fair
mean
gmean
sb1
1.0000
0.0861
0.5431
0.2935
sb2
0.9926
0.2997
0.6461
0.5454
sb3
0.9906
0.3006
0.6456
0.5457
sb104
0.0000
1.0000
0.5000
0.0000
sb103
0.0035
0.9560
0.4797
0.0579
sb102
0.0035
0.9560
0.4797
0.0579
sb4
0.9905
0.3031
0.6468
0.5479
sb5
0.9891
0.3040
0.6465
0.5483
sb2
see
sb2
above
sb5
0.9891
0.3039
0.6465
0.5483
sb4
see
sb4
above
sb3
see
sb3
above
table
blogs07
results
akin
to
trec8
results
in
table
das
and
lease
ranking
metric
trec8
blogs07
fu
fairtarget
uniform
0.01623
0.08028
fairtarget
population
0.03997
0.05489
mean
fu
r-prec
0.08503
0.03958
дmean
fu
r-prec
0.08503
0.12957
table
kendall
rank
correlation
over
participant
systems
when
ranked
by
relevance
metric
only
r-precision
vs
ranking
by
fairness
or
relevance-fairness
interpolation
5.4
rank
correlation
relevance
vs
fairness
another
question
is
how
evaluating
systems
based
on
relevance
vs
fairness
leads
to
different
relative
orderings
over
participant
systems
to
explore
this
we
assume
baseline
ordering
of
participant
systems
based
on
r-precision
then
consider
how
system
rankings
based
on
fairness
measure
differ
as
measured
by
kendall
table
show
that
the
rank-correlation
across
these
metrics
is
quite
low
the
top
rows
consider
target
distributions
uniform
and
population
ground
truth
in
dataset
the
bottom
rows
consider
ranking
induced
by
mean
and
gmean
between
uniform
target
and
r-precision
this
adds
further
evidence
to
our
earlier
results
in
showing
that
evaluating
systems
by
relevance
vs
fairness
leads
to
quite
different
results
in
our
assessment
of
ir
systems
moreover
this
highlights
the
need
to
consider
both
relevance
and
fairness
based
metrics
in
designing
and
optimizing
algorithms
conclusion
we
defined
notion
of
distributional
fairness
and
provide
conceptual
framework
for
evaluating
of
search
results
based
on
it
as
part
of
this
work
we
formulated
set
of
axioms
which
an
ideal
evaluation
framework
should
satisfy
for
distributional
fairness
we
showed
how
existing
trec
test
collections
can
be
repurposed
to
study
fairness
and
we
measured
potential
data
bias
to
inform
test
collection
design
for
fair
search
set
of
analyses
showed
metric
divergence
between
relevance
and
fairness
and
we
described
simple
but
flexible
interpolation
strategy
for
integrating
relevance
and
fairness
into
single
metric
for
optimization
and
evaluation
limitations
we
have
repurposed
existing
trec
test
collections
to
study
fairness
but
it
would
be
better
to
avoid
surrogate
data
while
we
have
defined
fairness
on
set-basis
our
distributional
approach
can
be
easily
extended
to
estimate
the
results
distribution
based
on
rank
information
assigning
greater
weight
to
categories
observed
at
higher
ranks
addressing
the
exposure
bias
d2
desiderata
currently
missed
our
min-max
normalization
simplifies
metric
combination
but
causes
scores
to
change
based
on
which
systems
are
being
compared
so
this
should
also
be
revisited
there
is
also
scope
of
feedback
loops
reinforcing
biases
in
search
systems
future
direction
would
be
to
expand
the
evaluation
desiderata
to
have
measure
for
feedback
loops
references
rakesh
agrawal
sreenivas
gollapudi
alan
halverson
and
samuel
ieong
2009
diversifying
search
results
in
proceedings
of
the
second
acm
international
conference
on
web
search
and
data
mining
acm
14
qingyao
ai
keping
bi
cheng
luo
jiafeng
guo
and
wb
croft
2018
unbiased
learning
to
rank
with
unbiased
propensity
estimation
arxiv
1804.05938
2018
asia
biega
krishna
gummadi
and
gerhard
weikum
2018
equity
of
attention
amortizing
individual
fairness
in
rankings
arxiv
1805.01788
2018
elisa
celis
damian
straszak
and
nisheeth
vishnoi
2018
ranking
with
fairness
constraints
in
icalp
conceptual
framework
for
evaluating
fairness
in
search
le
chen
ruijun
ma
anikó
hannák
and
christo
wilson
2018
investigating
the
impact
of
gender
on
rank
in
resume
search
engines
in
proceedings
of
the
2018
chi
conference
on
human
factors
in
computing
systems
acm
651
michael
ekstrand
robin
burke
and
fernando
diaz
2019
fairness
and
discrimination
in
retrieval
and
recommendation
in
proceedings
of
the
42nd
international
acm
sigir
conference
on
research
and
development
in
information
retrieval
sigir
19
acm
new
york
ny
usa
1403
1404
https
doi
org
10.1145
3331184.3331380
danielle
ensign
sorelle
friedler
scott
neville
carlos
scheidegger
and
suresh
venkatasubramanian
2017
runaway
feedback
loops
in
predictive
policing
arxiv
preprint
arxiv
1706.09847
2017
robert
epstein
and
ronald
robertson
2015
the
search
engine
manipulation
effect
seme
and
its
possible
impact
on
the
outcomes
of
elections
proceedings
of
the
national
academy
of
sciences
112
33
2015
e4512
e4521
matthew
lease
2018
fact
checking
and
information
retrieval
2018
10
vera
liao
and
wai-tat
fu
2013
beyond
the
filter
bubble
interactive
effects
of
perceived
threat
and
topic
involvement
on
selective
exposure
to
information
in
proceedings
of
chi
acm
2359
2368
11
christina
lioma
jakob
grue
simonsen
and
birger
larsen
2017
evaluation
measures
for
relevance
and
credibility
in
ranked
lists
in
proceedings
of
the
acm
sigir
international
conference
on
theory
of
information
retrieval
acm
91
98
12
craig
macdonald
iadh
ounis
and
ian
soboroff
2007
overview
of
the
trec
2007
blog
track
in
trec
july
2019
13
rishabh
mehrotra
james
mcinerney
hugues
bouchard
mounia
lalmas
and
fernando
diaz
2018
towards
fair
marketplace
counterfactual
evaluation
of
the
trade-off
between
relevance
fairness
satisfaction
in
recommendation
systems
in
proceedings
of
the
27th
acm
international
conference
on
information
and
knowledge
management
acm
2243
2251
14
safiya
umoja
noble
2018
algorithms
of
oppression
how
search
engines
reinforce
racism
nyu
press
15
piotr
sapiezynski
wesley
zeng
ronald
robertson
alan
mislove
and
christo
wilson
2019
quantifying
the
impact
of
user
attentionon
fair
group
representation
in
ranked
lists
in
companion
proceedings
of
the
2019
world
wide
web
conference
acm
553
562
16
ashudeep
singh
and
thorsten
joachims
2018
fairness
of
exposure
in
rankings
in
proceedings
of
the
24th
acm
sigkdd
international
conference
on
knowledge
discovery
data
mining
acm
2219
2228
17
ellen
voorhees
and
donna
harman
1999
overview
of
the
eighth
text
retrieval
conference
trec-8
in
trec
18
ke
yang
and
julia
stoyanovich
2017
measuring
fairness
in
ranked
outputs
in
ssdbm
19
meike
zehlike
francesco
bonchi
carlos
castillo
sara
hajian
mohamed
megahed
and
ricardo
baeza-yates
2017
fa
ir
fair
top-k
ranking
algorithm
in
cikm
20
meike
zehlike
and
carlos
castillo
2018
reducing
disparate
exposure
in
ranking
learning
to
rank
approach
corr
abs
1805.08716
2018