Fairness in Ranking under Disparate Uncertainty
Richa Rastogi

Thorsten Joachims

Cornell University
United States of America
rr568@cornell.edu

Cornell University
United States of America
tj@cs.cornell.edu

Abstract

1

Ranking is a ubiquitous method for focusing the attention of human evaluators on a manageable subset of options. Its use as part
of human decision-making processes ranges from surfacing potentially relevant products on an e-commerce site to prioritizing
college applications for human review. While ranking can make
human evaluation more effective by focusing attention on the most
promising options, we argue that it can introduce unfairness if
the uncertainty of the underlying relevance model differs between
groups of options. Unfortunately, such disparity in uncertainty appears widespread, often to the detriment of minority groups for
which relevance estimates can have higher uncertainty due to a
lack of data or appropriate features. To address this fairness issue,
we propose Equal-Opportunity Ranking (EOR) as a new fairness
criterion for ranking and show that it corresponds to a group-wise
fair lottery among the relevant options even in the presence of
disparate uncertainty. EOR optimizes for an even cost burden on
all groups, unlike the conventional Probability Ranking Principle,
and is fundamentally different from existing notions of fairness in
rankings, such as demographic parity and proportional Rooney rule
constraints that are motivated by proportional representation relative to group size. To make EOR ranking practical, we present an
efficient algorithm for computing it in time ùëÇ (ùëõ log(ùëõ)) and prove
its close approximation guarantee to the globally optimal solution.
In a comprehensive empirical evaluation on synthetic data, a US
Census dataset, and a real-world audit of Amazon search queries,
we find that the algorithm reliably guarantees EOR fairness while
providing effective rankings.

Human decision-processes are increasingly augmented with algorithmic decision-support systems, which has created opportunities
and challenges for addressing group-based disparities in decision
outcomes [5, 15, 51, 56]. In this paper, we focus on selection processes where humans evaluators use rankings to organize the order
of review under resource constraints. We argue that disparities in
uncertainty can be a major source of group-based discrimination in
this setting.
To illustrate the problem, consider the following example of college admissions at a highly selective institution. In this situation,
there are far more qualified candidates than available spots. Under
a fixed reviewing budget, the college could give all applications a
brief review (but risk high error rates in human decision making),
or use a ranking to focus reviewing efforts on the more promising
applications. The latter is likely to decrease error rates in human
review, but it risks that this prioritization unfairly favors some
groups over others. For example, consider 12,000 applicants competing for 500 slots. In this example, 10,000 applicants are from a
majority group with plenty of available data, and the model can
quite accurately predict which students will be admitted by the
human reviewers. In particular, it accurately assigns a probability
of 0.9 to 1000 of the students, and 0.01 to the remaining 9,000. The
remaining 2000 applicants are from a minority group, where the
model is less informed about individual students and thus assigns
0.1 to everybody. When naively ranking students by this probability,
the students with 0.9 from the majority group would be ranked
ahead of all the students from the minority group - and the class
will fill up with the expected 900 (1000 √ó 0.9) qualified majority
students before the admission staff even gets to any of the minority
students. This is clearly unfair even if the predictions are perfectly
calibrated for each group, since not even a single student of the
expected 200 (2000 √ó 0.1) qualified students in the minority group
has a chance to be selected by the admissions staff.
We aim to define a new way of ranking that does not introduce unfairness into a human decision-making process even if the
predictive model shows differential uncertainty between groups.
This goal recognizes that training models to have equal uncertainty
across groups may be difficult in practice, since a lack of data and
appropriate features for some groups may be difficult to overcome1 .
Importantly, a key principle behind our work is to leave the final decisions to human decision makers. We thus aim to design
new ranking algorithms to most effectively support a fair human
decision-making process, and not to replace the human decision
maker.
The main contributions of this paper are

CCS Concepts
‚Ä¢ Information systems ‚Üí Rankings; Top-k retrieval; Recommender systems; Decision support systems.

Keywords
ranking, fairness, disparate uncertainty, cost of opportunity
ACM Reference Format:
Richa Rastogi and Thorsten Joachims. 2024. Fairness in Ranking under
Disparate Uncertainty. In Equity and Access in Algorithms, Mechanisms,
and Optimization (EAAMO ‚Äô24), October 29‚Äì31, 2024, San Luis Potosi, Mexico.
ACM, New York, NY, USA, 31 pages. https://doi.org/10.1145/3689904.3694703
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
EAAMO ‚Äô24, October 29‚Äì31, 2024, San Luis Potosi, Mexico
¬© 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 979-8-4007-1222-7/24/10
https://doi.org/10.1145/3689904.3694703

Introduction

1 Arguably, the same applies to instructing human evaluators to provide such ranking

scores during a first phase of review.

EAAMO ‚Äô24, October 29‚Äì31, 2024, San Luis Potosi, Mexico

‚Ä¢ A new fairness criterion that provides a meaningful guarantee
for rankings that are used to support human decision making
in selection processes even under disparities in uncertainty.
We motivate this fairness criterion with a fair lottery [22, 44],
ensuring group-wise outcomes that are equivalent to allocating
scarce resources based on a group-fair lottery among the relevant
candidates.
‚Ä¢ Based on this notion of fairness, we develop a new ranking procedure that is group-fair under disparate uncertainty. Motivated
by its relation to the equality of opportunity framework [23], we
name this ranking procedure Equal Opportunity Ranking
(EOR). We analyze EOR from the lens of the cost burden on each
entity involved ‚Äì the principal decision maker and each of the
candidate groups ‚Äì and formulate the cost to each entity as the
lost opportunity of access given that the candidate was truly
relevant. We show that this EOR procedure equalizes the cost
burden between groups and present an efficient and practical
algorithm for computing EOR rankings. This procedure always
produces a near optimal and approximately EOR-fair solution.
In particular, we prove an approximation guarantee showing
that the gap in total cost to the principal compared to an optimal
algorithm is bounded by a small amount.
‚Ä¢ In addition to these theoretical worst-case guarantees, we present
extensive experiments benchmarking the EOR algorithm with
various existing ranking algorithms under different settings of
disparate uncertainty. We show that Demographic Parity [58, 61],
normative procedures like Proportional Rooney-rule-like constraints [9], Exposure based fairness criteria [49], and Thompson Sampling Policy [50] are not typically EOR-fair under disparate uncertainty. We find that these results hold on both a
wide range of synthetic datasets, as well as on real-world US
census data. Finally, we explore the use of our fairness criterion for auditing ranking systems, using a real-world dataset of
Amazon shopping search queries. Our code can be accessed at
https://github.com/RichRast/DisparateUncertainty.

These results have important societal implications. First, they provide evidence that naively applying existing fairness mechanisms in
rankings under disparate uncertainty leads to unfairness in terms of
one group bearing the majority of the cost of opportunity. Second,
even under high disparate uncertainty in the worst case, EOR guarantees an approximately equal cost burden among all groups with
bounded additional cost to the human decision maker. Finally, we
hope our results inform practitioners to collect data and appropriate
features for candidates in all groups to build predictive models that
reduce disparate uncertainty. As we will show, the EOR procedure
elevates the candidates with high uncertainty in the rankings for
human evaluation. This has the desirable effect of producing more
equitable training data for future use.
We now highlight some important considerations here. First, our
proposed method is grounded in the fairness of a lottery [45], which
is a common technique for allocating scarce resources (e.g., admission slots among a large number of qualified candidates). However
moral and philosophical arguments debating the use of lottery and
randomization for certain situations have also been made [26]. We
hope this work can spark discussions on alternative notions of

Rastogi and Joachims.

fairness in rankings that satisfy equality of opportunity under disparate uncertainty. Another important point is that our proposed
EOR procedure reduces unfairness due to disparate uncertainty,
which often but not necessarily coincides with the historically disadvantaged group. Since EOR doesn‚Äôt require the designation of the
disadvantaged group, the guarantees we provide are not making a
normative statement about any historically disadvantaged group.
To that end, we emphasize the careful consideration of historical
and social context that needs to be taken into account by the human
decision maker as well as the way groups are defined in the first
place.

2

Related Works

While the issue of fairness has been heavily studied in the classification setting, its counterpart ‚Äì the ranking setting has received
relatively less attention. Below we highlight key areas related to
our work and leave a more detailed discussion of these and other
related works to Appendix B.
Fairness in Rankings and Selection Processes: While there exist
several notions of fairness in rankings [64], predominantly, they
are variations of two fairness mechanisms in existing literature ‚Äì
representation by size [10, 57, 61, 63] and equitable allocation of
exposure [4, 31, 35, 48, 49]. We propose a new criterion different
from either of the two and our central point is that under disparate
uncertainty between groups, it is more fair to take an equal proportion of relevance in expectation rather than equality by size
or exposure. Proportional representation in the form of diversity
constraints like demographic parity [58] or affirmative action such
as the Rooney Rule [9] guarantee a minimum proportion by group
size in selection processes. Exposure based formulations in rankings ensure that groups of candidates are allocated exposure in an
equitable way such as in proportion of amortized relevance over
the full ranking [4]. In this work, we demonstrate that fairness
of representation by size and exposure, are not sufficient under
disparate uncertainty.
Fairness in Rankings under Uncertainty: Our work builds on [50],
in which the authors establish that uncertainty in relevance probabilities is a primary cause of unfairness for rankings. They propose
a Thompson sampling policy that randomizes relevances drawn
from the predictive posterior distribution. Separately, [19] studies
the role of affirmative action in the presence of differential variance
between groups in rankings. Differential variance implies that there
is more certainty about the true quality (scores) of candidates in
a group with less variance in the estimated quality and vice versa
for a group with higher variance. In contrast, we work with relevance probabilities instead of scores and focus on the certainty
of relevance of a candidate, which is determined by how close
the predicted relevance probabilities are to 1 or 0. For instance,
a group is highly certain (if the probabilities are all close to 1.0)
or highly uncertain (if the probabilities are all close to 0.5) while
both groups could have similar variance in probabilities. Fairness
under uncertainty has also been studied with respect to calibration of probabilities [11, 20, 29, 38]. Classical literature in this area
studies whether group-wise calibration is a necessary condition
for fairness, or not [32]. Our work is orthogonal to the question of

Fairness in Ranking under Disparate Uncertainty

the necessity of calibration for fairness and we only require groupwise calibration as a sufficient condition for the EOR criterion we
propose.
Our work complements and extends prior research on fairness
in rankings under uncertainty, contributing uniquely in several
ways. In particular, we provide a formal framework for analyzing
the unfairness that differential uncertainty induces in rankings.
Additionally, our approach involves accounting for the differential uncertainty directly at the ranking stage, unlike prior work
that involves learning the uncertainty [53] or correcting the noisy
relevance estimates [59]. Finally, our proposed EOR criterion is
non-amortized for every prefix ùëò of the ranking, which is strictly
stronger than the probabilistic but amortized notions of fairness
[4, 48, 49] shown to be problematic [28].

3

Un-fairness due to Disparate Uncertainty in
Rankings

We want to design a ranking policy ùúã that does not introduce unfairness into a human decision process due to disparate uncertainty.
More formally, the task of ùúã is to compute a ranking ùúé of ùëõ candidates, where each candidate ùëñ has a binary2 relevance ùëüùëñ ‚àà {0, 1}
which is unknown to the ranking policy ùúã, and true relevance can
only be revealed through a human decision maker. When assessing the relevance, we assume that the human decision maker goes
through the ranking ùúé from the top to some a priori unknown
position ùëò. The goal of the decision maker (a.k.a. principal) is to
find as many relevant candidates (e.g., relevant products, qualified
students) as possible.
While the true relevances ùëüùëñ are unknown, we assume that the
ranking policy ùúã has access to a predictive model of relevance
P(ùëüùëñ |D), typically trained on prior human decisions D and features
of the candidates. Sorting the candidates in decreasing order of
ùëùùëñ = P(ùëüùëñ = 1|D) is called the Probability Ranking Principle (PRP)
[41], and it is by far the most common way of computing a ranking.
The justification for PRP ranking is that it maximizes the expected
number of relevant candidates in any top-k prefix of the ranking.
On the other hand, Demographic Parity (DP) is the dominant form
of fairness mechanism in rankings, where candidates are selected
from groups in proportion to the group size. While PRP ranking is
provably optimal according to the efficiency goal of the principal
and DP ranking ensures representation by group size, the following
elaborates how both PRP and DP can violate fairness.

3.1

Illustrative Example

Consider a medical setting, where candidates need to be evaluated for eligibility to participate in a controlled medical trial. While
group A consists of candidates with a rich set of diagnostic tests that
inform eligibility (e.g., candidates with health insurance), group
B consists of candidates without prior access to such tests (e.g.,
candidates without health insurance). As a result, according to
P(ùëüùëñ = 1|D) in Figure 1, the model can make very informed predictions for candidates in group A, while for group B the model
cannot reliably differentiate between eligible and not eligible candidates. This means the model knows exactly which candidates in
2We conjecture that our framework can be extended to categorical or real-valued

relevances.

EAAMO ‚Äô24, October 29‚Äì31, 2024, San Luis Potosi, Mexico

group A will be judged as eligible by the human decision maker,
but it will make undifferentiated (but well-calibrated) predictions
for candidates in group B.
Figure 2 shows that the PRP ranking is oblivious to this disparity between groups. If the principal needs to find four eligible
candidates based on the PRP ranking, they are all selected from
group A. However, by summing the probabilities in group B, our
model tells us that we can also expect four eligible candidates in
group B. We argue that deterministically selecting only candidates
from group A is unfair since it is not consistent with the outcome
of a group-fair lottery for the four spots among the eight eligible
candidates. Now, consider the DP ranking in Figure 2. Since group
A has 17 candidates and group B has 8 candidates, DP will select
roughly one candidate from group B for every two candidates from
group A. We argue that in this setting, DP is also unfair, (though
less in comparison to PRP) as it selects three eligible candidates
from group A and only one from group B. In expectation, it selects
2.6 out of 4 relevant candidates from group A, but only 0.6 out
of 4 relevant candidates from group B. We show empirically later
that other fairness mechanisms motivated by representation of size
such as proportional Rooney Rule or threshold-based formulations
have the same failure mode. Importantly, note that it is not evident
whether group A or B should be the majority group.
We argue that a more principled and fair way would be to select
an equal fraction of relevant candidates from each group in expectation. Consider the last ranking in Figure 2, which approximately
fulfills the EOR fairness we formally introduce later. In expectation,
this ranking selects a more equal number of relevant candidates
from both groups, making it similar to a fair lottery. In particular,
it selects 1.8 out of 4 relevant candidates from group A and 1.2 out
of 4 relevant candidates from group B. This EOR ranking, however,
comes at an increased evaluation cost to the principal as it selects
3.0 expected relevant candidates from both the groups, compared
to 3.2 with DP and 3.3 with PRP. As a result, the principal needs
to review more candidates to select the same number of relevant
candidates with EOR ranking. However, it is still far more effective
than a lottery, which selects the candidates in a uniform random
order.
Our key insight is that EOR ranking is more fair not because
it takes an equal ‚Äúnumber‚Äù of candidates from each group but it
is more fair because it takes an equal fraction of ‚Äúrelevant‚Äù candidates in expectation from each group. This accounts for predictive
uncertainty in the relevance probabilities because even when one
group has sharp and the other group has non-sharp ùëùùëñ , it takes
approximately equal fraction of relevance from each of the groups.
This example illustrates the intuition behind the EOR principle
we formalize in the following, and we will show how to efficiently
compute rankings that fulfill EOR fairness.

3.2

Sources of Disparate Uncertainty

It remains to show that disparate uncertainty is a fundamental problem when estimating the relevance probabilities P(ùëüùëñ = 1|D) that is
not easily remedied by improved learning methods. The following
illustrates that even a Bayes-optimal procedure is vulnerable to
producing disparate uncertainty.
Consider the posterior distribution illustrated in Figure 3, which
shows the uncertainty P(ùúÉùëñ |D) that a Bayesian model has about

EAAMO ‚Äô24, October 29‚Äì31, 2024, San Luis Potosi, Mexico

Rastogi and Joachims.

pi‚ààgroup A

0.05

0.05

0.05

0.05

0.05

0.05

0.05

0.05

pi‚ààgroup B

0.4

0.4

0.4

0.5

0.5

0.6

0.6

0.6

0.05

0.05

0.05

0.05

0.1

0.7

=4

=4

0.8

Expected Relevance of
the groups

[ri‚ààg] =

‚àë

pi

0.9

0.9

True Relevance

ri = 1

i‚ààg

Figure 1: The expected probability of relevance ùëùùëñ and their true relevance ùëüùëñ for all candidates in both groups.

œÉ PRP

œÉ DP

œÉ EOR

0.9 0.9 0.8 0.7

0.9 0.6 0.9 0.8

0.6 0.9 0.6 0.9

( Selected, Total ) Expected Relevant number of candidates

0, 4
3.3, 4
3.3, 8

2.6, 4 0.6, 4
3.2, 8

1.8, 4 1.2, 4
3.0, 8

Figure 2: Top-4 ranking for Probability Ranking Principle (PRP),
Demographic Parity (DP), and our proposed EOR for the example
in Figure 1. Selected relevant number of candidates in expectation
and total relevant number of candidates in expectation are shown
corresponding to each ranking.

to zero or one for candidates in group A (i.e., highly informative),
and middling for group B (i.e., less informative).
Note that there is ample evidence that non-Bayesian methods
also produce such disparities (e.g., [5, 51, 56]). Furthermore, disparate amounts of data are not the only cause for disparity. For
example, in college admissions, disparately more URM candidates
may miss AP grades because their school does not offer AP classes.
Their epistemic uncertainty [27] of qualification will thus be higher
since the model has less information about these students. This
higher uncertainty does not mean individual students are not qualified, and elevating them in the ranking for human evaluation can
accurately reveal qualification through additional information (e.g.,
an interview, deep reading of the SOP, or recommendation letters).
But if they are never selected for human review, then they do not
have a chance for an admission spot.

ùîº

group A

Posterior (Œ∏i | )

(r i = 1| )

0.0

0.2

0.4

Œ∏i

0.6

group B

0.8

1.0

Figure 3: An illustration of disparate uncertainty between groups
from a Bayesian perspective for all the candidates of Figure 1. The
candidates in group A have peaky posteriors, while those in group
B have relatively flat posteriors.

the relevance probability ùúÉùëñ of candidate ùëñ, where ùúÉùëñ is the parameter
of a Bernoulli distribution. For group A, the posterior P(ùúÉùëñ |D) is
peaked, meaning that the model can accurately pinpoint the correct
relevance probabilities. For group B, the posterior is flat, which is
to be expected if group B is smaller and thus has less data. The
Bayes-optimal way of handling this uncertainty is to infer P(ùëüùëñ |D)
via the posterior predictive distribution
‚à´
‚à´
P(ùëüùëñ = 1|D) =
P(ùëüùëñ = 1|ùúÉùëñ ) P(ùúÉùëñ |D) ùëëùúÉùëñ =
ùúÉùëñ P(ùúÉùëñ |D) ùëëùúÉùëñ
Figure 3 shows how even this Bayes-optimal procedure leads to disparate uncertainty between groups, where the P(ùëüùëñ = 1|D) is closer

4

Equality of Opportunity in Ranking

In this section, we first discuss the assumptions and modeling
choices and then formulate the cost that the uncertainty of the
predictive model imposes on the principal and the relevant candidates from the different groups.
Our first assumption includes access to group-wise calibration
[3, 38] with the probability estimates calibrated within groups. To
simplify notation, we do not differentiate between P(ùëüùëñ |D) and a
group-wise calibrated score P(ùëüùëñ |ùë†, ùê¥, D) = ùë† and we only require
this group-wise calibration as a sufficient condition for our framework. Additionally, we assume that the true relevance ùëüùëñ is revealed
perfectly to the human decision-maker upon review, and we do
not model any bias in the human decision-making review process.
Finally, we assume that candidates have group membership to a
single protected attribute and do not consider intersectional group
membership, which is a practically important consideration in fairness. Relaxing these three assumptions for future work could allow
modeling even more real-world complexities.
To formulate the cost of opportunity, we first recognize that any
group-wise calibrated model allows us to compute the expected
number of relevant candidates ùëõùëÖùëíùëô (.) of a particular group
ùëî ‚Äì no matter how well the model can differentiate relevant and
non-relevant candidates in that group.
ùëõùëÖùëíùëô (ùëî) =

‚àëÔ∏Å
ùëñ ‚ààùëî

Eùëüùëñ ‚àºP(ùëüùëñ | D ) [ùëüùëñ ] =

‚àëÔ∏Å

P(ùëüùëñ = 1|D)

ùëñ ‚ààùëî

Extending this to rankings, the expected number of relevant candidates from group ùëî for any prefix ùëò of ranking ùúé that only depends

Fairness in Ranking under Disparate Uncertainty

EAAMO ‚Äô24, October 29‚Äì31, 2024, San Luis Potosi, Mexico

on P(ùëüùëñ = 1|D) to ensure unconfoundedness is
‚àëÔ∏Å
‚àëÔ∏Å
ùëõùëÖùëíùëô (ùëî|ùúéùëò ) =
E [ùëüùëñ ] =
P(ùëüùëñ = 1|D)
ùëñ ‚ààùëî‚à©ùúéùëò

ùëñ ‚ààùëî‚à©ùúéùëò

Further extending this to a potentially stochastic ranking policy ùúã
that represents a distribution over rankings for a particular query
leads to
‚àëÔ∏Å
ùëõùëÖùëíùëô (ùëî|ùúãùëò ) =
Eùëüùëñ ‚àºP(ùëüùëñ | D ),ùúéùëò ‚àºùúã [ùëüùëñ Iùëñ ‚ààùúéùëò ]
ùëñ ‚ààùëî

=

‚àëÔ∏Å

P(ùëñ ‚àà ùúéùëòùúã )P(ùëüùëñ = 1|D)

4.2

where P(ùëñ ‚àà ùúéùëòùúã ) = Eùúéùëò ‚àºùúã [Iùëñ ‚ààùúéùëò ] is the probability that policy ùúã
ranks candidate ùëñ into the top k. As a side note notation-wise, for a
specific policy, for example, ùúã ùê∏ùëÇùëÖ , we denote the corresponding
ùê∏ùëÇùëÖ
ranking ùúéùëòùúã
in the abbreviated form as ùúéùëòùê∏ùëÇùëÖ .
The ability to compute these expected numbers of relevant candidates from each group allows us to reason about the cost resulting
from the uncertainty of the model that each ranking imposes on
the respective groups, which we detail in the following.

Cost Burden to Candidate Groups and the
Principal

We define the cost ùëê (.) to candidate ùëñ as missing out on the opportunity to be selected if the candidate was truly relevant. For a
ranking policy ùúã that produces rankings ùúé ‚àº ùúã based on P(ùëüùëñ |D),
and a principal that reviews the top ùëò candidates, the cost to a
relevant candidate ùëñ is the probability of not being included in the
top ùëò.
ùëê (ùëñ |ùúãùëò , ùëüùëñ ) = ùëüùëñ (1 ‚àí P(ùëñ ‚àà ùúéùëòùúã ))

We again normalize this quantity to make it proportional to the
total expected number of relevant candidates. Note that Eq. (4) is
related to the conventional metric of Recall@k.

(1)

ùëñ ‚ààùëî

4.1

The principal incurs a cost whenever the ranking misses a
relevant candidate, independent of group membership. For a principal that reviews the top ùëò applications from two groups ‚Äì A and
B, the total cost can thus be quantified via the expected number of
relevant candidates that are overlooked.
√ç
ùúã
ùëñ (1 ‚àí P(ùëñ ‚àà ùúéùëò ))P(ùëüùëñ = 1|D)
ùëê (Principal|ùúãùëò ) =
(4)
ùëõùëÖùëíùëô (ùê¥) + ùëõùëÖùëíùëô (ùêµ)

(2)

Note that only relevant candidates can incur a cost, since nonrelevant candidates will be rejected by human review and thus
draw no utility independent of whether they are ranked into the
top ùëò. Also, note that P(ùëñ ‚àà ùúéùëòùúã ) can be estimated by Monte-Carlo
sampling even for complicated ranking policies that have no closedform distribution.
While determining the cost to a specific individual ùëñ is difficult since it involves knowledge of the true relevance ùëüùëñ , getting
a measure of the aggregate cost to the group is more tractable. In
particular, we define the group cost as the expected cost to the relevant candidates in the group, normalized by the expected number
of relevant candidates.
√ç
ùëñ ‚ààùëî Eùëüùëñ ‚àºP(ùëüùëñ | D ) [ùëê (ùëñ |ùúãùëò , ùëüùëñ = 1)]
ùëê (ùëî|ùúãùëò ) =
ùëõùëÖùëíùëô (ùëî)
√ç
ùúã
ùëñ ‚ààùëî (1 ‚àí P(ùëñ ‚àà ùúéùëò ))P(ùëüùëñ = 1|D)
=
ùëõùëÖùëíùëô (ùëî)
ùëõùëÖùëíùëô (ùëî|ùúãùëò )
= 1‚àí
(3)
ùëõùëÖùëíùëô (ùëî)
The last equality in (3) follows directly from Eq. (1). We normalize
the expected group cost with the total expected number of relevant
candidates in the group so that the above approximates the fraction of relevant candidates from that group that miss out on the
opportunity of being selected by the human reviewers.

Equality of Opportunity Ranking (EOR)
Criterion

We now formally define our EOR fairness criterion and argue that
a disparity in uncertainty should not lead to disparate costs for any
of the groups. We have already seen that ùúã ùëÉùëÖùëÉ and ùúã ùê∑ùëÉ can violate
this goal. For a possible solution, we turn to the principle of random
lottery that has been historically used to justify fair allocation of
resources [22, 44]. Take, for example, the uniform ranking policy
ùúã unif , which ignores P(ùëüùëñ |D) and picks a ranking uniformly at
random. Use of ùúã unif ensures that any relevant candidate has an
equal chance of being evaluated and selected since any top ùëò of
the ranking contains a uniform random sample of the relevant
candidates ‚Äì independent of group membership. While the ranking
effectiveness of ùúã unif is bad, it has the attractive property that the
fraction of relevant candidates that get selected from each group
is equal in expectation. For example, if both group A and group B
contain 100 relevant candidates in expectation and if ùúã unif selects
ùëô relevant candidate in expectation from group A, it also selects
ùëô relevant candidates in expectation from group B. Similarly, if
group A contains 200 relevant candidates and group B contains 100,
the selection ratio will be 2 to 1 in expectation. We formalize this
property of the uniform lottery as our key fairness axiom.
Axiom 1 (EOR Fair Ranking Policy). For two groups of candidates A and B, a ranking policy ùúã is Equality-of-Opportunity fair,
if for every ùëò the top-k subsets ùúãùëò contain in expectation an equal
fraction of the relevant candidates from each group. More precisely:
ùëõùëÖùëíùëô (ùê¥|ùúãùëò ) ùëõùëÖùëíùëô (ùêµ|ùúãùëò )
=
ùëõùëÖùëíùëô (ùê¥)
ùëõùëÖùëíùëô (ùêµ)

‚àÄùëò

(5)

While this fairness property of ùúã unif is desirable, its completely
uninformed rankings come at a cost to the principal and the relevant
candidates from both groups, since only a few relevant candidates
will be found. The uniform policy ùúã unif is particularly inefficient
when the fraction of relevant candidates is small. The key question
is thus whether we can define an alternate ranking policy that
retains the group-wise fairness properties of ùúã unif , but retains as
much effectiveness in surfacing relevant candidates as possible.
To illustrate that such rankings exist, which are
both EOR fair and more effective, consider our
motivating example of Figure 1, where ùúé ùê∏ùëÇùëÖ
=
ùêµ

ùê¥

ùêµ

ùê¥

ùêµ

ùêµ

ùê¥

ùêµ

ùê¥

ùêµ

ùê¥

ùêµ

ùê¥

ùê¥

ùê¥

[ 0.6, 0.9, 0.6, 0.9, 0.6, 0.5, 0.8, 0.5, 0.7, 0.4, 0.1, 0.4, 0.05, 0.05, 0.05,
ùê¥

ùê¥

ùê¥

ùê¥

ùê¥

ùêµ

ùê¥

ùê¥

ùê¥

ùê¥

0.05, 0.05, 0.05, 0.05, 0.05, 0.4, 0.05, 0.05, 0.05, 0.05] has the property that the expected number of relevant candidates for each

EAAMO ‚Äô24, October 29‚Äì31, 2024, San Luis Potosi, Mexico

group in the top ùëò never differs by more than 0.6 for any value of ùëò.
In one way, this guarantee is even stronger than what is defined
in Axiom 1, since it holds for the specific ranking ùúé ùê∏ùëÇùëÖ without
the need for stochasticity in the ranking policy. This provides a
non-amortized notion of fairness, which is particularly desirable
for high-stakes ranking tasks that do not repeat, and we thus
need to provide the strongest possible guarantees for the specific
ranking ùúé we present. However, a guarantee for an individual
ranking makes the problem inherently discrete, which means that
we require some tolerance (i.e., 0.6 in the example above) in the
fairness criterion depending on the choice of ùëò. This leads to the
following ùõø-EOR Fairness criterion for an individual ranking ùúé.
Definition 4.1 (ùõø-EOR Fair Ranking). For two groups of candidates A and B, a ranking ùúé is ùõø-EOR fair, if for every ùëò the top-k
subset ùúéùëò differs in its fraction of expected relevant candidates from
each group by no more than ùõø. More precisely:
ùëõùëÖùëíùëô (ùê¥|ùúéùëò ) ùëõùëÖùëíùëô (ùêµ|ùúéùëò )
‚àí
‚â§ùõø
(6)
‚àÄùëò
ùëõùëÖùëíùëô (ùê¥)
ùëõùëÖùëíùëô (ùêµ)
Note that we can also define a specific ‚Äúslack‚Äù ùõø (ùúéùëò ) for each
position ùëò. For a fair ranking ùúé, this slack should ideally oscillate
close to zero as we increase ùëò, and so minimizing its deviation from
zero would translate to ensuring ùõø-EOR fairness. Formally, we can
define ùõø (ùúéùëò ) as
√ç
√ç
ùëñ ‚ààùê¥‚à©ùúéùëò P(ùëüùëñ |D)
ùëñ ‚ààùêµ‚à©ùúéùëò P(ùëüùëñ |D)
‚àÄùëò ùõø (ùúéùëò ) = √ç
‚àí √ç
(7)
ùëñ ‚ààùê¥ P(ùëüùëñ |D)
ùëñ ‚ààùêµ P(ùëüùëñ |D)
ùõø-EOR fairness balances the selection of candidates from the two
groups, accounting for predictive uncertainty in their estimation
of relevances. If for instance, the ML model is less certain in its
predictions for group B, but both groups have the same total expected relevance, the ùõø-EOR criterion will rank candidates from
group B higher to ensure fairness. Importantly, note how this produces more human relevance labels of candidates from groups with
high uncertainty, which has the desirable side-effect of producing
new training data that allows training of more equitable relevance
models for future use.
Finally, note how the ùõø-EOR fair ranking provides a means for
ensuring procedural fairness and avoiding disparate treatment. Importantly, we leave the decision of which candidates to select to
the human decision maker, and EOR fairness does not require the
designation of a disadvantaged group. Instead, the EOR fair condition in Eq. (6) is symmetrical w.r.t. both groups and by definition
treats both groups similarly, and its intervention in the ranking
process is entirely driven by the predictive model P(ùëüùëñ |D). Even
though it uses group membership, EOR-fairness is thus fundamentally different from demographic parity [17, 58] and affirmative
action rules like Rooney rule [9, 12], 45 th rule (selection rate for a
protected group must be at least 80% of the rate for the group with
the highest rate)3 or ùõæ-based notions of fairness [18] and threshold
based formulations such as FA‚àó IR [61].
To illustrate the difference with existing fairness notions, we
return to our running example from Figure 1. For top-4 ranking in
Figure 2, the EOR criterion can be computed as |ùõø (ùúé4ùê∏ùëÇùëÖ )| = 0.15,
|ùõø (ùúé4ùê∑ùëÉ )| = 0.5 and |ùõø (ùúé4ùëÉùëÖùëÉ )| = 0.83, quantifying the unfairness
3 Uniform Guidelines on Employment Selection Procedures, 29 C.F.R.¬ß1607.4(D) (2015)

Rastogi and Joachims.

of DP and PRP as compared to EOR. While DP selects one candidate from group B for every two candidates from group A, applying 45 th rule with group B as the disadvantaged group will select roughly 4/5 number of candidates from group B for every
two candidates from group A. For top-4 ranking, the 45 th rule is
ùê¥

ùêµ

ùê¥

ùê¥

ùúé4FourFifth = [ 0.9, 0.6, 0.9, 0.8] with |ùõø (ùúé4FourFifth )| = 0.5. If instead,
group A is selected as the disadvantaged group, 45 th rule will select
all four candidates from group A resulting in |ùõø (ùúé4FourFifth )| = 0.83,
same as that of PRP. The FA‚àó IR criterion (ùúã ùêπùëÜ ) is similarly anchored
on the principle that a top-k ranking is fair when the proportion of
disadvantaged candidates selected doesn‚Äôt fall far below a required
minimum proportion and also requires the designation of a disadvantaged group. In this example, ùúã ùêπùëÜ gives the exact same top-4
ranking and EOR criterion as shown for 45 th rule. In summary, the
predominant fairness criteria in rankings motivated by the representation of size perform very differently than the ùúã ùê∏ùëÇùëÖ . As an
example, consider the well-documented issue of female candidates
not being selected for leadership positions primarily due to their
small applicant pool size [25]. If the female applicants have high
disparate uncertainty (due to lack of historical data), affirmative
action may still select far fewer (based on group size) of them than
deserved (based on the number of relevant female candidates).
We now briefly consider two other notions of fairness in rankings for the running example. First, we look at the exposure-based
formulations[4, 49]. The principle of exposure is motivated by position bias in rankings and ensures the allocation of position in
rankings in proportion to the expected total relevance. While the
position of a selected candidate is certainly important, it does not
take disparate uncertainty into consideration. ùúã ùê∏ùëã ùëÉ is a stochastic
policy that allocates equal exposure between the two groups (in this
example, both groups have an equal expected total relevance) over
the full 25 positions of the ranking. ùúã ùê∏ùëã ùëÉ allocates most of the probability mass to candidates in group B for all of the top-4 positions
(not because they have high uncertainty but because their group
size is smaller than group A). This results in a high cost burden for
group A and the EOR criterion is computed as |ùõø (ùúé4ùê∏ùëã ùëÉ )| = 0.58
higher than both ùúã ùê∏ùëÇùëÖ and ùúã ùê∑ùëÉ . Later in Section 7, we demonstrate
how ùúã ùê∏ùëã ùëÉ places a higher cost burden on the uninformative group
instead when both groups have relatively the same size.
Finally, we discuss the Thompson Sampling based fairness in
rankings [50]. For ùúãùëá ùëÜ , binary relevances are drawn according to
ùëüùëñ ‚àº P(ùëüùëñ |D), and candidates are sorted in decreasing order of
relevance ùëüùëñ with their ranking randomized for the same value of
relevance. The EOR criterion for a top-4 ranking produced by ùúãùëá ùëÜ
can be computed as |ùõø (ùúéùëá4 ùëÜ )| = 0.29 for the running example. While
ùúãùëá ùëÜ takes the predictive uncertainty of relevance into account by
randomization of rankings, it is group oblivious and so does not
account for the difference in the predictive uncertainty of relevance
between groups. This explains the high EOR criterion of a specific
√ç
ùúéùëá ùëÜ with median ùëõùëò=1 |ùõø (ùúéùëòùëá ùëÜ )| as compared to that of the ùúé ùê∏ùëÇùëÖ .
While we discussed how EOR differs from existing fairness notions
above, we will further demonstrate this comparison via extensive
empirical evaluations in Section 7.
One of our key contributions includes formalizing the connection
between ùõø-EOR Fair Ranking described in Definition 4.1 and the

Fairness in Ranking under Disparate Uncertainty

EAAMO ‚Äô24, October 29‚Äì31, 2024, San Luis Potosi, Mexico

Algorithm 1: EOR Algorithm
Input: Groups ùëî ‚àà {ùê¥, ùêµ}; Rankings ùúé ùëÉùëÖùëÉ,ùëî per group in the
sorted (decreasing) order of relevance probabilities P(ùëüùëñ |D).
Initialize: ùëó ‚Üê 0; empty ranking ùúé ùê∏ùëÇùëÖ
while ùëó < ùëò do
ùëôùëî ‚Üê ùúé ùëÉùëÖùëÉ,ùëî [1] ‚àÄùëî ‚àà {ùê¥, ùêµ}
ùëî‚àó ‚Üê arg min ùõø (ùúé ùê∏ùëÇùëÖ ‚à™ {ùëôùëî }) ,
ùëî‚àà {ùê¥,ùêµ }

where ùõø (.) is computed using (7)
‚àó
‚àó
‚àó
ùëôùëî‚àó ‚Üê ùúé ùëÉùëÖùëÉ,ùëî [1]; ùúé ùëÉùëÖùëÉ,ùëî ‚Üê ùúé ùëÉùëÖùëÉ,ùëî \{ùëôùëî‚àó }
ùúé ùê∏ùëÇùëÖ ‚Üê ùúé ùê∏ùëÇùëÖ ‚à™ {ùëôùëî‚àó }; ùëó ‚Üê ùëó + 1
Return ùúé ùê∏ùëÇùëÖ

cost of opportunity in rankings described in Section 4.1. Both ùõøEOR Fair Ranking and cost of opportunity in rankings are derived
separately ‚Äì the former from the axiom of fairness of a uniform
lottery, the latter from the cost of errors that any realistic prediction
model is bound to make. In the next section, we show that these
two are elegantly related via theoretical results on cost optimality.

5

Computing EOR-Fair Rankings

We now turn to the question of how to compute a ùõø-EOR fair ranking ùúé ùê∏ùëÇùëÖ for any given relevance model P(ùëüùëñ |D). This ranking
procedure needs to account for two potentially opposing goals.
First, it needs to ensure that ùõø-EOR fairness is not violated, ideally for a ùõø that is not larger than required by the discreteness
of the ranking. Second, it should maximize the number of relevant candidates contained in the top ùëò, for any a-priori unknown
ùëò. While solving this optimization problem in the exponentially
sized space of rankings is computationally inefficient, we show
that Algorithm 1 is an efficient ranking method that provides a
close-to-optimal solution.
Algorithm 1 uses as input the PRP rankings ùúé ùëÉùëÖùëÉ,ùê¥ and ùúé ùëÉùëÖùëÉ,ùêµ
for each of the groups A and B respectively. We denote ùúé ùëÉùëÖùëÉ,ùëî [ùëñ] as
the ùëñ ùë°‚Ñé element in the PRP ranking of group ùëî. The basic idea is to
compare the highest relevance candidate from each group and select
the candidate that would minimize the ùõø for the resultant ranking
(breaking ties arbitrarily when selecting an element from either
group results in the same ùõø for the resultant ranking). Consider our
running example from Figure 1. At ùëò = 1, selecting the first element
from group A, ùúé ùëÉùëÖùëÉ,ùê¥ [1], would result in a ùõø (ùúé1 ) = 0.9/4 while
selecting the first element from group B, ùúé ùëÉùëÖùëÉ,ùêµ [1], would result
in a ùõø (ùúé1 ) = ‚àí0.6/4. To minimize |ùõø (ùúé1 )|, the algorithm selects the
ùêµ

first element from group B with ùúé1ùê∏ùëÇùëÖ = [ 0.6], |ùõø (ùúé1 )| = 0.6/4. For
ùëò = 2, the first element from group A, and the second element from
group B are considered. It proceeds to select the first element from
ùêµ

ùê¥

group A with ùúé2ùê∏ùëÇùëÖ = [ 0.6, 0.9], |ùõø (ùúé2 )| = 0.3/4 and so on. The
Algorithm does not change the relative ordering between candidates
within a group and its runtime complexity is ùëÇ (ùëõ log ùëõ), since the
elements from the two groups each need to be sorted once by
P(ùëüùëñ |D). Composing the final EOR ranking ùúé ùê∏ùëÇùëÖ by merging the
two group-based rankings ùúé ùëÉùëÖùëÉ,ùê¥ and ùúé ùëÉùëÖùëÉ,ùêµ takes only linear time
since each computation per iteration is constant time per prefix ùëò.

While Algorithm 1 is inspired by existing algorithms such as
[61] in that both select the top element from the PRP ranking of
each group, they are fundamentally different. Existing methods
including [61] ensure a form of demographic parity which we have
already shown to be fundamentally different than the EOR criterion
we propose. Additionally, while [61] requires a threshold input and
the designation of a disadvantaged group, the EOR Algorithm does
not require this normative designation and guarantees EOR fairness
without requiring any tolerance ùõø as an input. We show this both
theoretically and in empirical evaluations and provide a detailed
description of baseline algorithms in Appendix E.1.
It remains to be shown that Algorithm 1 always produces a ranking ùúé ùê∏ùëÇùëÖ with small ùõø while surfacing as many relevant candidates
as possible in any top ùëò prefix. We break the proof of this guarantee
into the following steps. First, we show that for any particular ùëò
and its associated ùõø (ùúéùëòùê∏ùëÇùëÖ ), the number of relevant candidates in
the top-ùëò is close to optimal. Second, we provide an upper bound on
ùõø (ùúéùëòùê∏ùëÇùëÖ ) that is entirely determined a priori by the specific P(ùëüùëñ |D).
To address the first step, the following Theorem 5.1, shows that the
rankings produced by Algorithm 1 have a cost to the principal that
is close to optimal.
Theorem 5.1 (Cost Approximation Guarantee at ùëò).
The EOR fair ranking ùúé ùê∏ùëÇùëÖ produced by Algorithm 1 is at
least ùúôùõø (ùúéùëòùê∏ùëÇùëÖ ) cost optimal for any prefix ùëò, where ùúô =
ùëùùê¥ ‚àíùëù ùêµ
ùëùùê¥
ùëùùêµ
2
ùëõùëÖùëíùëô (ùê¥)+ùëõùëÖùëíùëô (ùêµ) ùëûùê¥ +ùëûùêµ , ùëûùê¥ = ùëõùëÖùëíùëô (ùê¥) , and ùëû ùêµ = ùëõùëÖùëíùëô (ùêµ) . Further, ùëùùê¥ = ùúé ùëÉùëÖùëÉ,ùê¥ [ùëòùê¥ ], ùëù ùêµ = ùúé ùëÉùëÖùëÉ,ùêµ [ùëòùêµ ], where ùëòùê¥ is the last

element from group A that was selected by EOR Algorithm for
prefix ùëò and similarly for ùëòùêµ .
Proof Sketch: We use linear duality to prove this theorem. To find
a lower bound on the cost optimal ranking that satisfies the EOR
fairness constraint, we formulate the corresponding Linear Integer
Problem (ILP) for selecting the optimal top-k subset under the ùõøEOR constraint. This leads to the following optimization problem,
where ùëã ‚àà {0, 1}ùëõ is the variable for whether the ùëñ ùë°‚Ñé candidate was
chosen or not, ùëÉ is the relevance probability for all candidates.
Minimize total cost as defined in Eq. (4)
min
ùë• ‚àà {0,1}

1‚àí

ùëÉùëá ùëã
ùëõùëÖùëíùëô (ùê¥) + ùëõùëÖùëíùëô (ùêµ)

(ILP)

s.t. ùëã ùëá 1 = ùëò
(select up to ùëò candidates)

ùëá
ùëÉIùê¥
ùëÉIùêµ
‚àíùõø (ùúéùëòùê∏ùëÇùëÖ ) ‚â§
‚àí
ùëã ‚â§ ùõø (ùúéùëòùê∏ùëÇùëÖ )
ùëõùëÖùëíùëô (ùê¥) ùëõùëÖùëíùëô (ùêµ)
(EOR fairness from Eq. (6) must be satisfied ‚àÄùëò)
We relax this ILP to a Linear Program (LP) by turning any integer
constraints ùë• ‚àà {0, 1} in the primal into 0 ‚â§ ùë• ‚â§ 1. For the relaxed
LP, we formulate its dual and construct a set of dual variables ùúÜ
corresponding to the solution from the EOR Algorithm. Using the
dual value of the EOR solution and the relaxed LP solution, we
obtain an upper bound of the duality gap. Since the upper bound on
this duality gap is w.r.t. the relaxed LP solution, it is also an upper
bound for the optimal ILP solution. We provide a complete proof
of the theorem and associated lemmas in Appendix C.1.
‚ñ°
Note that ùúô depends only on the relevance probabilities of the
last elements selected from each group by the EOR Algorithm in the

EAAMO ‚Äô24, October 29‚Äì31, 2024, San Luis Potosi, Mexico

Rastogi and Joachims.

ùëò ùë°‚Ñé position. Furthermore, note that the solution of Algorithm 1 is
the exact optimum for any ùëò where the unfairness ùõø (ùúéùëòùê∏ùëÇùëÖ ) is zero,
indicating that any suboptimality of the EOR algorithm is merely
due to some (presumably unavoidable) discretization effects.
While the previous theorem characterized cost optimality, the
following Theorem 5.2 shows that the magnitude of unfairness
ùõø (ùúéùëòùê∏ùëÇùëÖ ) is bounded by some ùõøùëöùëéùë• , providing an a priori approximation guarantee for both the amount of unfairness and the cost
optimality of Algorithm 1.
Theorem 5.2 (Global Cost and Fairness Guarantee). Algorithm 1 always produces a rankingùúé ùê∏ùëÇùëÖ that is at least ùúôùõøùëöùëéùë• cost
optimal for any ùëò, with ùõøùëöùëéùë• = 12

ùúé ùëÉùëÖùëÉ,ùê¥ [1]
ùúé ùëÉùëÖùëÉ,ùêµ [1]
ùëõùëÖùëíùëô (ùê¥) + ùëõùëÖùëíùëô (ùêµ)

.

The following selection rule then provides the selected group ùëî‚àó
and candidate ùëôùëî‚àó to append to the EOR ranking.
ùëôùëî
ùëî

‚àó

=
=

ùúé ùëÉùëÖùëÉ,ùëî [1]

‚àÄùëî ‚àà {1 ¬∑ ùê∫ }

arg min ùõø (ùúé

ùê∏ùëÇùëÖ

‚àó

‚à™ {ùëôùëî }); ùëôùëî‚àó = ùúé ùëÉùëÖùëÉ,ùëî [1]

(9)

ùëî‚àà [1..ùê∫ ]

Note that the above selection rule is a strict generalization of Algorithm 1 and it reflects the intuition of minimizing the gap in
relevance proportions for all the groups. It can be verified that the
runtime complexity with selection rule according to Eqs. (8), (9) for
a constant number of groups ùê∫ is ùëÇ (ùëõ log ùëõ + ùê∫ùëõ). Furthermore, we
can extend the cost-approximation guarantee to the multi-group
case.

Proof Sketch: We show via an inductive argument that according to the EOR algorithm, minimizing ùõø (ùúéùëòùê∏ùëÇùëÖ ) at every ùëò ensures that the resultant EOR ranking always satisfies ùõø (ùúéùëòùê∏ùëÇùëÖ ) ‚â§


ùúé ùëÉùëÖùëÉ,ùêµ [1]
1 ùúé ùëÉùëÖùëÉ,ùê¥ [1]
2 ùëõùëÖùëíùëô (ùê¥) + ùëõùëÖùëíùëô (ùêµ) , that is bounded by the average of the
relevance proportions from the first two elements considered in
the selection from group A and B. We denote this global fairness
guarantee by ùõøùëöùëéùë• . Using ùúô from Theorem 5.1 the cost guarantee
is given by


ùëù ‚àíùëù

ùúé ùëÉùëÖùëÉ,ùê¥ [1]

ùúé ùëÉùëÖùëÉ,ùêµ [1]

ùê¥
ùêµ
1
ùúôùõøùëöùëéùë• = ùëõùëÖùëíùëô (ùê¥)+ùëõùëÖùëíùëô
(ùêµ) ùëûùê¥ +ùëûùêµ
ùëõùëÖùëíùëô (ùê¥) + ùëõùëÖùëíùëô (ùêµ) . Further, we show that if the EOR algorithm selects all the elements
from one group at some position ùëò, then selecting the remaining
elements from the other group satisfies the ùõøùëöùëéùë• constraint. We
provide a complete proof of this theorem in Appendix C.2.
‚ñ°
We now compare EOR with the Uniform ranking policy and
analyze positions ùëò with ùõø = 0 to avoid discretization effects.

Proposition 5.1 (Costs from EOR vs. Uniform Policy). The
EOR ranking never has higher costs to the groups and total cost to
the principal as compared to the Uniform Policy, for those ùëò where
ùõø (ùúéùëò ) = 0.
We provide the proof of Proposition 5.1 in Appendix C.3. In
summary, we have shown that Algorithm 1 is an efficient algorithm
that computes rankings close to the optimal solution, making it a
promising candidate for practical use.

6

Theorem 6.1 (Global Cost and Fairness Guarantee for
multiple groups). The EOR rankings are cost optimal up to a gap
of ùúôùõø (ùúéùëòùê∏ùëÇùëÖ ) for ùê∫ groups, with ùõø (ùúéùëòùê∏ùëÇùëÖ ) bounded by ùõøùëöùëéùë• , such
that,

Extension to ùê∫ Groups

In this section, we discuss the extension of the EOR algorithm
beyond two groups. In particular, we consider the general case
where a candidate belongs to one of G groups ùëî ‚àà [1 ¬∑ ¬∑ ¬∑ ùê∫]. From
Section 4, we can generalize the cost burden to the principal similar
to Eq. (4), taking all the groups into account for the normalization
factor as follows
√ç
ùúã
ùëñ (1 ‚àí P(ùëñ ‚àà ùúéùëò ))P(ùëüùëñ = 1|D)
ùëê (Principal|ùúãùëò ) =
√çùê∫
ùëî=1 ùëõùëÖùëíùëô (ùëî)
To generalize Algorithm 1 for selecting top ùëò candidates from multiple groups, we define ùõø (ùúé) as the EOR criterion that captures the
gap between the group with the maximum accumulated relevance
proportion and the group with the minimum accumulated relevance
proportion,




ùëõùëÖùëíùëô (ùëî|ùúé)
ùëõùëÖùëíùëô (ùëî|ùúé)
ùõø (ùúé) = max
‚àí min
(8)
ùëî
ùëî
ùëõùëÖùëíùëô (ùëî)
ùëõùëÖùëíùëô (ùëî)

ùúô

=

ùõøùëöùëéùë•

=

¬© ‚àëÔ∏Å ùëùùê¥ ‚àí ùëù ùêµ ¬™
¬Æ ‚àÄùëò
¬≠
(ùê∫ ‚àí 1) ùëî=1 ùëõùëÖùëíùëô (ùëî) {ùê¥,ùêµ } ùëûùê¥ + ùëûùêµ
¬¨
¬´
 ùëÉùëÖùëÉ,ùëî

ùúé
[1]
max
ùëî
ùëõùëÖùëíùëô (ùëî)
2
√çùê∫

where {ùê¥, ùêµ} are all ùê∫ choose 2 possible pairs of groups.
Proof Sketch: We extend the LP formed in Theorem 5.1 to include
ùê∫ (ùê∫ ‚àí 1) ùõø constraints and construct feasible dual variables from
the EOR solution for each pair of groups. We then show that the
duality gap is bounded by ùúôùõø (ùúéùëòùê∏ùëÇùëÖ ) for a particular prefix ùëò. Note
that the ùúô bound for multi-group reduces to the one presented in
Theorem 5.1 for two groups. Finally, we present the global a priori
bound on ùõø (ùúéùëòùê∏ùëÇùëÖ ) as ùõøùëöùëéùë• , which is a strict generalization of the
two groups case. We provide complete proof of this theorem in
Appendix D.1.
‚ñ°

7

Experimental Evaluation

We now evaluate the EOR framework and algorithm empirically
and compare against several baselines ‚Äì namely Demographic (Statistical) Parity (ùúã ùê∑ùëÉ ) [58], FA‚àó IR Ranking Principle (ùúã ùêπùëÜ ) [61], Probability Ranking Principle (ùúã ùëÉùëÖùëÉ ) [41], Thompson Sampling Policy
(ùúãùëá ùëÜ ) [50], Uniform Policy (ùúã unif ), Disparate Treatment of Exposure
(ùúã ùê∏ùëã ùëÉ ) [49], and Fair Rank Aggregation (ùúã ùëÖùê¥ ) [7] with proportional
representation of exposure. We discuss implementation details of
these baselines in Appendix E.1.

7.1

Synthetic Data

We first present results on synthetic data where we can control
the level of disparate uncertainty. We report a) unfairness and b)
effectiveness of rankings for each scenario. The unfairness metric is
defined as the area under the curve for the EOR criterion, given by
√çùëõ
|ùõø (ùúéùëò )|. To measure the effectiveness of rankings, we report
ùëò=1
the improvement in total cost over the expected total cost of ùúã unif ,
√ç
(.)
computed as ùëõùëò=1 ùëê (Prinicpal|ùúãùëòunif ) ‚àí ùëê (Prinicpal|ùúãùëò ).
7.1.1 How does ùúã ùê∏ùëÇùëÖ compare against the baselines under varying
amounts of disparate uncertainty? Table 1 (left) reports unfairness

EAAMO ‚Äô24, October 29‚Äì31, 2024, San Luis Potosi, Mexico

Un-fairness ‚Üì

Effectiveness ‚Üë

ùúã \Disp. Unc.

High

Medium

Low

High

Medium

Low

ùúã ùê∏ùëÇùëÖ
ùúã ùê∑ùëÉ
ùúã ùëÉùëÖùëÉ
ùúãùëá ùëÜ
ùúã unif
ùúã ùê∏ùëã ùëÉ
ùúã ùëÖùê¥
ùúã ùêπùëÜ

1.07 ¬±0.01
11.09 ¬±0.38
15.41 ¬±0.69
11.77 ¬±0.57
5.96 ¬±0.13
9.23 ¬±0.77
13.97 ¬±0.71
13.33 ¬±0.70

1.02 ¬±0.00
6.02 ¬±0.07
7.68 ¬±0.13
4.96 ¬±0.07
5.80 ¬±0.00
5.62 ¬±0.01
6.57 ¬±0.16
7.04 ¬±0.16

1.02 ¬±0.00
2.42 ¬±0.20
2.63 ¬±0.17
4.49 ¬±0.45
6.49 ¬±0.09
3.26 ¬±0.62
2.40 ¬±0.00
2.95 ¬±0.17

10.44 ¬±0.15
10.07 ¬±0.20
12.11 ¬±0.20
7.66 ¬±0.04
0.00 ¬±0.00
11.59 ¬±0.23
12.02 ¬±0.19
11.98 ¬±0.20

11.89 ¬±0.04
11.33 ¬±0.04
12.00 ¬±0.02
9.62 ¬±0.06
0.00 ¬±0.00
11.97 ¬±0.03
12.00 ¬±0.02
12.00 ¬±0.02

14.58 ¬±0.10
14.49 ¬±0.11
14.62 ¬±0.09
12.81 ¬±0.69
0.00 ¬±0.00
14.62 ¬±0.09
14.60 ¬±0.00
14.62 ¬±0.09

Table 1: Left: Effect of varying disparate uncertainty on Synthetic Dataset, Right: Posterior
distribution and expected probabilities of relevance shown for a sample from each of high,
medium, and low uncertainty setting.

and effectiveness for ùúã ùê∏ùëÇùëÖ and the baselines in terms of mean and
standard error over 100 simulations, while Table 1 (right) demonstrates the posterior distribution formed by sampling an instance
of each of high, medium and low disparate uncertainty settings.
These posterior distributions similar to Figure 3 are for illustrative purposes since only the expected probability of relevance ùëùùëñ is
used for rankings (refer to Section 3.2). The different disparate uncertainty settings are generated synthetically to demonstrate how
ranking policies behave if, for example, the Principal collects more
data for group B thus reducing the disparate uncertainty among
groups. Note, how in the low disparate uncertainty setting, the
sharp ùëùùëñ (close to 0 or 1), would make the identification of relevant
candidates easy for both groups. The synthetic generation involves
sampling ùëùùëñ from sharp and flat distributions for group A and B
respectively and gradually increasing the sharpness of ùëùùëñ for group
B (implementation details in Appendix E.2).
As predicted by theory, ùúã ùê∏ùëÇùëÖ maintains low unfairness at all levels of disparate uncertainty, outperforming all the baselines ùúã ùëÉùëÖùëÉ ,
ùúã ùê∑ùëÉ , ùúãùëá ùëÜ , ùúã ùê∏ùëã ùëÉ , ùúã ùëÖùê¥ , and ùúã ùêπùëÜ . Note that ùúã ùê∏ùëÇùëÖ even outperforms
the uniform policy ùúã unif , since any individual ranking drawn from
ùúã unif is likely to be unfair. In terms of effectiveness, the theoretically optimal skyline is given by ùúã ùëÉùëÖùëÉ . Across all levels of disparate
uncertainty, ùúã ùê∏ùëÇùëÖ is at least competitive with the other baselines,
indicating that the EOR fairness does not impose a disproportionate
cost of fairness for the Principal.
Note how the gap in the unfairness between ùúã ùê∏ùëÇùëÖ and all other
ranking policies is largest when disparate uncertainty is highest.
At low levels of disparate uncertainty, ùúã ùê∏ùëÇùëÖ is still more fair as
compared to other ranking policies (though the gap in unfairness
is smaller) and the effectiveness of ùúã ùê∏ùëÇùëÖ is almost the same as that
of ùúã ùëÉùëÖùëÉ .
7.1.2 At which positions in the rankings do the policies incur unfairness? While the previous table summarized unfairness across
the whole ranking, Figure 4 (left) provides more detailed insights
into how unfairness accumulates across positions in the ranking.
The only method that is systematically fair across all positions ùëò
is ùúã ùê∏ùëÇùëÖ , keeping the unfairness ùõø (ùúéùëò ) from Definition 4.1 close

Posterior ( i| )

Fairness in Ranking under Disparate Uncertainty

(ri = 1| )

group B

group A

High Disparate Uncertainty

Medium Disparate Uncertainty

Low Disparate Uncertainty
0.0

0.2

0.4

0.6

0.8

1.0

i

to zero everywhere in the ranking. The baselines generally start
accumulating unfairness towards one group right from the top of
the ranking. Their unfairness only decreases once they run out of
viable candidates from the group they prefer. The only exception
√ç
is ùúã unif , here for a specific ranking with median ùëõùëò=1 |ùõø (ùúéùëòunif )|.
However, rankings from ùúã unif tend to stray much further from zero
than the ùúã ùê∏ùëÇùëÖ ranking. Additional results for the medium and low
disparate uncertainty settings in Figure 11 of Appendix E.2 further
support these findings.
7.1.3 How do the ranking policies distribute the costs between the
stakeholders? In Figure 4 (middle) we investigate how the ranking
policies distribute the cost ùëê (ùëî|ùúãùëò ) from Eq. (3) between group A and
group B. It shows that only ùúã ùê∏ùëÇùëÖ has an equal cost to both groups
across the whole ranking, which can be seen from the overlapping
cost curves for both groups. Furthermore, the cost is substantially
lower for both groups than their expected cost under the uniform
policy (diagonal line).Figure 4 (right) shows the total cost to the
principal, and again ùúã ùê∏ùëÇùëÖ is competitive with the baselines.
All other baselines incur substantial disparate costs to the groups,
some even worse than the uniform lottery. In particular, ùúã ùê∑ùëÉ selects
the candidates alternately between the two groups since group sizes
are relatively similar, but this results in selecting a higher proportion
of relevance from group A because the relevance probabilities are
sharper for group A than for B. As a result, the cost burden is higher
for group B. ùúãùëá ùëÜ is fairer than ùúã ùëÉùëÖùëÉ , since it randomizes relevant
candidates before sorting them in decreasing order of relevance,
however being group oblivious, it still places an uneven cost burden.
The exposure based policies ùúã ùê∏ùëã ùëÉ , ùúã ùëÖùê¥ motivated by position
bias in rankings also do not distribute the costs evenly. ùúã ùê∏ùëã ùëÉ will
stochastically allocate most of the top positions to candidates with
sharp and high probabilities, close to 1.0 from group A, then to
candidates of group B with flat and middle relevance probabilities,
and finally the rest of the candidates from group A with sharp
but low probabilities, close to 0.0 in the last positions. While this
perfectly allocates exposure between group A and B over the full
ranking of 61 candidates, group B (the uninformative group) suffers
from a high cost burden. Note how the direction of cost burden

EAAMO ‚Äô24, October 29‚Äì31, 2024, San Luis Potosi, Mexico

EOR
DP

PRP
TS

Rastogi and Joachims.

Uniform
EXP
1.0

RA

FS

EOR

DP

Group A
PRP

Group B

Principal

1.0

TS

0.5

0.0
1.0

61

61

61

EXP

RA

FS

Total Costs

Group Costs

( k)

0.8
61

0.6
0.4
0.2

0.0

=0

0

0.0

61

61

(a) Length of Ranking (k)

(b)

61

61

0.0

(c)

61

( k)

is opposite
example of Figure 1,
0.5 to the one ùúã ùê∏ùëã ùëÉ induced in the
0.0A.
where group B was smaller in size to group

7.2

1.0

61

EXP

US Census Survey Data

While the synthetic experiments provide insights into the behavior
0.0 policies under varying conditions,
of ranking
k = 0 we now investigate
how far ùúã ùê∏ùëÇùëÖ can mitigate unfairness as0.0
it arises in real-world
0 the relevance probabilities
61 P(ùëüùëñ |D) are learned
61
datasets where
Lengthweofconsider
Ranking
from data. In(a)
particular,
the(k)
US Census Survey dataset
[14] for the year 2018 and the state of Alabama and New York,
consisting of 22,268 and 103,021 records respectively. The task is
to predict whether the income for an individual > $50ùêæ based
on features such as educational attainment, occupation, class of
worker etc. We use this task as a stand-in for some task where
individuals receive a benefit from being evaluated positively. To get
group-calibrated estimates of P(ùëüùëñ |D), we train a gradient boosting
classifier followed by Platt Scaling on the validation subset of the
data. We evaluate the EOR criterion and costs on the test subset of
these records. Full details for dataset pre-processing and training
can be found in Appendix E.3. Because these rankings are large (up
to ‚àº 20ùêæ size), ùúã ùê∏ùëã ùëÉ and ùúã ùêπùëÜ are not computationally tractable.
ùúã ùëÖùê¥ performs similarly to ùúã ùëÉùëÖùëÉ and we include it in Appendix E.3
for completeness.
7.2.1 How do the ranking policies compare when using learned probability estimates? To evaluate the two-group EOR algorithm, we
first only rank individuals labeled as White and Black or African
American. Figure 5 (top) shows that EOR ranking is effective even
with estimated probabilities. In particular, while the ranking algorithms only use estimated probabilities, the EOR criterion, and
costs are evaluated on the true relevance labels from the test set.
Nevertheless, ùúã ùê∏ùëÇùëÖ still evaluates ùõø close to zero and distributes
costs among the stakeholders more evenly than the other baseline policies ùúã ùëÉùëÖùëÉ , ùúã ùê∑ùëÉ , and even ùúã unif, ùúãùëá ùëÜ for a specific ranking
√ç
with median ùëõùëò=1 |ùõø (ùúéùëò )|. Additional experiments in Appendix E.3
further confirm these findings.

Total Costs

Group Costs

Figure 4: Left: EOR criterion ùõø (ùúéùëò ), Middle: group costs according to (3), Right: the principal‚Äôs total cost according to (4) of the ranking
policies for the synthetic dataset with high1.0
disparate uncertainty shown in top right of Table 1. Group A consists of 30
1.0candidates with sharp
EOR(ùê¥) = 14.96 expected
DP number of relevant
PRP
probabilities with ùëùùëñ ‚àº Beta(1/20, 1/20). This provides ùëõùëÖùëíùëô
candidates.TS
Group B also has similar
candidates, in particular, it has 31 candidates, with relatively flat probabilities ùëùùëñ ‚àº Beta(5, 5), providing ùëõùëÖùëíùëô (ùêµ) = 14.94 expected number of
0.8
relevant candidates.
7.2.2 How does EOR Ranking perform for0.6
more than two groups?
Figure 5 (bottom) shows results on the US Census Dataset for four
61
61
61
groups,
RA again using estimated relevances for0.4ranking but evaluating
against the true relevance labels from the test dataset. Note that for
more than two groups, the EOR constraint 0.2
defined according to (8)
will always be non-negative as it measures the absolute difference
in relevance proportions between the groups
0.0that are furthest apart.
We observe that similar to the results with two groups, the EOR
0 10 20 30 40
61keeps the unfairness
61 ùõø lower (close to zero)
ranking
as compared to
(c)
(b)other policies in Figure 5 (left). Additionally, ùúã ùê∏ùëÇùëÖ also distributes
the costs evenly among all stakeholders for the generalized case of
more than two groups, as noted by the overlapping of dashed lines
for the four group costs (middle). Finally, ùúã ùê∏ùëÇùëÖ is competitive with
the optimal ùúã ùëÉùëÖùëÉ in terms of total cost for the principal.

7.3

Amazon Shopping Audit

In the final experiment, we investigate how the EOR framework
can be used for auditing. To illustrate this point, we use a dataset of
Amazon shopping queries [39], which includes a baseline model for
predicting the relevance of products given a search query. We further augment this dataset with logged rankings from the Amazon
website as collected for the Markup report [60], which investigated
Amazon‚Äôs placement of its own brand products as compared to
other brands based on star ratings, reviews etc. The Markup data
consists of popular search query-product pairs along with logged
rankings of these products on Amazon‚Äôs platform, but it does not
contain human-annotated relevance labels. We focus the audit on
bias between the group of Amazon-owned brands (group A) or any
other brand (group B). As the first step of the audit, we calibrate ùëùùëñ
by fitting a Platt-scaling calibrator using validation data for both
groups. Figure 6a shows that the calibrated ùëùùëñ on the test dataset
binned across 20 equal-sized bins, lies close to the perfectly calibrated line. As the second step of the audit, we use the Markup
dataset with logged rankings4 and compute ùëùùëñ using the calibrated
4 https://github.com/the-markup/investigation-amazon-brands

50

60

Fairness in Ranking under Disparate Uncertainty

( k)

0.2

Group Costs

0.2

0.3

0.1

0.0
1.0

0.0

0.1

k=0

-0.1

0.0

0

0

Group Costs

1.0

0.3

0.4

Uniform
White
1.0

0.4

DP

PRP

TS

(a)

0.2
0.1
k=0

0

Length of Ranking (k)

0.0
1.0

1.0
1.0

0.5
0.5

PRP

TS

19985

19985

0.0

19985

4268

(c)

19985

0.5

0.0

(b)

(a)

Principal

0.0
4268 0.0
1.0 0
19985
DP

0.0
0.0 4268
4268
1.0 19985 EOR
Length19985
of Ranking (k)
(b)
(a)

Group Costs

( k)

0.0
1.0

Others

EOR

=0

0.3

0.0

Black
Asian

TotalCosts
Costs
Total

PRP
TS

Total Costs

EOR
DP

EAAMO ‚Äô24, October 29‚Äì31, 2024, San Luis Potosi, Mexico

19985

(c)

Figure 5: US Census Dataset: EOR criterion ùõø (ùúéùëò ) and cost of the ranking policies computed with true relevance labels from the test subset
for the US Census dataset. Top: Two groups setting using the White and Black/African American racial groups for the state of Alabama.
Bottom: Multiple (four groups) setting using White, Black/African American, Asian, and Other for the state of NY.

0.8

0.15

Perfect calibration
Amazon (group A)
Non-Amazon (group B)

0.10

0.6

Œ¥(œÉk )

Mean empirical rate

1.0

0.4

0.00

Œ¥k = 0

0.05

0.2
0.00.0

0.05

0.2

0.4

0.6

0.8

1.0

(a) Mean predicted rate

0.10

EOR
Logged Ranking
10

20

30

40

50

60

(b) Length of Ranking (k)

Figure 6: Left: Group-wise calibration of P(ùëüùëñ |D) for Amazon
shopping queries on the test set according to the baseline model
after Platt Scaling. Right: Fairness of logged Amazon rankings
compared to EOR rankings in terms of ùõø (ùúéùëò ) averaged over queries.
baseline relevance prediction model. The EOR criterion (7) is averaged over queries for the logged rankings, and the EOR rankings
are produced by Algorithm 1. Figure 6b shows that there exists
a ranking ùúé ùê∏ùëÇùëÖ that has ùõø (ùúéùëòùê∏ùëÇùëÖ ) closer to zero for most prefix
ùëò. The logged rankings from Amazon‚Äôs platform show estimated
ùõø (ùúéùëò ) that are farther away from zero for at least some prefixes
of ùëò, reflecting a potential favoring of Amazon brand products. A

limitation of this analysis is that unlike in a real audit where the
auditor has access to the production model of ùëùùëñ , our baseline model
may be subject to hidden confounding, and thus does not provide
conclusive evidence of unfairness. In particular, the production
rankings may depend on other features beyond product titles (e.g,
product descriptions, bullet points, star ratings, etc.). However, the
analysis does demonstrate how the EOR criterion can be used for
auditing, if the auditor is given access to the production ranking
model to avoid confounding. We provide further details in Figure E.4
and our source code with experiment implementation can be found
here.5

8

Conclusion

This paper studies the problem of disparate uncertainty across
groups as a source of unfairness in ranking when these rankings
are used as part of a human decision-making process. In particular,
this paper introduces a framework that formalizes this unfairness
by relating it both to a fair lottery and to the costs that an imperfect
model imposes on the various stakeholders. Recognizing that it
may be difficult to avoid disparate uncertainty in real-world models, the paper develops the EOR procedure to produce rankings
that provably mitigate the effects of disparate uncertainty between
groups. Beyond its strong theoretical guarantees, we find that the
5 https://github.com/RichRast/DisparateUncertainty

EAAMO ‚Äô24, October 29‚Äì31, 2024, San Luis Potosi, Mexico

EOR method outperforms existing methods for fair ranking across
a wide range of settings. Furthermore, we illustrate that the EOR
criterion can also be used as a tool to audit a real-world system.
We conjecture that this combination of theoretical grounding, computational efficiency, and strong empirical performance provides
viable conditions for making the proposed framework and algorithm accessible for thoughtful use in practice.

9

Ethical Considerations

This work explicitly addresses the potentially negative societal
impact of machine learning predictions that include disparities
between groups in the context of ranking interfaces. However, as
pointed out by previous research [34, 46], we do not prescribe
distilling down the fairness of a system into a single metric ‚Äì the
fairness criterion we propose. We emphasize that it is important to
carefully consider the domain specifics and the particular situation
where our method may be deployed.
We also note that while our EOR algorithm does not worsen
the fairness within each group (i.e., within group ordering is maintained), it doesn‚Äôt improve within-group fairness either. Exploring
this dichotomy of satisfying within and between group fairness
simultaneously in the presence of differential uncertainty is an
important open question.

Acknowledgments
This research was supported in part by NSF Awards IIS-2008139
and IIS-2312865. All content represents the opinion of the authors,
which is not necessarily shared or endorsed by their respective
employers and/or sponsors. We thank Kate Donahue, Marios Papachristou, Aaron Tucker, Sarah Dean, Luke Wang, Emily Ryu,
Ashudeep Singh, Taran Pal Singh, and Woojeong Kim for helpful
comments and discussions. We also thank the anonymous reviewers
at the Epistemic AI, UAI workshop for helpful feedback.

References
[1] Kenneth Arrow. 1971. The Theory of Discrimination. Working Papers 403.
Princeton University, Department of Economics, Industrial Relations Section.
https://EconPapers.repec.org/RePEc:pri:indrel:30a
[2] Pranjal Awasthi, Matth√§us Kleindessner, and Jamie Morgenstern. 2020. Equalized odds postprocessing under imperfect group information. In Proceedings
of the Twenty Third International Conference on Artificial Intelligence and Statistics (Proceedings of Machine Learning Research, Vol. 108), Silvia Chiappa and
Roberto Calandra (Eds.). PMLR, 1770‚Äì1780. https://proceedings.mlr.press/v108/
awasthi20a.html
[3] Richard Berk, Hoda Heidari, Shahin Jabbari, Michael Kearns, and Aaron Roth.
2021. Fairness in Criminal Justice Risk Assessments: The State of the Art.
Sociological Methods & Research 50, 1 (2021), 3‚Äì44. https://doi.org/10.1177/
0049124118782533 arXiv:https://doi.org/10.1177/0049124118782533
[4] Asia J. Biega, Krishna P. Gummadi, and Gerhard Weikum. 2018. Equity of
Attention: Amortizing Individual Fairness in Rankings. CoRR abs/1805.01788
(2018). arXiv:1805.01788 http://arxiv.org/abs/1805.01788
[5] Joy Buolamwini and Timnit Gebru. 2018. Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification. In Proceedings of the 1st
Conference on Fairness, Accountability and Transparency (Proceedings of Machine
Learning Research, Vol. 81), Sorelle A. Friedler and Christo Wilson (Eds.). PMLR,
77‚Äì91. https://proceedings.mlr.press/v81/buolamwini18a.html
[6] Robin Burke. 2017.
Multisided Fairness for Recommendation.
CoRR
abs/1707.00093 (2017). arXiv:1707.00093 http://arxiv.org/abs/1707.00093
[7] Kathleen Cachel and Elke Rundensteiner. 2023. Fairer Together: Mitigating
Disparate Exposure in Kemeny Rank Aggregation. In Proceedings of the 2023 ACM
Conference on Fairness, Accountability, and Transparency (Chicago, IL, USA) (FAccT
‚Äô23). Association for Computing Machinery, New York, NY, USA, 1347‚Äì1357.
https://doi.org/10.1145/3593013.3594085

Rastogi and Joachims.

[8] L. Elisa Celis, Chris Hays, Anay Mehrotra, and Nisheeth K. Vishnoi. 2021. The
Effect of the Rooney Rule on Implicit Bias in the Long Term. In Proceedings of
the 2021 ACM Conference on Fairness, Accountability, and Transparency (Virtual
Event, Canada) (FAccT ‚Äô21). Association for Computing Machinery, New York,
NY, USA, 678‚Äì689. https://doi.org/10.1145/3442188.3445930
[9] L. Elisa Celis, Anay Mehrotra, and Nisheeth K. Vishnoi. 2020. Interventions
for Ranking in the Presence of Implicit Bias. In Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency (Barcelona, Spain) (FAT*
‚Äô20). Association for Computing Machinery, New York, NY, USA, 369‚Äì380.
https://doi.org/10.1145/3351095.3372858
[10] L. Elisa Celis, Damian Straszak, and Nisheeth K. Vishnoi. 2017. Ranking with
Fairness Constraints. In International Colloquium on Automata, Languages and
Programming.
[11] Alexandra Chouldechova. 2017. Fair Prediction with Disparate Impact: A Study
of Bias in Recidivism Prediction Instruments. Big Data 5, 2 (2017), 153‚Äì163.
https://doi.org/10.1089/BIG.2016.0047
[12] Brian Collins. 2007. Tackling Unconscious Bias in Hiring Practices: The Plight of
the Rooney Rule. NYU Law Review 82 (06 2007).
[13] Sam Corbett-Davies, Emma Pierson, Avi Feller, Sharad Goel, and Aziz Huq. 2017.
Algorithmic Decision Making and the Cost of Fairness. In Proceedings of the 23rd
ACM SIGKDD International Conference on Knowledge Discovery and Data Mining
(Halifax, NS, Canada) (KDD ‚Äô17). Association for Computing Machinery, New
York, NY, USA, 797‚Äì806. https://doi.org/10.1145/3097983.3098095
[14] Frances Ding, Moritz Hardt, John Miller, and Ludwig Schmidt. 2021. Retiring Adult: New Datasets for Fair Machine Learning. In Advances in Neural Information Processing Systems, M. Ranzato, A. Beygelzimer, Y. Dauphin,
P.S. Liang, and J. Wortman Vaughan (Eds.), Vol. 34. Curran Associates,
Inc., 6478‚Äì6490. https://proceedings.neurips.cc/paper_files/paper/2021/file/
32e54441e6382a7fbacbbbaf3c450059-Paper.pdf
[15] Ezekiel Dixon-Roman, Howard Everson, and John Mcardle. 2013. Race, Poverty
and SAT Scores: Modeling the Influences of Family Income on Black and White
High School Students‚Äô SAT Performance. Teachers College Record 115 (05 2013).
https://doi.org/10.1177/016146811311500406
[16] Marina Drosou, H.V. Jagadish, Evaggelia Pitoura, and Julia Stoyanovich. 2017.
Diversity in Big Data: A Review. Big Data 5, 2 (2017), 73‚Äì84. https://doi.org/10.
1089/big.2016.0054 arXiv:https://doi.org/10.1089/big.2016.0054 PMID: 28632443.
[17] Cynthia Dwork, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Richard
Zemel. 2012. Fairness through Awareness. In Proceedings of the 3rd Innovations
in Theoretical Computer Science Conference (Cambridge, Massachusetts) (ITCS
‚Äô12). Association for Computing Machinery, New York, NY, USA, 214‚Äì226. https:
//doi.org/10.1145/2090236.2090255
[18] Vitalii Emelianov, Nicolas Gast, Krishna P. Gummadi, and Patrick Loiseau. 2020.
On Fair Selection in the Presence of Implicit Variance. In Proceedings of the
21st ACM Conference on Economics and Computation (Virtual Event, Hungary)
(EC ‚Äô20). Association for Computing Machinery, New York, NY, USA, 649‚Äì675.
https://doi.org/10.1145/3391403.3399482
[19] Vitalii Emelianov, Nicolas Gast, Krishna P. Gummadi, and Patrick Loiseau. 2022.
On fair selection in the presence of implicit and differential variance. Artificial
Intelligence 302 (2022), 103609. https://doi.org/10.1016/j.artint.2021.103609
[20] Anthony W. Flores, Kristin Bechtel, and Christopher T. Lowenkamp. 2016.
False Positives, False Negatives, and False Analyses: A Rejoinder to "Machine Bias: There‚Äôs Software Used across the Country to Predict Future
Criminals. and It‚Äôs Biased against Blacks". Federal Probation 80 (2016),
38. https://www.uscourts.gov/federal-probation-journal/2016/09/false-positivesfalse-negatives-and-false-analyses-rejoinder
[21] Nikhil Garg, Hannah Li, and Faidra Monachou. 2021. Standardized Tests and
Affirmative Action: The Role of Bias and Variance. In Proceedings of the 2021
ACM Conference on Fairness, Accountability, and Transparency (Virtual Event,
Canada) (FAccT ‚Äô21). Association for Computing Machinery, New York, NY, USA,
261. https://doi.org/10.1145/3442188.3445889
[22] Barbara Goodwin. 1992. Justice by Lottery. University of Chicago Press, Chicago.
[23] Moritz Hardt, Eric Price, and Nati Srebro. 2016. Equality of Opportunity in
Supervised Learning. In Advances in Neural Information Processing Systems,
D. Lee, M. Sugiyama, U. Luxburg, I. Guyon, and R. Garnett (Eds.), Vol. 29. Curran Associates, Inc. https://proceedings.neurips.cc/paper_files/paper/2016/file/
9d2682367c3935defcb1f9e247a97c0d-Paper.pdf
[24] Tatsunori B. Hashimoto, Megha Srivastava, Hongseok Namkoong, and Percy
Liang. 2018. Fairness Without Demographics in Repeated Loss Minimization. In
International Conference on Machine Learning.
[25] Li He and Toni M. Whited. 2023.
Underrepresentation of Women
CEOs. (2023).
Available at SSRN: https://ssrn.com/abstract=4615373 or
http://dx.doi.org/10.2139/ssrn.4615373.
[26] Tim Henning. 2015. From Choice to Chance? Saving People, Fairness, and
Lotteries. Philosophical Review 124, 2 (2015), 169‚Äì206. https://doi.org/10.1215/
00318108-2842176
[27] Eyke H√ºllermeier and Willem Waegeman. 2021. Aleatoric and epistemic uncertainty in machine learning: an introduction to concepts and methods. Machine
Learning 110, 3 (2021), 457‚Äì506. https://doi.org/10.1007/s10994-021-05946-3

Fairness in Ranking under Disparate Uncertainty

[28] Tim De Jonge and Djoerd Hiemstra. 2023. UNFair: Search Engine Manipulation,
Undetectable by Amortized Inequity (FAccT ‚Äô23). Association for Computing
Machinery, New York, NY, USA.
[29] Jon Kleinberg, Sendhil Mullainathan, and Manish Raghavan. 2017. Inherent TradeOffs in the Fair Determination of Risk Scores. In 8th Innovations in Theoretical
Computer Science Conference (ITCS 2017) (Leibniz International Proceedings in
Informatics (LIPIcs), Vol. 67), Christos H. Papadimitriou (Ed.). Schloss Dagstuhl
‚Äì Leibniz-Zentrum f√ºr Informatik, Dagstuhl, Germany, 43:1‚Äì43:23. https://doi.
org/10.4230/LIPIcs.ITCS.2017.43
[30] Jon Kleinberg and Manish Raghavan. 2018. Selection Problems in the Presence
of Implicit Bias. In 9th Innovations in Theoretical Computer Science Conference
(ITCS 2018). Schloss Dagstuhl-Leibniz-Zentrum fuer Informatik.
[31] Nikola Konstantinov and Christoph H. Lampert. 2021. Fairness Through Regularization for Learning to Rank. CoRR abs/2102.05996 (2021). arXiv:2102.05996
https://arxiv.org/abs/2102.05996
[32] Michele Loi and Christoph Heitz. 2022. Is calibration a fairness requirement? An
argument from the point of view of moral philosophy and decision theory. In Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency
(<conf-loc>, <city>Seoul</city>, <country>Republic of Korea</country>, </confloc>) (FAccT ‚Äô22). Association for Computing Machinery, New York, NY, USA,
2026‚Äì2034. https://doi.org/10.1145/3531146.3533245
[33] Anay Mehrotra and Nisheeth K Vishnoi. 2022. Fair Ranking with Noisy Protected Attributes. In Advances in Neural Information Processing Systems, Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho (Eds.).
https://openreview.net/forum?id=mTra5BIUyRV
[34] Jakob M√∂kander, Jessica Morley, Mariarosaria Taddeo, and L. Floridi. 2021. EthicsBased Auditing of Automated Decision-Making Systems: Nature, Scope, and
Limitations. Science and Engineering Ethics 27 (2021).
[35] Harikrishna Narasimhan, Andy Cotter, Maya Gupta, and Serena Lutong Wang.
2020. Pairwise Fairness for Ranking and Regression. In 33rd AAAI Conference on
Artificial Intelligence.
[36] Edmund S. Phelps. 1972. The Statistical Theory of Racism and Sexism. The
American Economic Review 62, 4 (1972), 659‚Äì661. http://www.jstor.org/stable/
1806107
[37] J. Platt. 2000. Probabilistic outputs for support vector machines and comparison
to regularized likelihood methods. In Advances in Large Margin Classifiers.
[38] Geoff Pleiss, Manish Raghavan, Felix Wu, Jon Kleinberg, and Kilian Q Weinberger. 2017. On Fairness and Calibration. In Advances in Neural Information Processing Systems, I. Guyon, U. Von Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett (Eds.), Vol. 30. Curran
Associates, Inc.
https://proceedings.neurips.cc/paper_files/paper/2017/file/
b8b9c74ac526fffbeb2d39ab038d1cd7-Paper.pdf
[39] Chandan K. Reddy, Llu√≠s M√†rquez, Fran Valero, Nikhil Rao, Hugo Zaragoza,
Sambaran Bandyopadhyay, Arnab Biswas, Anlu Xing, and Karthik Subbian. 2022.
Shopping Queries Dataset: A Large-Scale ESCI Benchmark for Improving Product
Search. (2022). arXiv:2206.06588
[40] Nils Reimers and Iryna Gurevych. 2019. Sentence-BERT: Sentence Embeddings
using Siamese BERT-Networks. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing. Association for Computational
Linguistics. https://arxiv.org/abs/1908.10084
[41] Stephen Robertson. 1977. The Probability Ranking Principle in IR. Journal of
Documentation 33 (12 1977), 294‚Äì304. https://doi.org/10.1108/eb026647
[42] Yuta Saito and Thorsten Joachims. 2022. Fair Ranking as Fair Division: ImpactBased Individual Fairness in Ranking. In Proceedings of the 28th ACM SIGKDD
Conference on Knowledge Discovery and Data Mining (Washington DC, USA)
(KDD ‚Äô22). Association for Computing Machinery, New York, NY, USA, 1514‚Äì1524.
https://doi.org/10.1145/3534678.3539353
[43] Piotr Sapiezynski, Wesley Zeng, Ronald E Robertson, Alan Mislove, and Christo
Wilson. 2019. Quantifying the Impact of User Attentionon Fair Group Representation in Ranked Lists. In Companion Proceedings of The 2019 World Wide Web
Conference (San Francisco, USA) (WWW ‚Äô19). Association for Computing Machinery, New York, NY, USA, 553‚Äì562. https://doi.org/10.1145/3308560.3317595
[44] Ben Saunders. 2008. The Equality of Lotteries. Philosophy 83, 3 (2008), 359‚Äì372.
https://doi.org/10.1017/s0031819108000727
[45] Ben Saunders. 2018. Equality in the Allocation of Scarce Vaccines. Les Ateliers de
l‚Äô√âthique / the Ethics Forum 13, 3 (2018), 65‚Äì84. https://doi.org/10.7202/1061219ar
[46] Andrew D. Selbst, Danah Boyd, Sorelle A. Friedler, Suresh Venkatasubramanian,
and Janet Vertesi. 2019. Fairness and Abstraction in Sociotechnical Systems.
In Proceedings of the Conference on Fairness, Accountability, and Transparency
(Atlanta, GA, USA) (FAT* ‚Äô19). Association for Computing Machinery, New York,
NY, USA, 59‚Äì68. https://doi.org/10.1145/3287560.3287598
[47] Zeyu Shen, Zhiyi Wang, Xingyu Zhu, Brandon Fain, and Kamesh Munagala. 2023. Fairness in the Assignment Problem with Uncertain Priorities.
arXiv:2301.13804 [cs.GT]
[48] Ashudeep Singh and Thorsten Joachims. 2017. Equality of Opportunity in Rankings.

EAAMO ‚Äô24, October 29‚Äì31, 2024, San Luis Potosi, Mexico

[49] Ashudeep Singh and Thorsten Joachims. 2018. Fairness of Exposure in Rankings.
In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge
Discovery & Data Mining (London, United Kingdom) (KDD ‚Äô18). Association for
Computing Machinery, New York, NY, USA, 2219‚Äì2228. https://doi.org/10.1145/
3219819.3220088
[50] Ashudeep Singh, David Kempe, and Thorsten Joachims. 2021. Fairness in Ranking
under Uncertainty. In Advances in Neural Information Processing Systems, Vol. 34.
Curran Associates, Inc., 11896‚Äì11908. https://proceedings.neurips.cc/paper_
files/paper/2021/file/63c3ddcc7b23daa1e42dc41f9a44a873-Paper.pdf
[51] Rachael Tatman. 2017. Gender and Dialect Bias in YouTube‚Äôs Automatic Captions.
In Proceedings of the First ACL Workshop on Ethics in Natural Language Processing.
Association for Computational Linguistics, Valencia, Spain, 53‚Äì59. https://doi.
org/10.18653/v1/W17-1606
[52] Lequn Wang and Thorsten Joachims. 2021. User Fairness, Item Fairness, and
Diversity for Rankings in Two-Sided Markets. In Proceedings of the 2021 ACM
SIGIR International Conference on Theory of Information Retrieval (Virtual Event,
Canada) (ICTIR ‚Äô21). Association for Computing Machinery, New York, NY, USA,
23‚Äì41. https://doi.org/10.1145/3471158.3472260
[53] Lequn Wang and Thorsten Joachims. 2023. Uncertainty Quantification for Fairness in Two-Stage Recommender Systems. In Proceedings of the Sixteenth ACM
International Conference on Web Search and Data Mining (Singapore, Singapore)
(WSDM ‚Äô23). Association for Computing Machinery, New York, NY, USA, 940‚Äì948.
https://doi.org/10.1145/3539597.3570469
[54] Lequn Wang, Thorsten Joachims, and Manuel Gomez Rodriguez. 2022. Improving
Screening Processes via Calibrated Subset Selection. In International Conference
on Machine Learning.
[55] Dong Wei, Md Mouinul Islam, Baruch Schieber, and Senjuti Basu Roy. 2022.
Rank Aggregation with Proportionate Fairness. In Proceedings of the 2022 International Conference on Management of Data (Philadelphia, PA, USA) (SIGMOD ‚Äô22). Association for Computing Machinery, New York, NY, USA, 262‚Äì275.
https://doi.org/10.1145/3514221.3517865
[56] Benjamin Wilson, Judy Hoffman, and Jamie Morgenstern. 2019. Predictive Inequity in Object Detection. arXiv:1902.11097 [cs.CV]
[57] Ke Yang, Vasilis Gkatzelis, and Julia Stoyanovich. 2019. Balanced Ranking with
Diversity Constraints. 6035‚Äì6042. https://doi.org/10.24963/ijcai.2019/836
[58] Ke Yang and Julia Stoyanovich. 2016. Measuring Fairness in Ranked Outputs.
CoRR abs/1610.08559 (2016). arXiv:1610.08559 http://arxiv.org/abs/1610.08559
[59] Tao Yang, Zhichao Xu, Zhenduo Wang, Anh Tran, and Qingyao Ai. 2023.
Marginal-Certainty-Aware Fair Ranking Algorithm. In Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining (Singapore,
Singapore) (WSDM ‚Äô23). Association for Computing Machinery, New York, NY,
USA, 24‚Äì32. https://doi.org/10.1145/3539597.3570474
[60] Leon Yin and Adrianne Jeffries. 2021. How We Analyzed Amazons Treatment of
its Brands in Search Results. The Markup (10 2021). https://tinyurl.com/markupamazon
[61] Meike Zehlike, Francesco Bonchi, Carlos Castillo, Sara Hajian, Mohamed Megahed, and Ricardo Baeza-Yates. 2017. FA*IR: A Fair Top-k Ranking Algorithm. In
Proceedings of the 2017 ACM on Conference on Information and Knowledge Management (Singapore, Singapore) (CIKM ‚Äô17). Association for Computing Machinery,
New York, NY, USA, 1569‚Äì1578. https://doi.org/10.1145/3132847.3132938
[62] Meike Zehlike and Carlos Castillo. 2020. Reducing Disparate Exposure in Ranking:
A Learning To Rank Approach. In Proceedings of The Web Conference 2020 (Taipei,
Taiwan) (WWW ‚Äô20). Association for Computing Machinery, New York, NY, USA,
2849‚Äì2855. https://doi.org/10.1145/3366424.3380048
[63] Meike Zehlike, Tom S√ºhr, Ricardo Baeza-Yates, Francesco Bonchi, Carlos Castillo,
and Sara Hajian. 2022. Fair Top-k Ranking with Multiple Protected Groups. Inf.
Process. Manage. 59, 1 (jan 2022), 28 pages. https://doi.org/10.1016/j.ipm.2021.
102707
[64] Meike Zehlike, Ke Yang, and Julia Stoyanovich. 2021. Fairness in Ranking: A
Survey. CoRR abs/2103.14000 (2021). arXiv:2103.14000 https://arxiv.org/abs/2103.
14000

EAAMO ‚Äô24, October 29‚Äì31, 2024, San Luis Potosi, Mexico

A

Notation Summary
ùëõ

number of candidates

ùëñ ‚àà {1, ¬∑ ¬∑ ¬∑ , ùëõ}

candidate

ùê∫

number of groups

ùëî ‚àà {1, 2, ¬∑ ¬∑ ¬∑ ùê∫ }

group

ùëò

ranking prefix

ùëÜ (ùëî)

size of group ùëî

ùëõùëÖùëíùëô (ùëî) ‚àà R

expected number of relevant candidates for group ùëî

ùëüùëñ ‚àà {0, 1}

binary relevance of candidate ùëñ

ùúÉùëñ ‚àà [0, 1]

probability of relevance of candidate ùëñ

D

historical data

P(ùúÉùëñ |D)

posterior distribution

ùëùùëñ = P(ùëüùëñ |D) ‚àà [0, 1]

expected probability of relevance of candidate ùëñ

ùëÉ = (ùëùùëñ )ùëñ ‚àà {1,¬∑¬∑¬∑ ,ùëõ}

relevance probability vector

ùëã

vector indicating whether candidate ùëñ was selected
ùëõ

Iùëî ‚àà {0, 1}

indicator if candidate ùëñ belongs to group ùëî

ùúã

policy

ùúéùëòùúã
ùëÉùëÖùëÉ,ùëî

top ùëò ranking ùúéùëò ‚àº ùúã

ùúé

[ùëñ]

ùõø (ùúé)

B

Rastogi and Joachims.

ùëñ ùë°‚Ñé candidate in the PRP ranking of group g
EOR measure for ranking ùúé

Extended Related Work

Our work complements and extends prior research on fairness in rankings [64]. The classical fairness desiderata considered are variations of
proportional representation [17, 58]. Broadly, proportional representation ensures representation by group size in top ùëò selection or at every
prefix ùëò of the ranking. Other popular notions include diversity based constraints [10, 16, 57] like Rooney Rule and affirmative action that
ensure representation of the designated disadvantaged group, and threshold based formulations [54, 61, 63] that ensure a minimum number
of candidates to be selected from the disadvantaged group.
Another prominent class of fairness notions in rankings corresponds to exposure based formulations. Exposure [43, 49, 62] quantifies
the amount of attention allocated to candidates individually or from a particular group. These formulations include equity of exposure,
disparate treatment of exposure that allocates exposure proportional to amortized relevance, and disparate impact of exposure that allocates
exposure proportional to impact (e.g. economic impact of ranking) among other variations. See [4] for a similar concept of equity of attention.
Proportional representation, diversity constraints, and exposure are motivated by representation by group size, normative designation of
disadvantaged group, and allocation of attention respectively. Our work, on the other hand, is motivated by unfairness due to differential
uncertainty between groups and is grounded in the axiomatic fairness of a lottery system.
Our problem setup involves aggregating candidates from groups and while research on fair rank aggregation appears related, the goal
there is much different. In particular, fair rank aggregation achieves maximum consensus accuracy when multiple voters rank all candidates
subject to fairness constraints of group exposure [7] or p-fairness [55]. Work on multi sided fairness [6, 52] similarly considers diversity
constraints or exposure-based formulations. Finally, while [4, 31, 42, 50] propose an amortized notion of fairness, our work proposes a
non-amortized fairness criterion at every position ùëò of the ranking.
Recently, there has been a growing interest in the study of fairness in rankings under uncertainty. The classical desideratum in this
literature studies the relation of group-wise calibration for fairness [11, 20, 29, 32, 38]. Our work is orthogonal to this discussion. In particular,
we only assume that calibrated probability of relevance is given and instead focus on how differential sharpness of probabilities can cause
unfairness. [50] introduced an approximate notion of fairness that is violated if the principal ranks candidates that appear more than a
certain proportion of their estimated relevance distribution. One way to achieve this in expectation is through randomization of relevances
drawn from the predictive posterior distribution. Other works have introduced methods that quantify uncertainty in rankings [53] to update
and learn better estimates of relevances iteratively [59]. These works do not consider the unfairness caused due to differential uncertainty

Fairness in Ranking under Disparate Uncertainty

EAAMO ‚Äô24, October 29‚Äì31, 2024, San Luis Potosi, Mexico

between groups. While methods that reduce uncertainty for all groups are needed, we also need to account for unfairness due to the existing
disparate uncertainty that is unfortunately widespread in practical settings.
Another line of research focuses on statistical discrimination and the study of noisy estimates of relevances for selection problems [1, 36].
This literature establishes that the differential accuracy of models causes unfairness [5, 15, 24, 51, 56] for individuals based on their group
membership. Recently, [19, 21] studied the role of affirmative action in the presence of differential variance between groups in rankings.
Their method [19] corrects the bias in noisy relevance estimates given the variance of the true relevance distribution. Fairness in selection
processes has also been extensively studied in the presence of group-based implicit bias [8, 9, 18, 30], uncertainty in preferences [47] and in
the presence of noisy sensitive attributes [33]. This line of research analyzes the effect of affirmative actions like the Rooney rule on the
utility to the principal or how implicit bias affects the diversity of the selection set.
Our work is also motivated by Equality of opportunity framework, first introduced by [23] in the classification setting. It has provided a
compelling notion of balancing the cost burden among stakeholders [2, 11, 13]. For rankings, there has been some work in transferring the
idea of equalized odds with learning a ranking function during training [62] to reduce disparate exposure or augmenting the training loss
with regularizers that minimize costs for both groups [31, 35]. Our work extends this literature to introduce a framework connecting the
unfairness in rankings due to the disparate uncertainty to the distribution of cost burden among stakeholders by anchoring on the fairness
of random lottery.

C Proofs
C.1 Proof of Theorem 5.1
Proof. We use linear duality for proving this theorem. In order to find a lower bound on the cost optimal ranking that satisfies the EOR
fairness constraint, we relax the corresponding Integer Linear Problem (ILP) to a Linear Program (LP) by turning any integer constraints
ùëã ‚àà {0, 1} in the primal into 0 ‚â§ ùëã ‚â§ 1. For the relaxed LP, we formulate its dual and construct a set of dual variables ùúÜ corresponding to the
solution from the EOR Algorithm. With the dual solution of EOR and the relaxed LP solution, we obtain an upper bound of the duality gap.
Since the upper bound on this duality gap is w.r.t. the relaxed LP, it will also be an upper bound for the optimal ILP.
We define the primal of the LP for finding a solution ùëã as follows
ùëÉùëá ùëã
ùëõùëÖùëíùëô (ùê¥) + ùëõùëÖùëíùëô (ùêµ)
ùëã ‚â•0
s.t. ùëã ‚â§ 1

max

ùëì (ùëã ) =

(Primal)
(10)

ùëá

ùëã 1‚â§ùëò

(select up to k elements)

ùëÑùëáùê¥,ùêµ ùëã ‚â§ ùõø (ùúéùëòùê∏ùëÇùëÖ )
ùëÑùëáùêµ,ùê¥ ùëã ‚â§ ùõø (ùúéùëòùê∏ùëÇùëÖ )

(11)
(12)
ùëù

We define ùëÑ ùê¥,ùêµ ‚àà Rùëõ where each element of ùëÑ ùê¥,ùêµ is ùëûùëñ (Iùê¥ ‚àí Iùêµ )ùëñ , ùëûùëñ ‚ààùëî = ùëõùëÖùëíùëôùëñ (ùëî) and ùëÑ ùê¥,ùêµ = ‚àíùëÑ ùêµ,ùê¥ . Note that the Primal objective is
ùëá

ùëÉ ùëã
equivalent to minimizing the total cost = 1 ‚àí ùëõùëÖùëíùëô (ùê¥)+ùëõùëÖùëíùëô
(ùêµ) .
The first constraint (10) ensures valid values for ùëã (with corresponding dual variables ùúÜùëñ‚Ä≤ ). The second constraint is for selecting ùëò
candidates (dual variable ùúÜùëò ) and the last two constraints (11) and (12) ensure that the ranking solution is EOR-fair optimal (dual variables
ùúÜùê¥,ùêµ , ùúÜùêµ,ùê¥ ). The Dual LP is formed as follows

min ùëî(ùúÜ) = ùõø (ùúéùëòùê∏ùëÇùëÖ )(ùúÜùê¥,ùêµ + ùúÜùêµ,ùê¥ ) + ùëòùúÜùëò +

ùëõ
‚àëÔ∏Å

ùúÜùëñ‚Ä≤

(Dual)

ùúÜ‚â•0

ùëñ=1

s.t. ùëÑ ùê¥,ùêµ (ùúÜùê¥,ùêµ ‚àí ùúÜùêµ,ùê¥ ) + ùúÜùëò + ùúÜ ‚Ä≤ ‚â•

ùëÉ
ùëõùëÖùëíùëô (ùê¥) + ùëõùëÖùëíùëô (ùêµ)

(13)

We construct a feasible point of the dual from the EOR solution as follows. The key insight here is to reason w.r.t the last elements selected
(or the first elements available if no element from the group has been selected) by the EOR Algorithm at prefix ùëò from each of the groups A
and B, namely ùëòùê¥ , ùëòùêµ respectively.

ùúÜùê¥,ùêµ

=

ùúÜùêµ,ùê¥

=



ùëùùê¥ ‚àí ùëù ùêµ
1
ùëõùëÖùëíùëô (ùê¥) + ùëõùëÖùëíùëô (ùêµ) ùëûùê¥ + ùëûùêµ +
 

ùëùùê¥ ‚àí ùëù ùêµ
1
‚àí
ùëõùëÖùëíùëô (ùê¥) + ùëõùëÖùëíùëô (ùêµ)
ùëûùê¥ + ùëû ùêµ +

(14)
(15)

Using (14) and (15) we know that only ever one of ùúÜùê¥,ùêµ or ùúÜùêµ,ùê¥ is non zero. If ùëùùê¥ ‚â• ùëù ùêµ , then ùúÜùê¥,ùêµ ‚â• 0 and ùúÜùêµ,ùê¥ = 0. Similarly, if ùëù ùêµ ‚â• ùëùùê¥ ,
then ùúÜùêµ,ùê¥ ‚â• 0 and ùúÜùê¥,ùêµ = 0.

EAAMO ‚Äô24, October 29‚Äì31, 2024, San Luis Potosi, Mexico

Rastogi and Joachims.

We construct ùúÜùëò and ùúÜùëñ‚Ä≤ as follows

 

ùëùùê¥
ùëùùêµ
ùúÜùëò =
‚àí ùëûùê¥ (ùúÜùê¥,ùêµ ‚àí ùúÜùêµ,ùê¥ ) =
‚àí ùëûùêµ (ùúÜùêµ,ùê¥ ‚àí ùúÜùê¥,ùêµ )
ùëõùëÖùëíùëô (ùê¥) + ùëõùëÖùëíùëô (ùêµ)
ùëõùëÖùëíùëô (ùê¥) + ùëõùëÖùëíùëô (ùêµ)


ùëù
ùëñ
ùúÜùëñ‚Ä≤‚ààùê¥ =
‚àí ùúÜùëò ‚àí ùëûùëñ (ùúÜùê¥,ùêµ ‚àí ùúÜùêµ,ùê¥ )
ùëõùëÖùëíùëô (ùê¥) + ùëõùëÖùëíùëô (ùêµ)
+

ùëùùëñ
‚Ä≤
‚àí ùúÜùëò ‚àí ùëûùëñ (ùúÜùêµ,ùê¥ ‚àí ùúÜùê¥,ùêµ )
ùúÜùëñ ‚ààùêµ =
ùëõùëÖùëíùëô (ùê¥) + ùëõùëÖùëíùëô (ùêµ)
+

(16)
(17)
(18)

We prove that the constructed dual variables ùúÜ are non-negative in Lemma 5.2 and that ùúÜ ‚Ä≤ = 0 for any element not selected in the EOR
ranking. In Lemma 5.3, we prove that the constructed dual variables ùúÜ are feasible. Given the feasibility of dual variables, we analyze the
duality gap given by
ùëî(ùúÜ ‚àó ) ‚àí ùëì (ùëã ) = ùõø (ùúéùëòùê∏ùëÇùëÖ )(ùúÜùê¥,ùêµ + ùúÜùêµ,ùê¥ ) + ùëòùúÜùëò +

ùëõ
‚àëÔ∏Å

ùúÜùëñ‚Ä≤ ‚àí

ùëñ=1

ùëÉùëá ùëã
ùëõùëÖùëíùëô (ùê¥) + ùëõùëÖùëíùëô (ùêµ)

From Lemma 5.2, ùúÜùëñ‚Ä≤ = 0 for ùëñ > ùëòùê¥ , ùúÜ ‚Ä≤ùëó = 0 for ùëó > ùëòùêµ , where ùëòùê¥ elements are selected from group A, ùëòùêµ from group B by the EOR
Algorithm and ùëò = ùëòùê¥ + ùëòùêµ . Substituting the values for ùúÜ ‚Ä≤ from (17), (18), the duality gap is

=

+

ùëòùê¥ 
‚àëÔ∏Å

ùëùùëñ
‚àí ùúÜùëò ‚àí ùëûùëñ (ùúÜùê¥,ùêµ ‚àí ùúÜùêµ,ùê¥ )
ùëõùëÖùëíùëô
(ùê¥)
+ ùëõùëÖùëíùëô (ùêµ)
ùëñ=1

ùëòùêµ 
‚àëÔ∏Å
ùëùùëó
ùëÉùëá ùëã
‚àí ùúÜùëò ‚àí ùëû ùëó (ùúÜùêµ,ùê¥ ‚àí ùúÜùê¥,ùêµ ) ‚àí
ùëõùëÖùëíùëô (ùê¥) + ùëõùëÖùëíùëô (ùêµ)
ùëõùëÖùëíùëô (ùê¥) + ùëõùëÖùëíùëô (ùêµ)
ùëó=1

ùõø (ùúéùëòùê∏ùëÇùëÖ )(ùúÜùê¥,ùêµ + ùúÜùêµ,ùê¥ ) + ùëòùúÜùëò +



√çùê¥
√ç ùêµ
√çùê¥
√ç ùêµ
We know that ùëòùëñ=1
ùúÜùëò + ùëòùëó=1
ùúÜùëò = ùëòùúÜùëò and ùëÉùëá ùëã = ùëòùëñ=1
ùëùùëñ + ùëòùëó=1
ùëù ùëó . Further, only one of ùúÜùê¥,ùêµ or ùúÜùêµ,ùê¥ is non-negative according to (14),
(15).
If ùúÜùê¥,ùêµ ‚â• 0, then the duality gap can be written as
= ùõø (ùúéùëòùê∏ùëÇùëÖ )ùúÜùê¥,ùêµ ‚àí

ùëòùê¥
‚àëÔ∏Å

ùëûùëñ ùúÜùê¥,ùêµ +

ùëñ=1

ùëòùêµ
‚àëÔ∏Å

ùëòùê¥
ùëòùêµ
‚àëÔ∏Å
¬©
¬©‚àëÔ∏Å
¬™¬™
ùëû ùëó ¬Æ¬Æ
ùëû ùëó ùúÜùê¥,ùêµ = ùúÜùê¥,ùêµ ¬≠ùõø (ùúéùëòùê∏ùëÇùëÖ ) ‚àí ¬≠ ùëûùëñ ‚àí
ùëó=1
ùëó=1 ¬¨¬¨
¬´
¬´ ùëñ=1

√çùê¥
√ç ùêµ
Since we have ‚àíùõø (ùúéùëòùê∏ùëÇùëÖ ) ‚â§ ùëòùëñ=1
ùëûùëñ ‚àí ùëòùëó=1
ùëû ùëó ‚â§ ùõø (ùúéùëòùê∏ùëÇùëÖ ) from Lemma 5.1,
ùëòùê¥
ùëòùêµ
‚àëÔ∏Å
¬©
¬©‚àëÔ∏Å
¬™¬™
Duality Gap = ùúÜùê¥,ùêµ ¬≠ùõø (ùúéùëòùê∏ùëÇùëÖ ) ‚àí ¬≠ ùëûùëñ ‚àí
ùëû ùëó ¬Æ¬Æ ‚â§ 2ùúÜùê¥,ùêµ ùõø (ùúéùëòùê∏ùëÇùëÖ )
ùëó=1 ¬¨¬¨
¬´
¬´ ùëñ=1
If ùúÜùêµ,ùê¥ ‚â• 0, then the duality gap can be written as

= ùõø (ùúéùëòùê∏ùëÇùëÖ )ùúÜùêµ,ùê¥ +

ùëòùê¥
‚àëÔ∏Å
ùëñ=1

and again, since ‚àíùõø (ùúéùëòùê∏ùëÇùëÖ ) ‚â§

√çùëòùê¥

ùëñ=1 ùëûùëñ ‚àí

ùëûùëñ ùúÜùêµ,ùê¥ ‚àí

(19)

ùëòùêµ
‚àëÔ∏Å

ùëòùê¥
ùëòùêµ
‚àëÔ∏Å
‚àëÔ∏Å
¬©
¬™
ùëû ùëó ùúÜùêµ,ùê¥ = ùúÜùêµ,ùê¥ ¬≠ùõø (ùúéùëòùê∏ùëÇùëÖ ) + ( ùëûùëñ ‚àí
ùëû ùëó )¬Æ
ùëó=1
ùëñ=1
ùëó=1
¬´
¬¨

√çùëòùêµ

ùê∏ùëÇùëÖ ) from Lemma 5.1,
ùëó=1 ùëû ùëó ‚â§ ùõø (ùúéùëò

ùëòùê¥
ùëòùêµ
‚àëÔ∏Å
‚àëÔ∏Å
¬©
¬™
Duality Gap = ùúÜùêµ,ùê¥ ¬≠ùõø (ùúéùëòùê∏ùëÇùëÖ ) + ( ùëûùëñ ‚àí
ùëû ùëó ) ¬Æ ‚â§ 2ùúÜùêµ,ùê¥ ùõø (ùúéùëòùê∏ùëÇùëÖ )
ùëñ=1
ùëó=1
¬´
¬¨
From Eqs. (14), (15), (19), (20) , the duality gap between EOR solution and the optimal solution is bounded by

(20)

2ùõø (ùúéùëòùê∏ùëÇùëÖ )

ùëùùê¥ ‚àí ùëù ùêµ
ùëõùëÖùëíùëô (ùê¥) + ùëõùëÖùëíùëô (ùêµ) ùëûùê¥ + ùëûùêµ
This proves that the EOR solution can only be ever as worse as ùúôùõø (ùúéùëòùê∏ùëÇùëÖ ) when compared with the optimal solution, where ùúô =
ùëùùê¥ ‚àíùëù ùêµ
2
ùëõùëÖùëíùëô (ùê¥)+ùëõùëÖùëíùëô (ùêµ) ùëûùê¥ +ùëûùêµ

‚ñ°

√çùê¥
√ç ùêµ
Lemma 5.1. EOR ranking is ùõø (ùúéùëòùê∏ùëÇùëÖ ) fairness optimal, implying that ‚àíùõø (ùúéùëòùê∏ùëÇùëÖ ) ‚â§ ùëòùëñ=1
ùëûùëñ ‚àí ùëòùëó=1
ùëû ùëó ‚â§ ùõø (ùúéùëòùê∏ùëÇùëÖ ).
√çùëòùê¥
√çùëòùêµ
ùëõùëÖùëíùëô (ùê¥|ùúéùëò )
ùëõùëÖùëíùëô (ùêµ |ùúéùëò )
Since ùëñ=1 ùëûùëñ ‚àí ùëó=1 ùëû ùëó = ùëõùëÖùëíùëô (ùê¥) ‚àí ùëõùëÖùëíùëô (ùêµ) , the lemma follows directly from the definition of ùõø (ùúéùëò ) in Eq. (7) and the EOR ranking
principle of choosing the candidate that minimizes ùõø (ùúéùëò ).

Fairness in Ranking under Disparate Uncertainty

EAAMO ‚Äô24, October 29‚Äì31, 2024, San Luis Potosi, Mexico

‚ñ°
Lemma 5.2. The constructed dual variables ùúÜ ‚â• 0. In particular, for any ùëñ > ùëòùê¥ in group A and ùëó > ùëòùêµ in group B, it holds that ùúÜùëñ‚Ä≤ = 0 and
‚Ä≤
ùúÜ ùëó = 0 and for any ùëñ ‚â§ ùëòùê¥ and ùëó ‚â§ ùëòùêµ , it holds that ùúÜùëñ‚Ä≤ ‚â• 0 and ùúÜ ‚Ä≤ùëó ‚â• 0.
Proof. In this Lemma, we show that ùúÜ ‚Ä≤ = 0 for the elements not selected by the EOR Algorithm and ùúÜ ‚Ä≤ ‚â• 0 for the elements that were
selected. Without loss of generality, we consider the element at index ùëñ that belongs to group ùê¥.


ùëùùëñ
ùúÜùëñ‚Ä≤‚ààùê¥ =
‚àí ùúÜùëò ‚àí ùëûùëñ (ùúÜùê¥,ùêµ ‚àí ùúÜùêµ,ùê¥ )
ùëõùëÖùëíùëô (ùê¥) + ùëõùëÖùëíùëô (ùêµ)
+


ùëùùëñ
ùëùùê¥
=
‚àí
+ ùëûùê¥ (ùúÜùê¥,ùêµ ‚àí ùúÜùêµ,ùê¥ ) ‚àí ùëûùëñ (ùúÜùê¥,ùêµ ‚àí ùúÜùêµ,ùê¥ )
ùëõùëÖùëíùëô (ùê¥) + ùëõùëÖùëíùëô (ùêµ) ùëõùëÖùëíùëô (ùê¥) + ùëõùëÖùëíùëô (ùêµ)
+


ùëùùëñ ‚àí ùëù ùê¥
=
+ (ùëûùëñ ‚àí ùëûùê¥ )(ùúÜùêµ,ùê¥ ‚àí ùúÜùê¥,ùêµ )
(21)
ùëõùëÖùëíùëô (ùê¥) + ùëõùëÖùëíùëô (ùêµ)
+
The second equality above is obtained by substituting ùúÜùëò from Eq. (16) and the last equality by rearranging. We now consider two cases ‚Äì
for elements not selected and selected by the EOR Algorithm respectively.
Case I: Elements not selected by the EOR Algorithm.
We have i) ùëùùëñ ‚â§ ùëùùê¥ and ùëûùëñ ‚â§ ùëûùê¥ as EOR selects in decreasing order of probabilities, and ii) either ùúÜùê¥,ùêµ ‚â• 0 or ùúÜùêµ,ùê¥ ‚â• 0 as only one of them
can be nonzero from (14), (15).
In Eq. (21), if ùúÜùêµ,ùê¥ ‚â• 0, then ùúÜùê¥,ùêµ = 0 and with ùëùùëñ ‚â§ ùëùùê¥ , ùëûùëñ ‚â§ ùëûùê¥ the resultant quantity would be negative, which would result in ùúÜùëñ‚Ä≤
clipped to 0.


ùëùùëñ ‚àí ùëù ùê¥
+ (ùëûùëñ ‚àí ùëûùê¥ )ùúÜùêµ,ùê¥
ùúÜùëñ‚Ä≤ =
ùëõùëÖùëíùëô (ùê¥) + ùëõùëÖùëíùëô (ùêµ)
+
‚â§ 0


ùëùùê¥ ‚àíùëù ùêµ
1
In Eq. (21), if ùúÜùê¥,ùêµ ‚â• 0, then ùúÜùêµ,ùê¥ = 0. We can then substitute ùúÜùê¥,ùêµ = ùëõùëÖùëíùëô (ùê¥)+ùëõùëÖùëíùëô
(ùêµ) ùëûùê¥ +ùëûùêµ in Eq. (21),


ùëùùëñ ‚àí ùëù ùê¥
‚Ä≤
‚àí (ùëûùëñ ‚àí ùëûùê¥ )ùúÜùê¥,ùêµ
ùúÜùëñ =
ùëõùëÖùëíùëô (ùê¥) + ùëõùëÖùëíùëô (ùêµ)
+



ùëùùëñ ‚àí ùëù ùê¥
(ùëûùëñ ‚àí ùëûùê¥ )
ùëùùê¥ ‚àí ùëù ùêµ
=
‚àí
ùëõùëÖùëíùëô (ùê¥) + ùëõùëÖùëíùëô (ùêµ) ùëõùëÖùëíùëô (ùê¥) + ùëõùëÖùëíùëô (ùêµ) ùëûùê¥ + ùëûùêµ +


ùëù ùêµ (ùëûùëñ ‚àí ùëûùê¥ ) + ùëûùêµ (ùëùùëñ ‚àí ùëùùê¥ )
1
=
ùëõùëÖùëíùëô (ùê¥) + ùëõùëÖùëíùëô (ùêµ)
ùëûùê¥ + ùëû ùêµ
+
= 0
The second last term evaluates to ‚â§ 0 and so the last equality holds because ùúÜùëñ‚Ä≤ is clipped to 0.
Thus, for any element not been selected by the EOR Algorithm i.e. ùëñ > ùëòùê¥ , the corresponding dual variable ùúÜùëñ‚Ä≤ = 0. Analogously, for
any element ùëó > ùëòùêµ in group B it can be shown that ùúÜ ‚Ä≤ùëó = 0. We have shown that for any element not selected by the EOR Algorithm the
corresponding dual variable ùúÜ ‚Ä≤ = 0.
Case II: Elements selected by the EOR Algorithm.
We have i) ùëùùëñ ‚â• ùëùùê¥ and ùëûùëñ ‚â• ùëûùê¥ as EOR selects in decreasing order of probabilities, and ii) ùúÜùê¥,ùêµ ‚â• 0 or ùúÜùêµ,ùê¥ ‚â• 0 as only one of them can
be non zero.
In Eq. (21), if ùúÜùêµ,ùê¥ ‚â• 0, then ùúÜùê¥,ùêµ = 0 and with ùëùùëñ ‚â• ùëùùê¥ , ùëûùëñ ‚â• ùëûùê¥ the resultant quantity in (21) would be ‚â• 0, so that ùúÜùëñ‚Ä≤ ‚â• 0.


ùëùùëñ ‚àí ùëù ùê¥
+ (ùëûùëñ ‚àí ùëûùê¥ )ùúÜùêµ,ùê¥
ùúÜùëñ‚Ä≤ =
ùëõùëÖùëíùëô (ùê¥) + ùëõùëÖùëíùëô (ùêµ)
+
‚â• 0


ùëùùê¥ ‚àíùëù ùêµ
1
In Eq. (21), if ùúÜùê¥,ùêµ ‚â• 0, then ùúÜùêµ,ùê¥ = 0. We can then substitute ùúÜùê¥,ùêµ = ùëõùëÖùëíùëô (ùê¥)+ùëõùëÖùëíùëô
in (21),
ùëû
+ùëû
(ùêµ)
ùê¥
ùêµ


ùëùùëñ ‚àí ùëù ùê¥
ùúÜùëñ‚Ä≤ =
‚àí (ùëûùëñ ‚àí ùëûùê¥ )ùúÜùê¥,ùêµ
ùëõùëÖùëíùëô (ùê¥) + ùëõùëÖùëíùëô (ùêµ)
+



ùëùùëñ ‚àí ùëù ùê¥
(ùëûùëñ ‚àí ùëûùê¥ )
ùëùùê¥ ‚àí ùëù ùêµ
=
‚àí
ùëõùëÖùëíùëô (ùê¥) + ùëõùëÖùëíùëô (ùêµ) ùëõùëÖùëíùëô (ùê¥) + ùëõùëÖùëíùëô (ùêµ) ùëûùê¥ + ùëûùêµ +


ùëù ùêµ (ùëûùëñ ‚àí ùëûùê¥ ) + ùëûùêµ (ùëùùëñ ‚àí ùëùùê¥ )
1
=
ùëõùëÖùëíùëô (ùê¥) + ùëõùëÖùëíùëô (ùêµ)
ùëûùê¥ + ùëû ùêµ
+
‚â• 0

EAAMO ‚Äô24, October 29‚Äì31, 2024, San Luis Potosi, Mexico

Rastogi and Joachims.

The second last term evaluates to ‚â• 0, so the last equality holds. Thus, for any element selected by the EOR Algorithm in group ùê¥ i.e. ùëñ ‚â§ ùëòùê¥ ,
the corresponding dual variable ùúÜ ‚Ä≤ ‚â• 0. Analogously, for any element ùëó ‚â§ ùëòùêµ in group B, ùúÜùëñ‚Ä≤ ‚â• 0. We have shown that for any element
selected by the EOR Algorithm the corresponding dual variable ùúÜ ‚Ä≤ ‚â• 0.
We now show that ùúÜùëò ‚â• 0. From Eq. (16),


ùëùùê¥
ùúÜùëò =
‚àí ùëûùê¥ (ùúÜùê¥,ùêµ ‚àí ùúÜùêµ,ùê¥ )
(22)
ùëõùëÖùëíùëô (ùê¥) + ùëõùëÖùëíùëô (ùêµ)


ùëùùê¥ ‚àíùëù ùêµ
1
If ùúÜùê¥,ùêµ ‚â• 0 , then ùúÜùêµ,ùê¥ = 0. Substituting ùúÜùê¥,ùêµ = ùëõùëÖùëíùëô (ùê¥)+ùëõùëÖùëíùëô
(ùêµ) ùëûùê¥ +ùëûùêµ in Eq. (22),


ùëùùê¥
ùúÜùëò =
‚àí ùëûùê¥ ùúÜùê¥,ùêµ
ùëõùëÖùëíùëô (ùê¥) + ùëõùëÖùëíùëô (ùêµ)



ùëûùê¥
ùëùùê¥ ‚àí ùëù ùêµ
ùëùùê¥
‚àí
=
ùëõùëÖùëíùëô (ùê¥) + ùëõùëÖùëíùëô (ùêµ) ùëõùëÖùëíùëô (ùê¥) + ùëõùëÖùëíùëô (ùêµ) ùëûùê¥ + ùëûùêµ


ùëù ùê¥ ùëû ùêµ + ùëûùê¥ ùëù ùêµ
1
=
ùëõùëÖùëíùëô (ùê¥) + ùëõùëÖùëíùëô (ùêµ)
ùëûùê¥ + ùëû ùêµ
‚â• 0
The last inequality
 follows
 since each of the terms ùëùùê¥ , ùëûùê¥ , ùëù ùêµ , ùëûùêµ are ‚â• 0. If ùúÜùêµ,ùê¥ ‚â• 0, then ùúÜùê¥,ùêµ = 0. By substituting ùúÜùêµ,ùê¥ =
1
ùëõùëÖùëíùëô (ùê¥)+ùëõùëÖùëíùëô (ùêµ)

ùëù ‚àíùëù

‚àí ùëûùê¥ùê¥ +ùëûùêµùêµ in Eq. (22), we similarly get ùúÜùëò ‚â• 0.
The two duals ùúÜùê¥,ùêµ , ùúÜùêµ,ùê¥ are ‚â• 0 by their construction in Eqs. (14), (15). Thus, we have shown that all the constructed dual variables
ùúÜ ‚â• 0.
‚ñ°
Lemma 5.3. The dual variables ùúÜ = [ùúÜ1‚Ä≤ ¬∑ ¬∑ ¬∑ ùúÜùëõ‚Ä≤ , ùúÜùëò , ùúÜùê¥,ùêµ , ùúÜùêµ,ùê¥ ] are always feasible.
Proof. In Lemma 5.2, we proved that the constructed ùúÜ ‚â• 0. We now show that they satisfy the duality constraint.
For some element ùëñ, the duality constraint implies that
ùëùùëñ
ùëûùëñ (ùúÜùê¥,ùêµ ‚àí ùúÜùêµ,ùê¥ ) + ùúÜùëò + ùúÜùëñ‚Ä≤ ‚â•
ùëõùëÖùëíùëô (ùê¥) + ùëõùëÖùëíùëô (ùêµ)

(23)

Without loss of generality, we consider element at index ùëñ that belongs to group ùê¥. Similar to Lemma 5.2, we consider two cases.
Case I: Elements not selected by the EOR Algorithm.
Using the fact that ùúÜùëñ‚Ä≤ = 0 for ùëñ > ùëòùê¥ from Lemma 5.2, and substituting ùúÜùëò from Eq. (16), we get
ùëûùëñ (ùúÜùê¥,ùêµ ‚àí ùúÜùêµ,ùê¥ ) + ùúÜùëò + ùúÜùëñ‚Ä≤

=

ùëûùëñ (ùúÜùê¥,ùêµ ‚àí ùúÜùêµ,ùê¥ ) + ùúÜùëò

=

ùëûùëñ (ùúÜùê¥,ùêµ ‚àí ùúÜùêµ,ùê¥ ) +

=

ùëùùê¥
+ (ùëûùëñ ‚àí ùëûùê¥ )(ùúÜùê¥,ùêµ ‚àí ùúÜùêµ,ùê¥ )
ùëõùëÖùëíùëô (ùê¥) + ùëõùëÖùëíùëô (ùêµ)

ùëùùê¥
‚àí ùëûùê¥ (ùúÜùê¥,ùêµ ‚àí ùúÜùêµ,ùê¥ )
ùëõùëÖùëíùëô (ùê¥) + ùëõùëÖùëíùëô (ùêµ)

We have i) ùëùùëñ ‚â§ ùëùùê¥ and ùëûùëñ ‚â§ ùëûùê¥ as EOR selects in decreasing order of probabilities, and ii) either ùúÜùê¥,ùêµ ‚â• 0 or ùúÜùêµ,ùê¥ ‚â• 0 as only one of them
can be nonzero. If ùúÜùê¥,ùêµ ‚â• 0, then substituting ùúÜùê¥,ùêµ ,
ùëùùê¥
+ (ùëûùëñ ‚àí ùëûùê¥ )ùúÜùê¥,ùêµ
ùëûùëñ (ùúÜùê¥,ùêµ ‚àí ùúÜùêµ,ùê¥ ) + ùúÜùëò + ùúÜùëñ‚Ä≤ =
ùëõùëÖùëíùëô (ùê¥) + ùëõùëÖùëíùëô (ùêµ)
ùëùùê¥
(ùëûùëñ ‚àí ùëûùê¥ )
ùëùùê¥ ‚àí ùëù ùêµ
=
+
(
)
ùëõùëÖùëíùëô (ùê¥) + ùëõùëÖùëíùëô (ùêµ) ùëõùëÖùëíùëô (ùê¥) + ùëõùëÖùëíùëô (ùêµ) ùëûùê¥ + ùëûùêµ


ùëù ùêµ (ùëûùê¥ ‚àí ùëûùëñ ) + ùëûùêµ (ùëùùê¥ ‚àí ùëùùëñ )
1
=
ùëùùëñ +
ùëõùëÖùëíùëô (ùê¥) + ùëõùëÖùëíùëô (ùêµ)
ùëûùê¥ + ùëû ùêµ
ùëùùëñ
‚â•
ùëõùëÖùëíùëô (ùê¥) + ùëõùëÖùëíùëô (ùêµ)
Similarly, we can show that the dual constraint is satisfied if ùúÜùêµ,ùê¥ ‚â• 0. Thus, for any element not selected by the EOR Algorithm i.e. ùëñ > ùëòùê¥ ,
the corresponding dual constraint is satisfied. Analogously, for any element ùëó > ùëòùêµ in group B it can be shown that the corresponding dual
constraint is satisfied. We have shown that for any element not selected by EOR Algorithm the corresponding dual constraint is satisfied.
Case II: Elements selected by the EOR Algorithm.
Using the fact that ùúÜùëñ‚Ä≤ ‚â• 0 for ùëñ ‚â§ ùëòùê¥ from Lemma 5.2, and substituting ùúÜùëò from (16), ùúÜùëñ‚Ä≤ for ùëñ ‚â§ ùëòùê¥ in (23), we get
ùëùùëñ
ùëùùëñ
ùëûùëñ (ùúÜùê¥,ùêµ ‚àí ùúÜùêµ,ùê¥ ) + ùúÜùëò + ùúÜùëñ‚Ä≤ = ùëûùëñ (ùúÜùê¥,ùêµ ‚àí ùúÜùêµ,ùê¥ ) + ùúÜùëò +
‚àí ùúÜùëò ‚àí ùëûùëñ (ùúÜùê¥,ùêµ ‚àí ùúÜùêµ,ùê¥ ) =
ùëõùëÖùëíùëô (ùê¥) + ùëõùëÖùëíùëô (ùêµ)
ùëõùëÖùëíùëô (ùê¥) + ùëõùëÖùëíùëô (ùêµ)
Thus, for any element selected by the EOR Algorithm i.e. ùëñ ‚â§ ùëòùê¥ , ùëó ‚â§ ùëòùêµ , the corresponding dual constraint is satisfied.

‚ñ°

Fairness in Ranking under Disparate Uncertainty

EAAMO ‚Äô24, October 29‚Äì31, 2024, San Luis Potosi, Mexico

1.0

LP
ILP
EOR
¬° pA ‚àí pB ¬¢
2Œ¥(œÉkEOR )
LP + nRel(A)
+ nRel(B) | q A + q B |

|œÉk ) + nRel(B|œÉk )
Total Cost =1 ‚àí nRel(A
nRel(A) + nRel(B)

¬¥

0.8

¬≥

0.6

0.4

0.2

0.0

0

10

20

30

Length of Ranking (k)

40

50

Figure 7: Cost Optimality Gap of a synthetic example with ùëùùëñ ‚ààùê¥ = [1, 0.6, 0.5, 0.5, 0.4, 0.1, ¬∑ ¬∑ ¬∑ 0.1], ùëõùëÖùëíùëô (ùê¥) = 4, ùëÜ (ùê¥) = 15, and ùëùùëñ ‚ààùêµ =
[1, 0.1 ¬∑ ¬∑ ¬∑ 0.1], ùëõùëÖùëíùëô (ùêµ) = 4, ùëÜ (ùêµ) = 31. The cost from EOR ranking is nearly optimal to the ILP or even the relaxed LP solution. Further the
bound obtain in Theorem 5.1 (in grey) is tight for many ùëò prefixes.
We demonstrate the cost optimality bound proved in Theorem 5.1 in Figure 7 that shows an example with a ranking produced by
Linear Program (LP), Integer Linear Program (ILP), and the EOR algorithm along with the upper bound on the cost computed from the
duality gap proved in Theorem 5.1. The example is constructed such that P(ùëüùëñ |D)ùëñ ‚ààùê¥ = [1, 0.6, 0.5, 0.5, 0.4, 0.1, ¬∑ ¬∑ ¬∑ 0.1], ùëõùëÖùëíùëô (ùê¥) = 4, and
P(ùëüùëñ |D)ùëñ ‚ààùêµ = [1, 0.1 ¬∑ ¬∑ ¬∑ 0.1], ùëõùëÖùëíùëô (ùêµ) = 4. Figure 7 shows that at most prefixes ùëò, the EOR cost (in red) is optimal coinciding with the cost
from ILP solution (in green) as well as with the LP solution (in blue). Further, when the EOR ranking does not coincide with the LP solution,
2ùõø (ùúé ùê∏ùëÇùëÖ )

ùëù ‚àíùëù

ùê¥
ùêµ
ùëò
the upper bound ùëõùëÖùëíùëô (ùê¥)+ùëõùëÖùëíùëô
(ùêµ) ùëûùê¥ +ùëûùêµ is relatively small as is shown by the LP + duality gap (in grey).
We now present the proof for the global a priori bound on ùõø (ùúéùëòùê∏ùëÇùëÖ ) for two groups A,B.

C.2

Proof for Theorem 5.2

Proof. Let ùúé ùëÉùëÖùëÉ,ùê¥ , ùúé ùëÉùëÖùëÉ,ùêµ be the PRP rankings for elements in group A and B respectively. We show by induction that for any given
prefix ùëò, EOR algorithm selects the element such that ùõø (ùúéùëòùê∏ùëÇùëÖ ) ‚â§ ùõøùëöùëéùë• and as a consequence of Theorem 5.1, we get a global cost guarantee
of ùúôùõøùëöùëéùë• .
In the remaining proof, we drop the superscript of EOR for simplicity and ùúé ùëó refers to ùúé ùê∏ùëÇùëÖ
.
n ùëÉùëÖùëÉ,ùê¥
oùëó
ùúé
[1] ùúé ùëÉùëÖùëÉ,ùêµ [1]
ùúé ùëÉùëÖùëÉ,ùê¥ [1]
Consider the base case of ùëò = 1. Algorithm 1 will select arg min ùëõùëÖùëíùëô (ùê¥) , ùëõùëÖùëíùëô (ùêµ) resulting in the lower ùõø (ùúéùëò=1 ). If ùëõùëÖùëíùëô (ùê¥) ‚â§


ùúé ùëÉùëÖùëÉ,ùê¥ [1]
ùúé ùëÉùëÖùëÉ,ùêµ [1]
ùúé ùëÉùëÖùëÉ,ùê¥ [1]
ùúé ùëÉùëÖùëÉ,ùêµ [1]
ùúé ùëÉùëÖùëÉ,ùêµ [1]
1 ùúé ùëÉùëÖùëÉ,ùê¥ [1]
ùëõùëÖùëíùëô (ùêµ) , then ùõø (ùúé1 ) = ùëõùëÖùëíùëô (ùê¥) ‚â§ 2 ùëõùëÖùëíùëô (ùê¥) + ùëõùëÖùëíùëô (ùêµ) . Similarly, if ùëõùëÖùëíùëô (ùêµ) ‚â§ ùëõùëÖùëíùëô (ùê¥) , then ùõø (ùúéùëò=1 ) denoted in short by
 ùëÉùëÖùëÉ,ùê¥

ùúé
[1]
ùúé ùëÉùëÖùëÉ,ùêµ [1]
ùúé ùëÉùëÖùëÉ,ùêµ [1]
ùõø (ùúé1 ) = ùëõùëÖùëíùëô (ùêµ) ‚â§ 12 ùëõùëÖùëíùëô (ùê¥) + ùëõùëÖùëíùëô (ùêµ) . Thus, at ùëò = 1, by selecting the element with lower ùõø, EOR constraint is satisfied, i.e.
ùõø (ùúé1 ) ‚â§ ùõøùëöùëéùë• .
We assume that for a given ùëò ‚àí 1, |ùõø (ùúéùëò ‚àí1 )| ‚â§ ùõøùëöùëéùë• . Further, without loss of generality, we assume that ùõø (ùúéùëò ‚àí1 ) ‚â• 0. We now show that
at ùëò, |ùõø (ùúéùëò )| ‚â§ ùõøùëöùëéùë• by considering the following cases. First, we show that if adding the element from one of the groups violates the ùõøùëöùëéùë•
constraint, then adding the element from the other group guarantees the satisfaction of ùõøùëöùëéùë• constraint because EOR Algorithm selects
the element that minimizes ùõø. Secondly, in the case where adding an element from either group does not violate the ùõøùëöùëéùë• constraint, EOR
algorithm will select the element that minimizes |ùõø (ùúéùëò )| resulting in |ùõø (ùúéùëò )| ‚â§ ùõøùëöùëéùë• . Finally, we show that when all the elements have run
out from one of the groups at ùëò ‚àí 1, adding remaining elements from the other group will always satisfy the ùõøùëöùëéùë• constraint.
We assume that adding the element from group A with relevance probability ùëùùëñ at ùëò, exceeds the ùõøùëöùëéùë• constraint.
ùëùùëñ
ùõø (ùúéùëò ‚àí1 ) +
> ùõøùëöùëéùë•
(24)
ùëõùëÖùëíùëô (ùê¥)

EAAMO ‚Äô24, October 29‚Äì31, 2024, San Luis Potosi, Mexico

Rastogi and Joachims.

Adding the element ùëù ùëó from B at this prefix,
ùëùùëó
‚â§ ùõø (ùúéùëò ‚àí1 ) ‚â§ ùõøùëöùëéùë•
ùëõùëÖùëíùëô (ùêµ)

ùõø (ùúéùëò ) = ùõø (ùúéùëò ‚àí1 ) ‚àí
The last inequality holds by the induction assumption at ùëò ‚àí 1.
ùúé ùëÉùëÖùëÉ,ùêµ [1]

ùëù

ùúé ùëÉùëÖùëÉ,ùêµ [1]
ùúé ùëÉùëÖùëÉ,ùê¥ [1]
ùëõùëÖùëíùëô (ùê¥) + ùëõùëÖùëíùëô (ùêµ)

Further, since ùëõùëÖùëíùëôùëó(ùêµ) ‚â§ ùëõùëÖùëíùëô (ùêµ) , and ùõøùëöùëéùë• = 12

ùëù

(25)


, the above can be reduced to

ùõø (ùúéùëò )

=

ùõø (ùúéùëò ‚àí1 ) ‚àí

ùëùùëó
ùúé ùëÉùëÖùëÉ,ùêµ [1]
‚â• ùõø (ùúéùëò ‚àí1 ) ‚àí
ùëõùëÖùëíùëô (ùêµ)
ùëõùëÖùëíùëô (ùêµ)

ùõø (ùúéùëò )

‚â•

ùõø (ùúéùëò ‚àí1 ) +

ùúé ùëÉùëÖùëÉ,ùê¥ [1]
‚àí 2ùõøùëöùëéùë•
ùëõùëÖùëíùëô (ùê¥)

(26)

ùúé ùëÉùëÖùëÉ,ùê¥ [1]

Now using ùëõùëÖùëíùëôùëñ(ùê¥) ‚â§ ùëõùëÖùëíùëô (ùê¥) , and Eq. (26) above,
ùõø (ùúéùëò ) ‚â• ùõø (ùúéùëò ‚àí1 ) +

ùëùùëñ
ùúé ùëÉùëÖùëÉ,ùê¥ [1]
‚àí 2ùõøùëöùëéùë• ‚â• ùõø (ùúéùëò ‚àí1 ) +
‚àí 2ùõøùëöùëéùë•
ùëõùëÖùëíùëô (ùê¥)
ùëõùëÖùëíùëô (ùê¥)

(27)

Using Eqs. (27) and (24),
ùëùùëñ
‚àí 2ùõøùëöùëéùë• > ‚àíùõøùëöùëéùë•
(28)
ùëõùëÖùëíùëô (ùê¥)
We have shown that, if |ùõø (ùúéùëò )| exceeds ùõøùëöùëéùë• by adding the element from group A (from (24)), then the element in group B will satisfy
|ùõø (ùúéùëò )| ‚â§ ùõøùëöùëéùë• (from (25) and (28)). Since the EOR algorithm minimizes |ùõø (ùúéùëò )|, it will select the element from group B at prefix ùëò rather
than the element from group A. Thus, |ùõø (ùúéùëò )| ‚â§ ùõøùëöùëéùë• in this case.
Similarly, we can show that if |ùõø (ùúéùëò )| exceeds ùõøùëöùëéùë• by adding the element from group B, then adding the element from group A would
result in |ùõø (ùúéùëò )| ‚â§ ùõøùëöùëéùë• and would be selected by the EOR algorithm at prefix ùëò.
Finally, we consider the case where all the elements in a particular group have already been selected. Without loss of generality, let‚Äôs
assume that this is true with all the elements in group B added by prefix ùëò ‚àí 1. We need to show that adding from the remaining elements in
group A would still satisfy |ùõø | ‚â§ ùõøùëöùëéùë• for the remaining prefixes.
ùëõùëÖùëíùëô (ùêµ |ùúéùëò ‚àí1 )
From our assumption, ùëõùëÖùëíùëô (ùêµ)
= 1 since all elements from group B were selected at prefix ùëò ‚àí 1. From the inductive hypothesis
|ùõø (ùúéùëò ‚àí1 )| ‚â§ ùõøùëöùëéùë• ,
ùõø (ùúéùëò ) ‚â• ùõø (ùúéùëò ‚àí1 ) +

|ùõø (ùúéùëò ‚àí1 )| =
Since

ùëõùëÖùëíùëô (ùê¥|ùúéùëò ‚àí1 ) ùëõùëÖùëíùëô (ùêµ|ùúéùëò ‚àí1 )
‚àí
‚â§ ùõøùëöùëéùë•
ùëõùëÖùëíùëô (ùê¥)
ùëõùëÖùëíùëô (ùêµ)

(29)

ùëõùëÖùëíùëô (ùê¥|ùúéùëò ‚àí1 )
‚â§ 1 as some elements remain in group A,
ùëõùëÖùëíùëô (ùê¥)

ùëõùëÖùëíùëô (ùê¥|ùúéùëò ‚àí1 )
‚àí 1 ‚â• ‚àíùõøùëöùëéùë•
ùëõùëÖùëíùëô (ùê¥)
After adding the element ùëùùëñ from group A at prefix ùëò and from (30),
ùõø (ùúéùëò ‚àí1 ) =

ùõø (ùúéùëò )

=

ùõø (ùúéùëò ‚àí1 ) +

ùõø (ùúéùëò )

‚â•

‚àíùõøùëöùëéùë•

ùëõùëÖùëíùëô (ùê¥|ùúé )

(30)

ùëùùëñ
ùëùùëñ
ùëùùëñ
ùëõùëÖùëíùëô (ùê¥|ùúéùëò ‚àí1 )
=
‚àí1+
‚â• ‚àíùõøùëöùëéùë• +
ùëõùëÖùëíùëô (ùê¥)
ùëõùëÖùëíùëô (ùê¥)
ùëõùëÖùëíùëô (ùê¥)
ùëõùëÖùëíùëô (ùê¥)
(31)

ùëõùëÖùëíùëô (ùê¥|ùúé )

Additionally, since ùëõùëÖùëíùëô (ùê¥)ùëõ = 1 implying ùëõùëÖùëíùëô (ùê¥)ùëò ‚â§ 1,
ùõø (ùúéùëò ) =

ùëõùëÖùëíùëô (ùê¥|ùúéùëò )
‚àí1 ‚â§ 0
ùëõùëÖùëíùëô (ùê¥)

(32)

From Eqs. (31) and (32), ‚àíùõøùëöùëéùë• ‚â§ ùõø (ùúéùëò ) ‚â§ 0 and thus EOR algorithm will add all the remaining elements from group A resulting in
|ùõø (ùúéùëò )| ‚â§ ùõøùëöùëéùë• . Analogously, it can be shown that if all the elements from group A had been added by prefix ùëò, adding the next element
from group B would satisfy |ùõø (ùúéùëò )| ‚â§ ùõøùëöùëéùë• .
Thus, we have shown
 that Algorithm 1 provides rankings such that for any prefix ùëò, |ùõø (ùúéùëò )| ‚â§ ùõøùëöùëéùë• , where ùõøùëöùëéùë• =
1
2

ùúé ùëÉùëÖùëÉ,ùê¥ [1]
ùúé ùëÉùëÖùëÉ,ùêµ [1]
ùëõùëÖùëíùëô (ùê¥) + ùëõùëÖùëíùëô (ùêµ)

. As a consequence of this and Theorem 5.1, EOR rankings have total cost bounded by ùúôùõøùëöùëéùë• for any prefix
ùëù ‚àíùëù

ùê¥
ùêµ
2
ùëò of the ranking, where ùúô = ùëõùëÖùëíùëô (ùê¥)+ùëõùëÖùëíùëô
(ùêµ) ùëûùê¥ +ùëûùêµ .

‚ñ°
Next, we present the proof comparing costs from ùúã ùê∏ùëÇùëÖ , ùúã unif at prefix ùëò, where ùõø (ùúéùëòùê∏ùëÇùëÖ ) = 0.

Fairness in Ranking under Disparate Uncertainty

C.3

EAAMO ‚Äô24, October 29‚Äì31, 2024, San Luis Potosi, Mexico

Proof for Proposition 5.1

Proof. When ùõø (ùúéùëòùê∏ùëÇùëÖ ) = 0, by the definition of EOR fairness, we have that
(1 ‚àí

ùëõùëÖùëíùëô (ùêµ |ùúéùëòùê∏ùëÇùëÖ )
ùëõùëÖùëíùëô (ùê¥|ùúéùëòùê∏ùëÇùëÖ )
=
. As a result, the total cost
ùëõùëÖùëíùëô (ùê¥)
ùëõùëÖùëíùëô (ùêµ)

ùëõùëÖùëíùëô (ùê¥|ùúéùëòùê∏ùëÇùëÖ )+ùëõùëÖùëíùëô (ùêµ |ùúéùëòùê∏ùëÇùëÖ )
) as well as subgroup cost would be equal to
ùëõùëÖùëíùëô (ùê¥)+ùëõùëÖùëíùëô (ùêµ)

1‚àí
ùëõùëÖùëíùëô (ùê¥|ùúé ùê∏ùëÇùëÖ )

ùëõùëÖùëíùëô (ùê¥|ùúéùëòùê∏ùëÇùëÖ )
ùëõùëÖùëíùëô (ùê¥)

ùëõùëÖùëíùëô (ùêµ |ùúé ùê∏ùëÇùëÖ )

ùëõùëÖùëíùëô (ùê¥)

=1‚àí

ùëõùëÖùëíùëô (ùêµ|ùúéùëòùê∏ùëÇùëÖ )

(33)

ùëõùëÖùëíùëô (ùêµ)

ùëõùëÖùëíùëô (ùêµ)

ùëò
ùëò
We also know that
‚â• ùëÜ (ùê¥) and
‚â• ùëÜ (ùêµ) , since the EOR algorithm selects top ùëòùê¥ , ùëòùêµ elements from each
ùëòùê¥
ùëòùêµ
of the groups (with ùëòùê¥ + ùëòùêµ = ùëò, ùëÜ (ùê¥) + ùëÜ (ùêµ) = ùëõ), having a higher mean relevance than that of the group itself.

ùëõùëÖùëíùëô (ùê¥|ùúéùëòùê∏ùëÇùëÖ )ùëÜ (ùê¥)
ùëõùëÖùëíùëô (ùê¥)
ùëõùëÖùëíùëô (ùêµ|ùúéùëòùê∏ùëÇùëÖ )ùëÜ (ùêµ)
ùëõùëÖùëíùëô (ùêµ)

‚â• ùëòùê¥

(34)

‚â• ùëòùêµ

(35)

Adding Eqs. (34), (35) and using (33), we get that
ùëõùëÖùëíùëô (ùê¥|ùúéùëòùê∏ùëÇùëÖ )(ùëÜ (ùê¥) + ùëÜ (ùêµ))
ùëõùëÖùëíùëô (ùê¥)
ùëõùëÖùëíùëô (ùê¥|ùúéùëòùê∏ùëÇùëÖ )
ùëõùëÖùëíùëô (ùê¥)

‚â•

ùëò

‚â•

ùëõùëÖùëíùëô (ùê¥|ùúéùëòùê∏ùëÇùëÖ )
ùëò
ùëò
‚áî1‚àí
‚â§ 1‚àí
ùëõ
ùëõùëÖùëíùëô (ùê¥)
ùëõ

This and Eq. (33) are sufficient to claim that the total cost and subgroup costs of uniform policy given by 1 ‚àí ùëõùëò will always be higher than
the total cost and subgroup costs given by EOR ranking when ùõø (ùúéùëòùê∏ùëÇùëÖ ) = 0.
‚ñ°

D

Extension to Multiple Groups ùê∫

In the following, we prove the global cost and fairness guarantee for multiple groups ùê∫.

D.1

Proof for Theorem 6.1
ùê∫ (ùê∫ ‚àí1)

pairs and reduce each term of the duality
Proof. The overall strategy for this proof is to consider each pair of groups among the
2
gap to the two group case in Theorem 5.1. Fortunately, we can achieve such a reduction by careful construction of the dual variables.
The LP to find a solution ùëã for this problem is formulated as follows

max
ùë• ‚â•0

ùëì (ùë•) = √çùê∫

ùëÉùëá ùëã
(Primal)

ùëî=1 ùëõùëÖùëíùëô (ùëî)

s.t. ùëã ‚â§ 1

(36)

ùëá

ùëã .1 ‚â§ ùëò
Ô£±
Ô£¥
ùëÑùëá ùëã
Ô£¥
Ô£¥
Ô£≤ ùëáùê¥,ùêµ
Ô£¥
ùê∫ (ùê∫ ‚àí 1) constraints ùëÑ ùêµ,ùê¥ ùëã
Ô£¥
..
Ô£¥
Ô£¥
Ô£¥
.
Ô£≥

(select up to k elements)
‚â§
‚â§

ùõø (ùúéùëòùê∏ùëÇùëÖ )
ùõø (ùúéùëòùê∏ùëÇùëÖ )

The above LP is analogous to the two group case in Theorem 5.1, with the addition of ùê∫ (ùê∫ ‚àí 1) pairwise constraints ensuring EOR-fairness
for all pairs of groups.
We can construct the dual problem as follows
ùê∫ (ùê∫ ‚àí1)/2

min
ùúÜ‚â•0

s.t.

ùëî(ùúÜ) = ùõø (ùúéùëòùê∏ùëÇùëÖ )

z
‚àëÔ∏Å

}|

{

(ùúÜùê¥,ùêµ + ùúÜùêµ,ùê¥ ) +ùëòùúÜùëò +

{ùê¥,ùêµ }

‚àëÔ∏Å
{ùê¥,ùêµ }

ùëõ
‚àëÔ∏Å

ùúÜùëñ‚Ä≤

(Dual)

ùëñ=1

ùëÉ
ùëõùëÖùëíùëô
(ùëî)
ùëî

ùëÑ ùê¥,ùêµ (ùúÜùê¥,ùêµ ‚àí ùúÜùêµ,ùê¥ ) + ùúÜùëò + ùúÜ ‚Ä≤ ‚â• √ç

(37)

EAAMO ‚Äô24, October 29‚Äì31, 2024, San Luis Potosi, Mexico

Rastogi and Joachims.

We have pairs of dual variables that are constructed from the EOR solution as following


ùëùùê¥ ‚àí ùëù ùêµ
1
1
√ç
ùúÜùê¥,ùêµ =
(ùê∫ ‚àí 1) ùëî ùëõùëÖùëíùëô (ùëî) ùëûùê¥ + ùëûùêµ +

 
ùëùùê¥ ‚àí ùëù ùêµ
1
1
√ç
ùúÜùêµ,ùê¥ =
‚àí
(ùê∫ ‚àí 1) ùëî ùëõùëÖùëíùëô (ùëî)
ùëûùê¥ + ùëû ùêµ +

(38)

(39)

..
.
ùúÜ ‚Ä≤ùë†

ùê∫ (ùê∫ ‚àí 1)

We construct ùúÜùëñ‚Ä≤ corresponding to constraint (36) and ùúÜùëò corresponding to constraint (select up to k elements) below.

ùúÜùëò

=

ùúÜùëñ‚Ä≤‚ààùëî‚Ä≤

=

(ùê∫ ‚àí1)terms
(ùê∫ ‚àí1)terms Ô£π
Ô£π Ô£Æ
Ô£Æ
Ô£Ø
z
}|
{Ô£∫Ô£∫ Ô£ØÔ£Ø
z
}|
{Ô£∫Ô£∫
Ô£Ø
‚àëÔ∏Å
‚àëÔ∏Å
ùëù
ùëù
Ô£Ø
Ô£∫ Ô£Ø
Ô£∫
ùê¥
ùêµ
‚àí ùëûùê¥
‚àí ùëûùêµ
(ùúÜùê¥,ùëî ‚àí ùúÜùëî,ùê¥ ) Ô£∫ = Ô£Ø √ç
(ùúÜùêµ,ùëî ‚àí ùúÜùëî,ùêµ ) Ô£∫ = ¬∑ ¬∑ ¬∑ for each of ùê∫ groups
Ô£Ø√ç
Ô£Ø ùëî ùëõùëÖùëíùëô (ùëî)
Ô£∫ Ô£Ø ùëî ùëõùëÖùëíùëô (ùëî)
Ô£∫
ùëî‚â†ùê¥
ùëî‚â†ùêµ
Ô£Ø
Ô£∫ Ô£Ø
Ô£∫
Ô£Ø
Ô£∫ Ô£Ø
Ô£∫
Ô£∞
Ô£ª Ô£∞
Ô£ª
(ùê∫ ‚àí1)terms
Ô£π
Ô£Æ
Ô£Ø
z
}|
{Ô£∫Ô£∫
Ô£Ø
‚àëÔ∏Å
ùëùùëñ
Ô£∫
Ô£Ø
‚àí ùúÜùëò ‚àí ùëûùëñ
(ùúÜùëî‚Ä≤ ,ùëî ‚àí ùúÜùëî,ùëî‚Ä≤ ) Ô£∫
Ô£Ø√ç
Ô£∫
Ô£Ø ùëî ùëõùëÖùëíùëô (ùëî)
‚Ä≤
ùëî‚â†ùëî
Ô£∫
Ô£Ø
Ô£∫
Ô£Ø
Ô£ª+
Ô£∞

(40)

(41)

For instance, if ùëñ ‚àà ùê¥ then,
ùúÜùëñ‚Ä≤‚ààùê¥

=

Ô£π
Ô£Æ
‚àëÔ∏Å
Ô£∫
Ô£Ø
Ô£∫
Ô£Ø √ç ùëùùëñ
‚àí
ùúÜ
‚àí
ùëû
(ùúÜ
‚àí
ùúÜ
)
ùëñ
ùê¥,ùëî
ùëî,ùê¥
ùëò
Ô£∫
Ô£Ø
ùëõùëÖùëíùëô
(ùëî)
Ô£∫
Ô£Ø ùëî
ùëî‚â†ùê¥
Ô£ª+
Ô£∞

We show that the constructed dual variables are non-negative in Lemma 6.2 and always feasible in Lemma 6.3. Additionally, we have
ùúÜ ‚Ä≤ = 0 for any element not selected in the EOR ranking from Lemma 6.2.
The duality gap can now be formulated as follows
ùëî(ùúÜ ‚àó ) ‚àí ùëì (ùëã ) = ùõø (ùúéùëòùê∏ùëÇùëÖ )

‚àëÔ∏Å

(ùúÜùê¥,ùêµ + ùúÜùêµ,ùê¥ ) + ùëòùúÜùëò +

{ùê¥,ùêµ }

ùëõ
‚àëÔ∏Å

ùëÉùëá ùëã
ùëî ùëõùëÖùëíùëô (ùëî)

ùúÜùëñ‚Ä≤ ‚àí √ç

ùëñ=1

Substituting the values for ùúÜ ‚Ä≤ from (41) and breaking the ùëò elements selected into ùëòùê¥ from group ùê¥, ùëòùêµ from group ùêµ, and so on from
every group, we have the above duality gap as

ùê∫ terms, one for each group

¬©z
}|
{¬™¬Æ
¬≠
¬≠
¬Æ
ùëò
ùëò
ùê¥
ùêµ
‚àëÔ∏Å
‚àëÔ∏Å
¬≠‚àëÔ∏Å
¬Æ
ùëùùëñ
ùëÉùëá ùëã
¬™ ‚àëÔ∏Å
¬©
(.) + ¬∑ ¬∑ ¬∑¬Æ¬Æ ‚àí √ç
= ùõø (ùúéùëòùê∏ùëÇùëÖ )
(ùúÜùê¥,ùêµ + ùúÜùêµ,ùê¥ ) + ùëòùúÜùëò + ¬≠¬≠ ¬≠ √ç
‚àí ùúÜùëò ‚àí ùëûùëñ
(ùúÜùê¥,ùëî ‚àí ùúÜùëî,ùê¥ ) ¬Æ +
ùëî ùëõùëÖùëíùëô (ùëî)
ùëî ùëõùëÖùëíùëô (ùëî)
¬≠ ùëñ=1
¬Æ
ùëî‚â†ùê¥
{ùê¥,ùêµ }
¬¨
¬≠ ¬´
¬Æ
¬≠
¬Æ
¬´
¬¨


√ç
√ç
√ç
√çùëòùêµ
ùëá
ùëùùëó
ùëùùëñ
√ç
√ç ùëÉ ùëã
In the above ùê∫ terms, we can collect ùëòùê¥ ùúÜùëò + ùëòùêµ ùúÜùëò + ¬∑ ¬∑ ¬∑ = ùëòùúÜùëò and ùëòùê¥ √ç ùëõùëÖùëíùëô
(ùëî) +
ùëõùëÖùëíùëô (ùëî) + ¬∑ ¬∑ ¬∑ =
ùëõùëÖùëíùëô (ùëî) . This reduces
ùëî

ùëî

ùëî

the duality gap to
ùê∫ terms

=

ùõø (ùúéùëòùê∏ùëÇùëÖ )(

‚àëÔ∏Å
{ùê¥,ùêµ }

=

(ùúÜùê¥,ùêµ + ùúÜùêµ,ùê¥ )) ‚àí

z
ùëòùê¥
‚àëÔ∏Å
ùëñ=1

ùëûùëñ

‚àëÔ∏Å
ùëî‚â†ùê¥

(ùúÜùê¥,ùëî ‚àí ùúÜùëî,ùê¥ ) ‚àí

}|
ùëòùêµ
‚àëÔ∏Å

{
ùëûùëó

ùëó=1

ùëòùê¥
ùëòùêµ
‚àëÔ∏Å ¬©
‚àëÔ∏Å
‚àëÔ∏Å
¬™
ùëû ùëó )(ùúÜùê¥,ùêµ ‚àí ùúÜùêµ,ùê¥ ) ¬Æ
¬≠ùõø (ùúéùëòùê∏ùëÇùëÖ )(ùúÜùê¥,ùêµ + ùúÜùêµ,ùê¥ ) ‚àí ( ùëûùëñ ‚àí
ùëñ=1
ùëó=1
{ùê¥,ùêµ } ¬´
¬¨

‚àëÔ∏Å
ùëî‚â†ùêµ

(ùúÜùêµ,ùëî ‚àí ùúÜùëî,ùêµ ) ‚àí ¬∑ ¬∑ ¬∑

Fairness in Ranking under Disparate Uncertainty

EAAMO ‚Äô24, October 29‚Äì31, 2024, San Luis Potosi, Mexico

For each pair of groups ùê¥, ùêµ, the term inside the summation reduces to the two group case in Theorem 5.1. We also have that ‚àíùõø (ùúéùëòùê∏ùëÇùëÖ ) ‚â§
√çùëòùê¥
√ç
ùëûùëñ ‚àí ùëòùêµ ùëû ùëó ‚â§ ùõø (ùúéùëòùê∏ùëÇùëÖ ) from Lemma 6.1.
‚àëÔ∏Å
Duality gap ‚â§
2ùúÜùê¥,ùêµ ùõø (ùúéùëòùê∏ùëÇùëÖ )
{ùê¥,ùêµ }

‚â§

‚àëÔ∏Å ùëù ‚àí ùëù
2ùõø (ùúéùëòùê∏ùëÇùëÖ )
ùê¥
ùêµ
√ç
(ùê∫ ‚àí 1) ùëî ùëõùëÖùëíùëô (ùëî)
ùëûùê¥ + ùëû ùêµ
{ùê¥,ùêµ }

This proves that the EOR solution can
as ùúôùõøùëöùëéùë•
 only be ever as worse
o when compared with the optimal solution, where
n ùëÉùëÖùëÉ,ùëî
√ç
ùëùùê¥ ‚àíùëù ùêµ
ùúé
[1]
√çùê∫2
and
ùõø
=
max
from Lemma 6.4.
ùëöùëéùë•
ùëî
{ùê¥,ùêµ } ùëûùê¥ +ùëûùêµ
ùëõùëÖùëíùëô (ùëî)

ùúô=

(ùê∫ ‚àí1)

ùëî=1 ùëõùëÖùëíùëô (ùëî)

‚ñ°

Lemma 6.1. EOR ranking is ùõø (ùúéùëòùê∏ùëÇùëÖ ) fairness optimal, implying that for all ùê∫ choose 2 possible pairs of groups ùê¥, ùêµ ‚àà {1, ¬∑ ¬∑ ¬∑ ùê∫ }, we have
√çùê¥
√ç ùêµ
‚àíùõø (ùúéùëòùê∏ùëÇùëÖ ) ‚â§ ùëòùëñ=ùëñ
ùëûùëñ ‚àí ùëòùëó=1
ùëû ùëó ‚â§ ùõø (ùúéùëòùê∏ùëÇùëÖ ).
This lemma follows directly from the EOR ranking principle of choosing the candidate that minimizes ùõø (ùúéùëòùê∏ùëÇùëÖ ) defined according to
Eq. (8).
‚ñ°
Lemma 6.2. The constructed dual variables ùúÜ ‚â• 0. In particular, for any ùëñ > ùëòùëî in group g, where ùëî ‚àà {1, ¬∑ ¬∑ ¬∑ ùê∫ }, it holds that ùúÜùëñ‚Ä≤ = 0 and for
any ùëñ ‚â§ ùëòùëî it holds that ùúÜùëñ‚Ä≤ ‚â• 0.
Proof. In this Lemma, we show that ùúÜ ‚Ä≤ = 0 for the elements not selected and ùúÜ ‚Ä≤ ‚â• 0 for the selected elements by the EOR Algorithm.
Without loss of generality, we consider the element at index ùëñ that belongs to group ùê¥.
ùúÜùëñ‚Ä≤‚ààùê¥

=

=

=

=

Ô£π
Ô£Æ
‚àëÔ∏Å
Ô£∫
Ô£Ø
Ô£∫
Ô£Ø √ç ùëùùëñ
‚àí
ùúÜ
‚àí
ùëû
(ùúÜ
‚àí
ùúÜ
)
ùëñ
ùê¥,ùëî
ùëî,ùê¥
ùëò
Ô£∫
Ô£Ø
ùëõùëÖùëíùëô
(ùëî)
Ô£∫
Ô£Ø ùëî
ùëî‚â†ùê¥
Ô£ª+
Ô£∞
Ô£Æ
Ô£π
‚àëÔ∏Å
‚àëÔ∏Å
Ô£Ø
Ô£∫
ùëùùê¥
Ô£Ø √ç ùëùùëñ
Ô£∫
√ç
(ùúÜ
‚àí
ùúÜ
)
‚àí
ùëû
(ùúÜ
‚àí
ùúÜ
)
‚àí
+
ùëû
ùëñ
ùê¥,ùëî
ùëî,ùê¥
ùê¥,ùëî
ùëî,ùê¥
ùê¥
Ô£Ø
Ô£∫
ùëî ùëõùëÖùëíùëô (ùëî)
Ô£Ø ùëî ùëõùëÖùëíùëô (ùëî)
Ô£∫
ùëî‚â†ùê¥
ùëî‚â†ùê¥
Ô£∞
Ô£ª+
Ô£Æ
Ô£π
‚àëÔ∏Å
Ô£Ø ùëùùëñ ‚àí ùëù ùê¥
Ô£∫
Ô£Ø√ç
(ùúÜùëî,ùê¥ ‚àí ùúÜùê¥,ùëî ) Ô£∫Ô£∫
+ (ùëûùëñ ‚àí ùëûùê¥ )
Ô£Ø
Ô£∫
Ô£Ø ùëî ùëõùëÖùëíùëô (ùëî)
ùëî‚â†ùê¥
Ô£∞
Ô£ª+
!Ô£π
Ô£Æ ‚àëÔ∏Å
Ô£Ø
Ô£∫
ùëù
‚àí
ùëù
ùëñ
ùê¥
Ô£Ø
√ç
+ (ùëûùëñ ‚àí ùëûùê¥ )(ùúÜùëî,ùê¥ ‚àí ùúÜùê¥,ùëî ) Ô£∫Ô£∫
Ô£Ø
Ô£Øùëî‚â†ùê¥ (ùê∫ ‚àí 1) ùëî ùëõùëÖùëíùëô (ùëî)
Ô£∫
Ô£∞
Ô£ª+

(42)

For every pair of ùúÜùê¥,ùëî and ùúÜùëî,ùê¥ , where ùëî ‚àà {1, ¬∑ ¬∑ ¬∑ ùê∫ } and ùëî ‚â† ùê¥, only one of ùúÜùê¥,ùëî , ùúÜùëî,ùê¥ is ‚â• 0. Each of the ùê∫ ‚àí 1 terms inside the summation
in Eq. (42) reduces to the two group case as follows. For ùëñ > ùëòùê¥ and each {ùê¥, ùëî}, the term evaluates to ‚â§ 0 using Lemma 5.2 and thus ùúÜùëñ‚Ä≤ is
clipped to 0. Similarly, for ùëñ ‚â§ ùëòùê¥ and each {ùê¥, ùëî} the term evaluates to ‚â• 0 and thus ùúÜùëñ‚Ä≤ ‚â• 0.
We have shown that for any element not selected by EOR Algorithm the corresponding dual variable ùúÜ ‚Ä≤ = 0, and for any element selected
by the EOR Algorithm the corresponding dual variable ùúÜ ‚Ä≤ ‚â• 0.
We now show that ùúÜùëò ‚â• 0. From Eq. (40),
ùúÜùëò

=

=

Ô£Æ
Ô£π
‚àëÔ∏Å
Ô£Ø
Ô£∫
Ô£Ø √ç ùëùùê¥
Ô£∫
‚àí
ùëû
(ùúÜ
‚àí
ùúÜ
)
ùê¥
ùê¥,ùëî
ùëî,ùê¥
Ô£∫
Ô£Ø
Ô£Ø ùëî ùëõùëÖùëíùëô (ùëî)
Ô£∫
ùëî‚â†ùê¥
Ô£ª
Ô£∞
!
‚àëÔ∏Å
ùëù
√çùê¥
+ ùëûùê¥ (ùúÜùëî,ùê¥ ‚àí ùúÜùê¥,ùëî )
(ùê∫ ‚àí 1) ùëî ùëõùëÖùëíùëô (ùëî)

(43)

ùëî‚â†ùê¥

Each of the ùê∫ ‚àí 1 terms inside the summation in Eq. (43) reduces to the two group case. For each {ùê¥, ùëî}, the term evaluates to ‚â• 0 using
Lemma 5.2 and thus ùúÜùëò ‚â• 0.
The ùê∫ (ùê∫ ‚àí 1) duals ùúÜùê¥,ùêµ are ‚â• 0 by their construction in (38). Thus, we have shown that all the constructed dual variables ùúÜ ‚â• 0.
‚ñ°
Lemma 6.3. The dual variables ùúÜ = [ùúÜ1‚Ä≤ ¬∑ ¬∑ ¬∑ ùúÜùëõ‚Ä≤ , ùúÜùëò , ùúÜùê¥,ùêµ , ùúÜùêµ,ùê¥ , ¬∑ ¬∑ ¬∑ ] are always feasible.

EAAMO ‚Äô24, October 29‚Äì31, 2024, San Luis Potosi, Mexico

Rastogi and Joachims.

Proof. For some element ùëñ ‚àà ùê¥, the duality constraint implies that
ùê∫ ‚àí1 terms

}|
{¬™
¬©z
¬Æ
¬≠‚àëÔ∏Å
ùëùùëñ
¬Æ
¬≠
ùëûùëñ ¬≠ (ùúÜùê¥,ùëî ‚àí ùúÜùëî,ùê¥ ) ¬Æ + ùúÜùëò + ùúÜùëñ‚Ä≤ ‚â• √ç
¬Æ
¬≠ ùëî
ùëõùëÖùëíùëô (ùëî)
ùëî
¬Æ
¬≠
¬¨
¬´
Without loss of generality, we consider element ùëñ ‚àà ùê¥.
Case I: Elements not selected by the EOR Algorithm.
Using the fact that ùúÜùëñ‚Ä≤ = 0 for ùëñ > ùëòùê¥ from Lemma 6.2, and substituting ùúÜùëò from Eq. (40), we get
‚àëÔ∏Å
‚àëÔ∏Å
‚àëÔ∏Å
ùëùùê¥
‚àí ùëûùê¥
ùëûùëñ
(ùúÜùê¥,ùëî ‚àí ùúÜùëî,ùê¥ )
(ùúÜùê¥,ùëî ‚àí ùúÜùëî,ùê¥ ) + ùúÜùëò + ùúÜùëñ‚Ä≤ = ùëûùëñ
(ùúÜùê¥,ùëî ‚àí ùúÜùëî,ùê¥ ) + √ç
ùëî ùëõùëÖùëíùëô (ùëî)
ùëî‚â†ùê¥
ùëî‚â†ùê¥
ùëî‚â†ùê¥
‚àëÔ∏Å
ùëùùê¥
= √ç
+ (ùëûùëñ ‚àí ùëûùê¥ )
(ùúÜùê¥,ùëî ‚àí ùúÜùëî,ùê¥ )
ùëî ùëõùëÖùëíùëô (ùëî)
ùëî‚â†ùê¥
!
‚àëÔ∏Å
ùëùùê¥
√ç
+ (ùëûùëñ ‚àí ùëûùê¥ )(ùúÜùê¥,ùëî ‚àí ùúÜùëî,ùê¥ )
=
(ùê∫ ‚àí 1) ùëî ùëõùëÖùëíùëô (ùëî)
ùëî‚â†ùê¥
‚àëÔ∏Å
ùëùùëñ
ùëùùëñ
√ç
‚â• √ç
‚â•
(ùê∫ ‚àí 1) ùëî ùëõùëÖùëíùëô (ùëî)
ùëî ùëõùëÖùëíùëô (ùëî)

(44)

(45)

(46)

ùëî‚â†ùê¥

ùëù

Each of the ùê∫ ‚àí 1 terms inside the summation in Eq. (45) reduces to the two group case. For each {ùê¥, ùëî}, the term evaluates to (ùê∫ ‚àí1) √ç ùëñ ùëõùëÖùëíùëô (ùëî)
ùëî

using Lemma 5.3 and thus the corresponding duality constraint is satisfied.
Case II: Elements selected by the EOR Algorithm.
Using the fact that ùúÜùëñ‚Ä≤ ‚â• 0 for ùëñ ‚â§ ùëòùê¥ from Lemma 6.2, and substituting ùúÜùëò from Eq. (40), ùúÜùëñ‚Ä≤ for ùëñ ‚â§ ùëòùê¥ in (41), we get
‚àëÔ∏Å
‚àëÔ∏Å
‚àëÔ∏Å
ùëùùê¥
‚àí ùúÜùëò ‚àí ùëûùëñ
(ùúÜùê¥,ùëî ‚àí ùúÜùëî,ùê¥ )
ùëûùëñ
(ùúÜùê¥,ùëî ‚àí ùúÜùëî,ùê¥ ) + ùúÜùëò + ùúÜùëñ‚Ä≤ = ùëûùëñ
(ùúÜùê¥,ùëî ‚àí ùúÜùëî,ùê¥ ) + ùúÜùëò + √ç
ùëõùëÖùëíùëô
(ùëî)
ùëî
ùëî‚â†ùê¥

ùëî‚â†ùê¥

ùëî‚â†ùê¥

=

ùëùùëñ
ùëù
√ç ùê¥
‚â• √ç
ùëõùëÖùëíùëô
(ùëî)
ùëõùëÖùëíùëô
(ùëî)
ùëî
ùëî

Thus, for elements selected by the EOR Algorithm i.e. ùëñ ‚â§ ùëòùê¥ , the corresponding dual constraint is satisfied.

‚ñ°

We now present the proof for the global a priori bound on ùõø (ùúéùëòùê∏ùëÇùëÖ ) for ùê∫ groups.
Lemma 6.4. The global a priori bound on ùõø (ùúéùëòùê∏ùëÇùëÖ ) for ùê∫ groups is given by ùõøùëöùëéùë• = maxùëî

n ùëÉùëÖùëÉ,ùëî

ùúé
[1]
ùëõùëÖùëíùëô (ùëî)

o

prefix

min group

(min+1) group

other groups

max group

ùëò ‚àí1

1

2

‚Ä¢

ùëî

min group

other groups

other groups

max group

2

‚Ä¢

ùëî

1

ùëò

Figure 8: Illustration for the case of Multiple groups

Proof. We will show that for ùê∫ groups, the value of ùõøùëöùëéùë• such that a feasible ranking will be provided and that always satisfies
ùõø (ùúéùëòùê∏ùëÇùëÖ ) ‚â§ ùõøùëöùëéùë• for every given ùëò is given by
 ùëÉùëÖùëÉ,1

ùúé
[1] ùúé ùëÉùëÖùëÉ,2 [1]
ùúé ùëÉùëÖùëÉ,ùëî [1]
ùúé ùëÉùëÖùëÉ,ùê∫ [1]
ùõøùëöùëéùë• = max
,
,¬∑¬∑¬∑ ,
¬∑¬∑¬∑
(47)
ùëõùëÖùëíùëô (1)
ùëõùëÖùëíùëô (2)
ùëõùëÖùëíùëô (ùëî)
ùëõùëÖùëíùëô (ùê∫)

Fairness in Ranking under Disparate Uncertainty

EAAMO ‚Äô24, October 29‚Äì31, 2024, San Luis Potosi, Mexico

In the remaining, we drop the superscript of EOR for simplicity and ùúé ùëó refers to ùúé ùê∏ùëÇùëÖ
.
ùëó
We argue by an inductive argument similar to the proof of Theorem 5.2. Consider the base case of ùëò = 1, when the first element is to be
selected. The EOR algorithm will select according to Eq. (8) resulting in the lower ùõø (ùúéùëò=1 ). Thus, ùõø (ùúéùëò=1 ) is clearly ‚â§ ùõøùëöùëéùë• .
We assume that for a given ùëò ‚àí 1, ùõø (ùúéùëò ‚àí1 ) ‚â§ ùõøùëöùëéùë• and show that at ùëò, ùõø (ùúéùëò ) ‚â§ ùõøùëöùëéùë• .
Consider the general case as depicted in Figure 8, where a group 1 has the lowest accumulated proportion and group ùëî has the highest at
prefix ùëò ‚àí 1. Since ùõø (ùúéùëò ‚àí1 ) ‚â§ ùõøùëöùëéùë• from inductive assumption, we have
ùëõùëÖùëíùëô (ùëî|ùúéùëò ‚àí1 ) ùëõùëÖùëíùëô (1|ùúéùëò ‚àí1 )
‚àí
‚â§ ùõøùëöùëéùë•
ùëõùëÖùëíùëô (ùëî)
ùëõùëÖùëíùëô (1)
ùëõùëÖùëíùëô (.|ùúé )

ùëõùëÖùëíùëô (ùëî|ùúé

)

ùëò ‚àí1
At the next prefix ùëò, if the group that is selected has ùëõùëÖùëíùëô (.)ùëò ‚â§ ùëõùëÖùëíùëô (ùëî)
, then ùõø (ùúéùëò ) ‚â§ ùõøùëöùëéùë• . Note that ùõø (ùúéùëò ) is always non-negative
by definition from Eq. (8).
ùëõùëÖùëíùëô (ùëî‚Ä≤ |ùúé )
ùëõùëÖùëíùëô (ùëî|ùúéùëò ‚àí1 )
We now consider the case when a group ùëî‚Ä≤ is selected at the next prefix ùëò such that ùëõùëÖùëíùëô (ùëî‚Ä≤ )ùëò > ùëõùëÖùëíùëô (ùëî)
. Let us first consider that ùëî‚Ä≤

ùëõùëÖùëíùëô (1|ùúé )

ùëõùëÖùëíùëô (ùëî|ùúé )

is group 1. We have ùëõùëÖùëíùëô (1)ùëò > ùëõùëÖùëíùëô (ùëî)ùëò . Selecting group 1 at ùëò means that the rest of the groups have the same accumulated relevance
ùëõùëÖùëíùëô (.|ùúé )
ùëõùëÖùëíùëô (.|ùúé )
proportion ùëõùëÖùëíùëô (.)ùëò at prefix ùëò as ùëò ‚àí 1. We analyze the difference of ùëõùëÖùëíùëô (.)ùëò between the group that was most behind‚Äì group 1 and the
group that was second most behind ‚Äì group 2 and whether that remains within ùõøùëöùëéùë• . If the added element from group 1 is denoted by ùëùùëñ ,
the EOR constraint value at ùëò is
ùõø (ùúéùëò )

=
=

ùëùùëñ
ùëõùëÖùëíùëô (1|ùúéùëò ‚àí1 )
ùëõùëÖùëíùëô (2|ùúéùëò )
+
‚àí
ùëõùëÖùëíùëô (1)
ùëõùëÖùëíùëô (1)
ùëõùëÖùëíùëô (2)




ùëùùëñ
ùëùùëñ
ùëõùëÖùëíùëô (2|ùúéùëò ) ùëõùëÖùëíùëô (1|ùúéùëò ‚àí1 )
ùëõùëÖùëíùëô (2|ùúéùëò ‚àí1 ) ùëõùëÖùëíùëô (1|ùúéùëò ‚àí1 )
‚àí
‚àí
=
‚àí
‚àí
ùëõùëÖùëíùëô (1)
ùëõùëÖùëíùëô (2)
ùëõùëÖùëíùëô (1)
ùëõùëÖùëíùëô (1)
ùëõùëÖùëíùëô (2)
ùëõùëÖùëíùëô (1)

(48)

Eq. (48) holds since group 1 is now the group with maximum relevance proportion after adding ùëùùëñ - the top most current element from
group 1. Group 2 becomes the group with minimum relevance proportion.
ùëù

ùúé ùëÉùëÖùëÉ,1 [1]

Since ùëõùëÖùëíùëôùëñ (1) ‚â§ ùëõùëÖùëíùëô (1) ‚â§ ùõøùëöùëéùë• and because group 1 was behind group 2 at prefix ùëò ‚àí 1, we have
a result,
ùõø (ùúéùëò ) ‚â§

ùëõùëÖùëíùëô (2|ùúéùëò ‚àí1 )
ùëõùëÖùëíùëô (1|ùúéùëò ‚àí1 )
since . As
‚â• ùëõùëÖùëíùëô (1)
ùëõùëÖùëíùëô (2)

ùëùùëñ
ùúé ùëÉùëÖùëÉ,1 [1]
ùëõùëÖùëíùëô (1) ‚â§ ùëõùëÖùëíùëô (1) ‚â§ ùõøùëöùëéùë•

We have shown above that if the group with lowest relevance proportion at prefix ùëò ‚àí 1 (group 1 in this case) is selected and its relevance
proportion now exceeds the group with the highest relevance proportion at prefix ùëò ‚àí 1 (group ùëî in the case above), then ùõø (ùúéùëò ) ‚â§ ùõøùëöùëéùë• . Thus,
we can say that at least one group exists that satisfies ùõøùëöùëéùë• EOR constraint
at prefix
ùëò. This completes the proof that the EOR algorithm
n
o
always provides a feasible ranking that satisfies ùõøùëöùëéùë• = maxùëî‚àà {1¬∑¬∑¬∑ùê∫ }

ùúé ùëÉùëÖùëÉ,ùëî [1]
ùëõùëÖùëíùëô (ùëî)

for ùê∫ groups.

‚ñ°

E Experiment Details
E.1 Baselines
We compare rankings from Algorithm 1 with the following baselines
Probability Ranking Principle (ùúã ùëÉùëÖùëÉ ). Candidates are selected in decreasing order of relevance independent of their group membership.
Uniform Policy (ùúã unif ). Candidates are selected randomly independent of their group membership or relevance.
Thompson Sampling Ranking Policy (ùúãùëá ùëÜ ) [50]. For ùúãùëá ùëÜ , binary relevances are drawn according to ùëüùëñ ‚àº P(ùëüùëñ |D), and candidates are sorted
in decreasing order of relevance ùëüùëñ with their ranking randomized for the same value of relevance ùëüùëñ .
ùúãùëá ùëÜ ‚àº arg sortùëñ [ùëüùëñ ]

s.t ùëüùëñ ‚àº P(ùëüùëñ |D)

ùúãùëá ùëÜ ranks each candidate ùëñ in position ùëò with probability that ùëñ has ùëò ùë°‚Ñé highest relevance.
For both ùúãùëá ùëÜ and ùúã unif , we compute expectation over 100 rankings ùúé unif ‚àº ùúã unif or ùúéùëá ùëÜ ‚àº ùúãùëá ùëÜ respectively and compute ùõø (ùúéùëò ) used in
Table 1 as





ùëõùëÖùëíùëô (ùëî|ùúéùëò )
ùëõùëÖùëíùëô (ùëî|ùúéùëò )
ùõø (ùúéùëò ) = Eùúé‚àºùúã max
‚àí min
ùëî
ùëî
ùëõùëÖùëíùëô (ùëî)
ùëõùëÖùëíùëô (ùëî)
√ç
In order to plot a single ranking ùúé unif , ùúéùëá ùëÜ for all experiments, we select the ranking with median ùëõùëò=1 |ùõø (ùúéùëò )|

EAAMO ‚Äô24, October 29‚Äì31, 2024, San Luis Potosi, Mexico

PRR

1.0

=0

0

FS

EOR

0.0

DP

102
TS

102

102

(a) Length of Ranking (k)

Group A

1.0

0.0

Group B

PRP

102

Total Costs

0.6
0.5
0.4
0.3
0.2
0.1
0.0
-0.1
-0.2
-0.3

Uniform

102

PRR

FS

102

(b)

nDCG

PRP
TS

Group Costs

( k)

EOR
DP

Rastogi and Joachims.

102

Principal

1.0
0.5
0.0

102

1.0
0.5
0.0

(c)

102

Figure 9: EOR criterion ùõø (ùúéùëò ), costs of the ranking policies, and DCG Utility for Synthetic dataset with proportional Rooney-Rule like
constraint, ùúã ùëÉùëÖùëÖ . For group A we draw ùëÜ (ùê¥) = 30 relevance probabilities from ùëÉùëúùë§ùëíùëüùëôùëéùë§ (ùúÇ = 5), and then draw for group B from
ùëÉùëúùë§ùëíùëüùëôùëéùë§ (ùúÇ = 0.5) until ùëõùëÖùëíùëô (ùê¥) ‚âà ùëõùëÖùëíùëô (ùêµ).
0.6
1.01.0

( k)

Group Costs

EOR
0.5
0.8
Demographic Parity (ùúã ùê∑ùëÉ ). Candidates in each group are sorted in decreasing order of0.4
P(ùëüùëñ |D) and selected such that the following
0.3 in [58].
constraint is minimized. This constraint is similar to the statistical parity variations introduced
0.2
0.00.6
ùëÜ (ùê¥|ùúéùëò ) ùëÜ (ùêµ|ùúéùëò )
102
0.1
‚àí
(49)
‚àÄùëò
ùëÜ (ùê¥)
ùëÜ (ùêµ)
1.0
0.4
0.0
TS
ùê∏ùëÇùëÖ
=
0
where ùëÜ (.) represents the size of the group. For a fair comparison with ùúé
, we use Algorithm 1 and instead of minimizing Eq. (6), we
-0.1
minimize the above demographic parity constraint (49). We now discuss other variations of proportional representation constraints that
0.2 have
-0.2
been introduced in prior literature [8‚Äì10]. Generally, these constraints require that the disadvantaged
group selected is at least a specific
-0.3
proportion ùõº of top k.
0.0
0.0
0
102
102
ùëÜ (ùêµ|ùúéùëò ) ‚â• ùõºùëò
(50)

(a) Length of Ranking (k)

ùëÜ (ùêµ)

where ùõº = ùëÜ (ùê¥)+ùëÜ (ùêµ) and Eq. (50) is used as the fairness constraint while maximizing the utility to the principal. This type of representational
constraint by definition requires the designation of a disadvantaged group. By designating B as the disadvantaged group, the constraint for
proportional Rooney-Rule policy [47], which we denote by ùúã ùëÉùëÖùëÖ is as follows
‚àÄùëò

ùëÜ (ùêµ|ùúéùëò )
ùëÜ (ùêµ)
‚â•
ùëò
ùëÜ (ùê¥) + ùëÜ (ùêµ)

We empirically compare ùúã ùëÉùëÖùëÖ baseline with other ranking policies in Figure 9 and as expected, find that it is similar to the baseline of ùúã ùê∑ùëÉ ,
where ùúã ùëÉùëÖùëÖ and ùúã ùê∑ùëÉ almost overlap. Thus for a fair and analogous comparison with ùúã ùê∏ùëÇùëÖ , we use (49) as the ùúã ùê∑ùëÉ baseline for all empirical
evaluations. For more than two groups, we extend the DP baseline with the selection rule based on group size as follows. In particular,




ùëÜ (ùëî|ùúéùëò )
ùëÜ (ùëî|ùúéùëò )
ùõø (ùúé ùê∑ùëÉ ) = max
‚àí min
ùëî
ùëî
ùëÜ (ùëî)
ùëÜ (ùëî)
ùëôùëî
ùëî

‚àó

=
=

ùúé ùëÉùëÖùëÉ,ùëî [1]

‚àÄùëî ‚àà {1 ¬∑ ùê∫ }

arg min ùõø (ùúé

ùê∑ùëÉ

‚àó

‚à™ {ùëôùëî }); ùëôùëî‚àó = ùúé ùëÉùëÖùëÉ,ùëî [1]

(51)

ùëî‚àà [1..ùê∫ ]

FA‚àó IR Ranking Principle (ùúã ùêπùëÜ ). This criterion is anchored on the principle that a top-k ranking is fair when the proportion of disadvantaged
candidates selected doesn‚Äôt fall far below a required minimum proportion ùëù. This is formalized with a Binomial distribution, and a confidence
level (1 ‚àí ùõº). A function of the binomial cdf is computed apriori and is used as an input in the FA‚àó IR Algorithm. Since Binomial(p=0.5,n)
corresponds to a ranking where at each position, a candidate from either group is selected randomly, FA‚àó IR is a "softened" version of
demographic parity (DP). As a result, FA‚àó IR is fundamentally different from Axiom 1 and Definition 4.1 derived from the uniform lottery

Fairness in Ranking under Disparate Uncertainty

EAAMO ‚Äô24, October 29‚Äì31, 2024, San Luis Potosi, Mexico

fairness because, unlike DP, the uniform lottery is anchored on selecting an equal fraction of relevance from each group. Unlike ùúã ùê∏ùëÇùëÖ ,
ùúã ùêπùëÜ is oblivious to the relevance distribution and thus cannot take disparate uncertainty into account. FA‚àó IR also requires the normative
designation of a disadvantaged group.
Consider the following example for top k=4 selection, with the probability of relevance for group A = [0.7, 0.7, 0.7, 0.7, 0.1, 0.1], group size
= 6, relevant candidates = 3.0. Similarly, the probability of relevance for group B = [0.5, 0.5, 0.5, 0.5, 0.5, 0.5], group size = 6, relevant candidates
= 3.0. The EOR Ranking for top-4 is [0.5, 0.7, 0.5, 0.7] with 2 candidates from group A, and 2 from group B, resulting in ùõø (ùúé4ùê∏ùëÇùëÖ ) = 0.13.
The ùúã ùêπùëÜ Algorithm with Binomial(p=0.5, n=12), k=4 and ùõº = 0.1 requires that at least 1 candidate be selected from the disadvantaged
group while maximizing the utility to the principal. FA‚àó IR ranking with group B as the disadvantaged group is ùúé4ùêπùëÜ = [0.7, 0.7, 0.7, 0.5]. It
selects 3 candidates from group A, and 1 from group B, resulting in ùõø (ùúé4 ) = 0.53. If instead group A is designated as the disadvantaged
group, ùúé ùêπùëÜ = [0.7, 0.7, 0.7, 0.7] with all candidates selected from group A, and none from group B, resulting in ùõø (ùúé4ùêπùëÜ ) = 0.93. Note that for
both FA*IR rankings, far fewer relevant candidates are chosen from group B, even though both groups have an equal number of relevant
candidates in expectation.
In all the empirical evaluations in this paper, we assign group B as the minority group for ùúã ùêπùëÜ and use the fairsearch core library 6 with
default parameters of ùõº = 0.1.
Next, we discuss two exposure-based formulations ùúã ùê∏ùëã ùëÉ and ùúã ùëÖùê¥ .
Exposure-based Disparate Treatment (ùúã ùê∏ùëã ùëÉ ). This policy enforces that the allocation of exposure to each group is proportional to their
average utility. Specifically for two groups A and B,
Exposure(ùê¥|Œ£) Exposure(ùêµ|Œ£)
=
ùëà (ùê¥)
ùëà (ùêµ)
where Œ£ is the doubly stochastic ranking matrix obtained from solving the Linear Program in [49]. For multiple
groups, the above constraint
√ç
Œ£ ùë£

ùëùùëñ

ùëõùëÖùëíùëô (ùëî)

is added for each pair of groups. Exposure(ùëî|Œ£) = ùëÜùëñ,ùëó(ùëî)ùëó , ùë£ ùëó = log (1ùëó+1) for the ùëó ùë°‚Ñé position, and ùëà (ùëî) = ùëÜùëñ ‚ààùëî
(ùëî) = ùëÜ (ùëî) . In particular for
two groups A, B, we solve the following LP [49]

Maximize

ùëÉùëá Œ£ùë£

subject to

1ùëá Œ£ = 1ùëá
Œ£1 = 1
0 ‚â§ Œ£ùëñ,ùëó ‚â§ 1


I ùëó ‚ààùêµ
Iùëñ ‚ààùê¥
ùëõùëÖùëíùëô (ùê¥) ‚àí ùëõùëÖùëíùëô (ùêµ) Œ£ùë£ = 0

utility to the principal

(52)

(sum of probabilities for each position)
(sum of probabilities for each candidate)
(valid probability)
(exposure constraint)

n I ùëÉŒ£ o
n I ùëÉŒ£ o
Iùëî ùëÉ Œ£
ùëî
ùëî
√ç ùëÉŒ£
and
EOR
criterion
as
max
The group cost is computed as ùëõùëÖùëíùëô
,
total
cost
as
‚àí
min
ùëî
ùëî
(ùëî)
ùëõùëÖùëíùëô (ùëî)
ùëõùëÖùëíùëô (ùëî)
ùëî ùëõùëÖùëíùëô (ùëî)
Rank Aggregation w. proportional allocation of Exposure. For ùúã ùëÖùê¥ , we modify the baseline for fair rank aggregation in [7] as follows. In fair
rank aggregation, all ùëõ candidates are ranked by ùëö voters to achieve a ranking with maximum consensus accuracy, where consensus may
be according to different aggregation methods while achieving fairness of exposure w.r.t groups. [7] proposes an algorithm that finds the
consensus maximizing ranking and then swaps the candidates such that the equality of exposure is satisfied in that ranking. To adapt this
baseline, we use the ranking from utility maximizing ùúã ùëÉùëÖùëÉ as the consensus ranking and use the algorithm from [7] to swap elements in
PRP ranking until the exposure constraint below is satisfied,
minùëî ùê∏ùë•ùëùùëúùë†ùë¢ùëüùëí (ùëî)
‚â• threshold
maxùëî ùê∏ùë•ùëùùëúùë†ùë¢ùëüùëí (ùëî)
A threshold of 0.95 is used in experiments and on average over 100 runs, an exposure of 0.96 ¬± 0.01, 0.96 ¬± 0.00, 0.97 ¬± 0.00 is achieved for
high, medium, and low levels of disparate uncertainty respectively in Table 1.

E.2

Synthetic Dataset

To simulate disparate uncertainty between groups, we draw P(ùëüùëñ |D) directly from specific probability distributions as follows. For Group
1 , 1 ) and keep them fixed. We simulate 100 runs and in each run, ùëù for group B are sampled as follows until
A, we obtain ùëùùëñ ‚àº ùêµùëíùë°ùëé( 20
ùëñ
20
ùëõùëÖùëíùëô (ùêµ) ‚âà ùëõùëÖùëíùëô (ùê¥) (total expected relevance for groups can only differ by 1.0).
‚Ä¢ High Disparate Uncertainty: ùêµùëíùë°ùëé(5, 5)
‚Ä¢ Medium Disparate Uncertainty: ùêµùëíùë°ùëé( 21 , 12 )
1 , 1 ). Note that even when both groups are drawn from the same distribution, any sampled
‚Ä¢ Low Disparate Uncertainty: ùêµùëíùë°ùëé( 20
20
instance still contains some amount of disparate uncertainty.
6 https://github.com/fair-search/fairsearch-fair-python

EAAMO ‚Äô24, October 29‚Äì31, 2024, San Luis Potosi, Mexico

Rastogi and Joachims.

Results for unfairness and effectiveness of rankings are reported with standard error in Table 1 (left). The posterior distributions in Table 1
(right) uses 50 samples for each candidate in group A, while for group B, the number of samples increases from 10 to 30 to 50 as the setting
changes from high to medium to low disparate uncertainty respectively.
To estimate P(ùëñ ‚àà ùúéùëòùúã ) for stochastic policies‚Äì ùúã unif and ùúãùëá ùëÜ , we draw ùëë = 103 Monte Carlo samples and compute Monte Carlo estimate
according to (53).
1 ‚àëÔ∏Å
Iùëñ‚àâùúéùëò
1 ‚àí P(ùëñ ‚àà ùúéùëòùúã ) =
(53)
ùëë
ùëë

We compute the costs using P(ùëüùëñ |D), P(ùëñ ‚àà ùúéùëòùúã ) according to Eqs. (3), and (4).
In Figure 11, we plot a random sample from Table 1 according to the generation process described above. We also qualitatively analyze a
commonly used measure of utility to the principal, namely, the expected Normalized Discounted Cumulative Gain (nDCG), which according
to our model is,
√ç
ùê∑ùê∂ùê∫ (ùúéùëò )
ùëñ ‚ààùúéùëò ùë£ùëñ ùëüùëñ
= √ç
ùëõùê∑ùê∂ùê∫ (ùúéùëò ) =
;
ùúé ùêºùëëùëíùëéùëô = arg sortùëñ ùëüùëñ
ùëñùê∑ùê∂ùê∫
ùëñ ‚ààùúé ùêºùëëùëíùëéùëô ùë£ùëñ ùëüùëñ
ùëò

nDCG

1 for the ùëñ ùë°‚Ñé position. When true relevance labels are known, for instance in US Census experiments in Figure 14,
where ùë£ùëñ = ùëôùëúùëî2 (1+ùëñ
)
ùëüùëñ ‚àà {0, 1} consists of the true relevance labels, otherwise in synthetic experiments in Figure 11, ùëüùëñ ‚àà [0, 1] consists of the calibrated
P(ùëüùëñ = 1|D).
As shown in Figure 10, the nDCG for EOR ranking is only slightly lower than the nDCG optimal PRP ranking and competitive with all
other ranking policies. In all of these experiments, we confirm our findings that ùúã ùê∏ùëÇùëÖ , ùúã unif distribute the subgroup and total costs evenly

1.0
0.9
0.8
0.7
0.6
0.5
0.4

FS
RA
EXP
Uniform
TS
PRP
DP
EOR
20

40

60

Length of Ranking (k)

Figure 10: nDCG for High disparate uncertainty setting shown in Figure 4
while other ranking policies ùúã ùëÉùëÖùëÉ , ùúã ùê∑ùëÉ , and ùúãùëá ùëÜ place a high cost burden on one of the groups. Further, for ùúã ùê∏ùëÇùëÖ , the total cost to the
principal and nDCG utility is close to the optimal (but unfair) total cost and utility of ùúã ùëÉùëÖùëÉ , indicated by overlapping lines in subplots (c) of
Figure 11.

E.3

US Census Survey Dataset

We use the ACSIncome task with default settings [14] for the state of New York and Alabama for 2018, with 1-year horizon. The dataset
consists of 10 features, out of which 8 are categorical. Race is among the features that we include in the prediction task following [14]. There
are 103,021 records for New York and 22,268 records for Alabama. For pre-processing, the categorical features are one-hot encoded, while
the other two numerical features (‚ÄòAGE‚Äô and ‚ÄòWKHP‚Äô) are standardized to have mean 0 and standard deviation 1. We divide this dataset
into 60/20/20 for train/val/test split and fit a Gradient Boosting Classifier 7 with the parameters loss as ‚Äòexponential‚Äô and max_depth as 5
following hyperparameter configuration of [14]. This gives a DP violation ùëÉ (ùëåÀÜ = 1|ùëä ‚Ñéùëñùë°ùëí) ‚àí ùëÉ (ùëåÀÜ = 1|ùêµùëôùëéùëêùëò) of 0.19 and an EO violation
ùëÉ (ùëåÀÜ = 1|ùëå = 1,ùëä ‚Ñéùëñùë°ùëí) ‚àí ùëÉ (ùëåÀÜ = 1|ùëå = 1, ùêµùëôùëéùëêùëò) of 0.18 for New York and a a DP violation of 0.22, EO violation of 0.29 for Alabama, which is
roughly similar to Figure 2 and 6 of [14] before any fairness interventions are applied in the classification setting.
We subset the dataset to contain records with White or Black/African American racial membership (Alabama and New York) and subset
records with White, Black, Asian, and Others racial membership (New York only) for two and four groups respectively. To calibrate relevance
probabilities, we fit a Platt Scaling [37] calibrator on the validation data split group-wise and apply Platt Scaling to the test set probability
estimates. Figure 12a, 12b and 12c show that calibrated P(ùëüùëñ |D) on the test set, binned across 20 equal sized bins, lie close to the perfectly
calibrated line.
7 scikit-learn Gradient Boosting Classifier

Fairness in Ranking under Disparate Uncertainty

RA

1.0

( k)

Group Costs

0.5

0.0

0.0
1.0

Group A

Group B

DP

PRP

TS

59

59

59

EXP

RA

FS

59

=0

59

1.0

EOR

0.0
0

0.0

59

1.0
0.5
0.0

59

DP

0.5

(c)

TS1.0

PRP

59

EOR

0.0
1.0

DP

61

0.0
1.0k = 0

0.0
61

PRP

61

EXP

52

52

52

EXP

RA

FS

0.0

52

(a) Length of Ranking (k)

61

(b)

1.0

0.6

0.5
61
0.4

0.0
52 0.2
1.0

52

0.0

61

52

(b)

TS

61

RA

61

Total Costs

0.8

(a) Length of Ranking (k)
52

(b)

1.0

nDCG

0.5

59

Principal

Medium Disparate Uncertainty

1.0

=0

0

Group Costs

(a) Length of Ranking (k)

Group Costs

0.2
0.1
0.0
-0.1
-0.2
-0.3
-0.4
-0.5

0.0

59

( k)

0

( k)

EOR

FS

Total Costs

Uniform
EXP

nDCG

PRP
TS

Total Costs

EOR
DP

EAAMO ‚Äô24, October 29‚Äì31, 2024, San Luis Potosi, Mexico

0.80

10

52

20

(c)

30

(c)
52

Low Disparate Uncertainty

1.0

0.8
0.6
0.4
0.2
0.0

0.0

0.2

0.4

0.6

0.8

Mean predicted rate
(a) New York

1.0

White
Black
Perfect calibration

0.8

Mean empirical rate

White
Black
Perfect calibration

Mean empirical rate

Mean empirical rate

Figure 11: Top: Medium disparate uncertainty Bottom Low disparate uncertainty for a randomly sampled instance.

0.6
0.4
0.2
0.0

0.0

0.2

0.4

0.6

0.8

Mean predicted rate
(b) Alabama

1.0

White
Black
Asian
Others
Perfect calibration

0.8
0.6
0.4
0.2
0.0

0.0

0.2

0.4

0.6

0.8

Mean predicted rate

1.0

(c) New York

Figure 12: Calibration plot for P(ùëüùëñ |D) for the state of New York and Alabama

In Figure 5, estimates ùëõùëÖùëíùëô (ùê¥|ùúéùëò ), ùëõùëÖùëíùëô (ùê¥), ùëõùëÖùëíùëô (ùêµ|ùúéùëò ), and ùëõùëÖùëíùëô (ùêµ) are computed with the true relevance labels from the test set for
computing EOR criterion, costs, and nDCG. Figure 13, shows EOR criterion and costs with ùëõùëÖùëíùëô (ùê¥|ùúéùëò ), ùëõùëÖùëíùëô (ùê¥), ùëõùëÖùëíùëô (ùêµ|ùúéùëò ), ùëõùëÖùëíùëô (ùêµ) estimated

40

50

60

EAAMO ‚Äô24, October 29‚Äì31, 2024, San Luis Potosi, Mexico

Group Costs

( k)

0.2

0.0
1.0

0.1
0.0

k=0

-0.1
0

Length of Ranking (k)

0.0

4268

EOR

PRP

4268

Group Costs

( k)

0.3

0.0
1.0

0.2
0.1

Length of Ranking (k)

4268

19985

0.0

(a)

EOR

RA

PRP

0.3
0.2

1.0

1.0

0.5
0.0
1.0

4268

0.0
1.0

0.5

4268

0

(c)

k=0

Length
of1.0Ranking (k)
RA

TS

19985

Principal

0.1
0.0

DP

Others

nDCG

1.0

0

TS

(b)

0.4

k=0

DP

0.4

(a)

0.0

Asian

Group Costs

1.0

0.3

Black

Total Costs

White

nDCG

Uniform
RA

Total Costs

PRP
TS

( k)

EOR
DP

Rastogi and Joachims.

(a)

0.5
0.0
1.0

19985

0.5

19985

(b)

19985

19985

(c)

Figure 13: Top: EOR criterion ùõø (ùúéùëò ) and Costs computed using calibrated P(ùëüùëñ |D) for two groups for the state of Alabama. Bottom: EOR
criterion ùõø (ùúéùëò ) and Costs computed using calibrated P(ùëüùëñ |D) for four groups for the state of New York.
from the calibrated P(ùëüùëñ |D). Note that the evaluation on true relevance labels in Figure 5, though noisier is qualitatively similar to the
evaluation using the calibrated P(ùëüùëñ |D) in Figure 13. Additional experiment for two groups with true relevance labels for New York in
Figure 14 (top) and with calibrated P(ùëüùëñ |D) in Figure 14 (bottom) further confirm our findings, that ùúã ùê∏ùëÇùëÖ is the only ranking policy that
consistently achieves ùõø (ùúéùëò ) close to zero at every prefix ùëò with near optimal total cost to the principal.
Note the overlapping of ùúã ùëÖùê¥ and ùúã ùëÉùëÖùëÉ in Figure 13 and 14. This is expected because ùúã ùëÖùê¥ swaps the candidates in PRP ranking to satisfy
proportional exposure as described in Appendix E.1. Since the amortized exposure between groups is already satisfied with the PRP ranking
for this dataset, ùúã ùëÖùê¥ and ùúã ùëÉùëÖùëÉ compute similar rankings.

E.4

Amazon shopping queries dataset

Amazon‚Äôs shopping queries [39] consists of a large scale query-product pair dataset with baseline models for tasks related to predicting
the relevance of items given a search query. Each query-product pair has an associated human annotated label of an exact, substitute,
complement, or irrelevant label.
For our analysis, we focus on their task 1 of query-product ranking 8 to sort the list of products in the decreasing order of relevance for
every query. We use the publicly available baseline model for this task, consisting of Cross Encoders for the MS Marco dataset [40]. This
pretrained model encodes the query and product titles and is fine-tuned on the US part of the small version of training dataset. We use the
default hyperparameters for the Cross Encoder as maximum length=512, activation function=identity, and number of labels=1 (binary task).
Similarly, for training following the default configuration, all exact labels are mapped to 1.0, while the rest (substitute, complement, and
irrelevant) are mapped to 0.0. Default hyperparameter configuration includes MSE loss function, evaluation steps=5000, warm-up steps=5000,
learning rate=7e-6, training epochs=1, and number of development queries=400. Inference from the trained model provides relevance scores
and we apply a sigmoid function to transform these scores to probabilities of relevance P(ùëüùëñ |D).
8 https://github.com/amazon-science/esci-data

0.0

1.0

Group Costs

0.1

( k)

0.0
1.0

0.0
-0.1

k=0

0

Length of Ranking (k)

0.0

16922

Uniform
EOR

-0.1

k=0

0

Length of Ranking (k)

16922

(a)

0.0

0.1

16922
EOR

DP

PRP

-0.1

16922

(b)

1.0
0.5

1.0

0.0
1.0

16922

0.5
16922

(c)
RA

0

k=0

1.0
0.5

Length of Ranking (k)

TS

16922

Black

0.0

16922 0.0

nDCG

Group Costs

( k)

0.0

0.0
1.0

RA

TS

(b)

0.1

White

DP

PRP

(a)

1.0

RA

0.0 (a)
1.0

16922

16922

0.5

16922

(c)

Figure 14: Top: EOR criterion ùõø (ùúéùëò ) and Costs computed using true relevance labels from the test subset. Bottom: EOR criterion ùõø (ùúéùëò ) and
Costs computed using calibrated P(ùëüùëñ |D) for the state of New York.
To evaluate the calibration of predicted P(ùëüùëñ |D), we use the test split of the dataset [39] for the large version containing 22,458. We
filtered these queries so that they contain at least three products owned by one of the 158 brands owned by Amazon (we discuss in the next
paragraph the source of identifying these Amazon-owned brands) and at least three products owned by brands other than Amazon. These
result in 395 queries, out of which half are used for calibration with a Platt-scaling calibrator while the remaining half is used to evaluate the
calibration curve for the test dataset. P(ùëüùëñ |D) of the query-product pairs for the remainder half of the test dataset after calibration is binned
across 20 equal sized bins as shown in Figure 6a and lies close to the perfectly calibrated line.
We further augmented this with another dataset 9 collected from the Markup report [60], which investigated Amazon‚Äôs placement of
its own brand products as compared to other brands based on star ratings, reviews etc. The authors for the Markup report identified 158
brand products that are trademarked by Amazon. We use these 158 brands to form the Amazon owned group. Products belonging to any
other brand form the non-Amazon group. Importantly, this dataset contains logged rankings from Amazon‚Äôs website with 4566 queries for
popularly searched query terms. We filtered these such that each query contains exactly 60 products and at least three of them are owned by
Amazon, resulting in 1485 search queries.
Next, we obtain relevance probabilities P(ùëüùëñ |D) from Amazon‚Äôs pretrained baseline model described above and evaluate ùõø (ùúéùëò ) both for
the logged ranking as well as our computed EOR ranking. Figure 6b shows that our EOR ranking is closer to ùõø (ùúéùëò ) = 0 as compared to
logged rankings on Amazon‚Äôs platform. We note that this analysis is subject to confounding due to the use of features other than product
titles that may be used in practice for logged rankings. However, the analysis does demonstrate how the EOR criterion can be used for
auditing, if the auditor is given access to the production ranking model to avoid confounding.

9 https://github.com/the-markup/investigation-amazon-brands

Group Costs

TS

nDCG

PRP

Total Costs

DP

( k)

EOR

EAAMO ‚Äô24, October 29‚Äì31, 2024, San Luis Potosi, Mexico

Total Costs

Fairness in Ranking under Disparate Uncertainty

0.0
1.0

0.0

