stability
multigroup
fairness
ranking
uncertain
predictions
aleksandra
korolova
princeton
university
korolova@princeton.edu
arxiv
2402
09326v1
cs
lg
14
feb
2024
siddartha
devic
university
southern
california
devic@usc.edu
david
kempe
university
southern
california
david.m.kempe@gmail.com
vatsal
sharan
university
southern
california
vsharan@usc.edu
abstract
rankings
ubiquitous
across
many
applications
search
engines
hiring
committees
practice
many
rankings
derived
output
predictors
however
predictors
trained
classification
tasks
intrinsic
uncertainty
obvious
uncertainty
represented
derived
rankings
work
considers
ranking
functions
maps
individual
predictions
classification
task
distributions
rankings
focus
two
aspects
ranking
functions
stability
perturbations
predictions
fairness
towards
individuals
subgroups
stability
important
requirement
sake
show
composes
harmoniously
individual
fairness
sense
dwork
et
al
2012
deterministic
ranking
functions
stable
aside
trivial
scenarios
show
recently
proposed
uncertainty
aware
ua
ranking
functions
singh
et
al
2021
stable
main
result
ua
rankings
also
achieve
multigroup
fairness
successful
composition
multiaccurate
multicalibrated
predictors
work
demonstrates
ua
rankings
naturally
interpolate
group
individual
level
fairness
guarantees
simultaneously
satisfying
stability
guarantees
important
whenever
machine-learned
predictions
used
introduction
rankings
underpin
many
modern
systems
companies
rank
job
applications
geyik
et
al
2019
turbohire
2023
ad
marketplaces
rank
ads
serve
user
google
2023
social
media
platforms
feeds
rank
content
meta
2023
rankings
also
used
partially
automate
decision
making
settings
limited
resources
attention
span
job
candidate
interview
selections
ad
delivery
rankings
often
derived
predictions
generated
machine
learning
models
designed
deployed
relevant
classification
tasks
example
job
advertisement
platform
may
use
model
predicts
individual
relevance
score
job
apply
say
scale
corresponding
irrelevant
suitable
extremely
relevant
score
factored
platform
ranking
job
applicants
shown
company
recruiter
limited
time
budget
practice
machine
learning
models
often
predict
distributions
classes
instead
single
class
predictions
correspond
belief
future
may
possibly
hold
certainty
future
will
look
like
plethora
recent
research
model
calibration
guo
et
al
2017
gupta
ramdas
2022
minderer
et
al
2021
conformal
prediction
bastani
et
al
2022
jung
et
al
2023
uncertainty
quantification
angelopoulos
bates
2021
tackled
issue
ensuring
equal
contribution
order
authors
randomized
https://www.random.org/.
uncertainty
estimates
output
model
meaningful
rather
artifacts
particular
training
regime
uncertainty
inherent
predictions
argue
essential
revisit
question
meaningfully
convert
predictions
made
form
distributions
classes
rankings
without
uncertainty
example
one
access
oracle
future
usually
clear
ranking
look
like
meritocracy
suggest
one
always
places
suitable
candidates
higher
ranking
however
given
predictions
suitability
merit
intrinsic
uncertainty
approach
generating
meaningful
ranking
less
clear
one
must
choose
ranking
candidates
order
make
interview
decision
witnessing
exact
suitability
candidate
generally
observable
individual
works
job
months
even
years
since
uncertain
prediction
can
considered
prior
typically
imperfect
belief
qualifications
performance
given
individual
fundamental
task
designing
meaningful
ranking
algorithm
utilizing
predictions
must
reexamined
meaningful
derivation
rankings
predictors
consider
following
two
properties
essential
requirements
anonymity
individuals
must
treated
symmetrically
priori
predictions
permuted
ranking
permuted
according
permutation
stability
predictor
distribution
classes
changes
slightly
total
variation
distance
corresponding
induced
ranking
change
slightly
reason
requiring
anonymity
self-evident
rules
discrimination
basis
identity
individuals
stability
nuanced
articulates
desire
rankings
agnostic
small
amounts
noise
predictions
individual
deployed
applications
small
amount
variation
injected
seeded
training
test
data
set
split
randomized
training
procedure
can
introduce
noise
level
individual
predictions
ganesh
et
al
2023
furthermore
will
also
always
least
additional
noise
due
incomplete
data
entries
mistaken
inputs
etc
nettleton
et
al
2010
rankings
generally
agnostic
sources
noise
minute
noise
predictions
can
induce
large
changes
derived
ranking
ranking
meaningful
fair
begin
stability
can
therefore
interpreted
way
combat
micro-arbitrariness
rankings
induced
learned
predictors
cooper
et
al
2024
stability
meaningful
will
need
shift
focus
distributions
rankings
utilizing
randomness
deal
uncertainty
will
key
achieving
stability
anonymity
can
construed
fairness
notion
minimal
one
fairness
stronger
sense
focus
much
recent
work
context
ranking
see
singh
joachims
2018
2019
context
classifiers
predictors
see
awasthi
et
al
2020
caton
haas
2020
dwork
et
al
2012
hardt
et
al
2016
ml-based
predictors
often
used
order
ultimately
produce
rankings
wang
chen
2012
natural
desideratum
ranking
function
preserve
fairness
guarantees
underlying
predictor
ensures
additional
unfairness
introduced
post-processing
classifier
output
will
see
ranking
functions
satisfy
fairness
composition
properties
1.1
contributions
focus
scenarios
individuals
scored
predictor
must
presented
decision
maker
linear
order
ranking
assume
predictions
take
form
distributions
classes
modeling
inherent
uncertainty
underlying
ground
truth
data
section
define
ranking
function
map
probabilistic
predictions
distribution
rankings
figure
illustrates
setting
example
first
immediate
see
section
3.1
result
stability
naturally
composes
individual
fairness
dwork
et
al
2012
predictor
individually
fair
ranking
function
stable
coding
work
history
ability
3.0
excellent
applicable
3.5
poor
applicable
4.0
excellent
applicable
rank
student
gpa
observations
rank
prob
ml
algorithm
irrelevant
suitable
extremely
relevant
candidate
relevance
classes
uncertain
predictions
ranking
function
work
rank
prob
0.6
0.3
0.07
0.03
distribution
rankings
figure
overview
setting
using
students
ranked
employer
potential
interviews
observations
given
students
resume
coding
abilities
fed
machine
learning
algorithm
produces
distributions
relevance
classes
irrelevant
suitable
extremely
relevant
candidate
ranking
function
takes
input
uncertain
predictions
produce
distribution
rankings
three
candidates
although
may
appear
x3
qualified
relevant
due
inherent
uncertainty
observations
ranking
function
may
place
x1
x2
rank
one
non-zero
probability
composition
satisfies
natural
generalization
individual
fairness
rankings
result
confirms
stability
desirable
property
ranking
function
light
desirability
stability
next
investigate
ranking
functions
stable
deterministic
ranking
functions
natural
popular
unfortunately
show
section
3.2
stable
deterministic
ranking
functions
constant
trivial
functions
output
ranking
regardless
predictions
deterministic
ranking
functions
anonymous
thus
one
must
choose
stability
anonymity
determinism
providing
significant
evidence
favor
randomization
randomization
stability
anonymity
become
achievable
show
section
3.3
natural
adaptation
uncertainty
aware
ua
ranking
functions
devic
et
al
2023
singh
et
al
2021
case
multiclass
predictions
classifier
indeed
anonymous
stable
investigate
fairness
guarantees
ua
ranking
depth
prove
section
main
result
ua
ranking
naturally
preserves
multiaccuracy
multicalibration
guarantees1
bert-johnson
et
al
2018
kim
et
al
2019
show
predictor
multiaccurate
multicalibrated
ranking
distribution
output
ua
ranking
satisfies
natural
generalization
multiaccuracy
resp
multicalibration
towards
groups
result
can
interpreted
interpolation
individual
group
fairness
notions
ranking
set
subgroups
predictor
multicalibrated
becomes
refined
ua
ranking
predictions
accurately
reflects
ua
ranking
induced
unknown
ground
truth
classes
individuals
investigate
tradeoff
fairness
stability
utility
section
introduce
standard
ranking
utility
model
show
utility
optimal
ranking
function
hope
achieve
stability
fairness
guarantees
similar
ua
also
investigate
ranking
function
provides
guaranteed
tradeoff
stability
fairness
utility
believe
will
useful
practitioners
interested
employing
stable
rankings
practice
finally
section
corroborate
theoretical
results
experimental
evidence
various
notions
stability
rankings
proposed
see
asudeh
et
al
2018
framework
unique
frames
rankings
induced
predictions
machine
learning
algorithm
ties
work
closely
modern
applications
another
benefit
definition
stability
makes
progress
towards
broader
goal
rankings
compose
fair
predictors
multiaccuracy
requires
uncertainty
estimates
predictor
unbiased
set
subgroups
combating
discrimination
groups
multicalibration
guarantees
estimates
also
calibrated
subgroups
combating
discrimination
within
groups
arguably
popular
notions
fairness
settings
uncertain
predictions
predictors
output
uncertainty
estimates
since
obtaining
meaningful
accurate
estimates
level
individuals
usually
computationally
statistically
infeasible
1.2
related
work
fairness
ranking
far
relevant
related
work
dwork
et
al
2019
also
interested
fair
rankings
induced
predictors
importantly
restrict
focus
deterministic
rankings
better
prediction
means
individual
will
always
receive
higher
rank
induced
probabilistic
binary
predictors
indeed
motivating
example
setting
small
perturbations
predictor
can
massively
impact
induced
ranking
requiring
stability
ranking
functions
approach
problem
fundamentally
differently
allow
indeed
require
non-deterministic
rankings
multiaccuracy
multicalibration
guarantees
dwork
et
al
2019
induced
rankings
predictors
similar
flavor
however
fundamental
difference
show
guarantee
compatible
stability
furthermore
guarantees
hold
position
ranking
intersection
group
individually
fair
rankings
work
gorantla
et
al
2023
similar
show
one
can
sample
distribution
rankings
simultaneously
individually
group
fair
proportional
representation
sense
laminar
groups
contrast
group
fairness
hinges
group-level
statistical
constraints
multicalibration
imposed
underlying
predictor
instead
allow
potentially
arbitrarily
overlapping
groups
garcı
a-soriano
bonchi
2021
also
work
intersection
group
individual
fairness
rankings
although
group
fairness
constraints
require
certain
groups
get
representation
amongst
top-k
positions
ranking
works
broadly
explore
interplay
group
individual
fairness
constraints
far
rich
literature
group
individually
fair
rankings
cover
restrict
attention
works
related
uncertainty
fairness
comprehensive
overview
interested
reader
referred
survey
zehlike
et
al
2021
uncertainty
rankings
rastogi
joachims
2023
investigate
fairness
uncertainty
aware
rankings
uncertainty
estimates
may
biased
different
subgroups
work
simpler
setting
assume
uncertainty
estimates
unbiased
mehrotra
celis
2021
mehrotra
vishnoi
2022
investigate
uncertain
protected
attributes
settings
subset
selection
ranking
respectively
assume
anything
known
individuals
protected
attributes
instead
require
utilizing
output
group-fair
multiaccurate
predictor
section
training
predictor
however
will
require
certain
knowledge
protected
attributes
see
kim
et
al
2019
independently
line
work
ua
rankings
devic
et
al
2023
singh
et
al
2021
shen
et
al
2023
propose
ranked
proportionality
shares
similar
definition
work
general
setting
assignment
problem
uncertain
priorities
focus
algorithmic
approaches
achieving
variety
fairness
notions
simultaneously
tang
et
al
2023
also
consider
fair
assignment
problem
connections
calibration
work
instead
focused
proving
certain
properties
rankings
induced
predictors
predictors
stated
language
shen
et
al
2023
may
induce
uncertain
priorities
generally
fairness
uncertain
decision
making
tahir
et
al
2023
consider
different
sources
uncertainty
can
impact
fairness
guo
et
al
2023
utilize
conformal
prediction
techniques
feasibly
train
fair
learn-to-rank
models
also
partially
interested
similar
notion
stability
cohen
et
al
2021
guiver
snelson
2008
penha
hauff
2021
soliman
ilyas
2009
yang
et
al
2022
also
work
area
ranking
uncertain
scores
preferences
contrast
works
simultaneously
consider
uncertainty
fairness
stability
rankings
heuss
et
al
2023
also
model
uncertainty
bayesian
framework
allows
apply
method
post-hoc
arbitrary
retrieval
models
hopes
reducing
bias
perhaps
relevant
work
yang
et
al
2023
examine
rankings
utility
fairness
uncertainty
simultaneously
find
modeling
uncertainty
can
actually
improve
utility
cases
relative
fair
ranking
metrics
calibration
ranking
section
work
multi
calibrated
predictors
within
ranking
community
investigation
impact
calibration
ranking
models
menon
et
al
2012
initiated
study
attempting
obtain
predicted
probabilities
based
score
output
ranking
model
kweon
et
al
2022
work
similar
setting
refine
method
obtaining
predicted
probabilities
yan
et
al
2022
work
score-and-sort
model
scoring
function
learned
score
individual
ranking
function
derived
sorting
individuals
according
scores
yan
et
al
2022
aim
ensure
scoring
model
calibrated
respect
external
property
works
attempt
infer
uncertainty
scoring
function
whereas
assume
uncertainty
given
form
machine-learned
predictions
busa-fekete
et
al
2011
show
calibration
ranking
functions
can
help
increase
diversity
rankings
recently
diciccio
et
al
2023
show
conditional
predictive
parity
notion
appears
related
multicalibration
can
help
decrease
bias
rankings
works
highlight
benefits
using
calibrated
predictive
models
ranking
outside
guarantees
provide
korevaar
et
al
2023
relate
calibration
exposure
rankings
comparing
rankings
attained
subgroups
similar
score
distributions
stability
rankings
information
retrieval
literature
asudeh
et
al
2018
also
study
notion
stability
rankings
work
setting
score
calculated
based
weighted
sum
features
item
stability
respect
small
changes
weights
however
notion
stability
based
geometric
intuition
scoring
function
dual
holds
fixed
data
set
furthermore
state
stability
property
scoring
function
particular
weighted
sum
features
contrast
explicitly
defining
stability
property
ranking
function
maps
set
predictions
data
set
randomized
ranking
oh
et
al
2022
also
study
sensitivity
rankings
however
context
slightly
different
examine
stability
respect
user
interactions
recommendation
system
recent
followup
work
oh
et
al
2024
authors
also
provide
algorithm
empirically
achieve
stability
setting
bruch
et
al
2020
provide
experimental
evidence
showing
randomization
can
help
stability
define
robustness
training
learning-to-rank
models
theoretical
results
complementary
corroborate
empirical
evidence
bruch
et
al
2020
randomized
rankings
robust
noise
deterministic
ones
finally
terms
interplay
prediction
systems
rankings
work
narasimhan
et
al
2020
perhaps
relevant
show
ranking
problem
can
considered
pairwise
binary
classification
problem
items
determine
item
placed
higher
rank
notation
preliminaries
write
vectors
boldface
use
standard
notation
denote
vector
ith
coordinate
removed
random
event
write
1e
indicator
function
happens
otherwise
total
variation
distance
two
measures
defined
maximum
difference
probability
event
two
measures
dtv
maxe
will
use
entry-wise
matrix
norms
mi
maxi
mi
denotes
set
individuals
contains
humans
ads
service
requests
entities
towards
fairness
desired
elements
can
labeled
labels
label
set
work
multiclass
ordinal
classification
setting
labels
sorted
least
preferred
notation
corresponds
intuition
possessing
higher
merit
score
class
valued
decision
maker
common
special
case
binary
labels
label
might
represent
irrelevant
unsuitable
label
represents
relevant
suitable
2.1
predictors
focus
predictors
multiclass
setting
output
distributions
labels
let
denote
set
distributions
probabilistic
predictor
function
mapping
data
points
distributions
labels
let
denote
vector
probabilities
predictor
assigns
rather
induced
norms
typically
described
notation
individual
class
pℓ
denotes
probability
class
example
probabilistic
binary
predictor
context
determining
whether
candidate
qualified
job
p2
capture
probability
individual
qualified
p1
p2
probability
unqualified
rankings
involve
multiple
individuals
hence
multiple
predictions
prediction
individuals
matrix
row
corresponds
distribution
labels
particular
individual
define
pn
set
predictions
individuals
set
matrices
row
distribution
will
frequently
consider
case
predictor
single
individuals
applied
individuals
separately
vector
x1
xn
individuals
write
x1
xn
matrix
predictions
individuals
use
random
variable
λx
denote
random
label
individual
pwe
specifically
consider
individual
xi
vector
individuals
abbreviate
λi
λxi
write
1λi
random
variable
number
individuals
label
use
notation
domain
will
pl
clear
context
extend
notation
write
number
individuals
label
better
similarly
pfor
will
sometimes
restrict
count
individuals
particular
set
write
ns
1λi
similarly
derived
notation
particular
use
notation
number
individuals
particular
label
2.2
rankings
ranking
functions
principal
like
use
predictions
provided
predictor
output
distribution
rankings
examples
consider
site
service
linkedin
providing
employer
ranked
list
applicants
interview
geyik
et
al
2019
online
platform
deciding
order
display
ads
vendors
visitor
settings
attention
limited
resource
common
approach
principal
rank
items
question
based
function
predictions
ranking
total
order
individuals
randomized
ranking
distribution
rankings
let
mn
ds
denote
set
doubly
stochastic
matrices
matrix
mds
represents
randomized
ranking
individuals
mi
probability
individual
ranked
position
reasoning
random
rankings
use
ri
denote
random
event
individual
receives
position
ranking
refer
mappings
predictions
randomized
rankings
ranking
functions
definition
ranking
function
pn
mn
ds
maps
predictions
labels
data
set
individuals
randomized
ranking
individuals
focusing
ranking
functions
implicitly
state
principal
interacts
data
set
predictions
labels
consider
listwise
learning-to-rank
schemes
cao
et
al
2007
xu
li
2007
principal
directly
learns
function
mapping
data
sets
individuals
features
rankings
2.3
desiderata
ranking
functions
ranking
functions
general
natural
requirements
make
reasonable
used
particular
focus
following
basic
properties
definition
anonymity
ranking
function
pn
mn
ds
anonymous
every
permutation
predictions
individuals
results
identical
permutation
individuals
ranks
anonymity
states
outcome
individual
depends
everyone
else
prediction
index
individual
appeared
data
set
identity
essential
fairness
requirement
virtually
settings
precisely
represents
marginal
probabilities
distribution
can
typically
implemented
many
different
distributions
rankings
assume
individuals
care
probabilities
ranked
position
case
marginal
distributions
sufficiently
capture
fairness
second
essential
property
ranking
functions
stability
small
changes
predictions
lead
small
changes
rankings
definition
stability
fix
ranking
function
pn
mn
ds
γ-stable
predictions
pn
particularly
important
predictions
result
ml-based
training
methods
will
always
contain
non-trivial
amounts
noise
indeed
lack
stability
well-documented
problematic
aspect
many
ml-systems
shown
within
fairness
literature
cooper
et
al
2024
long
concern
image
classification
models
goodfellow
et
al
2015
recently
also
llms
zou
et
al
2023
predictions
rankings
first
show
useful
fairness
consequences
stability
combining
stable
ranking
function
individually
fair
predictor
results
fair
ranking
outcomes
show
stability
anonymity
fundamentally
odds
determinism
constant
deterministic
ranking
functions
stable
deterministic
ranking
function
anonymous
establishes
randomization
inherently
necessary
ranking
function
meaningful
anonymous
stable
present
adaptation
ua
ranking
function
singh
et
al
2021
show
anonymous
stable
3.1
consequences
stability
stability
implies
small
changes
predictions
change
distribution
rankings
much
two
immediate
noteworthy
consequences
predictions
made
individually
fair
predictor
similar
individuals
will
ranked
similarly
predictions
approach
ground
truth
ranking
distribution
produced
ranking
function
approaches
rankings
ground
truth
formalize
first
claim
recall
seminal
definition
individually
fair
predictor
dwork
et
al
2012
notion
assumes
metric
defined
capturing
relevant
measure
similarity
individuals
probabilistic
predictor
individually
fair
proposition
let
individually
fair
predictor
pn
mn
ds
anonymous
γ-stable
ranking
function
given
data
set
individuals
xi
associated
predictions
xi
pn
let
ith
th
rows
respectively
2βγ
xi
xj
proof
proof
straightforward
application
γ-stability
respect
given
prediction
matrix
matrix
exactly
rows
swapped
requiring
anonymity
condition
combined
definition
individual
fairness
completes
proof
result
can
interpreted
composition
guarantee
anonymous
stable
rankings
individually
fair
predictors
simultaneously
data
set
difference
distributions
rankings
can
proportional
dissimilarity
metric
another
interpretation
following
stability
individual
fairness
lipschitz
conditions
composition
lipschitzness
implies
individually
fair
predictor
combined
stable
ranking
will
induce
individually
fair
ranking
another
straightforward
desirable
consequence
stability
obtained
considering
one
prediction
ground
truth
obtained
learned
classifier
corollary
let
ground
truth
label
distribution
individual
learned
predictor
assume
ϵ-accurate
satisfying
γ-stable
ranking
function
guarantees
nϵ
put
differently
stable
ranking
function
accurate
individual
level
uncertainty
estimates
relative
ground
truth
will
induce
accurate
individual
level
rankings
although
somewhat
obvious
highlight
property
stability
since
ground
truth
approach
often
central
assumption
study
machine
learned
predictors
shalev-shwartz
ben-david
2014
3.2
stability
determinism
incompatible
third
property
rankings
used
practice
possess
often
considered
desirable
practitioners
determinism
given
inputs
one
ranking
rather
distribution
rankings
can
result
definition
determinism
ranking
function
pn
mn
ds
deterministic
iff
pn
resulting
distribution
rankings
entries
perhaps
well-known
deterministic
ranking
function
given
probability
ranking
principle
prp
robertson
1977
setting
binary
predictions
ranking
function
sorts
individuals
decreasing
probability
belonging
class
qualified
naturally
one
may
ask
whether
deterministic
ranking
function
like
prp
can
stable
anonymous
unfortunately
neither
possible
captured
following
proposition
deterministic
ranking
function
pn
mn
ds
anonymous
furthermore
deterministic
stable
ranking
function
must
constant
sense
im
ranking
function
outputs
ranking
input
predictions
proof
prove
impossibility
anonymity
consider
prediction
matrix
identical
predictions
individual
deterministic
ranking
function
must
order
individuals
based
indices
since
identical
predictions
permutation
let
pσ
represent
applying
permutation
rows
since
ranking
function
can
depend
input
matrix
deterministic
pσ
however
definition
anonymity
definition
permutation
rows
produce
permutation
individuals
resulting
ranking
contradiction
therefore
anonymous
prove
instability
result
prove
contrapositive
let
deterministic
non-constant
will
show
stable
non-constant
exist
pn
consider
straight
line
βp
pn
convex
pn
let
inf
well-defined
definition
hand
definition
infimum
every
thus
obtain
arbitrarily
close
pairs
deterministic
entries
implying
hand
2δ
implies
stable
completing
proof
remark
instability
portion
proof
rely
considering
straight
line
considering
path
curve
rn
connecting
parametrization
exact
proof
still
works
shows
even
consider
subset
possible
predictions
long
subset
path-connected4
deterministic
stable
ranking
function
must
constant
extends
proposition
settings
prediction
strategies
may
output
certain
path-connected
subsets
predictions
due
example
intrinsic
preferences
implicit
bias
particular
learning
algorithm
proposition
formalizes
intuition
randomness
required
achieve
stability
indeed
main
results
work
also
show
randomization
resulting
stability
crucial
achieving
desirable
fairness
guarantees
recall
set
path-connected
every
pair
elements
exists
continuous
path
entirely
contained
within
3.3
uncertainty
aware
rankings
meaningful
deterministic
ranking
functions
stable
fact
immediate
exist
non-constant
stable
ranking
functions
now
show
uncertainty
aware
ua
rankings
introduced
singh
et
al
2021
anonymous
stable
ua
rankings
originally
introduced
via
axiomatization
probabilistic
ranking
considered
fair
given
merit
distributions
devic
et
al
2023
refined
axiomatization
combining
notions
meritocracy
lifting
deterministic
decision
making
decision
making
uncertainty
definition
singh
et
al
2021
assumed
merit
distributions
continuous
ties
occurred
probability
motivated
predictors
output
distributions
discrete
label
sets
irrelevant
suitable
extremely
relevant
corresponding
total
order
adapt
definition
ua
rankings
definition
uncertainty
awareness
singh
et
al
2021
randomized
ranking
mn
ds
uncertainty
aware
prediction
pn
individual
position
entry
mi
probability
th
highest
label
labels
λi
pi
sampled
independently
respective
distributions
pi
ties
broken
uniformly
formally
conditioned
drawn
labels
λi
individuals
entail
counts
labels
probability
individual
obtain
rank
ri
λi
otherwise
ranking
function
pn
mn
ds
uncertainty
aware
uncertainty
aware
pn
definition
uncertainty
awareness
fully
prescribes
ranking
distribution
given
prediction
shown
lemma
4.2
singh
et
al
2021
unique
uncertainty
aware
ranking
function
given
henceforth
denote
rua
intuitively
fairness
ua
can
interpreted
possible
futures
viewpoint
given
two
individuals
merit
60
futures
merits
labels
sampled
respective
distributions
ua
implements
requirement
allocation
present
respect
uncertainty
give
better
rank
least
60
time
least
40
time
entails
need
randomization
refer
reader
devic
et
al
2023
singh
et
al
2021
formal
argument
fairness
ua
ranking
first
key
insight
proving
properties
ua
rankings
taking
account
randomness
draws
labels
tie
breaking
rank
distribution
produced
ua
ranking
can
summarized
follows
proposition
let
pn
prediction
rua
ranking
distribution
produced
rua
probability
individual
ranked
position
pp
prua
ri
pi
prua
ri
λi
prua
ri
λi
proof
first
part
observe
probability
ri
depends
considering
possible
values
gives
non-zero
probability
obtain
prua
ri
λi
pp
λi
result
obtained
noticing
conditioned
λi
second
part
proposition
simply
states
law
total
probability
also
remark
definition
singh
et
al
2021
contrast
definition
require
labels
merits
different
individuals
sampled
independently
respective
distributions
pi
add
independence
requirement
facilitate
connections
learning
algorithms
predictors
added
benefit
independence
assumption
makes
possible
explicitly
compute
rua
polynomial
time
captured
following
proposition
note
contrast
case
possibly
correlated
labels
merits
previous
work
devic
et
al
2023
singh
et
al
2021
indeed
main
technical
contribution
works
analyzing
loss
fairness
utility
incurred
due
imperfectly
approximating
rua
via
sampling
proposition
10
exists
algorithm
given
pn
exactly
computes
rua
time
n4
n3
proof
two
parts
proposition
combined
imply
order
compute
row
rua
sufficient
compute
pp
pairs
accomplished
dynamic
program
similar
standard
undergraduate
exercise
compute
poisson
binomial
distribution
explicitly
notational
convenience
assume
solely
avoid
special
case
recurrence
also
without
loss
generality
anonymity
ua
rule
let
pp
probability
among
first
individuals
exactly
label
exactly
label
strictly
better
values
can
construct
necessary
quantities
pp
give
recurrence
relationship
base
cases
individuals
possible
numbers
individuals
given
labels
now
consider
probability
pt
individual
label
case
desired
event
happens
pindividuals
among
first
label
labels
strictly
better
probability
pt
individual
label
strictly
better
case
desired
event
happens
individuals
pamong
first
label
labels
strictly
better
finally
probability
pt
individual
label
strictly
worse
case
desired
event
happens
individuals
among
first
label
labels
strictly
better
three
cases
disjointly
cover
possibilities
label
derived
following
recurrence
pt
pt
pt
avoid
case
distinctions
whether
treat
whenever
negative
notice
fixed
values
pt
prefix
sums
can
pre-computed
time
thus
precomputation
can
performed
time
nl
one
entry
can
computed
constant
time
previously
computed
values
table
size
n3
total
computation
takes
time
n3
summing
possible
values
total
time
compute
entire
ranking
distribution
rua
n4
n2
finally
post-processing
computing
pp
fixed
can
implemented
time
using
differences
prefix
sums
thus
values
can
computed
time
n3
gives
total
time
n4
n3
10
notion
use
uncertainty
aware
rankings
may
appear
primarily
theoretical
interest
fact
used
practice
example
nba
draft
lottery
can
understood
lens
uncertainty
aware
rankings
merit
team
need
better
choice
picks
can
imperfectly
inferred
team
performance
previous
season
draft
order
obtained
weighted
lottery
based
uncertain
merits
now
present
central
result
section
uncertainty
aware
ranking
function
anonymous
stable
theorem
11
let
rua
pn
mn
ds
ua
ranking
function
individuals
labels
rua
anonymous
stable
following
lemma
key
part
proof
stability
bounds
different
probabilities
individual
obtaining
rank
can
two
different
prediction
matrices
function
similar
matrices
lemma
12
let
pn
two
different
prediction
matrices
individual
let
pi
qi
ith
rows
respectively
label
distributions
individual
two
predictions
let
individual
position
label
prua
ri
λi
prua
ri
λi
dtv
pi
qi
defer
proof
lemma
12
appendix
proof
theorem
11
first
ua
ranking
rule
obviously
anonymous
simply
symmetric
definition
treats
indices
identically
thus
focus
proving
stability
now
let
individual
rank
given
equation
second
part
proposition
ri
pi
ri
λi
now
consider
two
different
predictors
bound
difference
probabilities
ranked
position
follows
prua
ri
prua
ri
pi
prua
ri
λi
qi
prua
ri
λi
pi
qi
prua
ri
λi
qi
prua
ri
λi
prua
ri
λi
pi
qi
qi
prua
ri
λi
prua
ri
λi
lemma
12
can
bound
prua
ri
λi
prua
ri
λi
dtv
pi
qi
substituting
bound
back
now
obtain
prua
ri
prua
ri
pi
qi
qi
dtv
pi
qi
dtv
pi
qi
dtv
pi
qi
final
step
absorbed
total
variation
distance
sum
larger
coefficient
used
norm
exactly
twice
total
variation
distance
number
labels
increases
predictor
can
provide
ranking
function
fine-grained
information
allow
ua
ranking
function
produce
wider
class
distributions
rankings
next
proposition
shows
indeed
case
11
proposition
13
expressivity
uncertainty
aware
ranking
functions
strictly
increasing
formally
let
rua
pn
mds
rua
pn
mn
ds
corresponding
ua
ranking
functions
rua
pn
rua
pn
proof
first
see
monotonicity
notice
adding
column
entries
unused
label
change
behavior
rua
pn
writing
pn
matrix
rua
rua
implying
rua
pn
rua
pn
prove
strictness
inclusion
consider
prediction
jn
individuals
jn
row-reversed
identity
matrix
ones
along
anti-diagonal
individual
deterministically
known
label
rua
identity
matrix
individual
ranked
deterministically
position
proved
rua
pn
note
due
tie
breaking
rua
achieve
deterministic
ranking
two
individuals
must
ever
label
supports
rows
prediction
matrix
yielding
rua
must
disjoint
implies
must
least
columns
rua
pn
completing
proof
strictness
inclusion
using
proposition
13
can
show
stability
analysis
essentially
tight
factor
ruling
possibility
example
n1
stability
ua
rankings
proposition
14
rua
γ-stable
21
proof
let
given
consider
suffices
proposition
13
embed
following
instance
ignore
extra
labels
consider
prediction
matrix
individual
prediction
p1
individuals
prediction
p2
similarly
prediction
matrix
will
individual
prediction
individuals
prediction
p2
identical
except
individual
let
rua
rua
resulting
probabilities
placing
individuals
specific
positions
since
individuals
except
individual
deterministic
qualifications
50
probability
individual
ranked
last
m1
whereas
m1
therefore
following
rua
rua
m1
m1
thus
rua
γ-stable
multigroup
fairness
guarantees
now
present
main
result
ua
rankings
naturally
compose
multiaccurate
multicalibrated
predictors
shown
ua
rankings
stable
furthermore
stable
rankings
compose
harmoniously
individually
fair
predictors
corollary
demonstrates
accurate
predictor
individual
level
can
combine
stable
ranking
function
ua
induce
ranking
close
underlying
ground
truth
practice
however
obtaining
accurate
uncertainty
estimates
individual
level
strong
assumption
arbitrary
data
sets
individuals
requirement
equivalent
learning
bayes
optimal
predictor
true
distribution
labels
conditioned
features
individual
shalev-shwartz
ben-david
2014
section
3.2
generally
requires
number
samples
running
time
exponential
dimensionality
features
used
prediction
can
statistically
computationally
infeasible
instead
focus
obtaining
coarser
guarantee
ua
rankings
level
subgroups
domain
data
sets
sampled
distribution
individuals
instead
arbitrary
data
sets
assumption
standard
setting
machine
learning
proven
useful
many
practical
settings
contributions
tightly
connected
statistical
group-fairness
conditions
multiaccuracy
multicalibration
bert-johnson
et
al
2018
kim
et
al
2019
guarantees
will
meaningful
since
directly
imply
relative
underlying
ground
truth
unbiased
predictors
will
induce
unbiased
rankings
12
4.1
group-wise
accuracy
guarantees
first
recall
definitions
multiaccuracy
multicalibration
fair
machine
learning
literature
state
result
average
accuracy
rankings
induced
multiaccurate
multicalibrated
predictors
compared
rankings
induced
nature
definition
15
multiaccuracy
multicalibration
bert-johnson
et
al
2018
kim
et
al
2019
let
distribution
individuals
let
ground
truth
distribution
labels
true
distribution
labels
individual
predictor
predicted
label
distribution
let
collection
sets
predictor
multiaccurate
multcalibrated
let
parameter
far
fully
accurate
calibrated
predictor
allowed
writing
vector-valued
quantity
mean
coordinate-wise
expectations
multiaccurate
every
set
ex
1x
given
groups
label
expected
probability
mass
label
approximately
predictor
ground
truth
let
interval
width
given
integer
multicalibrated
every
set
vector
j1
j2
jl
ex
1x
jℓ
jℓ
addition
fixing
group
even
also
fix
rough
interval
within
predicted
probability
mass
must
lie
predictor
still
close
ground
truth
possible
label
set
represents
protected
group
import
underlying
population
sets
can
complex
overlapping
nested
laminar
etc
since
multiaccuracy
multicalibration
respect
contrast
notions
group
fairness
supervised
learning
equalized
odds
awasthi
et
al
2020
equality
opportunity
hardt
et
al
2016
statistically
sound
consistent
underlying
ground
truth
variety
learning
post-processing
algorithms
terms
sample
time
complexity
efficiently
achieve
multiaccuracy
multicalibration
gopalan
et
al
2022
haghtalab
et
al
2023
bert-johnson
et
al
2018
kim
et
al
2019
now
present
central
contribution
section
multicalibration
multiaccuracy
predictor
guarantee
per
group
basis
ua
rankings
derived
will
close
ua
rankings
derived
ground
truth
theorem
16
let
distribution
individuals
let
ground
truth
distribution
labels
predictor
let
dn
distribution
obtained
drawing
vector
samples
let
collection
sets
sets
individuals
predictor
will
assumed
multiaccurate
multcalibrated
let
parameter
far
fully
accurate
calibrated
predictor
allowed
multiaccurate
following
holds
sets
ex
dn
unif
1xi
prua
ri
prua
ri
lnα
let
interval
width
given
integer
multicalibrated
multiaccurate
every
set
vector
j1
j2
jl
ex
dn
unif
1xi
1f
xi
jℓ
jℓ
prua
ri
prua
ri
lnα
13
proof
fix
set
position
proofs
parts
theorem
essentially
identical
minor
practically
syntactic
changes
will
give
proofs
simultaneously
pointing
places
differences
occur
proof
second
part
theorem
case
multi-calibrated
predictor
let
given
integer
fix
vector
j1
j2
jl
use
notation
denote
1x
proof
multiaccurate
predictor
denote
1x
1f
jℓ
jℓ
proof
multicalibrated
predictor
first
observe
can
simplify
notation
using
draws
xj
can
apply
law
total
probability
ex
dn
unif
xi
prua
ri
prua
ri
ex
dn
xn
prua
rn
prua
rn
exn
xn
ex
dn
prua
xn
rn
prua
xn
rn
next
sum
possible
labels
λn
condition
labels
individual
omit
probabilities
random
variables
affect
probability
rewrite
preceding
expression
exn
xn
ex
dn
pf
xn
λn
prua
xn
rn
λn
pf
xn
λn
prua
xn
rn
λn
exn
xn
ex
dn
pf
xn
λn
prua
rn
λn
pf
xn
λn
prua
rn
λn
exn
xn
ex
dn
pf
xn
λn
pf
xn
λn
prua
rn
λn
exn
xn
ex
dn
pf
xn
λn
prua
rn
λn
prua
rn
λn
exn
xn
pf
xn
λn
pf
xn
λn
ex
dn
prua
rn
λn
exn
xn
pf
xn
λn
ex
dn
prua
rn
λn
prua
rn
λn
bound
two
sums
separately
first
sum
simply
bound
exn
xn
pf
xn
λn
pf
xn
λn
final
step
applied
multi-accuracy
guarantee
every
label
sum
first
part
theorem
multi-calibration
guarantee
j1
jl
every
label
second
part
theorem
14
second
term
apply
triangle
inequality
bound
exn
pf
xn
λn
ex
dn
prua
rn
λn
prua
rn
λn
first
equation
first
part
proposition
ex
dn
prua
rn
λn
ex
dn
pf
label
drawn
first
drawing
xi
drawing
λi
xi
label
distribution
exactly
ex
take
expectation
vectors
componentwise
writing
pn
matrix
rows
pi
can
therefore
write
ex
dn
prua
rn
λn
pp
prua
rn
λn
identical
argument
applies
instead
writing
ex
pn
matrix
rows
qi
can
write
ex
dn
prua
rn
λn
prua
rn
λn
combining
calculations
applying
lemma
12
can
bound
ex
dn
prua
rn
λn
prua
rn
λn
prua
rn
λn
prua
rn
λn
dtv
pi
qi
dtv
pℓ
qℓ
ex
multiaccurate
bound
ex
ex
1x
identical
bound
holds
second
part
theorem
assumed
also
multiaccurate
finally
combine
bounds
obtain
exn
1xn
pf
xn
λn
pf
xn
λn
ex
dn
prua
rn
λn
exn
1xn
pf
xn
λn
ex
dn
prua
rn
λn
prua
rn
λn
exn
pf
xn
λn
nlα
completing
proof
15
theorem
16
can
intuitively
thought
following
predictor
unbiased
average
collection
subgroups
will
induce
uncertainty
aware
ranking
subgroups
similar
outcome
usually
inaccessible
uncertainty
aware
ranking
induced
ground
truth
label
distribution
multicalibration
guarantee
refines
hold
subgroups
intervals
predictions
predictor
within
subgroup
part
theorem
16
requires
simultaneously
multicalibrated
multiaccurate
unbiased
average
across
individuals
sampled
combination
properties
can
achieved
algorithm
gopalan
et
al
2022
4.2
multicalibration
interpolating
group
individual
fairness
contrast
learning
accurate
individual-level
estimates
bayes
optimal
predictor
multiaccuracy
multicalibration
can
achieved
time
samples
polynomial
number
sets
generally
polynomial
measures
complexity
vc-dimension
gopalan
et
al
2022
bert-johnson
et
al
2018
notice
define
cbayes
set
singleton
groups
cbayes
multiaccuracy
guarantees
increasingly
accurate
predictions
individuals
recovers
bayes
optimal
classifier
ground
truth
varying
level
granularity
collection
learned
multiaccurate
multicalibrated
predictor
represents
finer
coarser
approximation
bayes
optimal
classifier
thus
theorem
16
guarantees
induced
ranking
effectively
interpolates
individual
group-level
fair
rankings
granularity
defined
nonetheless
previously
noted
usually
unreasonable
expect
multiaccuracy
multicalibration
level
cbayes
due
information
computational
constraints
multicalibration
algorithms
must
use
poly
samples
learn
multiaccurate
multicalibrated
predictor
shabat
et
al
2020
addition
sample
complexity
requirements
class
must
agnostic
pac
learnable
shalev-shwartz
ben-david
2014
section
3.2
stringent
requirement
rarely
holds
complex
collections
cbayes
practice
envision
theorem
16
used
sufficiently
simple
classes
conjunctions
categorical
features
intervals
numeric
features
women
age
range
45
65
working
level
granularity
permits
efficient
algorithms
obtaining
multiaccurate
multicalibrated
predictors
also
guarantees
derived
rankings
will
unbiased
meaningful
protected
groups
individuals
ranking
functions
utility
online
marketplaces
utilizing
rankings
ranking
functions
also
concerned
utility
revenue
section
introduce
natural
class
utility
models
inspired
literature
standard
taylor
et
al
2008
prove
optimal
utility
ranking
function
achieve
stability
group
fairness
guarantees
ua
rankings
enjoy
show
simple
ranking
function
rmix
randomization
utility-optimal
ua
ranking
function
satisfies
approximate
notion
stability
fairness
simultaneously
retaining
utility
guarantee
may
use
practitioners
broadly
definition
17
utility
model
let
w1
w2
wn
position
weights
function
call
class
utility
map
determines
predictions
mapped
utilities
utility
prediction
matrix
pn
ranking
function
eσ
wk
pσ
wk
pi
pl
particularly
natural
common
type
class
utility
map
expected
utility
vℓ
pℓ
vl
vl
v1
utilities
labels
combined
weights
wk
log2
class
captures
dcg
ja
rvelin
keka
la
inen
2002
example
16
ranking
function
achieves
optimal
utility
will
clearly
depend
denote
ropt
can
simply
described
ranking
function
deterministically
orders
individuals
decreasing
values
pi
recall
pi
ith
row
pn
now
show
general
ropt
stable
demonstrates
necessity
trade
notions
utility
stability
proposition
18
even
binary
labels
expected
utility
map
utility-maximizing
map
ropt
unstable
proof
example
standard
literature
assume
v2
v1
12
define
12
pϵ
21
ropt
pϵ
deterministically
ranks
ahead
ropt
pϵ
deterministically
ranks
ahead
result
ropt
pϵ
ropt
pϵ
pϵ
pϵ
8ϵ
proves
instability
ropt
next
show
extremely
simple
class
instances
namely
two
types
individuals
uniform
distribution
binary
labels
identical
uniform
ground
truth
distribution
two
labels
types
groups
just
two
singleton
types
utility-maximizing
ranking
function
ropt
approach
optimal
multigroup
fairness
never
mind
close
perfectly
multiaccurate
predictor
gets
proposition
19
let
domain
two
types
individuals
let
uniform
distribution
two
types
let
consider
binary
labels
ground
truth
label
distribution
12
12
ground
truth
types
equally
likely
good
bad
let
collection
singleton
subgroups
12
let
fα
predictor
predictions
fα
12
12
fα
12
12
fα
slightly
overestimates
quality
type
slightly
underestimates
quality
type
let
utility
map
strictly
preferring
higher
labels
utility
map
12
12
12
21
let
ropt
utility-maximizing
ranking
function
utility
map
fα
multiaccurate
yet
every
number
individuals
group
fairness
ropt
towards
group
assignment
top
valuable
position
ranking
following
ex
dn
unif
1xi
ri
pr
ri
propt
opt
particular
fixed
quantity
stays
bounded
away
even
intuition
proposition
19
similar
proposition
utility-maximizing
ranking
function
arbitrarily
small
non-zero
predictive
mistake
can
induce
large
variations
resulting
ranking
distribution
preventing
preserving
group
fairness
predictor
proof
first
verify
fα
multiaccurate
ex
1x
fα
max
rest
proof
focuses
group
fairness
analysis
proving
equation
first
consider
ri
first
observe
ground
truth
classifier
term
propt
1n
1n
denotes
all-ones
matrix
input
matrix
ropt
must
distribution
q1
qn
individual
assigned
top
rank
crucially
analysis
ranking
function
observes
matrix
12
1n
must
use
distribution
type
vectors
ri
qi
type
vectors
thus
conclude
propt
ri
focus
type
vector
vector
next
consider
term
propt
least
one
individual
type
fα
fα
ropt
utility-maximizing
17
utility
map
ropt
fα
must
rank
individuals
pn
type
least
one
ahead
ri
individuals
type
obtain
1xi
propt
next
write
expectation
equation
use
terms
1xi
allows
us
drop
term
sum
use
uniform
type
distribution
drawn
probability
substitute
preceding
calculations
probabilities
gives
us
following
ri
pr
ri
ex
dn
unif
1xi
propt
opt
xx
ri
pr
ri
1xi
propt
opt
ri
1xi
qi
1xi
propt
pr
qi
1xi
qi
1xi
2n
qi
2n
2n
2n
step
labeled
used
exactly
2n
vectors
xi
following
step
used
qi
defining
probability
distribution
sum
completes
proof
5.1
utility-stability
tradeoffs
theory
practice
often
necessary
trade
utility
desiderata
fairness
stability
see
example
pitoura
et
al
2022
singh
joachims
2019
achieving
fairness
stability
comes
huge
price
utility
may
become
economically
infeasible
implement
fair
stable
rankings
section
introduce
discuss
class
rmix
ranking
functions
provide
quantifiable
tradeoff
objectives
rmix
linearly
interpolates
rua
ropt
trade-off
parameter
chosen
ranking
mechanism
designer
show
interpolation
naturally
leads
rmix
satisfying
approximate
stability
fairness
providing
lower-bound
guarantees
utility
proofs
relatively
straightforward
believe
practitioners
may
find
class
ranking
functions
useful
practical
applications
stringent
requirement
stability
may
necessary
interested
reader
referred
singh
et
al
2021
additional
discussion
choose
appropriately5
first
formally
define
notion
approximate
stability
definition
20
fix
ranking
function
pn
mn
ds
approximately
stable
predictions
pn
5we
note
approximate
fairness
guarantee
proposition
22
multiaccuracy
multicalibration
additive
slack
different
ϕ-approximate
fairness
singh
et
al
2021
multiplicative
notion
indeed
hold
simultaneously
rmix
18
notice
approximate
stability
recovers
stability
notion
definition
approximate
stability
relaxation
allows
additive
slack
dependence
additive
slack
relaxation
natural
akin
example
differential
privacy
compared
pure
differential
privacy
show
simple
mixture
ua
optimal
utility
ranking
satisfies
following
approximate
stability
utility
guarantee
proposition
21
fix
utility
map
let
rmix
ranking
function
randomizes
rua
probability
ropt
probability
rmix
approximately
stable
furthermore
pn
rmix
rua
ropt
proof
first
show
approximate
stability
pn
following
rmix
rmix
ϕrua
ropt
ϕrua
ropt
rua
rua
ropt
ropt
last
line
used
stability
rua
proved
theorem
11
well
fact
norm
difference
doubly
stochastic
matrices
claim
utility
simply
linearity
expectations
straightforward
show
similar
approximate
fairness
guarantee
holds
rmix
due
linearity
proposition
22
let
distribution
individuals
let
ground
truth
distribution
labels
predictor
let
dn
distribution
obtained
drawing
vector
samples
let
collection
sets
sets
individuals
predictor
will
assumed
multiaccurate
multcalibrated
let
parameter
far
fully
accurate
calibrated
predictor
allowed
multiaccurate
following
holds
sets
ex
dn
unif
1xi
prϕ
ri
prϕ
ri
ϕlnα
mix
mix
let
interval
width
given
integer
multicalibrated
multiaccurate
every
set
vector
j1
j2
jl
ex
dn
unif
1xi
1f
xi
jℓ
jℓ
prua
ri
prua
ri
ϕlnα
proof
proof
follows
following
computation
due
linearity
rmix
prmix
ri
prmix
ri
prua
ri
propt
ri
ri
prua
ri
propt
applying
decomposition
applying
linearity
expectation
applying
triangle
inequality
using
theorem
16
completes
proof
parts
19
experiments
stability
utility
ran
experiments
us
census
data
set
acs
curated
ding
et
al
2021
student
dropout
task
enrollment
introduced
martins
et
al
2021
uci
data
set
repository
experiments
demonstrate
empirically
stability
guarantees
ua
rankings
hold
using
multiclass
predictions
furthermore
find
practice
stability
guarantees
offered
ua
ranking
may
much
better
stability
stability
worst-case
lower
bound
proposition
14
show
utility
loss
suffered
rua
reasonable
although
experiments
relatively
simplistic
main
focus
work
demonstrate
ua
rankings
relatively
good
performance
terms
utility
outperform
uniformly
random
baseline
ranking
even
plackett-luce
distribution
time
also
retain
provable
fairness
stability
properties
related
experiments
previous
work
devic
et
al
2023
singh
et
al
2021
also
contain
experiments
demonstrating
utility
utility-fairness
tradeoff
ua
ranking
functions
past
work
assumed
real-valued
predictions
opposed
multiclass
predictions
work
singh
et
al
2021
actually
deployed
paper
recommendation
system
large
computer
science
conference
using
ua
rankings
demonstrate
viability
method
practice
furthermore
experiments
movielens
data
set
harper
konstan
2015
demonstrate
ua
ranking
corresponding
fairness
parameter
work
can
achieve
nearly
99
optimal
utility
given
ropt
applications
devic
et
al
2023
show
viability
ua
rankings
matching
setting
running
experiments
online
dating
data
set
6.1
stability
sgd
noise
neural
network
training
given
focus
combination
ranking
functions
noisy
predictions
derived
ml-based
classifiers
first
investigate
experimentally
stability
ua
utility-maximizing
rankings
natural
model
prediction
noise
particular
one
common
sources
noise
predictions
randomness
training
procedure
sgd
designed
natural
experiment
comparing
behavior
ranking
functions
predictors
learned
different
randomly
seeded
sgd
training
runs
focus
understanding
extent
stability
ua
ranking
functions
will
exceed
worst-case
theoretical
guarantees
quasi-realistic
settings
first
describe
data
sets
acs
prediction
target
binary
variable
whether
person
employed
filtering
individuals
age
range
16
90
computational
reasons
restrict
experiments
subset
data
california
parameters
survey
year
2018
horizon
1year
survey
person
parameters
standard
using
acs
testing
algorithmic
fairness
methods
due
large
amount
available
data
see
github
repository
ding
et
al
2021
left
378
817
entries
use
80
20
train
test
split
enrollment
target
multiclass
variable
whether
individual
enrolled
graduated
dropout
student
cleaning
data
left
424
entries
use
80
20
train
test
split
since
want
compare
stability
rua
ropt
next
define
simple
natural
utilities
acs
take
class
correspond
employment
class
correspond
unemployment
class
class
define
p2
probability
employment
enrollment
take
class
student
dropped
class
enrolled
class
graduated
class
class
class
define
p1
p2
p3
train
30
simple
three-layer
mlp
neural
networks
acs
data
set
divide
15
pairs
networks
pair
networks
initialized
random
weight
matrix
trained
separately
sgd
introduces
noise
final
trained
neural
network
weights
consequently
predictions
pair
networks
similar
test
accuracy
will
output
different
probabilities
individuals
acs
networks
achieve
75
80
train
test
accuracy
perform
identical
procedure
enrollment
data
set
networks
achieve
70
75
train
test
accuracy
due
less
data
available
20
let
fi
gi
15
classifiers
corresponding
given
pair
networks
trained
initialization
different
noise
due
sgd
test
stability
ranking
functions
rua
ropt
pair
fi
gi
randomly
select
30
individuals
test
set
data
set
individuals
obtain
probabilistic
predictions
fi
gi
run
ropt
rua
two
prediction
matrices
logging
deviations
rankings
resulting
value
pair
networks
fi
gi
repeat
procedure
10
times
different
randomly
selected
subsets
individuals
table
report
average
standard
deviation
experiment
quantity
acs
enrollment
rua
rua
ropt
ropt
0.011
0.002
0.947
0.224
0.971
0.582
0.012
0.002
0.680
0.466
0.653
0.453
table
measured
stability
30
neural
network
training
runs
15
pairs
networks
10
data
sets
30
individuals
norm
ua
deviation
bounded
confirms
stability
ua
theorem
11
instability
ranking
ropt
also
demonstrated
proposition
18
results
table
demonstrate
dominates
value
rua
rua
behavior
persisted
many
training
runs
conclude
ua
rankings
extremely
stable
face
noise
introduced
learning
predictor
drastically
surpassing
stability
bound
results
also
confirm
instability
optimal
ranking
function
ropt
theoretical
possibility
prevalent
working
real
data
see
notice
mean
value
ropt
ropt
two
orders
magnitude
larger
rua
enrollment
data
set
even
exceeds
mean
value
implying
impossible
acs
data
set
norms
comparable
meaning
impossible
fact
consistent
large
standard
deviations
multiple
instances
illustrating
must
significantly
larger
data
sets
6.2
utility
next
measure
utility
attained
different
ranking
functions
utility
map
data
sets
one
section
6.1
addition
two
rankings
functions
primary
interest
also
consider
following
two
baselines
runif
ranking
function
places
individuals
uniformly
random
order
rpl
plackett-luce
pl
ranking
defined
luce
axiom
luce
1959
plackett
1975
pl
model
similar
ua
defines
distribution
rankings
high
level
iteration
item
ith
position
sampled
based
softmax
mapping
remaining
items
relevance
scores
precisely
iteration
let
mt
set
individuals
yet
placed
ranking
m1
first
iteration
iteration
individual
mt
placed
position
probability
exp
pi
ri
mt
exp
pj
efficiently
compute
pl
ranking
use
now
standard
gumbel
trick
bruch
et
al
2020
sample
one
ranking
pl
ranking
distribution
rpl
sort
individuals
decreasing
order
pi
γi
γi
gumbel
independently
average
100k
samples
pl
ranking
distribution
compute
rpl
measure
utility
use
dcg
position
weights
wk
log2
order
make
scales
utilities
meaningful
comparisons
normalize
utilities
lie
thereto
let
rmin
worst-utility
ranking
obtained
ordering
individuals
increasing
relevance
score
individual
lowest
utility
deterministically
placed
first
ranking
function
compute
21
normalized
utility
score
follows
rmin
ropt
min
table
report
mean
standard
deviation
30
neural
network
training
runs
normalized
utility
ranking
functions
discussed
neural
network
associated
prediction
function
randomly
sample
20
40
60
individuals
test
set
construct
prediction
matrix
xi
report
ranking
function
find
ua
ranking
outperforms
uniform
pl
ranking
experimental
instance
however
ua
ranking
guaranteed
always
outperform
uniform
ranking
one
can
carefully
construct
instances
safe
bet
individual
provides
utility
individual
low
probability
moonshot
candidate
discussed
singh
et
al
2021
instance
crucially
depends
specific
choice
20
40
60
rua
rpl
runif
0.726
0.027
0.616
0.038
0.540
0.043
0.724
0.027
0.621
0.028
0.548
0.029
0.727
0.020
0.624
0.023
0.550
0.030
rua
rpl
runif
0.852
0.030
0.755
0.041
0.552
0.052
0.860
0.023
0.767
0.027
0.561
0.037
0.857
0.018
0.767
0.025
0.562
0.033
table
normalized
utility
achieved
rua
runif
rpl
20
40
60
random
individuals
test
set
acs
top
rows
enrollment
bottom
rows
mean
std
taken
across
30
neural
network
training
runs
ua
outperforms
uniform
pl
ranking
conclusions
future
work
stability
ranking
functions
natural
desideratum
prevent
large
deviations
arising
rankings
noise
learned
classifiers
combined
individually
fair
predictions
results
fair
rankings
stability
achieved
natural
uncertainty
aware
ranking
functions
also
preserve
multigroup
fairness
guarantees
underlying
classifiers
interesting
direction
future
work
find
general
sufficient
condition
ranking
functions
allows
inherit
properties
multiaccurate
multicalibrated
predictors
proof
theorem
16
crucially
make
use
fact
individual
competing
sampled
dataset
can
thought
competing
individuals
sampled
single
conditional
distribution
call
property
individual
interpolation
since
allows
linear
properties
multiaccuracy
multicalibration
noarov
roth
2023
compose
ranking
function
desirable
characterize
ranking
functions
satisfy
individual
interpolation
whether
property
necessary
guarantees
vein
theorem
16
another
important
extension
consider
correlations
sampled
labels
different
individuals
whether
analogous
individual
group
fairness
guarantees
can
still
provided
case
practice
predictors
used
rankings
applications
linkedin
trained
using
highly
correlated
data
due
consumer
click-through
behavior
diciccio
et
al
2023
investigating
ways
train
group-fair
predictors
multiaccurate
sense
relying
non-i
examples
furthermore
applying
predictors
rankings
correlated
merit
distributions
important
avenue
future
work
22
acknowledgements
sd
supported
department
defense
dod
national
defense
science
engineering
graduate
ndseg
fellowship
program
work
also
funded
part
nsf
awards
1916153
2333448
1956435
1943584
2344925
2239265
amazon
research
award
references
angelopoulos
bates
gentle
introduction
conformal
prediction
distribution-free
uncertainty
quantification
preprint
2021
asudeh
jagadish
miklau
stoyanovich
obtaining
stable
rankings
proc
44th
intl
conf
large
data
bases
volume
12
pages
237
250
2018
awasthi
kleindessner
morgenstern
equalized
odds
postprocessing
imperfect
group
information
proc
23rd
intl
conf
artificial
intelligence
statistics
pages
1770
1780
pmlr
2020
13
bastani
gupta
jung
noarov
ramalingam
roth
practical
adversarial
multivalid
conformal
prediction
proc
36th
advances
neural
information
processing
systems
2022
bruch
han
bendersky
najork
stochastic
treatment
learning
rank
scoring
functions
proc
13th
acm
intl
conf
web
search
data
mining
pages
61
69
2020
21
busa-fekete
ke
gl
lteto
szarvas
ranking
calibrated
adaboost
proceedings
learning
rank
challenge
pages
37
48
pmlr
2011
cao
qin
liu
tsai
li
learning
rank
pairwise
approach
listwise
approach
proc
24th
intl
conf
machine
learning
pages
129
136
2007
caton
haas
fairness
machine
learning
survey
acm
computing
surveys
2020
cohen
mitra
lesota
rekabsaz
eickhoff
relevance
scores
equal
efficient
uncertainty
calibration
modeling
deep
retrieval
models
proc
44th
intl
conf
research
development
information
retrieval
sigir
pages
654
664
2021
cooper
lee
barocas
de
sa
sen
zhang
prediction
arbitrary
measuring
self-consistency
fair
classification
proc
38th
aaai
conf
artificial
intelligence
2024
devic
kempe
sharan
korolova
fairness
matching
uncertainty
proc
40th
intl
conf
machine
learning
volume
202
pages
7775
7794
2023
10
20
diciccio
hsu
yu
nandy
basu
detection
mitigation
algorithmic
bias
via
predictive
parity
proceedings
2023
acm
conference
fairness
accountability
transparency
pages
1801
1816
2023
22
ding
hardt
miller
schmidt
retiring
adult
new
datasets
fair
machine
learning
proc
35th
advances
neural
information
processing
systems
2021
20
dwork
hardt
pitassi
reingold
zemel
fairness
awareness
proc
3rd
innovations
theoretical
computer
science
pages
214
226
2012
dwork
kim
reingold
rothblum
yona
learning
outcomes
evidence-based
rankings
proc
60th
ieee
symp
foundations
computer
science
pages
106
125
ieee
2019
23
ganesh
chang
strobel
shokri
impact
machine
learning
randomness
group
fairness
proceedings
2023
acm
conference
fairness
accountability
transparency
pages
1789
1800
2023
garcı
a-soriano
bonchi
maxmin-fair
ranking
individual
fairness
group-fairness
constraints
proceedings
27th
acm
sigkdd
conference
knowledge
discovery
data
mining
pages
436
446
2021
geyik
ambler
kenthapadi
fairness-aware
ranking
search
recommendation
systems
application
linkedin
talent
search
proc
25th
intl
conf
knowledge
discovery
data
mining
pages
2221
2231
2019
goodfellow
shlens
szegedy
explaining
harnessing
adversarial
examples
bengio
lecun
editors
3rd
international
conference
learning
representations
iclr
2015
san
diego
ca
usa
may
2015
2015
url
http://arxiv.org/abs/1412.6572.
google
ads
help
ad
rank
2023
url
https://support.google.com/google-ads/answer/
1722122
hl
en
accessed
2023
09
28
gopalan
kim
singhal
zhao
low-degree
multicalibration
proc
35th
conference
learning
theory
pages
3193
3234
pmlr
2022
13
16
gorantla
mehrotra
deshpande
louis
sampling
individually-fair
rankings
always
group
fair
rossi
das
davis
firth-butterfield
john
editors
proceedings
2023
aaai
acm
conference
ai
ethics
society
aies
2023
pages
205
216
acm
2023
guiver
snelson
learning
rank
softrank
gaussian
processes
proc
31st
intl
conf
research
development
information
retrieval
sigir
pages
259
266
2008
guo
pleiss
sun
weinberger
calibration
modern
neural
networks
proc
34th
intl
conf
machine
learning
pages
1321
1330
pmlr
2017
guo
ton
liu
fair
learning
rank
distribution-free
risk
control
preprint
2023
gupta
ramdas
top-label
calibration
multiclass-to-binary
reductions
tenth
international
conference
learning
representations
iclr
2022
virtual
event
april
25
29
2022
openreview
.net
2022
url
https://openreview.net/forum?id=wqobaaphs-.
gutie
rrez
perez-ortiz
sanchez-monedero
fernandez-navarro
hervas-martinez
ordinal
regression
methods
survey
experimental
study
ieee
transactions
knowledge
data
engineering
28
127
146
2015
haghtalab
jordan
zhao
unifying
perspective
multi-calibration
unleashing
game
dynamics
multi-objective
learning
proc
37th
advances
neural
information
processing
systems
36
2023
13
hardt
price
srebro
equality
opportunity
supervised
learning
proc
30th
advances
neural
information
processing
systems
29
2016
13
harper
konstan
movielens
datasets
history
context
acm
trans
interact
intell
syst
2015
20
bert-johnson
kim
reingold
rothblum
multicalibration
calibration
computationally-identifiable
masses
proc
35th
intl
conf
machine
learning
pages
1939
1948
pmlr
2018
12
13
16
24
heuss
cohen
mansoury
rijke
eickhoff
predictive
uncertainty-based
bias
mitigation
ranking
proceedings
32nd
acm
international
conference
information
knowledge
management
pages
762
772
2023
ja
rvelin
keka
la
inen
cumulated
gain-based
evaluation
ir
techniques
acm
transactions
information
systems
tois
20
422
446
2002
16
jung
noarov
ramalingam
roth
batch
multivalid
conformal
prediction
eleventh
international
conference
learning
representations
iclr
2023
kigali
rwanda
may
2023
2023
kim
ghorbani
zou
multiaccuracy
black-box
post-processing
fairness
classification
proceedings
2019
aaai
acm
conference
ai
ethics
society
pages
247
254
2019
12
13
korevaar
mcconnell
tong
brinkman
shine
abbas
metevier
corbett-davies
el-arini
matched
pair
calibration
ranking
fairness
arxiv
preprint
arxiv
2306.03775
2023
kweon
kang
yu
obtaining
calibrated
probabilities
personalized
ranking
models
proc
36th
aaai
conf
artificial
intelligence
volume
36
pages
4083
4091
2022
luce
individual
choice
behavior
courier
corporation
1959
21
martins
tolledo
machado
baptista
realinho
early
prediction
student
performance
higher
education
case
study
trends
applications
information
systems
technologies
volume
pages
166
175
springer
2021
20
mehrotra
celis
mitigating
bias
set
selection
noisy
protected
attributes
proceedings
2021
acm
conference
fairness
accountability
transparency
pages
237
248
2021
mehrotra
vishnoi
fair
ranking
noisy
protected
attributes
proc
36th
advances
neural
information
processing
systems
35
31711
31725
2022
menon
jiang
vembu
elkan
ohno-machado
predicting
accurate
probabilities
ranking
loss
proc
29th
intl
conf
machine
learning
volume
2012
page
703
2012
meta
approach
facebook
feed
ranking
2023
url
https://transparency.fb.com/features/
ranking-and-content
accessed
2023
09
28
minderer
djolonga
romijnders
hubis
zhai
houlsby
tran
lucic
revisiting
calibration
modern
neural
networks
proc
35th
advances
neural
information
processing
systems
34
15682
15694
2021
narasimhan
cotter
gupta
wang
pairwise
fairness
ranking
regression
proc
34th
aaai
conf
artificial
intelligence
volume
34
pages
5248
5255
2020
nettleton
orriols-puig
fornells
study
effect
different
types
noise
precision
supervised
learning
techniques
artificial
intelligence
review
33
275
306
2010
noarov
roth
statistical
scope
multicalibration
proc
40th
intl
conf
machine
learning
volume
202
pages
26283
26310
2023
22
oh
ustun
mcauley
kumar
rank
list
sensitivity
recommender
systems
interaction
perturbations
proceedings
31st
acm
international
conference
information
knowledge
management
pages
1584
1594
2022
oh
ustun
mcauley
kumar
finest
stabilizing
recommendations
rank-preserving
fine-tuning
arxiv
preprint
arxiv
2402.03481
2024
25
penha
hauff
calibration
uncertainty
neural
learning
rank
models
conversational
search
proceedings
16th
conference
european
chapter
association
computational
linguistics
main
volume
pages
160
170
2021
pitoura
stefanidis
koutrika
fairness
rankings
recommendations
overview
proc
48th
intl
conf
large
data
bases
2022
18
plackett
analysis
permutations
journal
royal
statistical
society
series
applied
statistics
24
193
202
1975
21
rastogi
joachims
fair
ranking
disparate
uncertainty
preprint
2023
robertson
probability
ranking
principle
ir
journal
documentation
33
294
304
1977
shabat
cohen
mansour
sample
complexity
uniform
convergence
multicalibration
proc
34th
advances
neural
information
processing
systems
33
13331
13340
2020
16
shalev-shwartz
ben-david
understanding
machine
learning
theory
algorithms
cambridge
university
press
2014
12
16
shen
wang
zhu
fain
munagala
fairness
assignment
problem
uncertain
priorities
proc
22nd
intl
conf
autonomous
agents
multiagent
systems
page
188
196
2023
singh
joachims
fairness
exposure
rankings
proceedings
24th
acm
sigkdd
international
conference
knowledge
discovery
data
mining
pages
2219
2228
2018
singh
joachims
policy
learning
fairness
ranking
proc
33rd
advances
neural
information
processing
systems
32
2019
18
singh
kempe
joachims
fairness
ranking
uncertainty
proc
35th
advances
neural
information
processing
systems
pages
11896
11908
2021
10
18
20
22
soliman
ilyas
ranking
uncertain
scores
2009
ieee
25th
international
conference
data
engineering
pages
317
328
ieee
2009
tahir
cheng
liu
fairness
aleatoric
uncertainty
preprint
2023
tang
koc
yig
rice
vayanos
learning
optimal
fair
policies
online
allocation
scarce
societal
resources
data
collected
deployment
arxiv
preprint
arxiv
2311.13765
2023
taylor
guiver
robertson
minka
softrank
optimizing
non-smooth
rank
metrics
proc
1st
acm
intl
conf
web
search
data
mining
pages
77
86
2008
16
turbohire
unleashing
power
ai
automation
effortlessly
discover
best
talent
2023
url
https://turbohire.co/features/talent-screening/#candidate-scoring.
accessed
2023
10
09
wang
chen
learning
predict
cost-per-click
ad
words
proceedings
21st
acm
international
conference
information
knowledge
management
pages
2291
2294
2012
xu
li
adarank
boosting
algorithm
information
retrieval
proc
30th
intl
conf
research
development
information
retrieval
sigir
pages
391
398
2007
yan
qin
wang
bendersky
najork
scale
calibration
deep
ranking
models
proceedings
28th
acm
sigkdd
conference
knowledge
discovery
data
mining
pages
4300
4309
2022
yang
luo
lu
gupta
yin
ai
can
clicks
labels
features
unbiased
behavior
feature
collection
uncertainty-aware
learning
rank
proc
45th
intl
conf
research
development
information
retrieval
sigir
pages
17
2022
26
yang
xu
wang
tran
ai
marginal-certainty-aware
fair
ranking
algorithm
proc
16th
acm
intl
conf
web
search
data
mining
pages
24
32
2023
zehlike
yang
stoyanovich
fairness
ranking
survey
preprint
2021
url
https
arxiv
org
abs
2103.14000
zou
wang
kolter
fredrikson
universal
transferable
adversarial
attacks
aligned
language
models
preprint
2023
27
proof
key
lemma
uncertainty
aware
ranking
proof
lemma
12
uses
following
lemma
bounding
total
variation
distance
sums
random
variables
terms
total
variation
distances
individual
variables
lemma
23
let
pn
pn
xi
pi
yi
qi
independent
categorical
random
variables
pn
let
respective
distributions
tv
tv
pi
qi
proof
consider
maximal
coupling
xi
corresponding
yi
coupling
lemma
xi
yi
dtv
pi
qi
dtv
now
union
bound
obtain
dtv
xi
yi
dtv
pi
qi
completing
proof
proof
lemma
12
first
equation
first
part
proposition
ri
λi
let
pp
pq
note
random
variable
simply
determined
distributions
substitute
characterization
use
triangle
inequality
well
fact
give
us
prua
ri
λi
prua
ri
λi
pp
pq
pp
pq
pq
pp
pp
pq
pq
pp
pp
pq
pp
pq
consider
vector-valued
random
variable
let
denote
distribution
respectively
events
can
expressed
terms
random
variable
definition
total
variation
distance
implies
pp
pq
dtv
pp
pq
dtv
28
bound
dtv
associate
individual
dimensional
random
vector
vi
1λi
1λi
vi
fixed
consider
distribution
vi
pi
qi
total
variation
distance
distributions
dtv
pi
qi
vectors
can
differ
labels
differ
lemma
23
thus
obtain
dtv
dtv
pi
qi
substituting
bound
back
now
obtain
prua
ri
λi
prua
ri
λi
dtv
pi
qi
completing
proof
29