fairness
in
ranking
under
disparate
uncertainty
richa
rastogi
thorsten
joachims
cornell
university
united
states
of
america
rr568@cornell.edu
cornell
university
united
states
of
america
tj@cs.cornell.edu
abstract
ranking
is
ubiquitous
method
for
focusing
the
attention
of
human
evaluators
on
manageable
subset
of
options
its
use
as
part
of
human
decision-making
processes
ranges
from
surfacing
potentially
relevant
products
on
an
e-commerce
site
to
prioritizing
college
applications
for
human
review
while
ranking
can
make
human
evaluation
more
effective
by
focusing
attention
on
the
most
promising
options
we
argue
that
it
can
introduce
unfairness
if
the
uncertainty
of
the
underlying
relevance
model
differs
between
groups
of
options
unfortunately
such
disparity
in
uncertainty
appears
widespread
often
to
the
detriment
of
minority
groups
for
which
relevance
estimates
can
have
higher
uncertainty
due
to
lack
of
data
or
appropriate
features
to
address
this
fairness
issue
we
propose
equal-opportunity
ranking
eor
as
new
fairness
criterion
for
ranking
and
show
that
it
corresponds
to
group-wise
fair
lottery
among
the
relevant
options
even
in
the
presence
of
disparate
uncertainty
eor
optimizes
for
an
even
cost
burden
on
all
groups
unlike
the
conventional
probability
ranking
principle
and
is
fundamentally
different
from
existing
notions
of
fairness
in
rankings
such
as
demographic
parity
and
proportional
rooney
rule
constraints
that
are
motivated
by
proportional
representation
relative
to
group
size
to
make
eor
ranking
practical
we
present
an
efficient
algorithm
for
computing
it
in
time
log
and
prove
its
close
approximation
guarantee
to
the
globally
optimal
solution
in
comprehensive
empirical
evaluation
on
synthetic
data
us
census
dataset
and
real-world
audit
of
amazon
search
queries
we
find
that
the
algorithm
reliably
guarantees
eor
fairness
while
providing
effective
rankings
human
decision-processes
are
increasingly
augmented
with
algorithmic
decision-support
systems
which
has
created
opportunities
and
challenges
for
addressing
group-based
disparities
in
decision
outcomes
15
51
56
in
this
paper
we
focus
on
selection
processes
where
humans
evaluators
use
rankings
to
organize
the
order
of
review
under
resource
constraints
we
argue
that
disparities
in
uncertainty
can
be
major
source
of
group-based
discrimination
in
this
setting
to
illustrate
the
problem
consider
the
following
example
of
college
admissions
at
highly
selective
institution
in
this
situation
there
are
far
more
qualified
candidates
than
available
spots
under
fixed
reviewing
budget
the
college
could
give
all
applications
brief
review
but
risk
high
error
rates
in
human
decision
making
or
use
ranking
to
focus
reviewing
efforts
on
the
more
promising
applications
the
latter
is
likely
to
decrease
error
rates
in
human
review
but
it
risks
that
this
prioritization
unfairly
favors
some
groups
over
others
for
example
consider
12
000
applicants
competing
for
500
slots
in
this
example
10
000
applicants
are
from
majority
group
with
plenty
of
available
data
and
the
model
can
quite
accurately
predict
which
students
will
be
admitted
by
the
human
reviewers
in
particular
it
accurately
assigns
probability
of
0.9
to
1000
of
the
students
and
0.01
to
the
remaining
000
the
remaining
2000
applicants
are
from
minority
group
where
the
model
is
less
informed
about
individual
students
and
thus
assigns
0.1
to
everybody
when
naively
ranking
students
by
this
probability
the
students
with
0.9
from
the
majority
group
would
be
ranked
ahead
of
all
the
students
from
the
minority
group
and
the
class
will
fill
up
with
the
expected
900
1000
0.9
qualified
majority
students
before
the
admission
staff
even
gets
to
any
of
the
minority
students
this
is
clearly
unfair
even
if
the
predictions
are
perfectly
calibrated
for
each
group
since
not
even
single
student
of
the
expected
200
2000
0.1
qualified
students
in
the
minority
group
has
chance
to
be
selected
by
the
admissions
staff
we
aim
to
define
new
way
of
ranking
that
does
not
introduce
unfairness
into
human
decision-making
process
even
if
the
predictive
model
shows
differential
uncertainty
between
groups
this
goal
recognizes
that
training
models
to
have
equal
uncertainty
across
groups
may
be
difficult
in
practice
since
lack
of
data
and
appropriate
features
for
some
groups
may
be
difficult
to
overcome1
importantly
key
principle
behind
our
work
is
to
leave
the
final
decisions
to
human
decision
makers
we
thus
aim
to
design
new
ranking
algorithms
to
most
effectively
support
fair
human
decision-making
process
and
not
to
replace
the
human
decision
maker
the
main
contributions
of
this
paper
are
ccs
concepts
information
systems
rankings
top-k
retrieval
recommender
systems
decision
support
systems
keywords
ranking
fairness
disparate
uncertainty
cost
of
opportunity
acm
reference
format
richa
rastogi
and
thorsten
joachims
2024
fairness
in
ranking
under
disparate
uncertainty
in
equity
and
access
in
algorithms
mechanisms
and
optimization
eaamo
24
october
29
31
2024
san
luis
potosi
mexico
acm
new
york
ny
usa
31
pages
https://doi.org/10.1145/3689904.3694703
permission
to
make
digital
or
hard
copies
of
all
or
part
of
this
work
for
personal
or
classroom
use
is
granted
without
fee
provided
that
copies
are
not
made
or
distributed
for
profit
or
commercial
advantage
and
that
copies
bear
this
notice
and
the
full
citation
on
the
first
page
copyrights
for
components
of
this
work
owned
by
others
than
the
author
must
be
honored
abstracting
with
credit
is
permitted
to
copy
otherwise
or
republish
to
post
on
servers
or
to
redistribute
to
lists
requires
prior
specific
permission
and
or
fee
request
permissions
from
permissions@acm.org
eaamo
24
october
29
31
2024
san
luis
potosi
mexico
2024
copyright
held
by
the
owner
author
publication
rights
licensed
to
acm
acm
isbn
979
4007
1222
24
10
https://doi.org/10.1145/3689904.3694703
introduction
arguably
the
same
applies
to
instructing
human
evaluators
to
provide
such
ranking
scores
during
first
phase
of
review
eaamo
24
october
29
31
2024
san
luis
potosi
mexico
new
fairness
criterion
that
provides
meaningful
guarantee
for
rankings
that
are
used
to
support
human
decision
making
in
selection
processes
even
under
disparities
in
uncertainty
we
motivate
this
fairness
criterion
with
fair
lottery
22
44
ensuring
group-wise
outcomes
that
are
equivalent
to
allocating
scarce
resources
based
on
group-fair
lottery
among
the
relevant
candidates
based
on
this
notion
of
fairness
we
develop
new
ranking
procedure
that
is
group-fair
under
disparate
uncertainty
motivated
by
its
relation
to
the
equality
of
opportunity
framework
23
we
name
this
ranking
procedure
equal
opportunity
ranking
eor
we
analyze
eor
from
the
lens
of
the
cost
burden
on
each
entity
involved
the
principal
decision
maker
and
each
of
the
candidate
groups
and
formulate
the
cost
to
each
entity
as
the
lost
opportunity
of
access
given
that
the
candidate
was
truly
relevant
we
show
that
this
eor
procedure
equalizes
the
cost
burden
between
groups
and
present
an
efficient
and
practical
algorithm
for
computing
eor
rankings
this
procedure
always
produces
near
optimal
and
approximately
eor-fair
solution
in
particular
we
prove
an
approximation
guarantee
showing
that
the
gap
in
total
cost
to
the
principal
compared
to
an
optimal
algorithm
is
bounded
by
small
amount
in
addition
to
these
theoretical
worst-case
guarantees
we
present
extensive
experiments
benchmarking
the
eor
algorithm
with
various
existing
ranking
algorithms
under
different
settings
of
disparate
uncertainty
we
show
that
demographic
parity
58
61
normative
procedures
like
proportional
rooney-rule-like
constraints
exposure
based
fairness
criteria
49
and
thompson
sampling
policy
50
are
not
typically
eor-fair
under
disparate
uncertainty
we
find
that
these
results
hold
on
both
wide
range
of
synthetic
datasets
as
well
as
on
real-world
us
census
data
finally
we
explore
the
use
of
our
fairness
criterion
for
auditing
ranking
systems
using
real-world
dataset
of
amazon
shopping
search
queries
our
code
can
be
accessed
at
https://github.com/richrast/disparateuncertainty.
these
results
have
important
societal
implications
first
they
provide
evidence
that
naively
applying
existing
fairness
mechanisms
in
rankings
under
disparate
uncertainty
leads
to
unfairness
in
terms
of
one
group
bearing
the
majority
of
the
cost
of
opportunity
second
even
under
high
disparate
uncertainty
in
the
worst
case
eor
guarantees
an
approximately
equal
cost
burden
among
all
groups
with
bounded
additional
cost
to
the
human
decision
maker
finally
we
hope
our
results
inform
practitioners
to
collect
data
and
appropriate
features
for
candidates
in
all
groups
to
build
predictive
models
that
reduce
disparate
uncertainty
as
we
will
show
the
eor
procedure
elevates
the
candidates
with
high
uncertainty
in
the
rankings
for
human
evaluation
this
has
the
desirable
effect
of
producing
more
equitable
training
data
for
future
use
we
now
highlight
some
important
considerations
here
first
our
proposed
method
is
grounded
in
the
fairness
of
lottery
45
which
is
common
technique
for
allocating
scarce
resources
admission
slots
among
large
number
of
qualified
candidates
however
moral
and
philosophical
arguments
debating
the
use
of
lottery
and
randomization
for
certain
situations
have
also
been
made
26
we
hope
this
work
can
spark
discussions
on
alternative
notions
of
rastogi
and
joachims
fairness
in
rankings
that
satisfy
equality
of
opportunity
under
disparate
uncertainty
another
important
point
is
that
our
proposed
eor
procedure
reduces
unfairness
due
to
disparate
uncertainty
which
often
but
not
necessarily
coincides
with
the
historically
disadvantaged
group
since
eor
doesn
require
the
designation
of
the
disadvantaged
group
the
guarantees
we
provide
are
not
making
normative
statement
about
any
historically
disadvantaged
group
to
that
end
we
emphasize
the
careful
consideration
of
historical
and
social
context
that
needs
to
be
taken
into
account
by
the
human
decision
maker
as
well
as
the
way
groups
are
defined
in
the
first
place
related
works
while
the
issue
of
fairness
has
been
heavily
studied
in
the
classification
setting
its
counterpart
the
ranking
setting
has
received
relatively
less
attention
below
we
highlight
key
areas
related
to
our
work
and
leave
more
detailed
discussion
of
these
and
other
related
works
to
appendix
fairness
in
rankings
and
selection
processes
while
there
exist
several
notions
of
fairness
in
rankings
64
predominantly
they
are
variations
of
two
fairness
mechanisms
in
existing
literature
representation
by
size
10
57
61
63
and
equitable
allocation
of
exposure
31
35
48
49
we
propose
new
criterion
different
from
either
of
the
two
and
our
central
point
is
that
under
disparate
uncertainty
between
groups
it
is
more
fair
to
take
an
equal
proportion
of
relevance
in
expectation
rather
than
equality
by
size
or
exposure
proportional
representation
in
the
form
of
diversity
constraints
like
demographic
parity
58
or
affirmative
action
such
as
the
rooney
rule
guarantee
minimum
proportion
by
group
size
in
selection
processes
exposure
based
formulations
in
rankings
ensure
that
groups
of
candidates
are
allocated
exposure
in
an
equitable
way
such
as
in
proportion
of
amortized
relevance
over
the
full
ranking
in
this
work
we
demonstrate
that
fairness
of
representation
by
size
and
exposure
are
not
sufficient
under
disparate
uncertainty
fairness
in
rankings
under
uncertainty
our
work
builds
on
50
in
which
the
authors
establish
that
uncertainty
in
relevance
probabilities
is
primary
cause
of
unfairness
for
rankings
they
propose
thompson
sampling
policy
that
randomizes
relevances
drawn
from
the
predictive
posterior
distribution
separately
19
studies
the
role
of
affirmative
action
in
the
presence
of
differential
variance
between
groups
in
rankings
differential
variance
implies
that
there
is
more
certainty
about
the
true
quality
scores
of
candidates
in
group
with
less
variance
in
the
estimated
quality
and
vice
versa
for
group
with
higher
variance
in
contrast
we
work
with
relevance
probabilities
instead
of
scores
and
focus
on
the
certainty
of
relevance
of
candidate
which
is
determined
by
how
close
the
predicted
relevance
probabilities
are
to
or
for
instance
group
is
highly
certain
if
the
probabilities
are
all
close
to
1.0
or
highly
uncertain
if
the
probabilities
are
all
close
to
0.5
while
both
groups
could
have
similar
variance
in
probabilities
fairness
under
uncertainty
has
also
been
studied
with
respect
to
calibration
of
probabilities
11
20
29
38
classical
literature
in
this
area
studies
whether
group-wise
calibration
is
necessary
condition
for
fairness
or
not
32
our
work
is
orthogonal
to
the
question
of
fairness
in
ranking
under
disparate
uncertainty
the
necessity
of
calibration
for
fairness
and
we
only
require
groupwise
calibration
as
sufficient
condition
for
the
eor
criterion
we
propose
our
work
complements
and
extends
prior
research
on
fairness
in
rankings
under
uncertainty
contributing
uniquely
in
several
ways
in
particular
we
provide
formal
framework
for
analyzing
the
unfairness
that
differential
uncertainty
induces
in
rankings
additionally
our
approach
involves
accounting
for
the
differential
uncertainty
directly
at
the
ranking
stage
unlike
prior
work
that
involves
learning
the
uncertainty
53
or
correcting
the
noisy
relevance
estimates
59
finally
our
proposed
eor
criterion
is
non-amortized
for
every
prefix
of
the
ranking
which
is
strictly
stronger
than
the
probabilistic
but
amortized
notions
of
fairness
48
49
shown
to
be
problematic
28
un-fairness
due
to
disparate
uncertainty
in
rankings
we
want
to
design
ranking
policy
that
does
not
introduce
unfairness
into
human
decision
process
due
to
disparate
uncertainty
more
formally
the
task
of
is
to
compute
ranking
of
candidates
where
each
candidate
has
binary2
relevance
ğ‘Ÿğ‘–
which
is
unknown
to
the
ranking
policy
and
true
relevance
can
only
be
revealed
through
human
decision
maker
when
assessing
the
relevance
we
assume
that
the
human
decision
maker
goes
through
the
ranking
from
the
top
to
some
priori
unknown
position
the
goal
of
the
decision
maker
principal
is
to
find
as
many
relevant
candidates
relevant
products
qualified
students
as
possible
while
the
true
relevances
ğ‘Ÿğ‘–
are
unknown
we
assume
that
the
ranking
policy
has
access
to
predictive
model
of
relevance
ğ‘Ÿğ‘–
typically
trained
on
prior
human
decisions
and
features
of
the
candidates
sorting
the
candidates
in
decreasing
order
of
ğ‘ğ‘–
ğ‘Ÿğ‘–
is
called
the
probability
ranking
principle
prp
41
and
it
is
by
far
the
most
common
way
of
computing
ranking
the
justification
for
prp
ranking
is
that
it
maximizes
the
expected
number
of
relevant
candidates
in
any
top-k
prefix
of
the
ranking
on
the
other
hand
demographic
parity
dp
is
the
dominant
form
of
fairness
mechanism
in
rankings
where
candidates
are
selected
from
groups
in
proportion
to
the
group
size
while
prp
ranking
is
provably
optimal
according
to
the
efficiency
goal
of
the
principal
and
dp
ranking
ensures
representation
by
group
size
the
following
elaborates
how
both
prp
and
dp
can
violate
fairness
3.1
illustrative
example
consider
medical
setting
where
candidates
need
to
be
evaluated
for
eligibility
to
participate
in
controlled
medical
trial
while
group
consists
of
candidates
with
rich
set
of
diagnostic
tests
that
inform
eligibility
candidates
with
health
insurance
group
consists
of
candidates
without
prior
access
to
such
tests
candidates
without
health
insurance
as
result
according
to
ğ‘Ÿğ‘–
in
figure
the
model
can
make
very
informed
predictions
for
candidates
in
group
while
for
group
the
model
cannot
reliably
differentiate
between
eligible
and
not
eligible
candidates
this
means
the
model
knows
exactly
which
candidates
in
2we
conjecture
that
our
framework
can
be
extended
to
categorical
or
real-valued
relevances
eaamo
24
october
29
31
2024
san
luis
potosi
mexico
group
will
be
judged
as
eligible
by
the
human
decision
maker
but
it
will
make
undifferentiated
but
well-calibrated
predictions
for
candidates
in
group
figure
shows
that
the
prp
ranking
is
oblivious
to
this
disparity
between
groups
if
the
principal
needs
to
find
four
eligible
candidates
based
on
the
prp
ranking
they
are
all
selected
from
group
however
by
summing
the
probabilities
in
group
our
model
tells
us
that
we
can
also
expect
four
eligible
candidates
in
group
we
argue
that
deterministically
selecting
only
candidates
from
group
is
unfair
since
it
is
not
consistent
with
the
outcome
of
group-fair
lottery
for
the
four
spots
among
the
eight
eligible
candidates
now
consider
the
dp
ranking
in
figure
since
group
has
17
candidates
and
group
has
candidates
dp
will
select
roughly
one
candidate
from
group
for
every
two
candidates
from
group
we
argue
that
in
this
setting
dp
is
also
unfair
though
less
in
comparison
to
prp
as
it
selects
three
eligible
candidates
from
group
and
only
one
from
group
in
expectation
it
selects
2.6
out
of
relevant
candidates
from
group
but
only
0.6
out
of
relevant
candidates
from
group
we
show
empirically
later
that
other
fairness
mechanisms
motivated
by
representation
of
size
such
as
proportional
rooney
rule
or
threshold-based
formulations
have
the
same
failure
mode
importantly
note
that
it
is
not
evident
whether
group
or
should
be
the
majority
group
we
argue
that
more
principled
and
fair
way
would
be
to
select
an
equal
fraction
of
relevant
candidates
from
each
group
in
expectation
consider
the
last
ranking
in
figure
which
approximately
fulfills
the
eor
fairness
we
formally
introduce
later
in
expectation
this
ranking
selects
more
equal
number
of
relevant
candidates
from
both
groups
making
it
similar
to
fair
lottery
in
particular
it
selects
1.8
out
of
relevant
candidates
from
group
and
1.2
out
of
relevant
candidates
from
group
this
eor
ranking
however
comes
at
an
increased
evaluation
cost
to
the
principal
as
it
selects
3.0
expected
relevant
candidates
from
both
the
groups
compared
to
3.2
with
dp
and
3.3
with
prp
as
result
the
principal
needs
to
review
more
candidates
to
select
the
same
number
of
relevant
candidates
with
eor
ranking
however
it
is
still
far
more
effective
than
lottery
which
selects
the
candidates
in
uniform
random
order
our
key
insight
is
that
eor
ranking
is
more
fair
not
because
it
takes
an
equal
number
of
candidates
from
each
group
but
it
is
more
fair
because
it
takes
an
equal
fraction
of
relevant
candidates
in
expectation
from
each
group
this
accounts
for
predictive
uncertainty
in
the
relevance
probabilities
because
even
when
one
group
has
sharp
and
the
other
group
has
non-sharp
ğ‘ğ‘–
it
takes
approximately
equal
fraction
of
relevance
from
each
of
the
groups
this
example
illustrates
the
intuition
behind
the
eor
principle
we
formalize
in
the
following
and
we
will
show
how
to
efficiently
compute
rankings
that
fulfill
eor
fairness
3.2
sources
of
disparate
uncertainty
it
remains
to
show
that
disparate
uncertainty
is
fundamental
problem
when
estimating
the
relevance
probabilities
ğ‘Ÿğ‘–
that
is
not
easily
remedied
by
improved
learning
methods
the
following
illustrates
that
even
bayes-optimal
procedure
is
vulnerable
to
producing
disparate
uncertainty
consider
the
posterior
distribution
illustrated
in
figure
which
shows
the
uncertainty
ğœƒğ‘–
that
bayesian
model
has
about
eaamo
24
october
29
31
2024
san
luis
potosi
mexico
rastogi
and
joachims
pi
group
0.05
0.05
0.05
0.05
0.05
0.05
0.05
0.05
pi
group
0.4
0.4
0.4
0.5
0.5
0.6
0.6
0.6
0.05
0.05
0.05
0.05
0.1
0.7
0.8
expected
relevance
of
the
groups
ri
pi
0.9
0.9
true
relevance
ri
figure
the
expected
probability
of
relevance
ğ‘ğ‘–
and
their
true
relevance
ğ‘Ÿğ‘–
for
all
candidates
in
both
groups
prp
dp
eor
0.9
0.9
0.8
0.7
0.9
0.6
0.9
0.8
0.6
0.9
0.6
0.9
selected
total
expected
relevant
number
of
candidates
3.3
3.3
2.6
0.6
3.2
1.8
1.2
3.0
figure
top-4
ranking
for
probability
ranking
principle
prp
demographic
parity
dp
and
our
proposed
eor
for
the
example
in
figure
selected
relevant
number
of
candidates
in
expectation
and
total
relevant
number
of
candidates
in
expectation
are
shown
corresponding
to
each
ranking
to
zero
or
one
for
candidates
in
group
highly
informative
and
middling
for
group
less
informative
note
that
there
is
ample
evidence
that
non-bayesian
methods
also
produce
such
disparities
51
56
furthermore
disparate
amounts
of
data
are
not
the
only
cause
for
disparity
for
example
in
college
admissions
disparately
more
urm
candidates
may
miss
ap
grades
because
their
school
does
not
offer
ap
classes
their
epistemic
uncertainty
27
of
qualification
will
thus
be
higher
since
the
model
has
less
information
about
these
students
this
higher
uncertainty
does
not
mean
individual
students
are
not
qualified
and
elevating
them
in
the
ranking
for
human
evaluation
can
accurately
reveal
qualification
through
additional
information
an
interview
deep
reading
of
the
sop
or
recommendation
letters
but
if
they
are
never
selected
for
human
review
then
they
do
not
have
chance
for
an
admission
spot
group
posterior
Î¸i
0.0
0.2
0.4
Î¸i
0.6
group
0.8
1.0
figure
an
illustration
of
disparate
uncertainty
between
groups
from
bayesian
perspective
for
all
the
candidates
of
figure
the
candidates
in
group
have
peaky
posteriors
while
those
in
group
have
relatively
flat
posteriors
the
relevance
probability
ğœƒğ‘–
of
candidate
where
ğœƒğ‘–
is
the
parameter
of
bernoulli
distribution
for
group
the
posterior
ğœƒğ‘–
is
peaked
meaning
that
the
model
can
accurately
pinpoint
the
correct
relevance
probabilities
for
group
the
posterior
is
flat
which
is
to
be
expected
if
group
is
smaller
and
thus
has
less
data
the
bayes-optimal
way
of
handling
this
uncertainty
is
to
infer
ğ‘Ÿğ‘–
via
the
posterior
predictive
distribution
ğ‘Ÿğ‘–
ğ‘Ÿğ‘–
ğœƒğ‘–
ğœƒğ‘–
ğ‘‘ğœƒğ‘–
ğœƒğ‘–
ğœƒğ‘–
ğ‘‘ğœƒğ‘–
figure
shows
how
even
this
bayes-optimal
procedure
leads
to
disparate
uncertainty
between
groups
where
the
ğ‘Ÿğ‘–
is
closer
equality
of
opportunity
in
ranking
in
this
section
we
first
discuss
the
assumptions
and
modeling
choices
and
then
formulate
the
cost
that
the
uncertainty
of
the
predictive
model
imposes
on
the
principal
and
the
relevant
candidates
from
the
different
groups
our
first
assumption
includes
access
to
group-wise
calibration
38
with
the
probability
estimates
calibrated
within
groups
to
simplify
notation
we
do
not
differentiate
between
ğ‘Ÿğ‘–
and
group-wise
calibrated
score
ğ‘Ÿğ‘–
and
we
only
require
this
group-wise
calibration
as
sufficient
condition
for
our
framework
additionally
we
assume
that
the
true
relevance
ğ‘Ÿğ‘–
is
revealed
perfectly
to
the
human
decision-maker
upon
review
and
we
do
not
model
any
bias
in
the
human
decision-making
review
process
finally
we
assume
that
candidates
have
group
membership
to
single
protected
attribute
and
do
not
consider
intersectional
group
membership
which
is
practically
important
consideration
in
fairness
relaxing
these
three
assumptions
for
future
work
could
allow
modeling
even
more
real-world
complexities
to
formulate
the
cost
of
opportunity
we
first
recognize
that
any
group-wise
calibrated
model
allows
us
to
compute
the
expected
number
of
relevant
candidates
ğ‘›ğ‘…ğ‘’ğ‘™
of
particular
group
no
matter
how
well
the
model
can
differentiate
relevant
and
non-relevant
candidates
in
that
group
ğ‘›ğ‘…ğ‘’ğ‘™
eğ‘Ÿğ‘–
ğ‘Ÿğ‘–
ğ‘Ÿğ‘–
ğ‘Ÿğ‘–
extending
this
to
rankings
the
expected
number
of
relevant
candidates
from
group
for
any
prefix
of
ranking
that
only
depends
fairness
in
ranking
under
disparate
uncertainty
eaamo
24
october
29
31
2024
san
luis
potosi
mexico
on
ğ‘Ÿğ‘–
to
ensure
unconfoundedness
is
ğ‘›ğ‘…ğ‘’ğ‘™
ğœğ‘˜
ğ‘Ÿğ‘–
ğ‘Ÿğ‘–
ğœğ‘˜
ğœğ‘˜
further
extending
this
to
potentially
stochastic
ranking
policy
that
represents
distribution
over
rankings
for
particular
query
leads
to
ğ‘›ğ‘…ğ‘’ğ‘™
ğœ‹ğ‘˜
eğ‘Ÿğ‘–
ğ‘Ÿğ‘–
ğœğ‘˜
ğ‘Ÿğ‘–
iğ‘–
ğœğ‘˜
ğœğ‘˜ğœ‹
ğ‘Ÿğ‘–
4.2
where
ğœğ‘˜ğœ‹
eğœğ‘˜
iğ‘–
ğœğ‘˜
is
the
probability
that
policy
ranks
candidate
into
the
top
as
side
note
notation-wise
for
specific
policy
for
example
ğ¸ğ‘‚ğ‘…
we
denote
the
corresponding
ğ¸ğ‘‚ğ‘…
ranking
ğœğ‘˜ğœ‹
in
the
abbreviated
form
as
ğœğ‘˜ğ¸ğ‘‚ğ‘…
the
ability
to
compute
these
expected
numbers
of
relevant
candidates
from
each
group
allows
us
to
reason
about
the
cost
resulting
from
the
uncertainty
of
the
model
that
each
ranking
imposes
on
the
respective
groups
which
we
detail
in
the
following
cost
burden
to
candidate
groups
and
the
principal
we
define
the
cost
to
candidate
as
missing
out
on
the
opportunity
to
be
selected
if
the
candidate
was
truly
relevant
for
ranking
policy
that
produces
rankings
based
on
ğ‘Ÿğ‘–
and
principal
that
reviews
the
top
candidates
the
cost
to
relevant
candidate
is
the
probability
of
not
being
included
in
the
top
ğœ‹ğ‘˜
ğ‘Ÿğ‘–
ğ‘Ÿğ‘–
ğœğ‘˜ğœ‹
we
again
normalize
this
quantity
to
make
it
proportional
to
the
total
expected
number
of
relevant
candidates
note
that
eq
is
related
to
the
conventional
metric
of
recall
4.1
the
principal
incurs
cost
whenever
the
ranking
misses
relevant
candidate
independent
of
group
membership
for
principal
that
reviews
the
top
applications
from
two
groups
and
the
total
cost
can
thus
be
quantified
via
the
expected
number
of
relevant
candidates
that
are
overlooked
ğœğ‘˜
ğ‘Ÿğ‘–
principal
ğœ‹ğ‘˜
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
note
that
only
relevant
candidates
can
incur
cost
since
nonrelevant
candidates
will
be
rejected
by
human
review
and
thus
draw
no
utility
independent
of
whether
they
are
ranked
into
the
top
also
note
that
ğœğ‘˜ğœ‹
can
be
estimated
by
monte-carlo
sampling
even
for
complicated
ranking
policies
that
have
no
closedform
distribution
while
determining
the
cost
to
specific
individual
is
difficult
since
it
involves
knowledge
of
the
true
relevance
ğ‘Ÿğ‘–
getting
measure
of
the
aggregate
cost
to
the
group
is
more
tractable
in
particular
we
define
the
group
cost
as
the
expected
cost
to
the
relevant
candidates
in
the
group
normalized
by
the
expected
number
of
relevant
candidates
eğ‘Ÿğ‘–
ğ‘Ÿğ‘–
ğœ‹ğ‘˜
ğ‘Ÿğ‘–
ğœ‹ğ‘˜
ğ‘›ğ‘…ğ‘’ğ‘™
ğœğ‘˜
ğ‘Ÿğ‘–
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğœ‹ğ‘˜
ğ‘›ğ‘…ğ‘’ğ‘™
the
last
equality
in
follows
directly
from
eq
we
normalize
the
expected
group
cost
with
the
total
expected
number
of
relevant
candidates
in
the
group
so
that
the
above
approximates
the
fraction
of
relevant
candidates
from
that
group
that
miss
out
on
the
opportunity
of
being
selected
by
the
human
reviewers
equality
of
opportunity
ranking
eor
criterion
we
now
formally
define
our
eor
fairness
criterion
and
argue
that
disparity
in
uncertainty
should
not
lead
to
disparate
costs
for
any
of
the
groups
we
have
already
seen
that
ğ‘ƒğ‘…ğ‘ƒ
and
ğ·ğ‘ƒ
can
violate
this
goal
for
possible
solution
we
turn
to
the
principle
of
random
lottery
that
has
been
historically
used
to
justify
fair
allocation
of
resources
22
44
take
for
example
the
uniform
ranking
policy
unif
which
ignores
ğ‘Ÿğ‘–
and
picks
ranking
uniformly
at
random
use
of
unif
ensures
that
any
relevant
candidate
has
an
equal
chance
of
being
evaluated
and
selected
since
any
top
of
the
ranking
contains
uniform
random
sample
of
the
relevant
candidates
independent
of
group
membership
while
the
ranking
effectiveness
of
unif
is
bad
it
has
the
attractive
property
that
the
fraction
of
relevant
candidates
that
get
selected
from
each
group
is
equal
in
expectation
for
example
if
both
group
and
group
contain
100
relevant
candidates
in
expectation
and
if
unif
selects
relevant
candidate
in
expectation
from
group
it
also
selects
relevant
candidates
in
expectation
from
group
similarly
if
group
contains
200
relevant
candidates
and
group
contains
100
the
selection
ratio
will
be
to
in
expectation
we
formalize
this
property
of
the
uniform
lottery
as
our
key
fairness
axiom
axiom
eor
fair
ranking
policy
for
two
groups
of
candidates
and
ranking
policy
is
equality-of-opportunity
fair
if
for
every
the
top-k
subsets
ğœ‹ğ‘˜
contain
in
expectation
an
equal
fraction
of
the
relevant
candidates
from
each
group
more
precisely
ğ‘›ğ‘…ğ‘’ğ‘™
ğœ‹ğ‘˜
ğ‘›ğ‘…ğ‘’ğ‘™
ğœ‹ğ‘˜
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
while
this
fairness
property
of
unif
is
desirable
its
completely
uninformed
rankings
come
at
cost
to
the
principal
and
the
relevant
candidates
from
both
groups
since
only
few
relevant
candidates
will
be
found
the
uniform
policy
unif
is
particularly
inefficient
when
the
fraction
of
relevant
candidates
is
small
the
key
question
is
thus
whether
we
can
define
an
alternate
ranking
policy
that
retains
the
group-wise
fairness
properties
of
unif
but
retains
as
much
effectiveness
in
surfacing
relevant
candidates
as
possible
to
illustrate
that
such
rankings
exist
which
are
both
eor
fair
and
more
effective
consider
our
motivating
example
of
figure
where
ğ¸ğ‘‚ğ‘…
0.6
0.9
0.6
0.9
0.6
0.5
0.8
0.5
0.7
0.4
0.1
0.4
0.05
0.05
0.05
0.05
0.05
0.05
0.05
0.05
0.4
0.05
0.05
0.05
0.05
has
the
property
that
the
expected
number
of
relevant
candidates
for
each
eaamo
24
october
29
31
2024
san
luis
potosi
mexico
group
in
the
top
never
differs
by
more
than
0.6
for
any
value
of
in
one
way
this
guarantee
is
even
stronger
than
what
is
defined
in
axiom
since
it
holds
for
the
specific
ranking
ğ¸ğ‘‚ğ‘…
without
the
need
for
stochasticity
in
the
ranking
policy
this
provides
non-amortized
notion
of
fairness
which
is
particularly
desirable
for
high-stakes
ranking
tasks
that
do
not
repeat
and
we
thus
need
to
provide
the
strongest
possible
guarantees
for
the
specific
ranking
we
present
however
guarantee
for
an
individual
ranking
makes
the
problem
inherently
discrete
which
means
that
we
require
some
tolerance
0.6
in
the
example
above
in
the
fairness
criterion
depending
on
the
choice
of
this
leads
to
the
following
ğ›¿-eor
fairness
criterion
for
an
individual
ranking
definition
4.1
ğ›¿-eor
fair
ranking
for
two
groups
of
candidates
and
ranking
is
ğ›¿-eor
fair
if
for
every
the
top-k
subset
ğœğ‘˜
differs
in
its
fraction
of
expected
relevant
candidates
from
each
group
by
no
more
than
more
precisely
ğ‘›ğ‘…ğ‘’ğ‘™
ğœğ‘˜
ğ‘›ğ‘…ğ‘’ğ‘™
ğœğ‘˜
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
note
that
we
can
also
define
specific
slack
ğœğ‘˜
for
each
position
for
fair
ranking
this
slack
should
ideally
oscillate
close
to
zero
as
we
increase
and
so
minimizing
its
deviation
from
zero
would
translate
to
ensuring
ğ›¿-eor
fairness
formally
we
can
define
ğœğ‘˜
as
ğœğ‘˜
ğ‘Ÿğ‘–
ğœğ‘˜
ğ‘Ÿğ‘–
ğœğ‘˜
ğ‘Ÿğ‘–
ğ‘Ÿğ‘–
ğ›¿-eor
fairness
balances
the
selection
of
candidates
from
the
two
groups
accounting
for
predictive
uncertainty
in
their
estimation
of
relevances
if
for
instance
the
ml
model
is
less
certain
in
its
predictions
for
group
but
both
groups
have
the
same
total
expected
relevance
the
ğ›¿-eor
criterion
will
rank
candidates
from
group
higher
to
ensure
fairness
importantly
note
how
this
produces
more
human
relevance
labels
of
candidates
from
groups
with
high
uncertainty
which
has
the
desirable
side-effect
of
producing
new
training
data
that
allows
training
of
more
equitable
relevance
models
for
future
use
finally
note
how
the
ğ›¿-eor
fair
ranking
provides
means
for
ensuring
procedural
fairness
and
avoiding
disparate
treatment
importantly
we
leave
the
decision
of
which
candidates
to
select
to
the
human
decision
maker
and
eor
fairness
does
not
require
the
designation
of
disadvantaged
group
instead
the
eor
fair
condition
in
eq
is
symmetrical
both
groups
and
by
definition
treats
both
groups
similarly
and
its
intervention
in
the
ranking
process
is
entirely
driven
by
the
predictive
model
ğ‘Ÿğ‘–
even
though
it
uses
group
membership
eor-fairness
is
thus
fundamentally
different
from
demographic
parity
17
58
and
affirmative
action
rules
like
rooney
rule
12
45
th
rule
selection
rate
for
protected
group
must
be
at
least
80
of
the
rate
for
the
group
with
the
highest
rate
or
ğ›¾-based
notions
of
fairness
18
and
threshold
based
formulations
such
as
fa
ir
61
to
illustrate
the
difference
with
existing
fairness
notions
we
return
to
our
running
example
from
figure
for
top-4
ranking
in
figure
the
eor
criterion
can
be
computed
as
ğœ4ğ¸ğ‘‚ğ‘…
0.15
ğœ4ğ·ğ‘ƒ
0.5
and
ğœ4ğ‘ƒğ‘…ğ‘ƒ
0.83
quantifying
the
unfairness
uniform
guidelines
on
employment
selection
procedures
29
1607.4
2015
rastogi
and
joachims
of
dp
and
prp
as
compared
to
eor
while
dp
selects
one
candidate
from
group
for
every
two
candidates
from
group
applying
45
th
rule
with
group
as
the
disadvantaged
group
will
select
roughly
number
of
candidates
from
group
for
every
two
candidates
from
group
for
top-4
ranking
the
45
th
rule
is
ğœ4fourfifth
0.9
0.6
0.9
0.8
with
ğœ4fourfifth
0.5
if
instead
group
is
selected
as
the
disadvantaged
group
45
th
rule
will
select
all
four
candidates
from
group
resulting
in
ğœ4fourfifth
0.83
same
as
that
of
prp
the
fa
ir
criterion
ğ¹ğ‘†
is
similarly
anchored
on
the
principle
that
top-k
ranking
is
fair
when
the
proportion
of
disadvantaged
candidates
selected
doesn
fall
far
below
required
minimum
proportion
and
also
requires
the
designation
of
disadvantaged
group
in
this
example
ğ¹ğ‘†
gives
the
exact
same
top-4
ranking
and
eor
criterion
as
shown
for
45
th
rule
in
summary
the
predominant
fairness
criteria
in
rankings
motivated
by
the
representation
of
size
perform
very
differently
than
the
ğ¸ğ‘‚ğ‘…
as
an
example
consider
the
well-documented
issue
of
female
candidates
not
being
selected
for
leadership
positions
primarily
due
to
their
small
applicant
pool
size
25
if
the
female
applicants
have
high
disparate
uncertainty
due
to
lack
of
historical
data
affirmative
action
may
still
select
far
fewer
based
on
group
size
of
them
than
deserved
based
on
the
number
of
relevant
female
candidates
we
now
briefly
consider
two
other
notions
of
fairness
in
rankings
for
the
running
example
first
we
look
at
the
exposure-based
formulations
49
the
principle
of
exposure
is
motivated
by
position
bias
in
rankings
and
ensures
the
allocation
of
position
in
rankings
in
proportion
to
the
expected
total
relevance
while
the
position
of
selected
candidate
is
certainly
important
it
does
not
take
disparate
uncertainty
into
consideration
ğ¸ğ‘‹
is
stochastic
policy
that
allocates
equal
exposure
between
the
two
groups
in
this
example
both
groups
have
an
equal
expected
total
relevance
over
the
full
25
positions
of
the
ranking
ğ¸ğ‘‹
allocates
most
of
the
probability
mass
to
candidates
in
group
for
all
of
the
top-4
positions
not
because
they
have
high
uncertainty
but
because
their
group
size
is
smaller
than
group
this
results
in
high
cost
burden
for
group
and
the
eor
criterion
is
computed
as
ğœ4ğ¸ğ‘‹
0.58
higher
than
both
ğ¸ğ‘‚ğ‘…
and
ğ·ğ‘ƒ
later
in
section
we
demonstrate
how
ğ¸ğ‘‹
places
higher
cost
burden
on
the
uninformative
group
instead
when
both
groups
have
relatively
the
same
size
finally
we
discuss
the
thompson
sampling
based
fairness
in
rankings
50
for
ğœ‹ğ‘‡
binary
relevances
are
drawn
according
to
ğ‘Ÿğ‘–
ğ‘Ÿğ‘–
and
candidates
are
sorted
in
decreasing
order
of
relevance
ğ‘Ÿğ‘–
with
their
ranking
randomized
for
the
same
value
of
relevance
the
eor
criterion
for
top-4
ranking
produced
by
ğœ‹ğ‘‡
can
be
computed
as
ğœğ‘‡4
0.29
for
the
running
example
while
ğœ‹ğ‘‡
takes
the
predictive
uncertainty
of
relevance
into
account
by
randomization
of
rankings
it
is
group
oblivious
and
so
does
not
account
for
the
difference
in
the
predictive
uncertainty
of
relevance
between
groups
this
explains
the
high
eor
criterion
of
specific
ğœğ‘‡
with
median
ğ‘›ğ‘˜
ğœğ‘˜ğ‘‡
as
compared
to
that
of
the
ğ¸ğ‘‚ğ‘…
while
we
discussed
how
eor
differs
from
existing
fairness
notions
above
we
will
further
demonstrate
this
comparison
via
extensive
empirical
evaluations
in
section
one
of
our
key
contributions
includes
formalizing
the
connection
between
ğ›¿-eor
fair
ranking
described
in
definition
4.1
and
the
fairness
in
ranking
under
disparate
uncertainty
eaamo
24
october
29
31
2024
san
luis
potosi
mexico
algorithm
eor
algorithm
input
groups
rankings
ğ‘ƒğ‘…ğ‘ƒ
per
group
in
the
sorted
decreasing
order
of
relevance
probabilities
ğ‘Ÿğ‘–
initialize
empty
ranking
ğ¸ğ‘‚ğ‘…
while
do
ğ‘™ğ‘”
ğ‘ƒğ‘…ğ‘ƒ
arg
min
ğ¸ğ‘‚ğ‘…
ğ‘™ğ‘”
where
is
computed
using
ğ‘™ğ‘”
ğ‘ƒğ‘…ğ‘ƒ
ğ‘ƒğ‘…ğ‘ƒ
ğ‘ƒğ‘…ğ‘ƒ
ğ‘™ğ‘”
ğ¸ğ‘‚ğ‘…
ğ¸ğ‘‚ğ‘…
ğ‘™ğ‘”
return
ğ¸ğ‘‚ğ‘…
cost
of
opportunity
in
rankings
described
in
section
4.1
both
ğ›¿eor
fair
ranking
and
cost
of
opportunity
in
rankings
are
derived
separately
the
former
from
the
axiom
of
fairness
of
uniform
lottery
the
latter
from
the
cost
of
errors
that
any
realistic
prediction
model
is
bound
to
make
in
the
next
section
we
show
that
these
two
are
elegantly
related
via
theoretical
results
on
cost
optimality
computing
eor-fair
rankings
we
now
turn
to
the
question
of
how
to
compute
ğ›¿-eor
fair
ranking
ğ¸ğ‘‚ğ‘…
for
any
given
relevance
model
ğ‘Ÿğ‘–
this
ranking
procedure
needs
to
account
for
two
potentially
opposing
goals
first
it
needs
to
ensure
that
ğ›¿-eor
fairness
is
not
violated
ideally
for
that
is
not
larger
than
required
by
the
discreteness
of
the
ranking
second
it
should
maximize
the
number
of
relevant
candidates
contained
in
the
top
for
any
a-priori
unknown
while
solving
this
optimization
problem
in
the
exponentially
sized
space
of
rankings
is
computationally
inefficient
we
show
that
algorithm
is
an
efficient
ranking
method
that
provides
close-to-optimal
solution
algorithm
uses
as
input
the
prp
rankings
ğ‘ƒğ‘…ğ‘ƒ
and
ğ‘ƒğ‘…ğ‘ƒ
for
each
of
the
groups
and
respectively
we
denote
ğ‘ƒğ‘…ğ‘ƒ
as
the
ğ‘¡â„
element
in
the
prp
ranking
of
group
the
basic
idea
is
to
compare
the
highest
relevance
candidate
from
each
group
and
select
the
candidate
that
would
minimize
the
for
the
resultant
ranking
breaking
ties
arbitrarily
when
selecting
an
element
from
either
group
results
in
the
same
for
the
resultant
ranking
consider
our
running
example
from
figure
at
selecting
the
first
element
from
group
ğ‘ƒğ‘…ğ‘ƒ
would
result
in
ğœ1
0.9
while
selecting
the
first
element
from
group
ğ‘ƒğ‘…ğ‘ƒ
would
result
in
ğœ1
0.6
to
minimize
ğœ1
the
algorithm
selects
the
first
element
from
group
with
ğœ1ğ¸ğ‘‚ğ‘…
0.6
ğœ1
0.6
for
the
first
element
from
group
and
the
second
element
from
group
are
considered
it
proceeds
to
select
the
first
element
from
group
with
ğœ2ğ¸ğ‘‚ğ‘…
0.6
0.9
ğœ2
0.3
and
so
on
the
algorithm
does
not
change
the
relative
ordering
between
candidates
within
group
and
its
runtime
complexity
is
log
since
the
elements
from
the
two
groups
each
need
to
be
sorted
once
by
ğ‘Ÿğ‘–
composing
the
final
eor
ranking
ğ¸ğ‘‚ğ‘…
by
merging
the
two
group-based
rankings
ğ‘ƒğ‘…ğ‘ƒ
and
ğ‘ƒğ‘…ğ‘ƒ
takes
only
linear
time
since
each
computation
per
iteration
is
constant
time
per
prefix
while
algorithm
is
inspired
by
existing
algorithms
such
as
61
in
that
both
select
the
top
element
from
the
prp
ranking
of
each
group
they
are
fundamentally
different
existing
methods
including
61
ensure
form
of
demographic
parity
which
we
have
already
shown
to
be
fundamentally
different
than
the
eor
criterion
we
propose
additionally
while
61
requires
threshold
input
and
the
designation
of
disadvantaged
group
the
eor
algorithm
does
not
require
this
normative
designation
and
guarantees
eor
fairness
without
requiring
any
tolerance
as
an
input
we
show
this
both
theoretically
and
in
empirical
evaluations
and
provide
detailed
description
of
baseline
algorithms
in
appendix
it
remains
to
be
shown
that
algorithm
always
produces
ranking
ğ¸ğ‘‚ğ‘…
with
small
while
surfacing
as
many
relevant
candidates
as
possible
in
any
top
prefix
we
break
the
proof
of
this
guarantee
into
the
following
steps
first
we
show
that
for
any
particular
and
its
associated
ğœğ‘˜ğ¸ğ‘‚ğ‘…
the
number
of
relevant
candidates
in
the
top-ğ‘˜
is
close
to
optimal
second
we
provide
an
upper
bound
on
ğœğ‘˜ğ¸ğ‘‚ğ‘…
that
is
entirely
determined
priori
by
the
specific
ğ‘Ÿğ‘–
to
address
the
first
step
the
following
theorem
5.1
shows
that
the
rankings
produced
by
algorithm
have
cost
to
the
principal
that
is
close
to
optimal
theorem
5.1
cost
approximation
guarantee
at
the
eor
fair
ranking
ğ¸ğ‘‚ğ‘…
produced
by
algorithm
is
at
least
ğœ™ğ›¿
ğœğ‘˜ğ¸ğ‘‚ğ‘…
cost
optimal
for
any
prefix
where
ğ‘ğ´
ğ‘ğ´
ğ‘ğµ
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘ğ´
ğ‘ğµ
ğ‘ğ´
ğ‘›ğ‘…ğ‘’ğ‘™
and
ğ‘›ğ‘…ğ‘’ğ‘™
further
ğ‘ğ´
ğ‘ƒğ‘…ğ‘ƒ
ğ‘˜ğ´
ğ‘ƒğ‘…ğ‘ƒ
ğ‘˜ğµ
where
ğ‘˜ğ´
is
the
last
element
from
group
that
was
selected
by
eor
algorithm
for
prefix
and
similarly
for
ğ‘˜ğµ
proof
sketch
we
use
linear
duality
to
prove
this
theorem
to
find
lower
bound
on
the
cost
optimal
ranking
that
satisfies
the
eor
fairness
constraint
we
formulate
the
corresponding
linear
integer
problem
ilp
for
selecting
the
optimal
top-k
subset
under
the
ğ›¿eor
constraint
this
leads
to
the
following
optimization
problem
where
is
the
variable
for
whether
the
ğ‘¡â„
candidate
was
chosen
or
not
is
the
relevance
probability
for
all
candidates
minimize
total
cost
as
defined
in
eq
min
ğ‘ƒğ‘‡
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ilp
select
up
to
candidates
ğ‘ƒiğ´
ğ‘ƒiğµ
ğœğ‘˜ğ¸ğ‘‚ğ‘…
ğœğ‘˜ğ¸ğ‘‚ğ‘…
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
eor
fairness
from
eq
must
be
satisfied
we
relax
this
ilp
to
linear
program
lp
by
turning
any
integer
constraints
in
the
primal
into
for
the
relaxed
lp
we
formulate
its
dual
and
construct
set
of
dual
variables
corresponding
to
the
solution
from
the
eor
algorithm
using
the
dual
value
of
the
eor
solution
and
the
relaxed
lp
solution
we
obtain
an
upper
bound
of
the
duality
gap
since
the
upper
bound
on
this
duality
gap
is
the
relaxed
lp
solution
it
is
also
an
upper
bound
for
the
optimal
ilp
solution
we
provide
complete
proof
of
the
theorem
and
associated
lemmas
in
appendix
note
that
depends
only
on
the
relevance
probabilities
of
the
last
elements
selected
from
each
group
by
the
eor
algorithm
in
the
eaamo
24
october
29
31
2024
san
luis
potosi
mexico
rastogi
and
joachims
ğ‘¡â„
position
furthermore
note
that
the
solution
of
algorithm
is
the
exact
optimum
for
any
where
the
unfairness
ğœğ‘˜ğ¸ğ‘‚ğ‘…
is
zero
indicating
that
any
suboptimality
of
the
eor
algorithm
is
merely
due
to
some
presumably
unavoidable
discretization
effects
while
the
previous
theorem
characterized
cost
optimality
the
following
theorem
5.2
shows
that
the
magnitude
of
unfairness
ğœğ‘˜ğ¸ğ‘‚ğ‘…
is
bounded
by
some
ğ›¿ğ‘šğ‘ğ‘¥
providing
an
priori
approximation
guarantee
for
both
the
amount
of
unfairness
and
the
cost
optimality
of
algorithm
theorem
5.2
global
cost
and
fairness
guarantee
algorithm
always
produces
ranking
ğ¸ğ‘‚ğ‘…
that
is
at
least
ğœ™ğ›¿
ğ‘šğ‘ğ‘¥
cost
optimal
for
any
with
ğ›¿ğ‘šğ‘ğ‘¥
12
ğ‘ƒğ‘…ğ‘ƒ
ğ‘ƒğ‘…ğ‘ƒ
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
the
following
selection
rule
then
provides
the
selected
group
and
candidate
ğ‘™ğ‘”
to
append
to
the
eor
ranking
ğ‘™ğ‘”
ğ‘ƒğ‘…ğ‘ƒ
arg
min
ğ¸ğ‘‚ğ‘…
ğ‘™ğ‘”
ğ‘™ğ‘”
ğ‘ƒğ‘…ğ‘ƒ
note
that
the
above
selection
rule
is
strict
generalization
of
algorithm
and
it
reflects
the
intuition
of
minimizing
the
gap
in
relevance
proportions
for
all
the
groups
it
can
be
verified
that
the
runtime
complexity
with
selection
rule
according
to
eqs
for
constant
number
of
groups
is
log
ğºğ‘›
furthermore
we
can
extend
the
cost-approximation
guarantee
to
the
multi-group
case
proof
sketch
we
show
via
an
inductive
argument
that
according
to
the
eor
algorithm
minimizing
ğœğ‘˜ğ¸ğ‘‚ğ‘…
at
every
ensures
that
the
resultant
eor
ranking
always
satisfies
ğœğ‘˜ğ¸ğ‘‚ğ‘…
ğ‘ƒğ‘…ğ‘ƒ
ğ‘ƒğ‘…ğ‘ƒ
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
that
is
bounded
by
the
average
of
the
relevance
proportions
from
the
first
two
elements
considered
in
the
selection
from
group
and
we
denote
this
global
fairness
guarantee
by
ğ›¿ğ‘šğ‘ğ‘¥
using
from
theorem
5.1
the
cost
guarantee
is
given
by
ğ‘ƒğ‘…ğ‘ƒ
ğ‘ƒğ‘…ğ‘ƒ
ğœ™ğ›¿ğ‘šğ‘ğ‘¥
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘ğ´
ğ‘ğµ
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
further
we
show
that
if
the
eor
algorithm
selects
all
the
elements
from
one
group
at
some
position
then
selecting
the
remaining
elements
from
the
other
group
satisfies
the
ğ›¿ğ‘šğ‘ğ‘¥
constraint
we
provide
complete
proof
of
this
theorem
in
appendix
we
now
compare
eor
with
the
uniform
ranking
policy
and
analyze
positions
with
to
avoid
discretization
effects
proposition
5.1
costs
from
eor
vs
uniform
policy
the
eor
ranking
never
has
higher
costs
to
the
groups
and
total
cost
to
the
principal
as
compared
to
the
uniform
policy
for
those
where
ğœğ‘˜
we
provide
the
proof
of
proposition
5.1
in
appendix
in
summary
we
have
shown
that
algorithm
is
an
efficient
algorithm
that
computes
rankings
close
to
the
optimal
solution
making
it
promising
candidate
for
practical
use
theorem
6.1
global
cost
and
fairness
guarantee
for
multiple
groups
the
eor
rankings
are
cost
optimal
up
to
gap
of
ğœ™ğ›¿
ğœğ‘˜ğ¸ğ‘‚ğ‘…
for
groups
with
ğœğ‘˜ğ¸ğ‘‚ğ‘…
bounded
by
ğ›¿ğ‘šğ‘ğ‘¥
such
that
extension
to
groups
in
this
section
we
discuss
the
extension
of
the
eor
algorithm
beyond
two
groups
in
particular
we
consider
the
general
case
where
candidate
belongs
to
one
of
groups
from
section
we
can
generalize
the
cost
burden
to
the
principal
similar
to
eq
taking
all
the
groups
into
account
for
the
normalization
factor
as
follows
ğœğ‘˜
ğ‘Ÿğ‘–
principal
ğœ‹ğ‘˜
Ã­ğº
ğ‘›ğ‘…ğ‘’ğ‘™
to
generalize
algorithm
for
selecting
top
candidates
from
multiple
groups
we
define
as
the
eor
criterion
that
captures
the
gap
between
the
group
with
the
maximum
accumulated
relevance
proportion
and
the
group
with
the
minimum
accumulated
relevance
proportion
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
max
min
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ›¿ğ‘šğ‘ğ‘¥
ğ‘ğ´
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘ğ´
ğ‘ğµ
ğ‘ƒğ‘…ğ‘ƒ
max
ğ‘›ğ‘…ğ‘’ğ‘™
Ã­ğº
where
are
all
choose
possible
pairs
of
groups
proof
sketch
we
extend
the
lp
formed
in
theorem
5.1
to
include
constraints
and
construct
feasible
dual
variables
from
the
eor
solution
for
each
pair
of
groups
we
then
show
that
the
duality
gap
is
bounded
by
ğœ™ğ›¿
ğœğ‘˜ğ¸ğ‘‚ğ‘…
for
particular
prefix
note
that
the
bound
for
multi-group
reduces
to
the
one
presented
in
theorem
5.1
for
two
groups
finally
we
present
the
global
priori
bound
on
ğœğ‘˜ğ¸ğ‘‚ğ‘…
as
ğ›¿ğ‘šğ‘ğ‘¥
which
is
strict
generalization
of
the
two
groups
case
we
provide
complete
proof
of
this
theorem
in
appendix
experimental
evaluation
we
now
evaluate
the
eor
framework
and
algorithm
empirically
and
compare
against
several
baselines
namely
demographic
statistical
parity
ğ·ğ‘ƒ
58
fa
ir
ranking
principle
ğ¹ğ‘†
61
probability
ranking
principle
ğ‘ƒğ‘…ğ‘ƒ
41
thompson
sampling
policy
ğœ‹ğ‘‡
50
uniform
policy
unif
disparate
treatment
of
exposure
ğ¸ğ‘‹
49
and
fair
rank
aggregation
ğ‘…ğ´
with
proportional
representation
of
exposure
we
discuss
implementation
details
of
these
baselines
in
appendix
7.1
synthetic
data
we
first
present
results
on
synthetic
data
where
we
can
control
the
level
of
disparate
uncertainty
we
report
unfairness
and
effectiveness
of
rankings
for
each
scenario
the
unfairness
metric
is
defined
as
the
area
under
the
curve
for
the
eor
criterion
given
by
Ã­ğ‘›
ğœğ‘˜
to
measure
the
effectiveness
of
rankings
we
report
the
improvement
in
total
cost
over
the
expected
total
cost
of
unif
computed
as
ğ‘›ğ‘˜
prinicpal
ğœ‹ğ‘˜unif
prinicpal
ğœ‹ğ‘˜
7.1
how
does
ğ¸ğ‘‚ğ‘…
compare
against
the
baselines
under
varying
amounts
of
disparate
uncertainty
table
left
reports
unfairness
eaamo
24
october
29
31
2024
san
luis
potosi
mexico
un-fairness
effectiveness
disp
unc
high
medium
low
high
medium
low
ğ¸ğ‘‚ğ‘…
ğ·ğ‘ƒ
ğ‘ƒğ‘…ğ‘ƒ
ğœ‹ğ‘‡
unif
ğ¸ğ‘‹
ğ‘…ğ´
ğ¹ğ‘†
1.07
0.01
11.09
0.38
15.41
0.69
11.77
0.57
5.96
0.13
9.23
0.77
13.97
0.71
13.33
0.70
1.02
0.00
6.02
0.07
7.68
0.13
4.96
0.07
5.80
0.00
5.62
0.01
6.57
0.16
7.04
0.16
1.02
0.00
2.42
0.20
2.63
0.17
4.49
0.45
6.49
0.09
3.26
0.62
2.40
0.00
2.95
0.17
10.44
0.15
10.07
0.20
12.11
0.20
7.66
0.04
0.00
0.00
11.59
0.23
12.02
0.19
11.98
0.20
11.89
0.04
11.33
0.04
12.00
0.02
9.62
0.06
0.00
0.00
11.97
0.03
12.00
0.02
12.00
0.02
14.58
0.10
14.49
0.11
14.62
0.09
12.81
0.69
0.00
0.00
14.62
0.09
14.60
0.00
14.62
0.09
table
left
effect
of
varying
disparate
uncertainty
on
synthetic
dataset
right
posterior
distribution
and
expected
probabilities
of
relevance
shown
for
sample
from
each
of
high
medium
and
low
uncertainty
setting
and
effectiveness
for
ğ¸ğ‘‚ğ‘…
and
the
baselines
in
terms
of
mean
and
standard
error
over
100
simulations
while
table
right
demonstrates
the
posterior
distribution
formed
by
sampling
an
instance
of
each
of
high
medium
and
low
disparate
uncertainty
settings
these
posterior
distributions
similar
to
figure
are
for
illustrative
purposes
since
only
the
expected
probability
of
relevance
ğ‘ğ‘–
is
used
for
rankings
refer
to
section
3.2
the
different
disparate
uncertainty
settings
are
generated
synthetically
to
demonstrate
how
ranking
policies
behave
if
for
example
the
principal
collects
more
data
for
group
thus
reducing
the
disparate
uncertainty
among
groups
note
how
in
the
low
disparate
uncertainty
setting
the
sharp
ğ‘ğ‘–
close
to
or
would
make
the
identification
of
relevant
candidates
easy
for
both
groups
the
synthetic
generation
involves
sampling
ğ‘ğ‘–
from
sharp
and
flat
distributions
for
group
and
respectively
and
gradually
increasing
the
sharpness
of
ğ‘ğ‘–
for
group
implementation
details
in
appendix
as
predicted
by
theory
ğ¸ğ‘‚ğ‘…
maintains
low
unfairness
at
all
levels
of
disparate
uncertainty
outperforming
all
the
baselines
ğ‘ƒğ‘…ğ‘ƒ
ğ·ğ‘ƒ
ğœ‹ğ‘‡
ğ¸ğ‘‹
ğ‘…ğ´
and
ğ¹ğ‘†
note
that
ğ¸ğ‘‚ğ‘…
even
outperforms
the
uniform
policy
unif
since
any
individual
ranking
drawn
from
unif
is
likely
to
be
unfair
in
terms
of
effectiveness
the
theoretically
optimal
skyline
is
given
by
ğ‘ƒğ‘…ğ‘ƒ
across
all
levels
of
disparate
uncertainty
ğ¸ğ‘‚ğ‘…
is
at
least
competitive
with
the
other
baselines
indicating
that
the
eor
fairness
does
not
impose
disproportionate
cost
of
fairness
for
the
principal
note
how
the
gap
in
the
unfairness
between
ğ¸ğ‘‚ğ‘…
and
all
other
ranking
policies
is
largest
when
disparate
uncertainty
is
highest
at
low
levels
of
disparate
uncertainty
ğ¸ğ‘‚ğ‘…
is
still
more
fair
as
compared
to
other
ranking
policies
though
the
gap
in
unfairness
is
smaller
and
the
effectiveness
of
ğ¸ğ‘‚ğ‘…
is
almost
the
same
as
that
of
ğ‘ƒğ‘…ğ‘ƒ
7.1
at
which
positions
in
the
rankings
do
the
policies
incur
unfairness
while
the
previous
table
summarized
unfairness
across
the
whole
ranking
figure
left
provides
more
detailed
insights
into
how
unfairness
accumulates
across
positions
in
the
ranking
the
only
method
that
is
systematically
fair
across
all
positions
is
ğ¸ğ‘‚ğ‘…
keeping
the
unfairness
ğœğ‘˜
from
definition
4.1
close
posterior
fairness
in
ranking
under
disparate
uncertainty
ri
group
group
high
disparate
uncertainty
medium
disparate
uncertainty
low
disparate
uncertainty
0.0
0.2
0.4
0.6
0.8
1.0
to
zero
everywhere
in
the
ranking
the
baselines
generally
start
accumulating
unfairness
towards
one
group
right
from
the
top
of
the
ranking
their
unfairness
only
decreases
once
they
run
out
of
viable
candidates
from
the
group
they
prefer
the
only
exception
is
unif
here
for
specific
ranking
with
median
ğ‘›ğ‘˜
ğœğ‘˜unif
however
rankings
from
unif
tend
to
stray
much
further
from
zero
than
the
ğ¸ğ‘‚ğ‘…
ranking
additional
results
for
the
medium
and
low
disparate
uncertainty
settings
in
figure
11
of
appendix
further
support
these
findings
7.1
how
do
the
ranking
policies
distribute
the
costs
between
the
stakeholders
in
figure
middle
we
investigate
how
the
ranking
policies
distribute
the
cost
ğœ‹ğ‘˜
from
eq
between
group
and
group
it
shows
that
only
ğ¸ğ‘‚ğ‘…
has
an
equal
cost
to
both
groups
across
the
whole
ranking
which
can
be
seen
from
the
overlapping
cost
curves
for
both
groups
furthermore
the
cost
is
substantially
lower
for
both
groups
than
their
expected
cost
under
the
uniform
policy
diagonal
line
figure
right
shows
the
total
cost
to
the
principal
and
again
ğ¸ğ‘‚ğ‘…
is
competitive
with
the
baselines
all
other
baselines
incur
substantial
disparate
costs
to
the
groups
some
even
worse
than
the
uniform
lottery
in
particular
ğ·ğ‘ƒ
selects
the
candidates
alternately
between
the
two
groups
since
group
sizes
are
relatively
similar
but
this
results
in
selecting
higher
proportion
of
relevance
from
group
because
the
relevance
probabilities
are
sharper
for
group
than
for
as
result
the
cost
burden
is
higher
for
group
ğœ‹ğ‘‡
is
fairer
than
ğ‘ƒğ‘…ğ‘ƒ
since
it
randomizes
relevant
candidates
before
sorting
them
in
decreasing
order
of
relevance
however
being
group
oblivious
it
still
places
an
uneven
cost
burden
the
exposure
based
policies
ğ¸ğ‘‹
ğ‘…ğ´
motivated
by
position
bias
in
rankings
also
do
not
distribute
the
costs
evenly
ğ¸ğ‘‹
will
stochastically
allocate
most
of
the
top
positions
to
candidates
with
sharp
and
high
probabilities
close
to
1.0
from
group
then
to
candidates
of
group
with
flat
and
middle
relevance
probabilities
and
finally
the
rest
of
the
candidates
from
group
with
sharp
but
low
probabilities
close
to
0.0
in
the
last
positions
while
this
perfectly
allocates
exposure
between
group
and
over
the
full
ranking
of
61
candidates
group
the
uninformative
group
suffers
from
high
cost
burden
note
how
the
direction
of
cost
burden
eaamo
24
october
29
31
2024
san
luis
potosi
mexico
eor
dp
prp
ts
rastogi
and
joachims
uniform
exp
1.0
ra
fs
eor
dp
group
prp
group
principal
1.0
ts
0.5
0.0
1.0
61
61
61
exp
ra
fs
total
costs
group
costs
0.8
61
0.6
0.4
0.2
0.0
0.0
61
61
length
of
ranking
61
61
0.0
61
is
opposite
example
of
figure
0.5
to
the
one
ğ¸ğ‘‹
induced
in
the
0a
where
group
was
smaller
in
size
to
group
7.2
1.0
61
exp
us
census
survey
data
while
the
synthetic
experiments
provide
insights
into
the
behavior
0.0
policies
under
varying
conditions
of
ranking
we
now
investigate
how
far
ğ¸ğ‘‚ğ‘…
can
mitigate
unfairness
as0
it
arises
in
real-world
the
relevance
probabilities
61
ğ‘Ÿğ‘–
are
learned
61
datasets
where
lengthweofconsider
ranking
from
data
in
particular
the
us
census
survey
dataset
14
for
the
year
2018
and
the
state
of
alabama
and
new
york
consisting
of
22
268
and
103
021
records
respectively
the
task
is
to
predict
whether
the
income
for
an
individual
50ğ¾
based
on
features
such
as
educational
attainment
occupation
class
of
worker
etc
we
use
this
task
as
stand-in
for
some
task
where
individuals
receive
benefit
from
being
evaluated
positively
to
get
group-calibrated
estimates
of
ğ‘Ÿğ‘–
we
train
gradient
boosting
classifier
followed
by
platt
scaling
on
the
validation
subset
of
the
data
we
evaluate
the
eor
criterion
and
costs
on
the
test
subset
of
these
records
full
details
for
dataset
pre-processing
and
training
can
be
found
in
appendix
because
these
rankings
are
large
up
to
20ğ¾
size
ğ¸ğ‘‹
and
ğ¹ğ‘†
are
not
computationally
tractable
ğ‘…ğ´
performs
similarly
to
ğ‘ƒğ‘…ğ‘ƒ
and
we
include
it
in
appendix
for
completeness
7.2
how
do
the
ranking
policies
compare
when
using
learned
probability
estimates
to
evaluate
the
two-group
eor
algorithm
we
first
only
rank
individuals
labeled
as
white
and
black
or
african
american
figure
top
shows
that
eor
ranking
is
effective
even
with
estimated
probabilities
in
particular
while
the
ranking
algorithms
only
use
estimated
probabilities
the
eor
criterion
and
costs
are
evaluated
on
the
true
relevance
labels
from
the
test
set
nevertheless
ğ¸ğ‘‚ğ‘…
still
evaluates
close
to
zero
and
distributes
costs
among
the
stakeholders
more
evenly
than
the
other
baseline
policies
ğ‘ƒğ‘…ğ‘ƒ
ğ·ğ‘ƒ
and
even
unif
ğœ‹ğ‘‡
for
specific
ranking
with
median
ğ‘›ğ‘˜
ğœğ‘˜
additional
experiments
in
appendix
further
confirm
these
findings
total
costs
group
costs
figure
left
eor
criterion
ğœğ‘˜
middle
group
costs
according
to
right
the
principal
total
cost
according
to
of
the
ranking
policies
for
the
synthetic
dataset
with
high1
disparate
uncertainty
shown
in
top
right
of
table
group
consists
of
30
0candidates
with
sharp
eor
14.96
expected
dp
number
of
relevant
prp
probabilities
with
ğ‘ğ‘–
beta
20
20
this
provides
ğ‘›ğ‘…ğ‘’ğ‘™
candidates
ts
group
also
has
similar
candidates
in
particular
it
has
31
candidates
with
relatively
flat
probabilities
ğ‘ğ‘–
beta
providing
ğ‘›ğ‘…ğ‘’ğ‘™
14.94
expected
number
of
0.8
relevant
candidates
7.2
how
does
eor
ranking
perform
for0
more
than
two
groups
figure
bottom
shows
results
on
the
us
census
dataset
for
four
61
61
61
groups
ra
again
using
estimated
relevances
for0
4ranking
but
evaluating
against
the
true
relevance
labels
from
the
test
dataset
note
that
for
more
than
two
groups
the
eor
constraint
0.2
defined
according
to
will
always
be
non-negative
as
it
measures
the
absolute
difference
in
relevance
proportions
between
the
groups
0that
are
furthest
apart
we
observe
that
similar
to
the
results
with
two
groups
the
eor
10
20
30
40
61keeps
the
unfairness
61
lower
close
to
zero
ranking
as
compared
to
other
policies
in
figure
left
additionally
ğ¸ğ‘‚ğ‘…
also
distributes
the
costs
evenly
among
all
stakeholders
for
the
generalized
case
of
more
than
two
groups
as
noted
by
the
overlapping
of
dashed
lines
for
the
four
group
costs
middle
finally
ğ¸ğ‘‚ğ‘…
is
competitive
with
the
optimal
ğ‘ƒğ‘…ğ‘ƒ
in
terms
of
total
cost
for
the
principal
7.3
amazon
shopping
audit
in
the
final
experiment
we
investigate
how
the
eor
framework
can
be
used
for
auditing
to
illustrate
this
point
we
use
dataset
of
amazon
shopping
queries
39
which
includes
baseline
model
for
predicting
the
relevance
of
products
given
search
query
we
further
augment
this
dataset
with
logged
rankings
from
the
amazon
website
as
collected
for
the
markup
report
60
which
investigated
amazon
placement
of
its
own
brand
products
as
compared
to
other
brands
based
on
star
ratings
reviews
etc
the
markup
data
consists
of
popular
search
query-product
pairs
along
with
logged
rankings
of
these
products
on
amazon
platform
but
it
does
not
contain
human-annotated
relevance
labels
we
focus
the
audit
on
bias
between
the
group
of
amazon-owned
brands
group
or
any
other
brand
group
as
the
first
step
of
the
audit
we
calibrate
ğ‘ğ‘–
by
fitting
platt-scaling
calibrator
using
validation
data
for
both
groups
figure
6a
shows
that
the
calibrated
ğ‘ğ‘–
on
the
test
dataset
binned
across
20
equal-sized
bins
lies
close
to
the
perfectly
calibrated
line
as
the
second
step
of
the
audit
we
use
the
markup
dataset
with
logged
rankings4
and
compute
ğ‘ğ‘–
using
the
calibrated
https://github.com/the-markup/investigation-amazon-brands
50
60
fairness
in
ranking
under
disparate
uncertainty
0.2
group
costs
0.2
0.3
0.1
0.0
1.0
0.0
0.1
0.1
0.0
group
costs
1.0
0.3
0.4
uniform
white
1.0
0.4
dp
prp
ts
0.2
0.1
length
of
ranking
0.0
1.0
1.0
1.0
0.5
0.5
prp
ts
19985
19985
0.0
19985
4268
19985
0.5
0.0
principal
0.0
4268
0.0
1.0
19985
dp
0.0
0.0
4268
4268
1.0
19985
eor
length19985
of
ranking
group
costs
0.0
1.0
others
eor
0.3
0.0
black
asian
totalcosts
costs
total
prp
ts
total
costs
eor
dp
eaamo
24
october
29
31
2024
san
luis
potosi
mexico
19985
figure
us
census
dataset
eor
criterion
ğœğ‘˜
and
cost
of
the
ranking
policies
computed
with
true
relevance
labels
from
the
test
subset
for
the
us
census
dataset
top
two
groups
setting
using
the
white
and
black
african
american
racial
groups
for
the
state
of
alabama
bottom
multiple
four
groups
setting
using
white
black
african
american
asian
and
other
for
the
state
of
ny
0.8
0.15
perfect
calibration
amazon
group
non-amazon
group
0.10
0.6
Ïƒk
mean
empirical
rate
1.0
0.4
0.00
Î´k
0.05
0.2
0.00
0.05
0.2
0.4
0.6
0.8
1.0
mean
predicted
rate
0.10
eor
logged
ranking
10
20
30
40
50
60
length
of
ranking
figure
left
group-wise
calibration
of
ğ‘Ÿğ‘–
for
amazon
shopping
queries
on
the
test
set
according
to
the
baseline
model
after
platt
scaling
right
fairness
of
logged
amazon
rankings
compared
to
eor
rankings
in
terms
of
ğœğ‘˜
averaged
over
queries
baseline
relevance
prediction
model
the
eor
criterion
is
averaged
over
queries
for
the
logged
rankings
and
the
eor
rankings
are
produced
by
algorithm
figure
6b
shows
that
there
exists
ranking
ğ¸ğ‘‚ğ‘…
that
has
ğœğ‘˜ğ¸ğ‘‚ğ‘…
closer
to
zero
for
most
prefix
the
logged
rankings
from
amazon
platform
show
estimated
ğœğ‘˜
that
are
farther
away
from
zero
for
at
least
some
prefixes
of
reflecting
potential
favoring
of
amazon
brand
products
limitation
of
this
analysis
is
that
unlike
in
real
audit
where
the
auditor
has
access
to
the
production
model
of
ğ‘ğ‘–
our
baseline
model
may
be
subject
to
hidden
confounding
and
thus
does
not
provide
conclusive
evidence
of
unfairness
in
particular
the
production
rankings
may
depend
on
other
features
beyond
product
titles
product
descriptions
bullet
points
star
ratings
etc
however
the
analysis
does
demonstrate
how
the
eor
criterion
can
be
used
for
auditing
if
the
auditor
is
given
access
to
the
production
ranking
model
to
avoid
confounding
we
provide
further
details
in
figure
and
our
source
code
with
experiment
implementation
can
be
found
here
conclusion
this
paper
studies
the
problem
of
disparate
uncertainty
across
groups
as
source
of
unfairness
in
ranking
when
these
rankings
are
used
as
part
of
human
decision-making
process
in
particular
this
paper
introduces
framework
that
formalizes
this
unfairness
by
relating
it
both
to
fair
lottery
and
to
the
costs
that
an
imperfect
model
imposes
on
the
various
stakeholders
recognizing
that
it
may
be
difficult
to
avoid
disparate
uncertainty
in
real-world
models
the
paper
develops
the
eor
procedure
to
produce
rankings
that
provably
mitigate
the
effects
of
disparate
uncertainty
between
groups
beyond
its
strong
theoretical
guarantees
we
find
that
the
https://github.com/richrast/disparateuncertainty
eaamo
24
october
29
31
2024
san
luis
potosi
mexico
eor
method
outperforms
existing
methods
for
fair
ranking
across
wide
range
of
settings
furthermore
we
illustrate
that
the
eor
criterion
can
also
be
used
as
tool
to
audit
real-world
system
we
conjecture
that
this
combination
of
theoretical
grounding
computational
efficiency
and
strong
empirical
performance
provides
viable
conditions
for
making
the
proposed
framework
and
algorithm
accessible
for
thoughtful
use
in
practice
ethical
considerations
this
work
explicitly
addresses
the
potentially
negative
societal
impact
of
machine
learning
predictions
that
include
disparities
between
groups
in
the
context
of
ranking
interfaces
however
as
pointed
out
by
previous
research
34
46
we
do
not
prescribe
distilling
down
the
fairness
of
system
into
single
metric
the
fairness
criterion
we
propose
we
emphasize
that
it
is
important
to
carefully
consider
the
domain
specifics
and
the
particular
situation
where
our
method
may
be
deployed
we
also
note
that
while
our
eor
algorithm
does
not
worsen
the
fairness
within
each
group
within
group
ordering
is
maintained
it
doesn
improve
within-group
fairness
either
exploring
this
dichotomy
of
satisfying
within
and
between
group
fairness
simultaneously
in
the
presence
of
differential
uncertainty
is
an
important
open
question
acknowledgments
this
research
was
supported
in
part
by
nsf
awards
iis-2008139
and
iis-2312865
all
content
represents
the
opinion
of
the
authors
which
is
not
necessarily
shared
or
endorsed
by
their
respective
employers
and
or
sponsors
we
thank
kate
donahue
marios
papachristou
aaron
tucker
sarah
dean
luke
wang
emily
ryu
ashudeep
singh
taran
pal
singh
and
woojeong
kim
for
helpful
comments
and
discussions
we
also
thank
the
anonymous
reviewers
at
the
epistemic
ai
uai
workshop
for
helpful
feedback
references
kenneth
arrow
1971
the
theory
of
discrimination
working
papers
403
princeton
university
department
of
economics
industrial
relations
section
https://econpapers.repec.org/repec:pri:indrel:30a
pranjal
awasthi
matthÃ¤us
kleindessner
and
jamie
morgenstern
2020
equalized
odds
postprocessing
under
imperfect
group
information
in
proceedings
of
the
twenty
third
international
conference
on
artificial
intelligence
and
statistics
proceedings
of
machine
learning
research
vol
108
silvia
chiappa
and
roberto
calandra
eds
pmlr
1770
1780
https://proceedings.mlr.press/v108/
awasthi20a
html
richard
berk
hoda
heidari
shahin
jabbari
michael
kearns
and
aaron
roth
2021
fairness
in
criminal
justice
risk
assessments
the
state
of
the
art
sociological
methods
research
50
2021
44
https://doi.org/10.1177/
0049124118782533
arxiv
https://doi.org/10.1177/0049124118782533
asia
biega
krishna
gummadi
and
gerhard
weikum
2018
equity
of
attention
amortizing
individual
fairness
in
rankings
corr
abs
1805.01788
2018
arxiv
1805.01788
http://arxiv.org/abs/1805.01788
joy
buolamwini
and
timnit
gebru
2018
gender
shades
intersectional
accuracy
disparities
in
commercial
gender
classification
in
proceedings
of
the
1st
conference
on
fairness
accountability
and
transparency
proceedings
of
machine
learning
research
vol
81
sorelle
friedler
and
christo
wilson
eds
pmlr
77
91
https://proceedings.mlr.press/v81/buolamwini18a.html
robin
burke
2017
multisided
fairness
for
recommendation
corr
abs
1707.00093
2017
arxiv
1707.00093
http://arxiv.org/abs/1707.00093
kathleen
cachel
and
elke
rundensteiner
2023
fairer
together
mitigating
disparate
exposure
in
kemeny
rank
aggregation
in
proceedings
of
the
2023
acm
conference
on
fairness
accountability
and
transparency
chicago
il
usa
facct
23
association
for
computing
machinery
new
york
ny
usa
1347
1357
https://doi.org/10.1145/3593013.3594085
rastogi
and
joachims
elisa
celis
chris
hays
anay
mehrotra
and
nisheeth
vishnoi
2021
the
effect
of
the
rooney
rule
on
implicit
bias
in
the
long
term
in
proceedings
of
the
2021
acm
conference
on
fairness
accountability
and
transparency
virtual
event
canada
facct
21
association
for
computing
machinery
new
york
ny
usa
678
689
https://doi.org/10.1145/3442188.3445930
elisa
celis
anay
mehrotra
and
nisheeth
vishnoi
2020
interventions
for
ranking
in
the
presence
of
implicit
bias
in
proceedings
of
the
2020
conference
on
fairness
accountability
and
transparency
barcelona
spain
fat
20
association
for
computing
machinery
new
york
ny
usa
369
380
https://doi.org/10.1145/3351095.3372858
10
elisa
celis
damian
straszak
and
nisheeth
vishnoi
2017
ranking
with
fairness
constraints
in
international
colloquium
on
automata
languages
and
programming
11
alexandra
chouldechova
2017
fair
prediction
with
disparate
impact
study
of
bias
in
recidivism
prediction
instruments
big
data
2017
153
163
https://doi.org/10.1089/big.2016.0047
12
brian
collins
2007
tackling
unconscious
bias
in
hiring
practices
the
plight
of
the
rooney
rule
nyu
law
review
82
06
2007
13
sam
corbett-davies
emma
pierson
avi
feller
sharad
goel
and
aziz
huq
2017
algorithmic
decision
making
and
the
cost
of
fairness
in
proceedings
of
the
23rd
acm
sigkdd
international
conference
on
knowledge
discovery
and
data
mining
halifax
ns
canada
kdd
17
association
for
computing
machinery
new
york
ny
usa
797
806
https://doi.org/10.1145/3097983.3098095
14
frances
ding
moritz
hardt
john
miller
and
ludwig
schmidt
2021
retiring
adult
new
datasets
for
fair
machine
learning
in
advances
in
neural
information
processing
systems
ranzato
beygelzimer
dauphin
liang
and
wortman
vaughan
eds
vol
34
curran
associates
inc
6478
6490
https://proceedings.neurips.cc/paper_files/paper/2021/file/
32e54441e6382a7fbacbbbaf3c450059-paper
pdf
15
ezekiel
dixon-roman
howard
everson
and
john
mcardle
2013
race
poverty
and
sat
scores
modeling
the
influences
of
family
income
on
black
and
white
high
school
students
sat
performance
teachers
college
record
115
05
2013
https://doi.org/10.1177/016146811311500406
16
marina
drosou
jagadish
evaggelia
pitoura
and
julia
stoyanovich
2017
diversity
in
big
data
review
big
data
2017
73
84
https://doi.org/10.
1089
big
2016.0054
arxiv
https://doi.org/10.1089/big.2016.0054
pmid
28632443
17
cynthia
dwork
moritz
hardt
toniann
pitassi
omer
reingold
and
richard
zemel
2012
fairness
through
awareness
in
proceedings
of
the
3rd
innovations
in
theoretical
computer
science
conference
cambridge
massachusetts
itcs
12
association
for
computing
machinery
new
york
ny
usa
214
226
https
doi
org
10.1145
2090236.2090255
18
vitalii
emelianov
nicolas
gast
krishna
gummadi
and
patrick
loiseau
2020
on
fair
selection
in
the
presence
of
implicit
variance
in
proceedings
of
the
21st
acm
conference
on
economics
and
computation
virtual
event
hungary
ec
20
association
for
computing
machinery
new
york
ny
usa
649
675
https://doi.org/10.1145/3391403.3399482
19
vitalii
emelianov
nicolas
gast
krishna
gummadi
and
patrick
loiseau
2022
on
fair
selection
in
the
presence
of
implicit
and
differential
variance
artificial
intelligence
302
2022
103609
https://doi.org/10.1016/j.artint.2021.103609
20
anthony
flores
kristin
bechtel
and
christopher
lowenkamp
2016
false
positives
false
negatives
and
false
analyses
rejoinder
to
machine
bias
there
software
used
across
the
country
to
predict
future
criminals
and
it
biased
against
blacks
federal
probation
80
2016
38
https://www.uscourts.gov/federal-probation-journal/2016/09/false-positivesfalse-negatives-and-false-analyses-rejoinder
21
nikhil
garg
hannah
li
and
faidra
monachou
2021
standardized
tests
and
affirmative
action
the
role
of
bias
and
variance
in
proceedings
of
the
2021
acm
conference
on
fairness
accountability
and
transparency
virtual
event
canada
facct
21
association
for
computing
machinery
new
york
ny
usa
261
https://doi.org/10.1145/3442188.3445889
22
barbara
goodwin
1992
justice
by
lottery
university
of
chicago
press
chicago
23
moritz
hardt
eric
price
and
nati
srebro
2016
equality
of
opportunity
in
supervised
learning
in
advances
in
neural
information
processing
systems
lee
sugiyama
luxburg
guyon
and
garnett
eds
vol
29
curran
associates
inc
https://proceedings.neurips.cc/paper_files/paper/2016/file/
9d2682367c3935defcb1f9e247a97c0d-paper
pdf
24
tatsunori
hashimoto
megha
srivastava
hongseok
namkoong
and
percy
liang
2018
fairness
without
demographics
in
repeated
loss
minimization
in
international
conference
on
machine
learning
25
li
he
and
toni
whited
2023
underrepresentation
of
women
ceos
2023
available
at
ssrn
https://ssrn.com/abstract=4615373
or
http://dx.doi.org/10.2139/ssrn.4615373.
26
tim
henning
2015
from
choice
to
chance
saving
people
fairness
and
lotteries
philosophical
review
124
2015
169
206
https://doi.org/10.1215/
00318108
2842176
27
eyke
hÃ¼llermeier
and
willem
waegeman
2021
aleatoric
and
epistemic
uncertainty
in
machine
learning
an
introduction
to
concepts
and
methods
machine
learning
110
2021
457
506
https://doi.org/10.1007/s10994-021-05946-3
fairness
in
ranking
under
disparate
uncertainty
28
tim
de
jonge
and
djoerd
hiemstra
2023
unfair
search
engine
manipulation
undetectable
by
amortized
inequity
facct
23
association
for
computing
machinery
new
york
ny
usa
29
jon
kleinberg
sendhil
mullainathan
and
manish
raghavan
2017
inherent
tradeoffs
in
the
fair
determination
of
risk
scores
in
8th
innovations
in
theoretical
computer
science
conference
itcs
2017
leibniz
international
proceedings
in
informatics
lipics
vol
67
christos
papadimitriou
ed
schloss
dagstuhl
leibniz-zentrum
fÃ¼r
informatik
dagstuhl
germany
43
43
23
https://doi.
org
10.4230
lipics
itcs
2017.43
30
jon
kleinberg
and
manish
raghavan
2018
selection
problems
in
the
presence
of
implicit
bias
in
9th
innovations
in
theoretical
computer
science
conference
itcs
2018
schloss
dagstuhl-leibniz-zentrum
fuer
informatik
31
nikola
konstantinov
and
christoph
lampert
2021
fairness
through
regularization
for
learning
to
rank
corr
abs
2102.05996
2021
arxiv
2102.05996
https://arxiv.org/abs/2102.05996
32
michele
loi
and
christoph
heitz
2022
is
calibration
fairness
requirement
an
argument
from
the
point
of
view
of
moral
philosophy
and
decision
theory
in
proceedings
of
the
2022
acm
conference
on
fairness
accountability
and
transparency
conf-loc
city
seoul
city
country
republic
of
korea
country
confloc
facct
22
association
for
computing
machinery
new
york
ny
usa
2026
2034
https://doi.org/10.1145/3531146.3533245
33
anay
mehrotra
and
nisheeth
vishnoi
2022
fair
ranking
with
noisy
protected
attributes
in
advances
in
neural
information
processing
systems
alice
oh
alekh
agarwal
danielle
belgrave
and
kyunghyun
cho
eds
https://openreview.net/forum?id=mtra5biuyrv
34
jakob
mÃ¶kander
jessica
morley
mariarosaria
taddeo
and
floridi
2021
ethicsbased
auditing
of
automated
decision-making
systems
nature
scope
and
limitations
science
and
engineering
ethics
27
2021
35
harikrishna
narasimhan
andy
cotter
maya
gupta
and
serena
lutong
wang
2020
pairwise
fairness
for
ranking
and
regression
in
33rd
aaai
conference
on
artificial
intelligence
36
edmund
phelps
1972
the
statistical
theory
of
racism
and
sexism
the
american
economic
review
62
1972
659
661
http://www.jstor.org/stable/
1806107
37
platt
2000
probabilistic
outputs
for
support
vector
machines
and
comparison
to
regularized
likelihood
methods
in
advances
in
large
margin
classifiers
38
geoff
pleiss
manish
raghavan
felix
wu
jon
kleinberg
and
kilian
weinberger
2017
on
fairness
and
calibration
in
advances
in
neural
information
processing
systems
guyon
von
luxburg
bengio
wallach
fergus
vishwanathan
and
garnett
eds
vol
30
curran
associates
inc
https://proceedings.neurips.cc/paper_files/paper/2017/file/
b8b9c74ac526fffbeb2d39ab038d1cd7-paper
pdf
39
chandan
reddy
lluÃ­s
mÃ rquez
fran
valero
nikhil
rao
hugo
zaragoza
sambaran
bandyopadhyay
arnab
biswas
anlu
xing
and
karthik
subbian
2022
shopping
queries
dataset
large-scale
esci
benchmark
for
improving
product
search
2022
arxiv
2206.06588
40
nils
reimers
and
iryna
gurevych
2019
sentence-bert
sentence
embeddings
using
siamese
bert-networks
in
proceedings
of
the
2019
conference
on
empirical
methods
in
natural
language
processing
association
for
computational
linguistics
https://arxiv.org/abs/1908.10084
41
stephen
robertson
1977
the
probability
ranking
principle
in
ir
journal
of
documentation
33
12
1977
294
304
https://doi.org/10.1108/eb026647
42
yuta
saito
and
thorsten
joachims
2022
fair
ranking
as
fair
division
impactbased
individual
fairness
in
ranking
in
proceedings
of
the
28th
acm
sigkdd
conference
on
knowledge
discovery
and
data
mining
washington
dc
usa
kdd
22
association
for
computing
machinery
new
york
ny
usa
1514
1524
https://doi.org/10.1145/3534678.3539353
43
piotr
sapiezynski
wesley
zeng
ronald
robertson
alan
mislove
and
christo
wilson
2019
quantifying
the
impact
of
user
attentionon
fair
group
representation
in
ranked
lists
in
companion
proceedings
of
the
2019
world
wide
web
conference
san
francisco
usa
www
19
association
for
computing
machinery
new
york
ny
usa
553
562
https://doi.org/10.1145/3308560.3317595
44
ben
saunders
2008
the
equality
of
lotteries
philosophy
83
2008
359
372
https://doi.org/10.1017/s0031819108000727
45
ben
saunders
2018
equality
in
the
allocation
of
scarce
vaccines
les
ateliers
de
Ã©thique
the
ethics
forum
13
2018
65
84
https://doi.org/10.7202/1061219ar
46
andrew
selbst
danah
boyd
sorelle
friedler
suresh
venkatasubramanian
and
janet
vertesi
2019
fairness
and
abstraction
in
sociotechnical
systems
in
proceedings
of
the
conference
on
fairness
accountability
and
transparency
atlanta
ga
usa
fat
19
association
for
computing
machinery
new
york
ny
usa
59
68
https://doi.org/10.1145/3287560.3287598
47
zeyu
shen
zhiyi
wang
xingyu
zhu
brandon
fain
and
kamesh
munagala
2023
fairness
in
the
assignment
problem
with
uncertain
priorities
arxiv
2301.13804
cs
gt
48
ashudeep
singh
and
thorsten
joachims
2017
equality
of
opportunity
in
rankings
eaamo
24
october
29
31
2024
san
luis
potosi
mexico
49
ashudeep
singh
and
thorsten
joachims
2018
fairness
of
exposure
in
rankings
in
proceedings
of
the
24th
acm
sigkdd
international
conference
on
knowledge
discovery
data
mining
london
united
kingdom
kdd
18
association
for
computing
machinery
new
york
ny
usa
2219
2228
https://doi.org/10.1145/
3219819.3220088
50
ashudeep
singh
david
kempe
and
thorsten
joachims
2021
fairness
in
ranking
under
uncertainty
in
advances
in
neural
information
processing
systems
vol
34
curran
associates
inc
11896
11908
https://proceedings.neurips.cc/paper_
files
paper
2021
file
63c3ddcc7b23daa1e42dc41f9a44a873-paper
pdf
51
rachael
tatman
2017
gender
and
dialect
bias
in
youtube
automatic
captions
in
proceedings
of
the
first
acl
workshop
on
ethics
in
natural
language
processing
association
for
computational
linguistics
valencia
spain
53
59
https://doi.
org
10.18653
v1
w17-1606
52
lequn
wang
and
thorsten
joachims
2021
user
fairness
item
fairness
and
diversity
for
rankings
in
two-sided
markets
in
proceedings
of
the
2021
acm
sigir
international
conference
on
theory
of
information
retrieval
virtual
event
canada
ictir
21
association
for
computing
machinery
new
york
ny
usa
23
41
https://doi.org/10.1145/3471158.3472260
53
lequn
wang
and
thorsten
joachims
2023
uncertainty
quantification
for
fairness
in
two-stage
recommender
systems
in
proceedings
of
the
sixteenth
acm
international
conference
on
web
search
and
data
mining
singapore
singapore
wsdm
23
association
for
computing
machinery
new
york
ny
usa
940
948
https://doi.org/10.1145/3539597.3570469
54
lequn
wang
thorsten
joachims
and
manuel
gomez
rodriguez
2022
improving
screening
processes
via
calibrated
subset
selection
in
international
conference
on
machine
learning
55
dong
wei
md
mouinul
islam
baruch
schieber
and
senjuti
basu
roy
2022
rank
aggregation
with
proportionate
fairness
in
proceedings
of
the
2022
international
conference
on
management
of
data
philadelphia
pa
usa
sigmod
22
association
for
computing
machinery
new
york
ny
usa
262
275
https://doi.org/10.1145/3514221.3517865
56
benjamin
wilson
judy
hoffman
and
jamie
morgenstern
2019
predictive
inequity
in
object
detection
arxiv
1902.11097
cs
cv
57
ke
yang
vasilis
gkatzelis
and
julia
stoyanovich
2019
balanced
ranking
with
diversity
constraints
6035
6042
https://doi.org/10.24963/ijcai.2019/836
58
ke
yang
and
julia
stoyanovich
2016
measuring
fairness
in
ranked
outputs
corr
abs
1610.08559
2016
arxiv
1610.08559
http://arxiv.org/abs/1610.08559
59
tao
yang
zhichao
xu
zhenduo
wang
anh
tran
and
qingyao
ai
2023
marginal-certainty-aware
fair
ranking
algorithm
in
proceedings
of
the
sixteenth
acm
international
conference
on
web
search
and
data
mining
singapore
singapore
wsdm
23
association
for
computing
machinery
new
york
ny
usa
24
32
https://doi.org/10.1145/3539597.3570474
60
leon
yin
and
adrianne
jeffries
2021
how
we
analyzed
amazons
treatment
of
its
brands
in
search
results
the
markup
10
2021
https://tinyurl.com/markupamazon
61
meike
zehlike
francesco
bonchi
carlos
castillo
sara
hajian
mohamed
megahed
and
ricardo
baeza-yates
2017
fa
ir
fair
top-k
ranking
algorithm
in
proceedings
of
the
2017
acm
on
conference
on
information
and
knowledge
management
singapore
singapore
cikm
17
association
for
computing
machinery
new
york
ny
usa
1569
1578
https://doi.org/10.1145/3132847.3132938
62
meike
zehlike
and
carlos
castillo
2020
reducing
disparate
exposure
in
ranking
learning
to
rank
approach
in
proceedings
of
the
web
conference
2020
taipei
taiwan
www
20
association
for
computing
machinery
new
york
ny
usa
2849
2855
https://doi.org/10.1145/3366424.3380048
63
meike
zehlike
tom
sÃ¼hr
ricardo
baeza-yates
francesco
bonchi
carlos
castillo
and
sara
hajian
2022
fair
top-k
ranking
with
multiple
protected
groups
inf
process
manage
59
jan
2022
28
pages
https://doi.org/10.1016/j.ipm.2021.
102707
64
meike
zehlike
ke
yang
and
julia
stoyanovich
2021
fairness
in
ranking
survey
corr
abs
2103.14000
2021
arxiv
2103.14000
https://arxiv.org/abs/2103.
14000
eaamo
24
october
29
31
2024
san
luis
potosi
mexico
notation
summary
number
of
candidates
candidate
number
of
groups
group
ranking
prefix
size
of
group
ğ‘›ğ‘…ğ‘’ğ‘™
expected
number
of
relevant
candidates
for
group
ğ‘Ÿğ‘–
binary
relevance
of
candidate
ğœƒğ‘–
probability
of
relevance
of
candidate
historical
data
ğœƒğ‘–
posterior
distribution
ğ‘ğ‘–
ğ‘Ÿğ‘–
expected
probability
of
relevance
of
candidate
ğ‘ğ‘–
relevance
probability
vector
vector
indicating
whether
candidate
was
selected
iğ‘”
indicator
if
candidate
belongs
to
group
policy
ğœğ‘˜ğœ‹
ğ‘ƒğ‘…ğ‘ƒ
top
ranking
ğœğ‘˜
rastogi
and
joachims
ğ‘¡â„
candidate
in
the
prp
ranking
of
group
eor
measure
for
ranking
extended
related
work
our
work
complements
and
extends
prior
research
on
fairness
in
rankings
64
the
classical
fairness
desiderata
considered
are
variations
of
proportional
representation
17
58
broadly
proportional
representation
ensures
representation
by
group
size
in
top
selection
or
at
every
prefix
of
the
ranking
other
popular
notions
include
diversity
based
constraints
10
16
57
like
rooney
rule
and
affirmative
action
that
ensure
representation
of
the
designated
disadvantaged
group
and
threshold
based
formulations
54
61
63
that
ensure
minimum
number
of
candidates
to
be
selected
from
the
disadvantaged
group
another
prominent
class
of
fairness
notions
in
rankings
corresponds
to
exposure
based
formulations
exposure
43
49
62
quantifies
the
amount
of
attention
allocated
to
candidates
individually
or
from
particular
group
these
formulations
include
equity
of
exposure
disparate
treatment
of
exposure
that
allocates
exposure
proportional
to
amortized
relevance
and
disparate
impact
of
exposure
that
allocates
exposure
proportional
to
impact
economic
impact
of
ranking
among
other
variations
see
for
similar
concept
of
equity
of
attention
proportional
representation
diversity
constraints
and
exposure
are
motivated
by
representation
by
group
size
normative
designation
of
disadvantaged
group
and
allocation
of
attention
respectively
our
work
on
the
other
hand
is
motivated
by
unfairness
due
to
differential
uncertainty
between
groups
and
is
grounded
in
the
axiomatic
fairness
of
lottery
system
our
problem
setup
involves
aggregating
candidates
from
groups
and
while
research
on
fair
rank
aggregation
appears
related
the
goal
there
is
much
different
in
particular
fair
rank
aggregation
achieves
maximum
consensus
accuracy
when
multiple
voters
rank
all
candidates
subject
to
fairness
constraints
of
group
exposure
or
p-fairness
55
work
on
multi
sided
fairness
52
similarly
considers
diversity
constraints
or
exposure-based
formulations
finally
while
31
42
50
propose
an
amortized
notion
of
fairness
our
work
proposes
non-amortized
fairness
criterion
at
every
position
of
the
ranking
recently
there
has
been
growing
interest
in
the
study
of
fairness
in
rankings
under
uncertainty
the
classical
desideratum
in
this
literature
studies
the
relation
of
group-wise
calibration
for
fairness
11
20
29
32
38
our
work
is
orthogonal
to
this
discussion
in
particular
we
only
assume
that
calibrated
probability
of
relevance
is
given
and
instead
focus
on
how
differential
sharpness
of
probabilities
can
cause
unfairness
50
introduced
an
approximate
notion
of
fairness
that
is
violated
if
the
principal
ranks
candidates
that
appear
more
than
certain
proportion
of
their
estimated
relevance
distribution
one
way
to
achieve
this
in
expectation
is
through
randomization
of
relevances
drawn
from
the
predictive
posterior
distribution
other
works
have
introduced
methods
that
quantify
uncertainty
in
rankings
53
to
update
and
learn
better
estimates
of
relevances
iteratively
59
these
works
do
not
consider
the
unfairness
caused
due
to
differential
uncertainty
fairness
in
ranking
under
disparate
uncertainty
eaamo
24
october
29
31
2024
san
luis
potosi
mexico
between
groups
while
methods
that
reduce
uncertainty
for
all
groups
are
needed
we
also
need
to
account
for
unfairness
due
to
the
existing
disparate
uncertainty
that
is
unfortunately
widespread
in
practical
settings
another
line
of
research
focuses
on
statistical
discrimination
and
the
study
of
noisy
estimates
of
relevances
for
selection
problems
36
this
literature
establishes
that
the
differential
accuracy
of
models
causes
unfairness
15
24
51
56
for
individuals
based
on
their
group
membership
recently
19
21
studied
the
role
of
affirmative
action
in
the
presence
of
differential
variance
between
groups
in
rankings
their
method
19
corrects
the
bias
in
noisy
relevance
estimates
given
the
variance
of
the
true
relevance
distribution
fairness
in
selection
processes
has
also
been
extensively
studied
in
the
presence
of
group-based
implicit
bias
18
30
uncertainty
in
preferences
47
and
in
the
presence
of
noisy
sensitive
attributes
33
this
line
of
research
analyzes
the
effect
of
affirmative
actions
like
the
rooney
rule
on
the
utility
to
the
principal
or
how
implicit
bias
affects
the
diversity
of
the
selection
set
our
work
is
also
motivated
by
equality
of
opportunity
framework
first
introduced
by
23
in
the
classification
setting
it
has
provided
compelling
notion
of
balancing
the
cost
burden
among
stakeholders
11
13
for
rankings
there
has
been
some
work
in
transferring
the
idea
of
equalized
odds
with
learning
ranking
function
during
training
62
to
reduce
disparate
exposure
or
augmenting
the
training
loss
with
regularizers
that
minimize
costs
for
both
groups
31
35
our
work
extends
this
literature
to
introduce
framework
connecting
the
unfairness
in
rankings
due
to
the
disparate
uncertainty
to
the
distribution
of
cost
burden
among
stakeholders
by
anchoring
on
the
fairness
of
random
lottery
proofs
proof
of
theorem
5.1
proof
we
use
linear
duality
for
proving
this
theorem
in
order
to
find
lower
bound
on
the
cost
optimal
ranking
that
satisfies
the
eor
fairness
constraint
we
relax
the
corresponding
integer
linear
problem
ilp
to
linear
program
lp
by
turning
any
integer
constraints
in
the
primal
into
for
the
relaxed
lp
we
formulate
its
dual
and
construct
set
of
dual
variables
corresponding
to
the
solution
from
the
eor
algorithm
with
the
dual
solution
of
eor
and
the
relaxed
lp
solution
we
obtain
an
upper
bound
of
the
duality
gap
since
the
upper
bound
on
this
duality
gap
is
the
relaxed
lp
it
will
also
be
an
upper
bound
for
the
optimal
ilp
we
define
the
primal
of
the
lp
for
finding
solution
as
follows
ğ‘ƒğ‘‡
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
max
primal
10
select
up
to
elements
ğ‘„ğ‘‡ğ´
ğœğ‘˜ğ¸ğ‘‚ğ‘…
ğ‘„ğ‘‡ğµ
ğœğ‘˜ğ¸ğ‘‚ğ‘…
11
12
we
define
rğ‘›
where
each
element
of
is
ğ‘ğ‘–
iğ´
iğµ
ğ‘ğ‘–
ğ‘›ğ‘…ğ‘’ğ‘™ğ‘–
and
note
that
the
primal
objective
is
equivalent
to
minimizing
the
total
cost
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
the
first
constraint
10
ensures
valid
values
for
with
corresponding
dual
variables
ğœ†ğ‘–
the
second
constraint
is
for
selecting
candidates
dual
variable
ğœ†ğ‘˜
and
the
last
two
constraints
11
and
12
ensure
that
the
ranking
solution
is
eor-fair
optimal
dual
variables
ğœ†ğ´
ğœ†ğµ
the
dual
lp
is
formed
as
follows
min
ğœğ‘˜ğ¸ğ‘‚ğ‘…
ğœ†ğ´
ğœ†ğµ
ğ‘˜ğœ†ğ‘˜
ğœ†ğ‘–
dual
ğœ†ğ´
ğœ†ğµ
ğœ†ğ‘˜
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
13
we
construct
feasible
point
of
the
dual
from
the
eor
solution
as
follows
the
key
insight
here
is
to
reason
the
last
elements
selected
or
the
first
elements
available
if
no
element
from
the
group
has
been
selected
by
the
eor
algorithm
at
prefix
from
each
of
the
groups
and
namely
ğ‘˜ğ´
ğ‘˜ğµ
respectively
ğœ†ğ´
ğœ†ğµ
ğ‘ğ´
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘ğ´
ğ‘ğµ
ğ‘ğ´
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘ğ´
14
15
using
14
and
15
we
know
that
only
ever
one
of
ğœ†ğ´
or
ğœ†ğµ
is
non
zero
if
ğ‘ğ´
then
ğœ†ğ´
and
ğœ†ğµ
similarly
if
ğ‘ğ´
then
ğœ†ğµ
and
ğœ†ğ´
eaamo
24
october
29
31
2024
san
luis
potosi
mexico
rastogi
and
joachims
we
construct
ğœ†ğ‘˜
and
ğœ†ğ‘–
as
follows
ğ‘ğ´
ğ‘ğµ
ğœ†ğ‘˜
ğ‘ğ´
ğœ†ğ´
ğœ†ğµ
ğ‘ğµ
ğœ†ğµ
ğœ†ğ´
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğœ†ğ‘–
ğœ†ğ‘˜
ğ‘ğ‘–
ğœ†ğ´
ğœ†ğµ
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘ğ‘–
ğœ†ğ‘˜
ğ‘ğ‘–
ğœ†ğµ
ğœ†ğ´
ğœ†ğ‘–
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
16
17
18
we
prove
that
the
constructed
dual
variables
are
non-negative
in
lemma
5.2
and
that
for
any
element
not
selected
in
the
eor
ranking
in
lemma
5.3
we
prove
that
the
constructed
dual
variables
are
feasible
given
the
feasibility
of
dual
variables
we
analyze
the
duality
gap
given
by
ğœğ‘˜ğ¸ğ‘‚ğ‘…
ğœ†ğ´
ğœ†ğµ
ğ‘˜ğœ†ğ‘˜
ğœ†ğ‘–
ğ‘ƒğ‘‡
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
from
lemma
5.2
ğœ†ğ‘–
for
ğ‘˜ğ´
for
ğ‘˜ğµ
where
ğ‘˜ğ´
elements
are
selected
from
group
ğ‘˜ğµ
from
group
by
the
eor
algorithm
and
ğ‘˜ğ´
ğ‘˜ğµ
substituting
the
values
for
from
17
18
the
duality
gap
is
ğ‘˜ğ´
ğ‘ğ‘–
ğœ†ğ‘˜
ğ‘ğ‘–
ğœ†ğ´
ğœ†ğµ
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘˜ğµ
ğ‘ğ‘—
ğ‘ƒğ‘‡
ğœ†ğ‘˜
ğœ†ğµ
ğœ†ğ´
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğœğ‘˜ğ¸ğ‘‚ğ‘…
ğœ†ğ´
ğœ†ğµ
ğ‘˜ğœ†ğ‘˜
Ã­ğ´
Ã­ğ´
we
know
that
ğ‘˜ğ‘–
ğœ†ğ‘˜
ğ‘˜ğ‘—
ğœ†ğ‘˜
ğ‘˜ğœ†ğ‘˜
and
ğ‘ƒğ‘‡
ğ‘˜ğ‘–
ğ‘ğ‘–
ğ‘˜ğ‘—
further
only
one
of
ğœ†ğ´
or
ğœ†ğµ
is
non-negative
according
to
14
15
if
ğœ†ğ´
then
the
duality
gap
can
be
written
as
ğœğ‘˜ğ¸ğ‘‚ğ‘…
ğœ†ğ´
ğ‘˜ğ´
ğ‘ğ‘–
ğœ†ğ´
ğ‘˜ğµ
ğ‘˜ğ´
ğ‘˜ğµ
ÂªÂª
ğœ†ğ´
ğœ†ğ´
ğœğ‘˜ğ¸ğ‘‚ğ‘…
ğ‘ğ‘–
Ã­ğ´
since
we
have
ğœğ‘˜ğ¸ğ‘‚ğ‘…
ğ‘˜ğ‘–
ğ‘ğ‘–
ğ‘˜ğ‘—
ğœğ‘˜ğ¸ğ‘‚ğ‘…
from
lemma
5.1
ğ‘˜ğ´
ğ‘˜ğµ
ÂªÂª
duality
gap
ğœ†ğ´
ğœğ‘˜ğ¸ğ‘‚ğ‘…
ğ‘ğ‘–
2ğœ†ğ´
ğœğ‘˜ğ¸ğ‘‚ğ‘…
if
ğœ†ğµ
then
the
duality
gap
can
be
written
as
ğœğ‘˜ğ¸ğ‘‚ğ‘…
ğœ†ğµ
ğ‘˜ğ´
and
again
since
ğœğ‘˜ğ¸ğ‘‚ğ‘…
Ã­ğ‘˜ğ´
ğ‘ğ‘–
ğ‘ğ‘–
ğœ†ğµ
19
ğ‘˜ğµ
ğ‘˜ğ´
ğ‘˜ğµ
ğœ†ğµ
ğœ†ğµ
ğœğ‘˜ğ¸ğ‘‚ğ‘…
ğ‘ğ‘–
Ã­ğ‘˜ğµ
ğ¸ğ‘‚ğ‘…
from
lemma
5.1
ğœğ‘˜
ğ‘˜ğ´
ğ‘˜ğµ
duality
gap
ğœ†ğµ
ğœğ‘˜ğ¸ğ‘‚ğ‘…
ğ‘ğ‘–
2ğœ†ğµ
ğœğ‘˜ğ¸ğ‘‚ğ‘…
from
eqs
14
15
19
20
the
duality
gap
between
eor
solution
and
the
optimal
solution
is
bounded
by
20
2ğ›¿
ğœğ‘˜ğ¸ğ‘‚ğ‘…
ğ‘ğ´
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘ğ´
ğ‘ğµ
this
proves
that
the
eor
solution
can
only
be
ever
as
worse
as
ğœ™ğ›¿
ğœğ‘˜ğ¸ğ‘‚ğ‘…
when
compared
with
the
optimal
solution
where
ğ‘ğ´
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘ğ´
ğ‘ğµ
Ã­ğ´
lemma
5.1
eor
ranking
is
ğœğ‘˜ğ¸ğ‘‚ğ‘…
fairness
optimal
implying
that
ğœğ‘˜ğ¸ğ‘‚ğ‘…
ğ‘˜ğ‘–
ğ‘ğ‘–
ğ‘˜ğ‘—
ğœğ‘˜ğ¸ğ‘‚ğ‘…
Ã­ğ‘˜ğ´
Ã­ğ‘˜ğµ
ğ‘›ğ‘…ğ‘’ğ‘™
ğœğ‘˜
ğ‘›ğ‘…ğ‘’ğ‘™
ğœğ‘˜
since
ğ‘ğ‘–
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
the
lemma
follows
directly
from
the
definition
of
ğœğ‘˜
in
eq
and
the
eor
ranking
principle
of
choosing
the
candidate
that
minimizes
ğœğ‘˜
fairness
in
ranking
under
disparate
uncertainty
eaamo
24
october
29
31
2024
san
luis
potosi
mexico
lemma
5.2
the
constructed
dual
variables
in
particular
for
any
ğ‘˜ğ´
in
group
and
ğ‘˜ğµ
in
group
it
holds
that
ğœ†ğ‘–
and
and
for
any
ğ‘˜ğ´
and
ğ‘˜ğµ
it
holds
that
ğœ†ğ‘–
and
proof
in
this
lemma
we
show
that
for
the
elements
not
selected
by
the
eor
algorithm
and
for
the
elements
that
were
selected
without
loss
of
generality
we
consider
the
element
at
index
that
belongs
to
group
ğ‘ğ‘–
ğœ†ğ‘–
ğœ†ğ‘˜
ğ‘ğ‘–
ğœ†ğ´
ğœ†ğµ
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘ğ‘–
ğ‘ğ´
ğ‘ğ´
ğœ†ğ´
ğœ†ğµ
ğ‘ğ‘–
ğœ†ğ´
ğœ†ğµ
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘ğ‘–
ğ‘ğ‘–
ğ‘ğ´
ğœ†ğµ
ğœ†ğ´
21
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
the
second
equality
above
is
obtained
by
substituting
ğœ†ğ‘˜
from
eq
16
and
the
last
equality
by
rearranging
we
now
consider
two
cases
for
elements
not
selected
and
selected
by
the
eor
algorithm
respectively
case
elements
not
selected
by
the
eor
algorithm
we
have
ğ‘ğ‘–
ğ‘ğ´
and
ğ‘ğ‘–
ğ‘ğ´
as
eor
selects
in
decreasing
order
of
probabilities
and
ii
either
ğœ†ğ´
or
ğœ†ğµ
as
only
one
of
them
can
be
nonzero
from
14
15
in
eq
21
if
ğœ†ğµ
then
ğœ†ğ´
and
with
ğ‘ğ‘–
ğ‘ğ´
ğ‘ğ‘–
ğ‘ğ´
the
resultant
quantity
would
be
negative
which
would
result
in
ğœ†ğ‘–
clipped
to
ğ‘ğ‘–
ğ‘ğ‘–
ğ‘ğ´
ğœ†ğµ
ğœ†ğ‘–
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘ğ´
in
eq
21
if
ğœ†ğ´
then
ğœ†ğµ
we
can
then
substitute
ğœ†ğ´
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘ğ´
ğ‘ğµ
in
eq
21
ğ‘ğ‘–
ğ‘ğ‘–
ğ‘ğ´
ğœ†ğ´
ğœ†ğ‘–
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘ğ‘–
ğ‘ğ‘–
ğ‘ğ´
ğ‘ğ´
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘ğ´
ğ‘ğµ
ğ‘ğ‘–
ğ‘ğ´
ğ‘ğµ
ğ‘ğ‘–
ğ‘ğ´
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘ğ´
the
second
last
term
evaluates
to
and
so
the
last
equality
holds
because
ğœ†ğ‘–
is
clipped
to
thus
for
any
element
not
been
selected
by
the
eor
algorithm
ğ‘˜ğ´
the
corresponding
dual
variable
ğœ†ğ‘–
analogously
for
any
element
ğ‘˜ğµ
in
group
it
can
be
shown
that
we
have
shown
that
for
any
element
not
selected
by
the
eor
algorithm
the
corresponding
dual
variable
case
ii
elements
selected
by
the
eor
algorithm
we
have
ğ‘ğ‘–
ğ‘ğ´
and
ğ‘ğ‘–
ğ‘ğ´
as
eor
selects
in
decreasing
order
of
probabilities
and
ii
ğœ†ğ´
or
ğœ†ğµ
as
only
one
of
them
can
be
non
zero
in
eq
21
if
ğœ†ğµ
then
ğœ†ğ´
and
with
ğ‘ğ‘–
ğ‘ğ´
ğ‘ğ‘–
ğ‘ğ´
the
resultant
quantity
in
21
would
be
so
that
ğœ†ğ‘–
ğ‘ğ‘–
ğ‘ğ‘–
ğ‘ğ´
ğœ†ğµ
ğœ†ğ‘–
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘ğ´
in
eq
21
if
ğœ†ğ´
then
ğœ†ğµ
we
can
then
substitute
ğœ†ğ´
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
in
21
ğ‘ğ‘–
ğœ†ğ‘–
ğ‘ğ‘–
ğ‘ğ´
ğœ†ğ´
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘ğ‘–
ğ‘ğ‘–
ğ‘ğ´
ğ‘ğ´
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘ğ´
ğ‘ğµ
ğ‘ğ‘–
ğ‘ğ´
ğ‘ğµ
ğ‘ğ‘–
ğ‘ğ´
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘ğ´
eaamo
24
october
29
31
2024
san
luis
potosi
mexico
rastogi
and
joachims
the
second
last
term
evaluates
to
so
the
last
equality
holds
thus
for
any
element
selected
by
the
eor
algorithm
in
group
ğ‘˜ğ´
the
corresponding
dual
variable
analogously
for
any
element
ğ‘˜ğµ
in
group
ğœ†ğ‘–
we
have
shown
that
for
any
element
selected
by
the
eor
algorithm
the
corresponding
dual
variable
we
now
show
that
ğœ†ğ‘˜
from
eq
16
ğ‘ğ´
ğœ†ğ‘˜
ğ‘ğ´
ğœ†ğ´
ğœ†ğµ
22
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘ğ´
if
ğœ†ğ´
then
ğœ†ğµ
substituting
ğœ†ğ´
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘ğ´
ğ‘ğµ
in
eq
22
ğ‘ğ´
ğœ†ğ‘˜
ğ‘ğ´
ğœ†ğ´
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘ğ´
ğ‘ğ´
ğ‘ğ´
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘ğ´
ğ‘ğµ
ğ‘ğ´
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘ğ´
the
last
inequality
follows
since
each
of
the
terms
ğ‘ğ´
ğ‘ğ´
ğ‘ğµ
are
if
ğœ†ğµ
then
ğœ†ğ´
by
substituting
ğœ†ğµ
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘ğ´ğ´
ğ‘ğµğµ
in
eq
22
we
similarly
get
ğœ†ğ‘˜
the
two
duals
ğœ†ğ´
ğœ†ğµ
are
by
their
construction
in
eqs
14
15
thus
we
have
shown
that
all
the
constructed
dual
variables
lemma
5.3
the
dual
variables
ğœ†1
ğœ†ğ‘›
ğœ†ğ‘˜
ğœ†ğ´
ğœ†ğµ
are
always
feasible
proof
in
lemma
5.2
we
proved
that
the
constructed
we
now
show
that
they
satisfy
the
duality
constraint
for
some
element
the
duality
constraint
implies
that
ğ‘ğ‘–
ğ‘ğ‘–
ğœ†ğ´
ğœ†ğµ
ğœ†ğ‘˜
ğœ†ğ‘–
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
23
without
loss
of
generality
we
consider
element
at
index
that
belongs
to
group
similar
to
lemma
5.2
we
consider
two
cases
case
elements
not
selected
by
the
eor
algorithm
using
the
fact
that
ğœ†ğ‘–
for
ğ‘˜ğ´
from
lemma
5.2
and
substituting
ğœ†ğ‘˜
from
eq
16
we
get
ğ‘ğ‘–
ğœ†ğ´
ğœ†ğµ
ğœ†ğ‘˜
ğœ†ğ‘–
ğ‘ğ‘–
ğœ†ğ´
ğœ†ğµ
ğœ†ğ‘˜
ğ‘ğ‘–
ğœ†ğ´
ğœ†ğµ
ğ‘ğ´
ğ‘ğ‘–
ğ‘ğ´
ğœ†ğ´
ğœ†ğµ
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘ğ´
ğ‘ğ´
ğœ†ğ´
ğœ†ğµ
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
we
have
ğ‘ğ‘–
ğ‘ğ´
and
ğ‘ğ‘–
ğ‘ğ´
as
eor
selects
in
decreasing
order
of
probabilities
and
ii
either
ğœ†ğ´
or
ğœ†ğµ
as
only
one
of
them
can
be
nonzero
if
ğœ†ğ´
then
substituting
ğœ†ğ´
ğ‘ğ´
ğ‘ğ‘–
ğ‘ğ´
ğœ†ğ´
ğ‘ğ‘–
ğœ†ğ´
ğœ†ğµ
ğœ†ğ‘˜
ğœ†ğ‘–
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘ğ´
ğ‘ğ‘–
ğ‘ğ´
ğ‘ğ´
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘ğ´
ğ‘ğµ
ğ‘ğ´
ğ‘ğ‘–
ğ‘ğµ
ğ‘ğ´
ğ‘ğ‘–
ğ‘ğ‘–
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘ğ´
ğ‘ğ‘–
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
similarly
we
can
show
that
the
dual
constraint
is
satisfied
if
ğœ†ğµ
thus
for
any
element
not
selected
by
the
eor
algorithm
ğ‘˜ğ´
the
corresponding
dual
constraint
is
satisfied
analogously
for
any
element
ğ‘˜ğµ
in
group
it
can
be
shown
that
the
corresponding
dual
constraint
is
satisfied
we
have
shown
that
for
any
element
not
selected
by
eor
algorithm
the
corresponding
dual
constraint
is
satisfied
case
ii
elements
selected
by
the
eor
algorithm
using
the
fact
that
ğœ†ğ‘–
for
ğ‘˜ğ´
from
lemma
5.2
and
substituting
ğœ†ğ‘˜
from
16
ğœ†ğ‘–
for
ğ‘˜ğ´
in
23
we
get
ğ‘ğ‘–
ğ‘ğ‘–
ğ‘ğ‘–
ğœ†ğ´
ğœ†ğµ
ğœ†ğ‘˜
ğœ†ğ‘–
ğ‘ğ‘–
ğœ†ğ´
ğœ†ğµ
ğœ†ğ‘˜
ğœ†ğ‘˜
ğ‘ğ‘–
ğœ†ğ´
ğœ†ğµ
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
thus
for
any
element
selected
by
the
eor
algorithm
ğ‘˜ğ´
ğ‘˜ğµ
the
corresponding
dual
constraint
is
satisfied
fairness
in
ranking
under
disparate
uncertainty
eaamo
24
october
29
31
2024
san
luis
potosi
mexico
1.0
lp
ilp
eor
pa
pb
2Î´
Ïƒkeor
lp
nrel
nrel
Ïƒk
nrel
Ïƒk
total
cost
nrel
nrel
nrel
0.8
0.6
0.4
0.2
0.0
10
20
30
length
of
ranking
40
50
figure
cost
optimality
gap
of
synthetic
example
with
ğ‘ğ‘–
0.6
0.5
0.5
0.4
0.1
0.1
ğ‘›ğ‘…ğ‘’ğ‘™
15
and
ğ‘ğ‘–
0.1
0.1
ğ‘›ğ‘…ğ‘’ğ‘™
31
the
cost
from
eor
ranking
is
nearly
optimal
to
the
ilp
or
even
the
relaxed
lp
solution
further
the
bound
obtain
in
theorem
5.1
in
grey
is
tight
for
many
prefixes
we
demonstrate
the
cost
optimality
bound
proved
in
theorem
5.1
in
figure
that
shows
an
example
with
ranking
produced
by
linear
program
lp
integer
linear
program
ilp
and
the
eor
algorithm
along
with
the
upper
bound
on
the
cost
computed
from
the
duality
gap
proved
in
theorem
5.1
the
example
is
constructed
such
that
ğ‘Ÿğ‘–
0.6
0.5
0.5
0.4
0.1
0.1
ğ‘›ğ‘…ğ‘’ğ‘™
and
ğ‘Ÿğ‘–
0.1
0.1
ğ‘›ğ‘…ğ‘’ğ‘™
figure
shows
that
at
most
prefixes
the
eor
cost
in
red
is
optimal
coinciding
with
the
cost
from
ilp
solution
in
green
as
well
as
with
the
lp
solution
in
blue
further
when
the
eor
ranking
does
not
coincide
with
the
lp
solution
2ğ›¿
ğ¸ğ‘‚ğ‘…
the
upper
bound
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘ğ´
ğ‘ğµ
is
relatively
small
as
is
shown
by
the
lp
duality
gap
in
grey
we
now
present
the
proof
for
the
global
priori
bound
on
ğœğ‘˜ğ¸ğ‘‚ğ‘…
for
two
groups
proof
for
theorem
5.2
proof
let
ğ‘ƒğ‘…ğ‘ƒ
ğ‘ƒğ‘…ğ‘ƒ
be
the
prp
rankings
for
elements
in
group
and
respectively
we
show
by
induction
that
for
any
given
prefix
eor
algorithm
selects
the
element
such
that
ğœğ‘˜ğ¸ğ‘‚ğ‘…
ğ›¿ğ‘šğ‘ğ‘¥
and
as
consequence
of
theorem
5.1
we
get
global
cost
guarantee
of
ğœ™ğ›¿ğ‘šğ‘ğ‘¥
in
the
remaining
proof
we
drop
the
superscript
of
eor
for
simplicity
and
refers
to
ğ¸ğ‘‚ğ‘…
ğ‘ƒğ‘…ğ‘ƒ
oğ‘—
ğ‘ƒğ‘…ğ‘ƒ
ğ‘ƒğ‘…ğ‘ƒ
consider
the
base
case
of
algorithm
will
select
arg
min
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
resulting
in
the
lower
ğœğ‘˜
if
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘ƒğ‘…ğ‘ƒ
ğ‘ƒğ‘…ğ‘ƒ
ğ‘ƒğ‘…ğ‘ƒ
ğ‘ƒğ‘…ğ‘ƒ
ğ‘ƒğ‘…ğ‘ƒ
ğ‘ƒğ‘…ğ‘ƒ
ğ‘›ğ‘…ğ‘’ğ‘™
then
ğœ1
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
similarly
if
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
then
ğœğ‘˜
denoted
in
short
by
ğ‘ƒğ‘…ğ‘ƒ
ğ‘ƒğ‘…ğ‘ƒ
ğ‘ƒğ‘…ğ‘ƒ
ğœ1
ğ‘›ğ‘…ğ‘’ğ‘™
12
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
thus
at
by
selecting
the
element
with
lower
eor
constraint
is
satisfied
ğœ1
ğ›¿ğ‘šğ‘ğ‘¥
we
assume
that
for
given
ğœğ‘˜
ğ›¿ğ‘šğ‘ğ‘¥
further
without
loss
of
generality
we
assume
that
ğœğ‘˜
we
now
show
that
at
ğœğ‘˜
ğ›¿ğ‘šğ‘ğ‘¥
by
considering
the
following
cases
first
we
show
that
if
adding
the
element
from
one
of
the
groups
violates
the
ğ›¿ğ‘šğ‘ğ‘¥
constraint
then
adding
the
element
from
the
other
group
guarantees
the
satisfaction
of
ğ›¿ğ‘šğ‘ğ‘¥
constraint
because
eor
algorithm
selects
the
element
that
minimizes
secondly
in
the
case
where
adding
an
element
from
either
group
does
not
violate
the
ğ›¿ğ‘šğ‘ğ‘¥
constraint
eor
algorithm
will
select
the
element
that
minimizes
ğœğ‘˜
resulting
in
ğœğ‘˜
ğ›¿ğ‘šğ‘ğ‘¥
finally
we
show
that
when
all
the
elements
have
run
out
from
one
of
the
groups
at
adding
remaining
elements
from
the
other
group
will
always
satisfy
the
ğ›¿ğ‘šğ‘ğ‘¥
constraint
we
assume
that
adding
the
element
from
group
with
relevance
probability
ğ‘ğ‘–
at
exceeds
the
ğ›¿ğ‘šğ‘ğ‘¥
constraint
ğ‘ğ‘–
ğœğ‘˜
ğ›¿ğ‘šğ‘ğ‘¥
24
ğ‘›ğ‘…ğ‘’ğ‘™
eaamo
24
october
29
31
2024
san
luis
potosi
mexico
rastogi
and
joachims
adding
the
element
from
at
this
prefix
ğ‘ğ‘—
ğœğ‘˜
ğ›¿ğ‘šğ‘ğ‘¥
ğ‘›ğ‘…ğ‘’ğ‘™
ğœğ‘˜
ğœğ‘˜
the
last
inequality
holds
by
the
induction
assumption
at
ğ‘ƒğ‘…ğ‘ƒ
ğ‘ƒğ‘…ğ‘ƒ
ğ‘ƒğ‘…ğ‘ƒ
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
further
since
ğ‘›ğ‘…ğ‘’ğ‘™ğ‘—
ğ‘›ğ‘…ğ‘’ğ‘™
and
ğ›¿ğ‘šğ‘ğ‘¥
12
25
the
above
can
be
reduced
to
ğœğ‘˜
ğœğ‘˜
ğ‘ğ‘—
ğ‘ƒğ‘…ğ‘ƒ
ğœğ‘˜
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğœğ‘˜
ğœğ‘˜
ğ‘ƒğ‘…ğ‘ƒ
2ğ›¿ğ‘šğ‘ğ‘¥
ğ‘›ğ‘…ğ‘’ğ‘™
26
ğ‘ƒğ‘…ğ‘ƒ
now
using
ğ‘›ğ‘…ğ‘’ğ‘™ğ‘–
ğ‘›ğ‘…ğ‘’ğ‘™
and
eq
26
above
ğœğ‘˜
ğœğ‘˜
ğ‘ğ‘–
ğ‘ƒğ‘…ğ‘ƒ
2ğ›¿ğ‘šğ‘ğ‘¥
ğœğ‘˜
2ğ›¿ğ‘šğ‘ğ‘¥
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
27
using
eqs
27
and
24
ğ‘ğ‘–
2ğ›¿ğ‘šğ‘ğ‘¥
ğ›¿ğ‘šğ‘ğ‘¥
28
ğ‘›ğ‘…ğ‘’ğ‘™
we
have
shown
that
if
ğœğ‘˜
exceeds
ğ›¿ğ‘šğ‘ğ‘¥
by
adding
the
element
from
group
from
24
then
the
element
in
group
will
satisfy
ğœğ‘˜
ğ›¿ğ‘šğ‘ğ‘¥
from
25
and
28
since
the
eor
algorithm
minimizes
ğœğ‘˜
it
will
select
the
element
from
group
at
prefix
rather
than
the
element
from
group
thus
ğœğ‘˜
ğ›¿ğ‘šğ‘ğ‘¥
in
this
case
similarly
we
can
show
that
if
ğœğ‘˜
exceeds
ğ›¿ğ‘šğ‘ğ‘¥
by
adding
the
element
from
group
then
adding
the
element
from
group
would
result
in
ğœğ‘˜
ğ›¿ğ‘šğ‘ğ‘¥
and
would
be
selected
by
the
eor
algorithm
at
prefix
finally
we
consider
the
case
where
all
the
elements
in
particular
group
have
already
been
selected
without
loss
of
generality
let
assume
that
this
is
true
with
all
the
elements
in
group
added
by
prefix
we
need
to
show
that
adding
from
the
remaining
elements
in
group
would
still
satisfy
ğ›¿ğ‘šğ‘ğ‘¥
for
the
remaining
prefixes
ğ‘›ğ‘…ğ‘’ğ‘™
ğœğ‘˜
from
our
assumption
ğ‘›ğ‘…ğ‘’ğ‘™
since
all
elements
from
group
were
selected
at
prefix
from
the
inductive
hypothesis
ğœğ‘˜
ğ›¿ğ‘šğ‘ğ‘¥
ğœğ‘˜
ğœğ‘˜
ğœğ‘˜
since
ğ‘›ğ‘…ğ‘’ğ‘™
ğœğ‘˜
ğ‘›ğ‘…ğ‘’ğ‘™
ğœğ‘˜
ğ›¿ğ‘šğ‘ğ‘¥
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
29
ğ‘›ğ‘…ğ‘’ğ‘™
ğœğ‘˜
as
some
elements
remain
in
group
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğœğ‘˜
ğ›¿ğ‘šğ‘ğ‘¥
ğ‘›ğ‘…ğ‘’ğ‘™
after
adding
the
element
ğ‘ğ‘–
from
group
at
prefix
and
from
30
ğœğ‘˜
ğœğ‘˜
ğœğ‘˜
ğœğ‘˜
ğ›¿ğ‘šğ‘ğ‘¥
ğ‘›ğ‘…ğ‘’ğ‘™
30
ğ‘ğ‘–
ğ‘ğ‘–
ğ‘ğ‘–
ğ‘›ğ‘…ğ‘’ğ‘™
ğœğ‘˜
ğ›¿ğ‘šğ‘ğ‘¥
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
31
ğ‘›ğ‘…ğ‘’ğ‘™
additionally
since
ğ‘›ğ‘…ğ‘’ğ‘™
implying
ğ‘›ğ‘…ğ‘’ğ‘™
ğœğ‘˜
ğ‘›ğ‘…ğ‘’ğ‘™
ğœğ‘˜
ğ‘›ğ‘…ğ‘’ğ‘™
32
from
eqs
31
and
32
ğ›¿ğ‘šğ‘ğ‘¥
ğœğ‘˜
and
thus
eor
algorithm
will
add
all
the
remaining
elements
from
group
resulting
in
ğœğ‘˜
ğ›¿ğ‘šğ‘ğ‘¥
analogously
it
can
be
shown
that
if
all
the
elements
from
group
had
been
added
by
prefix
adding
the
next
element
from
group
would
satisfy
ğœğ‘˜
ğ›¿ğ‘šğ‘ğ‘¥
thus
we
have
shown
that
algorithm
provides
rankings
such
that
for
any
prefix
ğœğ‘˜
ğ›¿ğ‘šğ‘ğ‘¥
where
ğ›¿ğ‘šğ‘ğ‘¥
ğ‘ƒğ‘…ğ‘ƒ
ğ‘ƒğ‘…ğ‘ƒ
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
as
consequence
of
this
and
theorem
5.1
eor
rankings
have
total
cost
bounded
by
ğœ™ğ›¿ğ‘šğ‘ğ‘¥
for
any
prefix
of
the
ranking
where
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘ğ´
ğ‘ğµ
next
we
present
the
proof
comparing
costs
from
ğ¸ğ‘‚ğ‘…
unif
at
prefix
where
ğœğ‘˜ğ¸ğ‘‚ğ‘…
fairness
in
ranking
under
disparate
uncertainty
eaamo
24
october
29
31
2024
san
luis
potosi
mexico
proof
for
proposition
5.1
proof
when
ğœğ‘˜ğ¸ğ‘‚ğ‘…
by
the
definition
of
eor
fairness
we
have
that
ğ‘›ğ‘…ğ‘’ğ‘™
ğœğ‘˜ğ¸ğ‘‚ğ‘…
ğ‘›ğ‘…ğ‘’ğ‘™
ğœğ‘˜ğ¸ğ‘‚ğ‘…
as
result
the
total
cost
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğœğ‘˜ğ¸ğ‘‚ğ‘…
ğ‘›ğ‘…ğ‘’ğ‘™
ğœğ‘˜ğ¸ğ‘‚ğ‘…
as
well
as
subgroup
cost
would
be
equal
to
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ¸ğ‘‚ğ‘…
ğ‘›ğ‘…ğ‘’ğ‘™
ğœğ‘˜ğ¸ğ‘‚ğ‘…
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ¸ğ‘‚ğ‘…
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğœğ‘˜ğ¸ğ‘‚ğ‘…
33
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
we
also
know
that
and
since
the
eor
algorithm
selects
top
ğ‘˜ğ´
ğ‘˜ğµ
elements
from
each
ğ‘˜ğ´
ğ‘˜ğµ
of
the
groups
with
ğ‘˜ğ´
ğ‘˜ğµ
having
higher
mean
relevance
than
that
of
the
group
itself
ğ‘›ğ‘…ğ‘’ğ‘™
ğœğ‘˜ğ¸ğ‘‚ğ‘…
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğœğ‘˜ğ¸ğ‘‚ğ‘…
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘˜ğ´
34
ğ‘˜ğµ
35
adding
eqs
34
35
and
using
33
we
get
that
ğ‘›ğ‘…ğ‘’ğ‘™
ğœğ‘˜ğ¸ğ‘‚ğ‘…
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğœğ‘˜ğ¸ğ‘‚ğ‘…
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğœğ‘˜ğ¸ğ‘‚ğ‘…
ğ‘›ğ‘…ğ‘’ğ‘™
this
and
eq
33
are
sufficient
to
claim
that
the
total
cost
and
subgroup
costs
of
uniform
policy
given
by
ğ‘›ğ‘˜
will
always
be
higher
than
the
total
cost
and
subgroup
costs
given
by
eor
ranking
when
ğœğ‘˜ğ¸ğ‘‚ğ‘…
extension
to
multiple
groups
in
the
following
we
prove
the
global
cost
and
fairness
guarantee
for
multiple
groups
proof
for
theorem
6.1
pairs
and
reduce
each
term
of
the
duality
proof
the
overall
strategy
for
this
proof
is
to
consider
each
pair
of
groups
among
the
gap
to
the
two
group
case
in
theorem
5.1
fortunately
we
can
achieve
such
reduction
by
careful
construction
of
the
dual
variables
the
lp
to
find
solution
for
this
problem
is
formulated
as
follows
max
Ã­ğº
ğ‘ƒğ‘‡
primal
ğ‘›ğ‘…ğ‘’ğ‘™
36
ğ‘„ğ‘‡
ğ‘‡ğ´
constraints
select
up
to
elements
ğœğ‘˜ğ¸ğ‘‚ğ‘…
ğœğ‘˜ğ¸ğ‘‚ğ‘…
the
above
lp
is
analogous
to
the
two
group
case
in
theorem
5.1
with
the
addition
of
pairwise
constraints
ensuring
eor-fairness
for
all
pairs
of
groups
we
can
construct
the
dual
problem
as
follows
min
ğœğ‘˜ğ¸ğ‘‚ğ‘…
ğœ†ğ´
ğœ†ğµ
ğ‘˜ğœ†ğ‘˜
ğœ†ğ‘–
dual
ğ‘›ğ‘…ğ‘’ğ‘™
ğœ†ğ´
ğœ†ğµ
ğœ†ğ‘˜
37
eaamo
24
october
29
31
2024
san
luis
potosi
mexico
rastogi
and
joachims
we
have
pairs
of
dual
variables
that
are
constructed
from
the
eor
solution
as
following
ğ‘ğ´
ğœ†ğ´
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘ğ´
ğ‘ğµ
ğ‘ğ´
ğœ†ğµ
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘ğ´
38
39
we
construct
ğœ†ğ‘–
corresponding
to
constraint
36
and
ğœ†ğ‘˜
corresponding
to
constraint
select
up
to
elements
below
ğœ†ğ‘˜
ğœ†ğ‘–
terms
terms
ğ‘ğ´
ğ‘ğµ
ğœ†ğ´
ğœ†ğ‘”
ğœ†ğµ
ğœ†ğ‘”
for
each
of
groups
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
terms
ğ‘ğ‘–
ğœ†ğ‘˜
ğ‘ğ‘–
ğœ†ğ‘”
ğœ†ğ‘”
ğ‘›ğ‘…ğ‘’ğ‘™
40
41
for
instance
if
then
ğœ†ğ‘–
ğ‘ğ‘–
ğ‘›ğ‘…ğ‘’ğ‘™
we
show
that
the
constructed
dual
variables
are
non-negative
in
lemma
6.2
and
always
feasible
in
lemma
6.3
additionally
we
have
for
any
element
not
selected
in
the
eor
ranking
from
lemma
6.2
the
duality
gap
can
now
be
formulated
as
follows
ğœğ‘˜ğ¸ğ‘‚ğ‘…
ğœ†ğ´
ğœ†ğµ
ğ‘˜ğœ†ğ‘˜
ğ‘ƒğ‘‡
ğ‘›ğ‘…ğ‘’ğ‘™
ğœ†ğ‘–
substituting
the
values
for
from
41
and
breaking
the
elements
selected
into
ğ‘˜ğ´
from
group
ğ‘˜ğµ
from
group
and
so
on
from
every
group
we
have
the
above
duality
gap
as
terms
one
for
each
group
ğ‘ğ‘–
ğ‘ƒğ‘‡
ğœğ‘˜ğ¸ğ‘‚ğ‘…
ğœ†ğ´
ğœ†ğµ
ğ‘˜ğœ†ğ‘˜
ğœ†ğ‘˜
ğ‘ğ‘–
ğœ†ğ´
ğœ†ğ‘”
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
Ã­ğ‘˜ğµ
ğ‘ğ‘—
ğ‘ğ‘–
in
the
above
terms
we
can
collect
ğ‘˜ğ´
ğœ†ğ‘˜
ğ‘˜ğµ
ğœ†ğ‘˜
ğ‘˜ğœ†ğ‘˜
and
ğ‘˜ğ´
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
this
reduces
the
duality
gap
to
terms
ğœğ‘˜ğ¸ğ‘‚ğ‘…
ğœ†ğ´
ğœ†ğµ
ğ‘˜ğ´
ğ‘ğ‘–
ğœ†ğ´
ğœ†ğ‘”
ğ‘˜ğµ
ğ‘ğ‘—
ğ‘˜ğ´
ğ‘˜ğµ
ğœ†ğ´
ğœ†ğµ
ğœğ‘˜ğ¸ğ‘‚ğ‘…
ğœ†ğ´
ğœ†ğµ
ğ‘ğ‘–
ğœ†ğµ
ğœ†ğ‘”
fairness
in
ranking
under
disparate
uncertainty
eaamo
24
october
29
31
2024
san
luis
potosi
mexico
for
each
pair
of
groups
the
term
inside
the
summation
reduces
to
the
two
group
case
in
theorem
5.1
we
also
have
that
ğœğ‘˜ğ¸ğ‘‚ğ‘…
Ã­ğ‘˜ğ´
ğ‘ğ‘–
ğ‘˜ğµ
ğœğ‘˜ğ¸ğ‘‚ğ‘…
from
lemma
6.1
duality
gap
2ğœ†ğ´
ğœğ‘˜ğ¸ğ‘‚ğ‘…
2ğ›¿
ğœğ‘˜ğ¸ğ‘‚ğ‘…
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘ğ´
this
proves
that
the
eor
solution
can
as
ğœ™ğ›¿ğ‘šğ‘ğ‘¥
only
be
ever
as
worse
when
compared
with
the
optimal
solution
where
ğ‘ƒğ‘…ğ‘ƒ
ğ‘ğ´
Ã­ğº2
and
max
from
lemma
6.4
ğ‘šğ‘ğ‘¥
ğ‘ğ´
ğ‘ğµ
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
lemma
6.1
eor
ranking
is
ğœğ‘˜ğ¸ğ‘‚ğ‘…
fairness
optimal
implying
that
for
all
choose
possible
pairs
of
groups
we
have
Ã­ğ´
ğœğ‘˜ğ¸ğ‘‚ğ‘…
ğ‘˜ğ‘–
ğ‘ğ‘–
ğ‘˜ğ‘—
ğœğ‘˜ğ¸ğ‘‚ğ‘…
this
lemma
follows
directly
from
the
eor
ranking
principle
of
choosing
the
candidate
that
minimizes
ğœğ‘˜ğ¸ğ‘‚ğ‘…
defined
according
to
eq
lemma
6.2
the
constructed
dual
variables
in
particular
for
any
ğ‘˜ğ‘”
in
group
where
it
holds
that
ğœ†ğ‘–
and
for
any
ğ‘˜ğ‘”
it
holds
that
ğœ†ğ‘–
proof
in
this
lemma
we
show
that
for
the
elements
not
selected
and
for
the
selected
elements
by
the
eor
algorithm
without
loss
of
generality
we
consider
the
element
at
index
that
belongs
to
group
ğœ†ğ‘–
ğ‘ğ‘–
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘ğ´
ğ‘ğ‘–
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘ğ‘–
ğœ†ğ‘”
ğœ†ğ´
ğ‘ğ‘–
ğ‘ğ´
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘ğ‘–
ğ‘ğ´
ğœ†ğ‘”
ğœ†ğ´
ğ‘›ğ‘…ğ‘’ğ‘™
42
for
every
pair
of
ğœ†ğ´
and
ğœ†ğ‘”
where
and
only
one
of
ğœ†ğ´
ğœ†ğ‘”
is
each
of
the
terms
inside
the
summation
in
eq
42
reduces
to
the
two
group
case
as
follows
for
ğ‘˜ğ´
and
each
the
term
evaluates
to
using
lemma
5.2
and
thus
ğœ†ğ‘–
is
clipped
to
similarly
for
ğ‘˜ğ´
and
each
the
term
evaluates
to
and
thus
ğœ†ğ‘–
we
have
shown
that
for
any
element
not
selected
by
eor
algorithm
the
corresponding
dual
variable
and
for
any
element
selected
by
the
eor
algorithm
the
corresponding
dual
variable
we
now
show
that
ğœ†ğ‘˜
from
eq
40
ğœ†ğ‘˜
ğ‘ğ´
ğ‘›ğ‘…ğ‘’ğ‘™
Ã­ğ´
ğ‘ğ´
ğœ†ğ‘”
ğœ†ğ´
ğ‘›ğ‘…ğ‘’ğ‘™
43
each
of
the
terms
inside
the
summation
in
eq
43
reduces
to
the
two
group
case
for
each
the
term
evaluates
to
using
lemma
5.2
and
thus
ğœ†ğ‘˜
the
duals
ğœ†ğ´
are
by
their
construction
in
38
thus
we
have
shown
that
all
the
constructed
dual
variables
lemma
6.3
the
dual
variables
ğœ†1
ğœ†ğ‘›
ğœ†ğ‘˜
ğœ†ğ´
ğœ†ğµ
are
always
feasible
eaamo
24
october
29
31
2024
san
luis
potosi
mexico
rastogi
and
joachims
proof
for
some
element
the
duality
constraint
implies
that
terms
ğ‘ğ‘–
ğ‘ğ‘–
ğœ†ğ´
ğœ†ğ‘”
ğœ†ğ‘˜
ğœ†ğ‘–
ğ‘›ğ‘…ğ‘’ğ‘™
without
loss
of
generality
we
consider
element
case
elements
not
selected
by
the
eor
algorithm
using
the
fact
that
ğœ†ğ‘–
for
ğ‘˜ğ´
from
lemma
6.2
and
substituting
ğœ†ğ‘˜
from
eq
40
we
get
ğ‘ğ´
ğ‘ğ´
ğ‘ğ‘–
ğœ†ğ´
ğœ†ğ‘”
ğœ†ğ´
ğœ†ğ‘”
ğœ†ğ‘˜
ğœ†ğ‘–
ğ‘ğ‘–
ğœ†ğ´
ğœ†ğ‘”
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘ğ´
ğ‘ğ‘–
ğ‘ğ´
ğœ†ğ´
ğœ†ğ‘”
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘ğ´
ğ‘ğ‘–
ğ‘ğ´
ğœ†ğ´
ğœ†ğ‘”
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘ğ‘–
ğ‘ğ‘–
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
44
45
46
each
of
the
terms
inside
the
summation
in
eq
45
reduces
to
the
two
group
case
for
each
the
term
evaluates
to
ğ‘›ğ‘…ğ‘’ğ‘™
using
lemma
5.3
and
thus
the
corresponding
duality
constraint
is
satisfied
case
ii
elements
selected
by
the
eor
algorithm
using
the
fact
that
ğœ†ğ‘–
for
ğ‘˜ğ´
from
lemma
6.2
and
substituting
ğœ†ğ‘˜
from
eq
40
ğœ†ğ‘–
for
ğ‘˜ğ´
in
41
we
get
ğ‘ğ´
ğœ†ğ‘˜
ğ‘ğ‘–
ğœ†ğ´
ğœ†ğ‘”
ğ‘ğ‘–
ğœ†ğ´
ğœ†ğ‘”
ğœ†ğ‘˜
ğœ†ğ‘–
ğ‘ğ‘–
ğœ†ğ´
ğœ†ğ‘”
ğœ†ğ‘˜
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘ğ‘–
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
thus
for
elements
selected
by
the
eor
algorithm
ğ‘˜ğ´
the
corresponding
dual
constraint
is
satisfied
we
now
present
the
proof
for
the
global
priori
bound
on
ğœğ‘˜ğ¸ğ‘‚ğ‘…
for
groups
lemma
6.4
the
global
priori
bound
on
ğœğ‘˜ğ¸ğ‘‚ğ‘…
for
groups
is
given
by
ğ›¿ğ‘šğ‘ğ‘¥
maxğ‘”
ğ‘ƒğ‘…ğ‘ƒ
ğ‘›ğ‘…ğ‘’ğ‘™
prefix
min
group
min
group
other
groups
max
group
min
group
other
groups
other
groups
max
group
figure
illustration
for
the
case
of
multiple
groups
proof
we
will
show
that
for
groups
the
value
of
ğ›¿ğ‘šğ‘ğ‘¥
such
that
feasible
ranking
will
be
provided
and
that
always
satisfies
ğœğ‘˜ğ¸ğ‘‚ğ‘…
ğ›¿ğ‘šğ‘ğ‘¥
for
every
given
is
given
by
ğ‘ƒğ‘…ğ‘ƒ
ğ‘ƒğ‘…ğ‘ƒ
ğ‘ƒğ‘…ğ‘ƒ
ğ‘ƒğ‘…ğ‘ƒ
ğ›¿ğ‘šğ‘ğ‘¥
max
47
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
fairness
in
ranking
under
disparate
uncertainty
eaamo
24
october
29
31
2024
san
luis
potosi
mexico
in
the
remaining
we
drop
the
superscript
of
eor
for
simplicity
and
refers
to
ğ¸ğ‘‚ğ‘…
we
argue
by
an
inductive
argument
similar
to
the
proof
of
theorem
5.2
consider
the
base
case
of
when
the
first
element
is
to
be
selected
the
eor
algorithm
will
select
according
to
eq
resulting
in
the
lower
ğœğ‘˜
thus
ğœğ‘˜
is
clearly
ğ›¿ğ‘šğ‘ğ‘¥
we
assume
that
for
given
ğœğ‘˜
ğ›¿ğ‘šğ‘ğ‘¥
and
show
that
at
ğœğ‘˜
ğ›¿ğ‘šğ‘ğ‘¥
consider
the
general
case
as
depicted
in
figure
where
group
has
the
lowest
accumulated
proportion
and
group
has
the
highest
at
prefix
since
ğœğ‘˜
ğ›¿ğ‘šğ‘ğ‘¥
from
inductive
assumption
we
have
ğ‘›ğ‘…ğ‘’ğ‘™
ğœğ‘˜
ğ‘›ğ‘…ğ‘’ğ‘™
ğœğ‘˜
ğ›¿ğ‘šğ‘ğ‘¥
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
at
the
next
prefix
if
the
group
that
is
selected
has
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
then
ğœğ‘˜
ğ›¿ğ‘šğ‘ğ‘¥
note
that
ğœğ‘˜
is
always
non-negative
by
definition
from
eq
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğœğ‘˜
we
now
consider
the
case
when
group
is
selected
at
the
next
prefix
such
that
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
let
us
first
consider
that
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
is
group
we
have
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
selecting
group
at
means
that
the
rest
of
the
groups
have
the
same
accumulated
relevance
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
proportion
ğ‘›ğ‘…ğ‘’ğ‘™
at
prefix
as
we
analyze
the
difference
of
ğ‘›ğ‘…ğ‘’ğ‘™
between
the
group
that
was
most
behind
group
and
the
group
that
was
second
most
behind
group
and
whether
that
remains
within
ğ›¿ğ‘šğ‘ğ‘¥
if
the
added
element
from
group
is
denoted
by
ğ‘ğ‘–
the
eor
constraint
value
at
is
ğœğ‘˜
ğ‘ğ‘–
ğ‘›ğ‘…ğ‘’ğ‘™
ğœğ‘˜
ğ‘›ğ‘…ğ‘’ğ‘™
ğœğ‘˜
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘ğ‘–
ğ‘ğ‘–
ğ‘›ğ‘…ğ‘’ğ‘™
ğœğ‘˜
ğ‘›ğ‘…ğ‘’ğ‘™
ğœğ‘˜
ğ‘›ğ‘…ğ‘’ğ‘™
ğœğ‘˜
ğ‘›ğ‘…ğ‘’ğ‘™
ğœğ‘˜
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
48
eq
48
holds
since
group
is
now
the
group
with
maximum
relevance
proportion
after
adding
ğ‘ğ‘–
the
top
most
current
element
from
group
group
becomes
the
group
with
minimum
relevance
proportion
ğ‘ƒğ‘…ğ‘ƒ
since
ğ‘›ğ‘…ğ‘’ğ‘™ğ‘–
ğ‘›ğ‘…ğ‘’ğ‘™
ğ›¿ğ‘šğ‘ğ‘¥
and
because
group
was
behind
group
at
prefix
we
have
result
ğœğ‘˜
ğ‘›ğ‘…ğ‘’ğ‘™
ğœğ‘˜
ğ‘›ğ‘…ğ‘’ğ‘™
ğœğ‘˜
since
as
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘ğ‘–
ğ‘ƒğ‘…ğ‘ƒ
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ›¿ğ‘šğ‘ğ‘¥
we
have
shown
above
that
if
the
group
with
lowest
relevance
proportion
at
prefix
group
in
this
case
is
selected
and
its
relevance
proportion
now
exceeds
the
group
with
the
highest
relevance
proportion
at
prefix
group
in
the
case
above
then
ğœğ‘˜
ğ›¿ğ‘šğ‘ğ‘¥
thus
we
can
say
that
at
least
one
group
exists
that
satisfies
ğ›¿ğ‘šğ‘ğ‘¥
eor
constraint
at
prefix
this
completes
the
proof
that
the
eor
algorithm
always
provides
feasible
ranking
that
satisfies
ğ›¿ğ‘šğ‘ğ‘¥
maxğ‘”
ğ‘ƒğ‘…ğ‘ƒ
ğ‘›ğ‘…ğ‘’ğ‘™
for
groups
experiment
details
baselines
we
compare
rankings
from
algorithm
with
the
following
baselines
probability
ranking
principle
ğ‘ƒğ‘…ğ‘ƒ
candidates
are
selected
in
decreasing
order
of
relevance
independent
of
their
group
membership
uniform
policy
unif
candidates
are
selected
randomly
independent
of
their
group
membership
or
relevance
thompson
sampling
ranking
policy
ğœ‹ğ‘‡
50
for
ğœ‹ğ‘‡
binary
relevances
are
drawn
according
to
ğ‘Ÿğ‘–
ğ‘Ÿğ‘–
and
candidates
are
sorted
in
decreasing
order
of
relevance
ğ‘Ÿğ‘–
with
their
ranking
randomized
for
the
same
value
of
relevance
ğ‘Ÿğ‘–
ğœ‹ğ‘‡
arg
sortğ‘–
ğ‘Ÿğ‘–
ğ‘Ÿğ‘–
ğ‘Ÿğ‘–
ğœ‹ğ‘‡
ranks
each
candidate
in
position
with
probability
that
has
ğ‘¡â„
highest
relevance
for
both
ğœ‹ğ‘‡
and
unif
we
compute
expectation
over
100
rankings
unif
unif
or
ğœğ‘‡
ğœ‹ğ‘‡
respectively
and
compute
ğœğ‘˜
used
in
table
as
ğ‘›ğ‘…ğ‘’ğ‘™
ğœğ‘˜
ğ‘›ğ‘…ğ‘’ğ‘™
ğœğ‘˜
ğœğ‘˜
eğœ
max
min
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
in
order
to
plot
single
ranking
unif
ğœğ‘‡
for
all
experiments
we
select
the
ranking
with
median
ğ‘›ğ‘˜
ğœğ‘˜
eaamo
24
october
29
31
2024
san
luis
potosi
mexico
prr
1.0
fs
eor
0.0
dp
102
ts
102
102
length
of
ranking
group
1.0
0.0
group
prp
102
total
costs
0.6
0.5
0.4
0.3
0.2
0.1
0.0
0.1
0.2
0.3
uniform
102
prr
fs
102
ndcg
prp
ts
group
costs
eor
dp
rastogi
and
joachims
102
principal
1.0
0.5
0.0
102
1.0
0.5
0.0
102
figure
eor
criterion
ğœğ‘˜
costs
of
the
ranking
policies
and
dcg
utility
for
synthetic
dataset
with
proportional
rooney-rule
like
constraint
ğ‘ƒğ‘…ğ‘…
for
group
we
draw
30
relevance
probabilities
from
ğ‘ƒğ‘œğ‘¤ğ‘’ğ‘Ÿğ‘™ğ‘ğ‘¤
and
then
draw
for
group
from
ğ‘ƒğ‘œğ‘¤ğ‘’ğ‘Ÿğ‘™ğ‘ğ‘¤
0.5
until
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
0.6
1.01
group
costs
eor
0.5
0.8
demographic
parity
ğ·ğ‘ƒ
candidates
in
each
group
are
sorted
in
decreasing
order
of0
ğ‘Ÿğ‘–
and
selected
such
that
the
following
0.3
in
58
constraint
is
minimized
this
constraint
is
similar
to
the
statistical
parity
variations
introduced
0.2
0.00
ğœğ‘˜
ğœğ‘˜
102
0.1
49
1.0
0.4
0.0
ts
ğ¸ğ‘‚ğ‘…
where
represents
the
size
of
the
group
for
fair
comparison
with
we
use
algorithm
and
instead
of
minimizing
eq
we
0.1
minimize
the
above
demographic
parity
constraint
49
we
now
discuss
other
variations
of
proportional
representation
constraints
that
0.2
have
0.2
been
introduced
in
prior
literature
10
generally
these
constraints
require
that
the
disadvantaged
group
selected
is
at
least
specific
0.3
proportion
of
top
0.0
0.0
102
102
ğœğ‘˜
ğ›¼ğ‘˜
50
length
of
ranking
where
and
eq
50
is
used
as
the
fairness
constraint
while
maximizing
the
utility
to
the
principal
this
type
of
representational
constraint
by
definition
requires
the
designation
of
disadvantaged
group
by
designating
as
the
disadvantaged
group
the
constraint
for
proportional
rooney-rule
policy
47
which
we
denote
by
ğ‘ƒğ‘…ğ‘…
is
as
follows
ğœğ‘˜
we
empirically
compare
ğ‘ƒğ‘…ğ‘…
baseline
with
other
ranking
policies
in
figure
and
as
expected
find
that
it
is
similar
to
the
baseline
of
ğ·ğ‘ƒ
where
ğ‘ƒğ‘…ğ‘…
and
ğ·ğ‘ƒ
almost
overlap
thus
for
fair
and
analogous
comparison
with
ğ¸ğ‘‚ğ‘…
we
use
49
as
the
ğ·ğ‘ƒ
baseline
for
all
empirical
evaluations
for
more
than
two
groups
we
extend
the
dp
baseline
with
the
selection
rule
based
on
group
size
as
follows
in
particular
ğœğ‘˜
ğœğ‘˜
ğ·ğ‘ƒ
max
min
ğ‘™ğ‘”
ğ‘ƒğ‘…ğ‘ƒ
arg
min
ğ·ğ‘ƒ
ğ‘™ğ‘”
ğ‘™ğ‘”
ğ‘ƒğ‘…ğ‘ƒ
51
fa
ir
ranking
principle
ğ¹ğ‘†
this
criterion
is
anchored
on
the
principle
that
top-k
ranking
is
fair
when
the
proportion
of
disadvantaged
candidates
selected
doesn
fall
far
below
required
minimum
proportion
this
is
formalized
with
binomial
distribution
and
confidence
level
function
of
the
binomial
cdf
is
computed
apriori
and
is
used
as
an
input
in
the
fa
ir
algorithm
since
binomial
0.5
corresponds
to
ranking
where
at
each
position
candidate
from
either
group
is
selected
randomly
fa
ir
is
softened
version
of
demographic
parity
dp
as
result
fa
ir
is
fundamentally
different
from
axiom
and
definition
4.1
derived
from
the
uniform
lottery
fairness
in
ranking
under
disparate
uncertainty
eaamo
24
october
29
31
2024
san
luis
potosi
mexico
fairness
because
unlike
dp
the
uniform
lottery
is
anchored
on
selecting
an
equal
fraction
of
relevance
from
each
group
unlike
ğ¸ğ‘‚ğ‘…
ğ¹ğ‘†
is
oblivious
to
the
relevance
distribution
and
thus
cannot
take
disparate
uncertainty
into
account
fa
ir
also
requires
the
normative
designation
of
disadvantaged
group
consider
the
following
example
for
top
selection
with
the
probability
of
relevance
for
group
0.7
0.7
0.7
0.7
0.1
0.1
group
size
relevant
candidates
3.0
similarly
the
probability
of
relevance
for
group
0.5
0.5
0.5
0.5
0.5
0.5
group
size
relevant
candidates
3.0
the
eor
ranking
for
top-4
is
0.5
0.7
0.5
0.7
with
candidates
from
group
and
from
group
resulting
in
ğœ4ğ¸ğ‘‚ğ‘…
0.13
the
ğ¹ğ‘†
algorithm
with
binomial
0.5
12
and
0.1
requires
that
at
least
candidate
be
selected
from
the
disadvantaged
group
while
maximizing
the
utility
to
the
principal
fa
ir
ranking
with
group
as
the
disadvantaged
group
is
ğœ4ğ¹ğ‘†
0.7
0.7
0.7
0.5
it
selects
candidates
from
group
and
from
group
resulting
in
ğœ4
0.53
if
instead
group
is
designated
as
the
disadvantaged
group
ğ¹ğ‘†
0.7
0.7
0.7
0.7
with
all
candidates
selected
from
group
and
none
from
group
resulting
in
ğœ4ğ¹ğ‘†
0.93
note
that
for
both
fa
ir
rankings
far
fewer
relevant
candidates
are
chosen
from
group
even
though
both
groups
have
an
equal
number
of
relevant
candidates
in
expectation
in
all
the
empirical
evaluations
in
this
paper
we
assign
group
as
the
minority
group
for
ğ¹ğ‘†
and
use
the
fairsearch
core
library
with
default
parameters
of
0.1
next
we
discuss
two
exposure-based
formulations
ğ¸ğ‘‹
and
ğ‘…ğ´
exposure-based
disparate
treatment
ğ¸ğ‘‹
this
policy
enforces
that
the
allocation
of
exposure
to
each
group
is
proportional
to
their
average
utility
specifically
for
two
groups
and
exposure
exposure
where
is
the
doubly
stochastic
ranking
matrix
obtained
from
solving
the
linear
program
in
49
for
multiple
groups
the
above
constraint
ğ‘ğ‘–
ğ‘›ğ‘…ğ‘’ğ‘™
is
added
for
each
pair
of
groups
exposure
ğ‘†ğ‘–
log
1ğ‘—
for
the
ğ‘¡â„
position
and
ğ‘†ğ‘–
in
particular
for
two
groups
we
solve
the
following
lp
49
maximize
ğ‘ƒğ‘‡
Ïƒğ‘£
subject
to
1ğ‘‡
1ğ‘‡
Ïƒ1
Ïƒğ‘–
iğ‘–
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
Ïƒğ‘£
utility
to
the
principal
52
sum
of
probabilities
for
each
position
sum
of
probabilities
for
each
candidate
valid
probability
exposure
constraint
ğ‘ƒÏ‚
ğ‘ƒÏ‚
iğ‘”
ğ‘ƒÏ‚
and
eor
criterion
as
max
the
group
cost
is
computed
as
ğ‘›ğ‘…ğ‘’ğ‘™
total
cost
as
min
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
rank
aggregation
proportional
allocation
of
exposure
for
ğ‘…ğ´
we
modify
the
baseline
for
fair
rank
aggregation
in
as
follows
in
fair
rank
aggregation
all
candidates
are
ranked
by
voters
to
achieve
ranking
with
maximum
consensus
accuracy
where
consensus
may
be
according
to
different
aggregation
methods
while
achieving
fairness
of
exposure
groups
proposes
an
algorithm
that
finds
the
consensus
maximizing
ranking
and
then
swaps
the
candidates
such
that
the
equality
of
exposure
is
satisfied
in
that
ranking
to
adapt
this
baseline
we
use
the
ranking
from
utility
maximizing
ğ‘ƒğ‘…ğ‘ƒ
as
the
consensus
ranking
and
use
the
algorithm
from
to
swap
elements
in
prp
ranking
until
the
exposure
constraint
below
is
satisfied
minğ‘”
ğ¸ğ‘¥ğ‘ğ‘œğ‘ ğ‘¢ğ‘Ÿğ‘’
threshold
maxğ‘”
ğ¸ğ‘¥ğ‘ğ‘œğ‘ ğ‘¢ğ‘Ÿğ‘’
threshold
of
0.95
is
used
in
experiments
and
on
average
over
100
runs
an
exposure
of
0.96
0.01
0.96
0.00
0.97
0.00
is
achieved
for
high
medium
and
low
levels
of
disparate
uncertainty
respectively
in
table
synthetic
dataset
to
simulate
disparate
uncertainty
between
groups
we
draw
ğ‘Ÿğ‘–
directly
from
specific
probability
distributions
as
follows
for
group
and
keep
them
fixed
we
simulate
100
runs
and
in
each
run
for
group
are
sampled
as
follows
until
we
obtain
ğ‘ğ‘–
ğµğ‘’ğ‘¡ğ‘
20
20
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
total
expected
relevance
for
groups
can
only
differ
by
1.0
high
disparate
uncertainty
ğµğ‘’ğ‘¡ğ‘
medium
disparate
uncertainty
ğµğ‘’ğ‘¡ğ‘
21
12
note
that
even
when
both
groups
are
drawn
from
the
same
distribution
any
sampled
low
disparate
uncertainty
ğµğ‘’ğ‘¡ğ‘
20
20
instance
still
contains
some
amount
of
disparate
uncertainty
https://github.com/fair-search/fairsearch-fair-python
eaamo
24
october
29
31
2024
san
luis
potosi
mexico
rastogi
and
joachims
results
for
unfairness
and
effectiveness
of
rankings
are
reported
with
standard
error
in
table
left
the
posterior
distributions
in
table
right
uses
50
samples
for
each
candidate
in
group
while
for
group
the
number
of
samples
increases
from
10
to
30
to
50
as
the
setting
changes
from
high
to
medium
to
low
disparate
uncertainty
respectively
to
estimate
ğœğ‘˜ğœ‹
for
stochastic
policies
unif
and
ğœ‹ğ‘‡
we
draw
103
monte
carlo
samples
and
compute
monte
carlo
estimate
according
to
53
iğ‘–
ğœğ‘˜
ğœğ‘˜ğœ‹
53
we
compute
the
costs
using
ğ‘Ÿğ‘–
ğœğ‘˜ğœ‹
according
to
eqs
and
in
figure
11
we
plot
random
sample
from
table
according
to
the
generation
process
described
above
we
also
qualitatively
analyze
commonly
used
measure
of
utility
to
the
principal
namely
the
expected
normalized
discounted
cumulative
gain
ndcg
which
according
to
our
model
is
ğ·ğ¶ğº
ğœğ‘˜
ğœğ‘˜
ğ‘£ğ‘–
ğ‘Ÿğ‘–
ğ‘›ğ·ğ¶ğº
ğœğ‘˜
ğ¼ğ‘‘ğ‘’ğ‘ğ‘™
arg
sortğ‘–
ğ‘Ÿğ‘–
ğ‘–ğ·ğ¶ğº
ğ¼ğ‘‘ğ‘’ğ‘ğ‘™
ğ‘£ğ‘–
ğ‘Ÿğ‘–
ndcg
for
the
ğ‘¡â„
position
when
true
relevance
labels
are
known
for
instance
in
us
census
experiments
in
figure
14
where
ğ‘£ğ‘–
ğ‘™ğ‘œğ‘”2
ğ‘Ÿğ‘–
consists
of
the
true
relevance
labels
otherwise
in
synthetic
experiments
in
figure
11
ğ‘Ÿğ‘–
consists
of
the
calibrated
ğ‘Ÿğ‘–
as
shown
in
figure
10
the
ndcg
for
eor
ranking
is
only
slightly
lower
than
the
ndcg
optimal
prp
ranking
and
competitive
with
all
other
ranking
policies
in
all
of
these
experiments
we
confirm
our
findings
that
ğ¸ğ‘‚ğ‘…
unif
distribute
the
subgroup
and
total
costs
evenly
1.0
0.9
0.8
0.7
0.6
0.5
0.4
fs
ra
exp
uniform
ts
prp
dp
eor
20
40
60
length
of
ranking
figure
10
ndcg
for
high
disparate
uncertainty
setting
shown
in
figure
while
other
ranking
policies
ğ‘ƒğ‘…ğ‘ƒ
ğ·ğ‘ƒ
and
ğœ‹ğ‘‡
place
high
cost
burden
on
one
of
the
groups
further
for
ğ¸ğ‘‚ğ‘…
the
total
cost
to
the
principal
and
ndcg
utility
is
close
to
the
optimal
but
unfair
total
cost
and
utility
of
ğ‘ƒğ‘…ğ‘ƒ
indicated
by
overlapping
lines
in
subplots
of
figure
11
us
census
survey
dataset
we
use
the
acsincome
task
with
default
settings
14
for
the
state
of
new
york
and
alabama
for
2018
with
year
horizon
the
dataset
consists
of
10
features
out
of
which
are
categorical
race
is
among
the
features
that
we
include
in
the
prediction
task
following
14
there
are
103
021
records
for
new
york
and
22
268
records
for
alabama
for
pre-processing
the
categorical
features
are
one-hot
encoded
while
the
other
two
numerical
features
age
and
wkhp
are
standardized
to
have
mean
and
standard
deviation
we
divide
this
dataset
into
60
20
20
for
train
val
test
split
and
fit
gradient
boosting
classifier
with
the
parameters
loss
as
exponential
and
max_depth
as
following
hyperparameter
configuration
of
14
this
gives
dp
violation
ğ‘ŒË†
â„ğ‘–ğ‘¡ğ‘’
ğ‘ŒË†
ğµğ‘™ğ‘ğ‘ğ‘˜
of
0.19
and
an
eo
violation
ğ‘ŒË†
â„ğ‘–ğ‘¡ğ‘’
ğ‘ŒË†
ğµğ‘™ğ‘ğ‘ğ‘˜
of
0.18
for
new
york
and
dp
violation
of
0.22
eo
violation
of
0.29
for
alabama
which
is
roughly
similar
to
figure
and
of
14
before
any
fairness
interventions
are
applied
in
the
classification
setting
we
subset
the
dataset
to
contain
records
with
white
or
black
african
american
racial
membership
alabama
and
new
york
and
subset
records
with
white
black
asian
and
others
racial
membership
new
york
only
for
two
and
four
groups
respectively
to
calibrate
relevance
probabilities
we
fit
platt
scaling
37
calibrator
on
the
validation
data
split
group-wise
and
apply
platt
scaling
to
the
test
set
probability
estimates
figure
12a
12b
and
12c
show
that
calibrated
ğ‘Ÿğ‘–
on
the
test
set
binned
across
20
equal
sized
bins
lie
close
to
the
perfectly
calibrated
line
scikit-learn
gradient
boosting
classifier
fairness
in
ranking
under
disparate
uncertainty
ra
1.0
group
costs
0.5
0.0
0.0
1.0
group
group
dp
prp
ts
59
59
59
exp
ra
fs
59
59
1.0
eor
0.0
0.0
59
1.0
0.5
0.0
59
dp
0.5
ts1
prp
59
eor
0.0
1.0
dp
61
0.0
0k
0.0
61
prp
61
exp
52
52
52
exp
ra
fs
0.0
52
length
of
ranking
61
1.0
0.6
0.5
61
0.4
0.0
52
0.2
1.0
52
0.0
61
52
ts
61
ra
61
total
costs
0.8
length
of
ranking
52
1.0
ndcg
0.5
59
principal
medium
disparate
uncertainty
1.0
group
costs
length
of
ranking
group
costs
0.2
0.1
0.0
0.1
0.2
0.3
0.4
0.5
0.0
59
eor
fs
total
costs
uniform
exp
ndcg
prp
ts
total
costs
eor
dp
eaamo
24
october
29
31
2024
san
luis
potosi
mexico
0.80
10
52
20
30
52
low
disparate
uncertainty
1.0
0.8
0.6
0.4
0.2
0.0
0.0
0.2
0.4
0.6
0.8
mean
predicted
rate
new
york
1.0
white
black
perfect
calibration
0.8
mean
empirical
rate
white
black
perfect
calibration
mean
empirical
rate
mean
empirical
rate
figure
11
top
medium
disparate
uncertainty
bottom
low
disparate
uncertainty
for
randomly
sampled
instance
0.6
0.4
0.2
0.0
0.0
0.2
0.4
0.6
0.8
mean
predicted
rate
alabama
1.0
white
black
asian
others
perfect
calibration
0.8
0.6
0.4
0.2
0.0
0.0
0.2
0.4
0.6
0.8
mean
predicted
rate
1.0
new
york
figure
12
calibration
plot
for
ğ‘Ÿğ‘–
for
the
state
of
new
york
and
alabama
in
figure
estimates
ğ‘›ğ‘…ğ‘’ğ‘™
ğœğ‘˜
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğœğ‘˜
and
ğ‘›ğ‘…ğ‘’ğ‘™
are
computed
with
the
true
relevance
labels
from
the
test
set
for
computing
eor
criterion
costs
and
ndcg
figure
13
shows
eor
criterion
and
costs
with
ğ‘›ğ‘…ğ‘’ğ‘™
ğœğ‘˜
ğ‘›ğ‘…ğ‘’ğ‘™
ğ‘›ğ‘…ğ‘’ğ‘™
ğœğ‘˜
ğ‘›ğ‘…ğ‘’ğ‘™
estimated
40
50
60
eaamo
24
october
29
31
2024
san
luis
potosi
mexico
group
costs
0.2
0.0
1.0
0.1
0.0
0.1
length
of
ranking
0.0
4268
eor
prp
4268
group
costs
0.3
0.0
1.0
0.2
0.1
length
of
ranking
4268
19985
0.0
eor
ra
prp
0.3
0.2
1.0
1.0
0.5
0.0
1.0
4268
0.0
1.0
0.5
4268
length
of1
0ranking
ra
ts
19985
principal
0.1
0.0
dp
others
ndcg
1.0
ts
0.4
dp
0.4
0.0
asian
group
costs
1.0
0.3
black
total
costs
white
ndcg
uniform
ra
total
costs
prp
ts
eor
dp
rastogi
and
joachims
0.5
0.0
1.0
19985
0.5
19985
19985
19985
figure
13
top
eor
criterion
ğœğ‘˜
and
costs
computed
using
calibrated
ğ‘Ÿğ‘–
for
two
groups
for
the
state
of
alabama
bottom
eor
criterion
ğœğ‘˜
and
costs
computed
using
calibrated
ğ‘Ÿğ‘–
for
four
groups
for
the
state
of
new
york
from
the
calibrated
ğ‘Ÿğ‘–
note
that
the
evaluation
on
true
relevance
labels
in
figure
though
noisier
is
qualitatively
similar
to
the
evaluation
using
the
calibrated
ğ‘Ÿğ‘–
in
figure
13
additional
experiment
for
two
groups
with
true
relevance
labels
for
new
york
in
figure
14
top
and
with
calibrated
ğ‘Ÿğ‘–
in
figure
14
bottom
further
confirm
our
findings
that
ğ¸ğ‘‚ğ‘…
is
the
only
ranking
policy
that
consistently
achieves
ğœğ‘˜
close
to
zero
at
every
prefix
with
near
optimal
total
cost
to
the
principal
note
the
overlapping
of
ğ‘…ğ´
and
ğ‘ƒğ‘…ğ‘ƒ
in
figure
13
and
14
this
is
expected
because
ğ‘…ğ´
swaps
the
candidates
in
prp
ranking
to
satisfy
proportional
exposure
as
described
in
appendix
since
the
amortized
exposure
between
groups
is
already
satisfied
with
the
prp
ranking
for
this
dataset
ğ‘…ğ´
and
ğ‘ƒğ‘…ğ‘ƒ
compute
similar
rankings
amazon
shopping
queries
dataset
amazon
shopping
queries
39
consists
of
large
scale
query-product
pair
dataset
with
baseline
models
for
tasks
related
to
predicting
the
relevance
of
items
given
search
query
each
query-product
pair
has
an
associated
human
annotated
label
of
an
exact
substitute
complement
or
irrelevant
label
for
our
analysis
we
focus
on
their
task
of
query-product
ranking
to
sort
the
list
of
products
in
the
decreasing
order
of
relevance
for
every
query
we
use
the
publicly
available
baseline
model
for
this
task
consisting
of
cross
encoders
for
the
ms
marco
dataset
40
this
pretrained
model
encodes
the
query
and
product
titles
and
is
fine-tuned
on
the
us
part
of
the
small
version
of
training
dataset
we
use
the
default
hyperparameters
for
the
cross
encoder
as
maximum
length
512
activation
function
identity
and
number
of
labels
binary
task
similarly
for
training
following
the
default
configuration
all
exact
labels
are
mapped
to
1.0
while
the
rest
substitute
complement
and
irrelevant
are
mapped
to
0.0
default
hyperparameter
configuration
includes
mse
loss
function
evaluation
steps
5000
warm-up
steps
5000
learning
rate
7e-6
training
epochs
and
number
of
development
queries
400
inference
from
the
trained
model
provides
relevance
scores
and
we
apply
sigmoid
function
to
transform
these
scores
to
probabilities
of
relevance
ğ‘Ÿğ‘–
https://github.com/amazon-science/esci-data
0.0
1.0
group
costs
0.1
0.0
1.0
0.0
0.1
length
of
ranking
0.0
16922
uniform
eor
0.1
length
of
ranking
16922
0.0
0.1
16922
eor
dp
prp
0.1
16922
1.0
0.5
1.0
0.0
1.0
16922
0.5
16922
ra
1.0
0.5
length
of
ranking
ts
16922
black
0.0
16922
0.0
ndcg
group
costs
0.0
0.0
1.0
ra
ts
0.1
white
dp
prp
1.0
ra
0.0
1.0
16922
16922
0.5
16922
figure
14
top
eor
criterion
ğœğ‘˜
and
costs
computed
using
true
relevance
labels
from
the
test
subset
bottom
eor
criterion
ğœğ‘˜
and
costs
computed
using
calibrated
ğ‘Ÿğ‘–
for
the
state
of
new
york
to
evaluate
the
calibration
of
predicted
ğ‘Ÿğ‘–
we
use
the
test
split
of
the
dataset
39
for
the
large
version
containing
22
458
we
filtered
these
queries
so
that
they
contain
at
least
three
products
owned
by
one
of
the
158
brands
owned
by
amazon
we
discuss
in
the
next
paragraph
the
source
of
identifying
these
amazon-owned
brands
and
at
least
three
products
owned
by
brands
other
than
amazon
these
result
in
395
queries
out
of
which
half
are
used
for
calibration
with
platt-scaling
calibrator
while
the
remaining
half
is
used
to
evaluate
the
calibration
curve
for
the
test
dataset
ğ‘Ÿğ‘–
of
the
query-product
pairs
for
the
remainder
half
of
the
test
dataset
after
calibration
is
binned
across
20
equal
sized
bins
as
shown
in
figure
6a
and
lies
close
to
the
perfectly
calibrated
line
we
further
augmented
this
with
another
dataset
collected
from
the
markup
report
60
which
investigated
amazon
placement
of
its
own
brand
products
as
compared
to
other
brands
based
on
star
ratings
reviews
etc
the
authors
for
the
markup
report
identified
158
brand
products
that
are
trademarked
by
amazon
we
use
these
158
brands
to
form
the
amazon
owned
group
products
belonging
to
any
other
brand
form
the
non-amazon
group
importantly
this
dataset
contains
logged
rankings
from
amazon
website
with
4566
queries
for
popularly
searched
query
terms
we
filtered
these
such
that
each
query
contains
exactly
60
products
and
at
least
three
of
them
are
owned
by
amazon
resulting
in
1485
search
queries
next
we
obtain
relevance
probabilities
ğ‘Ÿğ‘–
from
amazon
pretrained
baseline
model
described
above
and
evaluate
ğœğ‘˜
both
for
the
logged
ranking
as
well
as
our
computed
eor
ranking
figure
6b
shows
that
our
eor
ranking
is
closer
to
ğœğ‘˜
as
compared
to
logged
rankings
on
amazon
platform
we
note
that
this
analysis
is
subject
to
confounding
due
to
the
use
of
features
other
than
product
titles
that
may
be
used
in
practice
for
logged
rankings
however
the
analysis
does
demonstrate
how
the
eor
criterion
can
be
used
for
auditing
if
the
auditor
is
given
access
to
the
production
ranking
model
to
avoid
confounding
https://github.com/the-markup/investigation-amazon-brands
group
costs
ts
ndcg
prp
total
costs
dp
eor
eaamo
24
october
29
31
2024
san
luis
potosi
mexico
total
costs
fairness
in
ranking
under
disparate
uncertainty
0.0
1.0
0.0