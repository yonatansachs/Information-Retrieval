iew
ed

Biased Search Engine Autosuggestions Against Females and Migrants Can Lead to Hiring
Discrimination: An Experimental Investigation
Cong Lin1 +, Wang Liao2 +, Na Ta3,4 *
1 School

of Journalism and Communication, Tsinghua University

3 Research

Center of Journalism and Social Development, Renmin University of China
of Journalism and Communication, Renmin University of China

er
r

4 School

+ Cong

of Communication, University of Washington

ev

2 Department

Lin and Wang Liao contributed equally to this work and shared the first authorship.
Author: Na Ta; Address: No. 59, Zhongguancun Street, Haidian Dist, Beijing,
100872, China; Email: tanayun@ruc.edu.cn

Pr

ep

rin

tn

ot

pe

*Corresponding

This preprint research paper has not been peer reviewed. Electronic copy available at: https://ssrn.com/abstract=4683734

pe
er
re
vie
we

to Hiring Discrimination: An Experimental Investigation

d

Biased Search Engine Autosuggestions Against Females and Migrants Can Lead

Abstract

Research has identified biased languages against certain social groups in
search engine autosuggestions, but their actual effects on the users remain
underexplored. This article addresses the effects of biased search engine

autosuggestions on hiring discrimination against females and migrants. In two preregistered experiments (N = 266, N = 263), we exposed the participants to biased
1

2

autosuggestions against these two groups in certain occupations (female lapidaries in

Experiment 1 and migrant rideshare drivers in Experiment 2) and measured the hiring
preference. We found the biased autosuggestions affected the hiring preference,

ot

contingent on stereotypical beliefs of the respective groups: When the group was

perceived relatively cold (e.g., females colder than males), the biased autosuggestions

tn

increased users’ hiring discrimination against the group. In contrast, when the group
was perceived relatively warm (e.g., migrants warmer than US citizens), the biased

rin

autosuggestions triggered a reactance response, reducing their hiring discrimination.

ep

Keywords: search engine, autosuggestion, algorithmic bias, stereotype, hiring

Pr

decision

This preprint research paper has not been peer reviewed. Electronic copy available at: https://ssrn.com/abstract=4683734

pe
er
re
vie
we

to Hiring Discrimination: An Experimental Investigation

d

Biased Search Engine Autosuggestions Against Females and Migrants Can Lead

Scholars have raised many concerns of search engines’ potentials in

propagating prejudice and discrimination (Epstein & Robertson, 2015; Noble, 2018;

Vlasceanu & Amodio, 2022), and one of such concerns pertains to the autosuggestion
feature. Search engine autosuggestion is a feature where algorithm-predicted search

terms appear as users typing their own to ease the search experience (Sullivan, 2018).

Scholars worry that such autosuggestions could propagate biases against certain social
groups (e.g., misogynistic beliefs, Graham, 2023; and racist stereotypes, Noble,

2018), and research has already identified such biases in the contents of major search
engines’ autosuggestions (e.g., Roy & Ayalon, 2020; Lin et al., 2023). That said,

researchers only recently started to assess the actual effects of biased autosuggestions

ot

on user behaviors, for example, voting (Epstein et al., 2023), and so far, little attention

tn

has been paid to the effects on discrimination.
The current study addresses the effects of biased search engine

rin

autosuggestions on discrimination against females and migrants. Previous studies
have found prevalent biases against women and immigrants in search engine

ep

autosuggestions (UN Women, 2013; Hazen et al., 2022). Assessing the extent to
which such biases can instigate discrimination against these two disadvantaged
groups, therefore, holds realistic importance. We particularly focus on hiring

Pr

discrimination, because women and migrants are particularly vulnerable in the job
market (Esses, 2021; Lambrecht & Tucker, 2019). To study such discrimination, we

This preprint research paper has not been peer reviewed. Electronic copy available at: https://ssrn.com/abstract=4683734

d

designed and pre-registered two experiments that involved making decisions about

pe
er
re
vie
we

hiring female versus male lapidaries (i.e., the professionals of crafting gemstones),

and migrant versus US-born rideshare drivers. The two occupations were chosen to
reduce stereotypical associations between occupations and certain social groups,

because such associations can interfere with the effect of biased autosuggestions (e.g,
female plumbers may be less preferred over male plumbers because of the already
gendered plumbing occupation, thus overshadowing potential effects of biased

autosuggestions). Since many occupations are gendered, we use lapidary as a novel

occupation to study gender bias, following previous research (Vlasceanu & Amodio,

2022). For migrants, we choose rideshare drivers as data suggest migrants counted for
about half of the current rideshare workforces in the US (Brenner, 2020; Uber, 2023),
suggesting a relatively weak association between this occupation and migrant status.

ot

To study the effects of autosuggestions, we invited participants to “visually
describe” their impressions of lapidaries or rideshare drivers using images that they

tn

found from a mock Google Images search engine. We manipulated the
autosuggestions as the participants typing in search terms. Then, we presented

rin

scenarios where the participants were asked to choose from multiple candidates to
hire, measuring their preference for female lapidaries (over male lapidaries) or

ep

migrant drivers (over US-born drivers). In addition to the effects of the manipulated
autosuggestions, we explore the underlying mechanisms involving existing

Pr

stereotypes, which are central to how biased autosuggestions perpetuates
discrimination (Miller & Record, 2017). Particularly, we focus on participant’s

This preprint research paper has not been peer reviewed. Electronic copy available at: https://ssrn.com/abstract=4683734

d

stereotypical beliefs about the two groups’ warmth and competence––the two basic

pe
er
re
vie
we

dimensions of the content of social stereotypes (Fiske et al., 2002; 2007). We then

study whether such beliefs could play a moderating role (i.e., as pre-existing beliefs
that intensifies the effect of biased autosuggestions) and/or a mediating role (i.e., as
volatile knowledge that can be learned socially from the autosuggestions and
subsequently affects discriminatory behaviors) over the effects of biased
autosuggestions on hiring discrimination.

The following sections first introduce the biases in search engine

autosuggestions and discuss how biased autosuggestions can psychologically impact

people’s hiring decisions. Next, we discuss the roles that stereotypes could play in the
effects of biased autosuggestions. We then describe the experiments in detail.

Regression models and the results of mediation/moderation analyses are reported, and

ot

implications discussed.
Algorithmic Bias in Search Engine Autosuggestions

tn

Algorithms can absorb and reproduce widespread biases in a society (i.e.,
“bias in, bias out,” Mayson, 2018, p. 2224) at various stages of algorithmic operation

rin

(Mehrabi et al., 2021). Likewise, the search engine autosuggestion algorithms are
likely to learn from biased search queries and clicking traces, re-producing the biases

ep

in the generated autosuggestions. So far, studies have identified biases against certain
social groups (e.g., groups with different gender, race or sexual orientation, Lin et al.,

Pr

2023) in search engines’ autosuggestions, particularly in terms of harmful speech,
misinformation, and social stereotypes (Olteanu et al., 2020). For example, there have

This preprint research paper has not been peer reviewed. Electronic copy available at: https://ssrn.com/abstract=4683734

d

been prevalent negative constructions of racial and sexual minorities in earlier years

pe
er
re
vie
we

of Google autosuggestions (e.g., gay people were constructed as disproportionately
associated with AIDS, and gay people do not deserve equal rights, Baker & Potts,
2013; Black women were associated with words such as sassy and angry, Noble,
2018). As search engines evolve, research found less blatant but increasingly

insidious biases (Graham, 2023). For example, a study of autosuggestions involving
629 German politicians found a nuanced gender bias, that is, search queries about

female politicians triggered more suggestions on personal and emotional topics than
male politicians (Bonart et al., 2020). Today, biased autosuggestions about certain

social groups can still be found across languages and social contexts (e.g., in African
languages, Chonka et al., 2023), as well as search engine platforms such as Google,
Duckduckgo, Bing (Bonart et al. 2020).

ot

Compared to the efforts in identifying biased search engine autosuggestions,
less attention is paid to the extent to which such biased autosuggestions affect users.

tn

As discussed below, biased autosuggestions can lead to discrimination, such as
discriminatory hiring decisions against women and migrants.

rin

Effects of Biased Autosuggestions on Hiring Decisions
Although autosuggestions can be a fleeting experience for many search engine

ep

users, the prevalence of search engine uses can still instill biases into people’s
worldview and decision making, reinforcing prejudice and discrimination (Miller &

Pr

Record, 2017; Graham, 2023). From a psychological point of view, priming is likely
one of the most relevant processes through which biased autosuggestions can lead to

This preprint research paper has not been peer reviewed. Electronic copy available at: https://ssrn.com/abstract=4683734

d

discriminatory behaviors (Uhlmann & Cohen, 2007; Houli et al., 2021). Priming

pe
er
re
vie
we

refers to the effects of a preceding stimulus or event on an individual’s reactions to

subsequent stimuli (Roskos-Ewoldsen et al., 2002; Tulving, 1983). Such effects are
likely achieved through the heightened accessibility of cognitive structures (e.g.,

gender stereotypes) recently or frequently activated by contextual cues (e.g., biased
autosuggestions). These cognitive structures then influence the evaluation of

subsequent objects within a certain period of time (Iyengar & Kinder, 2010; Srull &
Wyer, 1989). It is also possible that the activation of cognitive structure (e.g., a

concept like “nurse”) can spread to other semantically similar cognitive structures

(e.g., the concept “doctor”) as if these structures are stored in memory like a network

of semantic similarities (Anderson, 2014; Berkowitz & Rogers, 1986). The activation
of one cognitive structure can make other structures salient to subsequent judgment

ot

and decision making.
Priming likely takes place when users are exposed to biased autosuggestions.

tn

Particularly, biased autosuggestions such as prejudicial or stereotypic words could act
as contextual cues, activating cognitive structures that have negative evaluation about

rin

a certain social group in users’ memory. These unfavorable cognitive structures
remain accessible and influence the subsequent judgment and decision making within

ep

a period of time. Many studies have found such priming effects on discriminatory
behaviors. For example, stereotypical media contents about foreigners can lead to

Pr

biased judgments and discrimination against foreigners (Arendt, 2013). Similarly, the
exposure to stereotypic portrayals of an African American woman resulted in much

This preprint research paper has not been peer reviewed. Electronic copy available at: https://ssrn.com/abstract=4683734

pe
er
re
vie
we

American female interviewee (Brown Given & Monahan, 2005). In online

d

quicker responses of stereotype-consistent evaluation of the subsequent African

environments, research shows that hateful language towards refugees in online
comments primes participants’ stereotypes against refugees and decreases the
intention to donate money (Weber et al., 2020).

Therefore, we argue that biased search engine autosuggestions against a

certain social group should have a likewise priming effect on subsequent judgments
and decisions towards members of the group. In our research contexts, biased

autosuggestions against female lapidaries or migrant rideshare drivers should reduce
users’ willingness to hire them in comparison to the opposing groups (i.e., male
lapidaries and US-born drivers), as hypothesized below:

H1: Exposure to search engine autosuggestions that are biased against (a)

ot

female lapidaries or (b) migrant rideshare drivers will reduce the preference of
hiring them compared to their male or US-born counterparts.

tn

Because priming relies on the accessibility and activation of existing cognitive
structures, stereotypes about females and migrants are likely to play an important role

rin

(Pechmann, 2001). The following section discusses two possibilities of the role that
stereotypes may play in biased autosuggestions’ effects on discrimination.

ep

Two Mechanisms of Stereotypes under the Effects of Biased Autosuggestions
Stereotypes are schematic beliefs about a group of individuals in people’s

Pr

mind (Augoustinos & Walker, 1998; Weber & Crocker, 1983). For example, women
are often believed more likely than men to be homemakers, and are less likely to be

This preprint research paper has not been peer reviewed. Electronic copy available at: https://ssrn.com/abstract=4683734

d

employed in the paid workforce (Eagly & Steffen, 1984). Likewise, migrants are

pe
er
re
vie
we

often stereotyped as taking job opportunities from the locals or natives (Burns &

Gimpel, 2000; Feldmeyer, 2009). Despite the variety of specific stereotypes, their
contents appear to be organized along two universal dimensions: warmth (e.g.,

perceived to be warm and friendly) and competence (e.g., perceived to be capable and
competent, Fiske et al., 2002). These two dimensions are deeply rooted in the desires
to judge potential interaction partners’ cooperative intention (i.e., good or bad

intentions toward me or my group, Lee & Fiske, 2006) and their capabilities to ensure
successful cooperation outcomes (i.e., able or unable to enact the cooperative
intention, Lee & Fiske, 2006).

Autosuggestions’ behavioral impacts may involve stereotypes in two different
ways. First of all, stereotypes may be considered as pre-existing conditions that may

ot

not be changed by exposures to biased autosuggestions given the fleeting experience,
but made salient by such exposures. Thus, the stereotypes may play a moderating role

tn

over the discriminatory effects of biased autosuggestions. Research suggests that
priming can automatically activate existing stereotypes, increasing the likelihood that

rin

the knowledge contained in the stereotype will be used in subsequent judgments and
decisions (Power et al., 1996). However, when the stereotypes do not exist, or have

ep

different contents, priming may have no effect or have different effects across
individuals (Dijksterhuis et al., 2014). For example, Dixon (2007) identified such a

Pr

moderation effect after exposing participants to Black criminal suspects or
unidentified suspects in a newscast: People who held a greater extent of negative

This preprint research paper has not been peer reviewed. Electronic copy available at: https://ssrn.com/abstract=4683734

d

stereotypes against African American were more likely to support the death penalty

pe
er
re
vie
we

for the Black suspects.

Therefore, biased autosuggestions could activate pre-existing stereotypes
against females or migrants, and depending on the nature of the stereotype,

subsequent behaviors can be biased accordingly, even without reaching awareness.

Focusing on the two dimensions of stereotypes (Fiske et al., 2002), we anticipate that
the stereotypical beliefs of warmth and competence about females or migrants,

especially in terms of the negative beliefs (cold and incompetent) will function as

moderators over the priming effects of biased autosuggestions on discrimination, as
hypothesized below:

H2: Users’ stereotypes in terms of warmth and competence moderate the

discriminatory effect of biased search engine autosuggestions such that a more

ot

negative stereotype (cold and/or incompetent) would lead to stronger hiring
discrimination against (a) females or (b) migrants.

tn

Alternatively, the stereotypical beliefs may be changeable or learnable through
exposure to other people’s opinions implied in autosuggestions, thus playing a

rin

mediating role over the effect of biased autosuggestions on discrimination. Both
social learning theory (Bandura & Walter, 1969) and social comparison theory

ep

(Festinger, 1954) point out that individuals actively learn and adopt behaviors from
others. Research has noted that many people consider algorithm outputs, such as the

Pr

autosuggestions, as authoritative or truthful in representing public opinions (Beer,
2009; Oleinik, 2022). In this way, biased autosuggestions about females and migrants

This preprint research paper has not been peer reviewed. Electronic copy available at: https://ssrn.com/abstract=4683734

d

might update people’s stereotypical beliefs about them, such as warmth and

pe
er
re
vie
we

competence. Subsequently, the warmth and competence beliefs can influence various

judgments and decisions about these groups, including hiring decisions (Cuddy et al.,
2011). Similar mediating roles have been identified in previous research. For

example, Rudman and Phelan (2010) found women primed with traditional gender

roles (e.g., a male surgeon and a female nurse) showed increased automatic gender

stereotypes relative to controls. And the improved gender stereotypes mediated their
reduced preference in masculine occupations such as the Air Force officer.

Likewise, we expect that users’ stereotypical beliefs of females and migrants’
warmth and competence might be influenced by biased autosuggestions, and

consequently mediate the autosuggestions’ effect on hiring discrimination. Therefore,
we proposed the following hypothesis:

ot

H3: The effect of biased search engine autosuggestions against (a) females or
(b) migrants on users’ hiring preference is mediated by users’ stereotypes

tn

against the respective social group in terms of warmth and competence.
Methods

rin

We conducted two pre-registered experiments, each with two conditions

(https://osf.io/q794h/?view_only=4ccccd9da91d422aa3b60e8c822f8f25). In

ep

Experiment 1, participants were randomly exposed to biased autosuggestions against
male vs. female lapidaries. In Experiment 2, the autosuggestions were manipulated to

Pr

be biased against migrant rideshare drivers vs. no bias (i.e., control). The computer

This preprint research paper has not been peer reviewed. Electronic copy available at: https://ssrn.com/abstract=4683734

Participants

pe
er
re
vie
we

https://osf.io/6e5cz/?view_only=89828ab44fa34a9ab6f34d1bd50b14d2.

d

code and data can be found at

An a priori power analysis determined that a sample size at 260 is sufficient to
detect a small-to-medium effect (Cohen’s d = .35) of the manipulation, with alpha

= .05 and power = .8. We then recruited gender-balanced samples of US adults (≥18
years old) with English as the first language from Prolific (www.prolific.co).

Participants were paid $1.5 for completing a 7-minute task titled ‘visual impression of
lapidaries / rideshare drivers.’

Experiment 1 recruited 308 participants, and 266 were kept (50% female; M

age

= 39.8, SD = 13.49; 62.2% White, 17.4% Black, 8.9% Asian, 8.5% Mixed, and 3.1%
age

Other). Experiment 2 recruited 320 participants, and 263 were kept (50.8% female;

M = 40.26, SD = 13.10; 65.6% White, 9.8% Black, 8.2% Asian, 9.0% Mixed and
age

ot

age

7.4% Other). Participants were excluded if (a) they failed any of three attention

tn

checks throughout while finishing the task within 5 minutes, or (b) if they failed two
or more checks while spending more than 5 minutes to complete (the two different

rin

criteria were made in accordance to Prolific’s policy on attention check questions).
Procedure and Stimulus

ep

In both experiments, participants read the cover story and were led to believe

the study is about providing their visual impression of the occupation of lapidaries /

Pr

rideshare drivers. To increase the authenticity, participants were first asked a few
questions in relation to the occupation, such as “have you heard of the lapidary /

This preprint research paper has not been peer reviewed. Electronic copy available at: https://ssrn.com/abstract=4683734

pe
er
re
vie
we

/ rideshare driver in your region.”

d

rideshare profession” and “what is your best guess of the annual income of a lapidary

Then, participants were asked to search for images of lapidaries or rideshare
drivers and click on the image that best fits their impression of the occupation (see

Figure 1 for the mocked image search interface). The search process repeated three
times. Each time, participants were asked to include certain keywords in search

inquiries (“lapidary”, “jeweler”, “jewelry designer” in Experiment 1, and “Uber
driver” “Lyft driver,” and “rideshare driver” in Experiment 2). While typing,

participants were exposed to 10 autosuggestions displayed in the search box. In

Experiment 1, negatively biased autosuggestions against female or male lapidaries

(e.g., “female/male lapidary lazy”), depending on the condition, were included among
other normal suggestions (e.g., “lapidary association”). In Experiment 2, biased

ot

suggestions against migrant drivers were included in one condition (e.g., ‘Uber driver
kicks out passengers’), and the other condition (control) had no explicitly biased

tn

suggestions. The biased and normal autosuggestions were adapted from leading
search engines, including Google and Bing. Appendix A in Supplementary Materials

rin

lists all autosuggestions for every condition. Images in the result pages were derived
from Google Images and we tried to balance the positive and negative representations

ep

of the respective occupations in the two experiments.
After the image search task, we asked the participants to indicate their hiring

Pr

preferences and the stereotypical beliefs of warmth and competence, as described
below.

This preprint research paper has not been peer reviewed. Electronic copy available at: https://ssrn.com/abstract=4683734

d

Figure 1

pe
er
re
vie
we

Protocols of the mock Google search engine (the first screenshot) and the mocked
image search results page (the second screenshot) used as the stimulus of the

Pr

ep

rin

tn

ot

experiments

This preprint research paper has not been peer reviewed. Electronic copy available at: https://ssrn.com/abstract=4683734

d

Measures

pe
er
re
vie
we

Hiring Preference. In Experiment 1, participants were asked to play the role of
a recruiter for a jewelry company, and saw four short text biographies of job

applicants. They rated to what extent they would hire these applicants as lapidaries (1
= unlikely, 10 = certainly). Of the four biographies (see examples in Figure 2), two
were male applicants and the other two were females. We balanced working

experience, passion for the occupation, and the professional degree between the male
and the female applicants in the texts. Finally, we derived the measure of hiring

preference by subtracting the averaged hire scores of males from the averaged hire
scores of females (M = -2.211, SD = 3.111), such that a greater value denotes a
stronger preference for hiring female lapidaries.
Figure 2

Pr

ep

rin

tn

ot

Examples of stimulus used for measuring participants’ hiring preferences

This preprint research paper has not been peer reviewed. Electronic copy available at: https://ssrn.com/abstract=4683734

d

In Experiment 2, participants were asked to choose a rideshare driver in two

pe
er
re
vie
we

different scenarios (i.e., requesting a rideshare to the airport, and to a mall). In each

scenario, participants were given 4 rideshare drivers (a male migrant driver, a female
migrant driver, a male US-born driver, and a female US-born driver). The 4 drivers
were shown as mock Uber profiles with pictures, names, ratings, and years of

experience (also see examples in Figure 2). We balanced their ratings and years of
experience, and manipulated the pictures and names to make the drivers look and
sound like migrants or US-born citizens. For example, the migrant drivers were

named as Vish Makhijani and Aman Yusra Halabi, whereas the US-born drivers were
named as Susan Blandford and Benjamin John. Since a random decision would still
have a 50% chance of choosing a migrant driver, we coded the hiring preference as

favoring migrant drivers only when the participant chose the migrant drivers (coded

ot

as 1, 41.1%, SD = 49.3%) over US-born drivers (coded as 0) in both scenarios.
Relative Warmth and Competence. Following Fiske et al. (2002), we asked the

tn

participants to indicate separately how female and male lapidaries (Experiment 1), or
migrant and US-born rideshare drivers (Experiment 2), are “viewed by the society” in

rin

terms of warmth and competence, using a 5-level scale (1=“Not at all”,
5=“Extremely”). Warmth was measured with three adjectives, “friendly,” “warm,”

ep

“well-intentioned” (Cronbach’s α = 0.78 and 0.81 for female and male lapidaries, and
0.93 and 0.90 for migrant and US-born drivers). Competence was measured with

Pr

“competent,” “confident,” “capable” (Cronbach’s α = 0.81 and 0.80 for female and
male lapidaries, and 0.94 and 0.92 for migrant and US-born drivers). We then derived

This preprint research paper has not been peer reviewed. Electronic copy available at: https://ssrn.com/abstract=4683734

d

a relative warmth score by subtracting the averaged warmth scores of male lapidaries

pe
er
re
vie
we

from the averaged warmth scores of female lapidaries (M = 1.053, SD = 2.356). A
greater score indicates a more positive belief about female lapidaries (i.e., being

warmer) than male lapidaries. Likewise, we calculated the relative competence score

for female lapidaries (M = -1.410, SD = 2.359), the relative warmth score for migrant
drivers (M = -1.829, SD = 3.028), and the relative competence score for migrant
drivers (M = -1.878, SD = 2.886).

Control variables. The demographic variables such as the gender, age and

ethnicity were measured by Prolific. We also asked the participants if they had any
suspicion about the purpose of the task at the end of the study. Such suspicion was

treated as another binary control variable, with M = 0.15 (SD = 0.36) in Experiment 1,
and M = 0.21 (SD = 0.40) in Experiment 2.

ot

Results
H1 stipulates that exposure to biased search engine autosuggestions against

tn

female lapidaries or migrant rideshare drivers will reduce the preference of hiring
them. We first regressed the hiring preference for female lapidary on the binary

rin

manipulation (biased against female = 1, biased against male = 0). The effect of
manipulation was non-significant (B = -0.171, p = 0.666). We then regressed the

ep

hiring preference for migrant rideshare drivers also on the binary manipulation (bias
against migrant = 1, control = 0). The results also showed no significant effects (B =

Pr

0.388, p = 0.269). Thus, H1 was not supported. That said, the non-significant results
do not prevent us from further investigating the moderation and mediation

This preprint research paper has not been peer reviewed. Electronic copy available at: https://ssrn.com/abstract=4683734

pe
er
re
vie
we

significant overall effect as the results for H1 (MacKinnon, 2012).

d

mechanisms, as certain situations of moderation and mediation can yield a non-

H2 stipulates the moderating role of stereotypes over the effect of biased

search engine autosuggestions on hiring preferences towards females and migrants.

We regressed the hiring preference on binary manipulation (biased against female = 1,
biased against male = 0; bias against migrant = 1, control = 0), warmth and
competence perceptions and the interactions between the manipulation and

perceptions. The results were shown in Table 1. We found a significant interaction
effect between biased autosuggestions and relative warmth perceptions on hiring

preferences. This is consistent in both Experiment 1 (favoring female lapidaries, B =
0.492, t = 2.840, p = 0.005) and Experiment 2 (favoring migrants, B = 0.302, z =

2.593, p = 0.009). In contrast, there were no significant interaction effects between

ot

biased autosuggestions and relative competence perceptions on hiring preferences in
both experiments. To further illuminate this interaction effect involving the warmth

tn

perception, we conducted a floodlight analysis. As shown in Figure 3, the patterns of
the relative warmth perception for both females and migrants are consistent with H2:

rin

When a group was stereotypically believed as colder than the opposite group to a
certain degree (i.e., female lapidaries being 1.41-unit colder than male lapidaries, and

ep

migrant drivers being 7.36-unit colder than US-born drivers), the autosuggestions
significantly reduced participants’ preference to hire them (or, increased the hiring

Pr

discrimination against them) versus the other group. At the same time, the analysis
reveals a less expected but logically consistent finding for H2: When the group was

This preprint research paper has not been peer reviewed. Electronic copy available at: https://ssrn.com/abstract=4683734

d

perceived as warmer than the opposite group to a certain degree (i.e., female

pe
er
re
vie
we

lapidaries being 3.99-unit warmer than male lapidaries, and migrant drivers being
0.77-unit warmer than US-born drivers), the biased autosuggestions apparently

triggered a reactance: Participants indicated a greater hiring preference for female
lapidaries or migrant drivers. We will discuss this additional finding later.

Table 1

The moderating effects of warmth and competence stereotypes
Outcome Variable

Moderator

Hiring preference of
females
Hiring preference of
females
Hiring preference of
migrants
Hiring preference of
migrants

warmth

Estimate Std.
Error
0.492
0.173

t/z
value
2.840

p value

0.005**

competence -0.031

0.172

-0.179

0.858

warmth

0.116

2.593

0.009**

0.124

-0.741

0.459

0.302

ot

competence -0.091

tn

* p < .05; ** p < .01; *** p < .001

To test H3, which stipulates that the effect of biased autosuggestions on hiring

rin

preference is mediated by warmth and competence stereotypes, a series of mediation
models were estimated, with bootstrapped confidence intervals (bias adjusted; 1,000

ep

re-samples). Overall, the autosuggestion manipulation had only non-significant
indirect effects on the hiring preference, through warmth (95% CI [-0.184, 0.060] for

Pr

lapidaries, and 95% CI [-0.015, 0.040] for rideshare drivers) and competence (95% CI
[-0.215, 0.040] for lapidaries, and 95% CI [-0.006, 0.040] for drivers). Therefore, H3

This preprint research paper has not been peer reviewed. Electronic copy available at: https://ssrn.com/abstract=4683734

pe
er
re
vie
we

significant positive effect on the relative warmth perception of migrant drivers

d

is not supported. That said, results revealed that the biased autosuggestions had a

compared to the US-born drivers (B = 0. 851, p = 0.031), suggesting that biased
autosuggestion could potentially influence people’s stereotypical beliefs, i.e.,
triggering some reactance of warmth perceptions.

Figure 3

Effect of exposure to biased autosuggestions against females (compared to males) and
migrants (compared to control) on hiring preferences moderated by relative warmth

Pr

ep

rin

tn

ot

and competence perceptions

This preprint research paper has not been peer reviewed. Electronic copy available at: https://ssrn.com/abstract=4683734

pe
er
re
vie
we

Previous studies have found biases in the autosuggestions from multiple

d

Discussion

search engines across different societies. However, little attention has been paid to
explore the effects of biased autosuggestions on users’ behaviors, especially

discriminatory behaviors against disadvantaged social groups. Through two preregistered experiments, we found biased autosuggestions can lead to hiring

discrimination against females and migrants, contingent on the stereotypical warmth
perceptions of these groups.

Our study has several implications. First, our findings demonstrate that biased

search engine autosuggestions can actually lead to discriminatory behaviors. Scholars
have discussed how biased autosuggestions might influence their behaviors (Graham,
2023; Houli et al., 2021), but very little research has empirically investigated the

ot

tangible effects of biased autosuggestions. One recent research found that the
manipulation of search engine suggestions about the unfamiliar political candidates

tn

could change the voting of undecided voters in a foreign election context (Esptein et
al., 2023). Joining this effort, our study also demonstrates the behavioral effects of

rin

biased autosuggestions, particularly in the contexts of prejudice and discrimination,
which are at heart of the many social justice and equity concerns over contemporary

ep

search engines (Noble, 2018; Urman et al., 2022).
Second, this study sheds light on the psychological mechanisms behind the

Pr

behavioral effects of biased autosuggestions, particularly in terms of the role played
by existing stereotypes in people’s minds. We did not find a simple, total effect of our

This preprint research paper has not been peer reviewed. Electronic copy available at: https://ssrn.com/abstract=4683734

d

autosuggestion manipulation on hiring preference, but this is not unexpected:

pe
er
re
vie
we

Previous studies suggest that the short-term effects of biased autosuggestions might
be subtle because the effect is likely contingent on existing stereotypical beliefs

(Miller & Record, 2017). Consistent with the rationale behind our H2, participants

who held negative stereotypes against women and migrants (i.e., perceiving female

lapidaries as much colder than male lapidaries, and migrant rideshare drivers as much
colder than US-born drivers) were more susceptive to the biased autosuggestions,
leading to greater hiring discrimination against these two groups This finding

confirms that the effects of autosuggestions vary for different users (Miller & Record,
2017), and a potential factor is people’s pre-existing stereotypes.

Notably, our findings reveal additional nuances regarding the role of existing
stereotypes. One of them is the primacy of warmth perception in moderating the

ot

behavioral effects of biased autosuggestions, in contrast to the non-significant
moderating effects of competence perception. This is consistent with social cognition

tn

theories. Particularly, social cognition researchers have argued that, when perceiving
others, individuals weigh the perception of warmth heavier than competence (Abele

rin

& Wojciszke, 2007). This is because individuals are predispositioned to avoid harms
and acquire benefits when initiating relationships with strangers (Abele & Wojciszke,

ep

2014; Fiske et al., 2007). Therefore, it is unsurprising to see that our participants only
fell for biased autosuggestions when they held negative stereotypes against women

Pr

and migrants in terms of warmth (i.e., cold).

This preprint research paper has not been peer reviewed. Electronic copy available at: https://ssrn.com/abstract=4683734

d

Another nuance is the discovery of the reactance towards biased

pe
er
re
vie
we

autosuggestions in the presence of positive stereotypes (i.e., relative warmth) about

women and migrants. This discovery resonates with previous findings that people can
exhibit reactance or behave in a manner inconsistent with the biases when explicit

stereotypes are activated (Kray et al., 2001). Existent scholarly discussions on search
engine autosuggestions have mostly focused on how negative stereotypical beliefs
such as prejudice or defamation might be involved in the processing of biased

autosuggestions (Graham, 2023). But at the same time, people could hold positive

stereotypes towards certain social groups (e.g., the Black people are stronger, Baker et
al., 2013). Our findings suggest an additional research avenue that addresses the roles
that positive stereotypes play in users’ interactions with search engine
autosuggestions.

ot

Finally, the mediating roles of stereotypes in terms of warmth and competence
were non-significant between biased autosuggestions and hiring discrimination. This

tn

finding suggests that established stereotypical beliefs may not be easily changed
(Johnston, 1996), especially considering the fleeting exposure of the biased

rin

autosuggestions. That said, we did find some evidence that the warmth perceptions
towards migrants were influenced by the autosuggestions: Some participants reacted

ep

to the biases and reported higher levels of warmth perception (B = 0. 851, p = 0.031,
see Appendix B in Supplementary Materials). Nonetheless, such a change did not

Pr

further influence the hiring preference, suggesting that the change of perception might

This preprint research paper has not been peer reviewed. Electronic copy available at: https://ssrn.com/abstract=4683734

d

be confounded with, or as a side effect of the aforementioned reactance in hiring

pe
er
re
vie
we

preference.
These theoretical implications of our findings can also shed lights on

practices. First, practitioners of search engine autosuggestion features or algorithms
such as engineers should be more mindful and serious about the biased

autosuggestions, given that our study, along with others (Esptein et al., 2023),

confirms that biased autosuggestions can lead to discriminatory behaviors. Second, as
existing stereotypes can moderate the effects of biased autosuggestions, it is not

enough for practitioners only checking the algorithm operation but should also take

into account the stereotypes held by users within and beyond given communities, in
order to alleviate the potential negative influences. Lastly, designers could consider

countering discriminatory effects of biased autosuggestion by making positive beliefs

ot

about disadvantaged groups more salient. Particularly, highlighting the warmth of
disadvantaged populations might be more effective.

tn

Limitations and Future Directions

This study has several limitations that deserve future improvements. First, we

rin

conducted the experiments with a mock Google Image search engine and the measure
of outcome variables were based on imagined scenarios. These could have triggered

ep

suspicion for a small portion of the participants (about 15% in Experiment 1; about
21% in Experiment 2), and also influenced the ecological validity of our findings.

Pr

Future studies should investigate the effects of biased autosuggestions in more
realistic settings, such as utilizing natural experiments or real user data from search

This preprint research paper has not been peer reviewed. Electronic copy available at: https://ssrn.com/abstract=4683734

d

engine companies if possible. Second, the measure of warmth and competence

pe
er
re
vie
we

perceptions is only one approach to investigate stereotypes, and is limited to people’s
explicit, conscious attitudes toward certain social groups. Other approaches to

stereotypes should be utilized to better understand the complexity of stereotypes in

users’ interactions with search engine autosuggestions. For example, future research
could investigate implicit stereotypes by using the implicit association test (IAT,

Greenwald et al., 1998) as well as the linguistic intergroup bias (LIB, Von Hippel et

al., 1997). Third, this study focused on hiring discrimination as an important context

of discrimination for women and migrant workers. Given that hiring discrimination is
a salient issue in the United States, our measurement of hiring discrimination could
have been biased by social desirability perceived by our participants. Although the

randomized experiments should have protected the validity of our findings, the effect

ot

estimates may not be accurate. Future studies could employ other ways to assess
discrimination in different contexts. Finally, our experiments only focused on women

tn

and migrants. Future studies should examine the biased autosuggestions against other

rin

disadvantaged or minority groups.
Conclusion

Biased search engine autosuggestions have been reported and criticized by

ep

many previous studies, and scholars have been concerned of their potential effects on
propagating prejudice and discrimination (Graham, 2023; Miller & Record, 2017).

Pr

Our study empirically demonstrated such discriminatory effects of biased
autosuggestions against women and migrants. We also revealed nuanced roles played

This preprint research paper has not been peer reviewed. Electronic copy available at: https://ssrn.com/abstract=4683734

d

by stereotypes when people encounter biased autosuggestions. We believe the current

pe
er
re
vie
we

study sheds lights on the further directions to understanding the social impacts of
search engine autosuggestions, along with the related technologies (e.g.,

autocompletion, AI driven chatbots or smartspeaker), in building the socio-technical
environments for better societies.

Reference

Abele, A. E., & Wojciszke, B. (2007). Agency and communion from the perspective of self
versus others. Journal of personality and social psychology, 93(5), 751.
https://psycnet.apa.org/doi/10.1037/0022-3514.93.5.751

Abele, A. E., & Wojciszke, B. (2014). Communal and agentic content in social cognition: A
dual perspective model. In Advances in experimental social psychology (Vol. 50, pp.
195-255). Academic Press. https://doi.org/10.1016/B978-0-12-800284-1.00004-7

ot

Anderson, J. R. (2014). Rules of the mind. Psychology Press.
Arendt, F. (2013). Dose-dependent media priming effects of stereotypic newspaper articles

tn

on implicit and explicit stereotypes. Journal of Communication, 63(5), 830-851.
https://doi.org/10.1111/jcom.12056

rin

Augoustinos, M., & Walker, I. (1998). The construction of stereotypes within social
psychology: From social cognition to ideology. Theory & Psychology, 8(5), 629-652.

ep

https://doi.org/10.1177/0959354398085003

Bandura, A. (1969). Social-learning theory of identificatory processes. Handbook of

Pr

socialization theory and research, 213, 262.

This preprint research paper has not been peer reviewed. Electronic copy available at: https://ssrn.com/abstract=4683734

pe
er
re
vie
we

perpetuation of stereotypes via auto-complete search forms. Critical Discourse

d

Baker, P., & Potts, A. (2013). ‘Why do white people have thin lips?’ Google and the

Studies, 10(2), 187–204. https://doi.org/10.1080/17405904.2012.744320

Beer, D. (2009). Power through the algorithm? Participatory web cultures and the
technological unconscious. New media & society, 11(6), 985-1002.
https://doi.org/10.1177/1461444809336551

Berkowitz, L., & Rogers, K. H. (1986). A priming effect analysis of media influences.
Perspectives on media effects, 57, 81.

Bonart, M., Samokhina, A., Heisenberg, G., & Schaer, P. (2019). An investigation of biases

in web search engine query suggestions. Online Information Review, 44(2), 365–381.
https://doi.org/10.1108/OIR-11-2018-0341

Brown Givens, S. M., & Monahan, J. L. (2005). Priming mammies, jezebels, and other

ot

controlling images: An examination of the influence of mediated stereotypes on
perceptions of an African American woman. Media Psychology, 7(1), 87-106.

tn

https://doi.org/10.1207/S1532785XMEP0701_5
Burns, P., & Gimpel, J. G. (2000). Economic insecurity, prejudicial stereotypes, and public

rin

opinion on immigration policy. Political science quarterly, 115(2), 201-225.
https://doi.org/10.2307/2657900

ep

Chonka, P., Diepeveen, S., & Haile, Y. (2023). Algorithmic power and African indigenous
languages: Search engine autocomplete and the global multilingual Internet. Media,

Pr

Culture & Society, 45(2), 246–265. https://doi.org/10.1177/01634437221104705

This preprint research paper has not been peer reviewed. Electronic copy available at: https://ssrn.com/abstract=4683734

d

Cuddy, A. J., Glick, P., & Beninger, A. (2011). The dynamics of warmth and competence

pe
er
re
vie
we

judgments, and their outcomes in organizations. Research in organizational behavior,
31, 73-98. https://doi.org/10.1016/j.riob.2011.10.004

Dijksterhuis, A., Van Knippenberg, A., & Holland, R. W. (2014). Evaluating behavior

priming research: Three observations and a recommendation. Social Cognition,
32(Supplement), 196-208. https://doi.org/10.1521/soco.2014.32.supp.196

Dixon, T. L., & Azocar, C. L. (2007). Priming crime and activating blackness: Understanding
the psychological impact of the overrepresentation of blacks as lawbreakers on
television news. Journal of communication, 57(2), 229-253.
https://doi.org/10.1111/j.1460-2466.2007.00341.x

Eagly, A. H., & Steffen, V. J. (1984). Gender stereotypes stem from the distribution of

women and men into social roles. Journal of personality and social psychology,

ot

46(4), 735. https://psycnet.apa.org/doi/10.1037/0022-3514.46.4.735
Epstein, R., & Robertson, R. E. (2015). The search engine manipulation effect (SEME) and

tn

its possible impact on the outcomes of elections. Proceedings of the National
Academy of Sciences, 112(33). https://doi.org/10.1073/pnas.1419828112

rin

Epstein, R., Aries, S., Grebbien, K., Salcedo, A. M., & Zankich, V. R. (2023). The Search
Suggestion Effect (SSE): How Autocomplete Search Suggestions Can Be Used to

ep

Impact Opinions and Votes. Available at SSRN 4535163.
https://dx.doi.org/10.2139/ssrn.4535163

Pr

Esses, V. M. (2021). Prejudice and discrimination toward immigrants. Annual Review of
Psychology, 72, 503-531. https://doi.org/10.1146/annurev-psych-080520-102803

This preprint research paper has not been peer reviewed. Electronic copy available at: https://ssrn.com/abstract=4683734

pe
er
re
vie
we

concentration on Latino violence. Social science research, 38(3), 717-731.

d

Feldmeyer, B. (2009). Immigration and violence: The offsetting effects of immigrant

https://doi.org/10.1016/j.ssresearch.2009.03.003

Festinger, L. (1954). A theory of social comparison processes. Human relations, 7(2), 117140. https://doi.org/10.1177/001872675400700202

Fiske, S. T., Cuddy, A. J., Glick, P., & Xu, J. (2002). A Model of (Often Mixed) Stereotype
Content: Competence and Warmth Respectively Follow From Perceived Status and
Competition. Journal of Personality and Social Psychology, 82(6), 878-902.

Fiske, S. T., Cuddy, A. J., & Glick, P. (2007). Universal dimensions of social cognition:
Warmth and competence. Trends in cognitive sciences, 11(2), 77-83.
https://doi.org/10.1016/j.tics.2006.11.005

Graham, R. (2023). The ethical dimensions of Google autocomplete. Big Data & Society,

ot

10(1), 205395172311565. https://doi.org/10.1177/20539517231156518
Greenwald, A. G., McGhee, D. E., & Schwartz, J. L. (1998). Measuring individual

tn

differences in implicit cognition: the implicit association test. Journal of personality
and social psychology, 74(6), 1464. https://psycnet.apa.org/doi/10.1037/0022-

rin

3514.74.6.1464

Hazen, T. J., Olteanu, A., Kazai, G., Diaz, F., & Golebiewski, M. (2022). On the Social and

ep

Technical Challenges of Web Search Autosuggestion Moderation. First Monday.

Pr

https://doi.org/10.5210/fm.v27i2.10887

This preprint research paper has not been peer reviewed. Electronic copy available at: https://ssrn.com/abstract=4683734

pe
er
re
vie
we

Coronavirus Conspiracy Theories via Google Autocomplete. Proceedings of the

d

Houli, D., Radford, M. L., & Singh, V. K. (2021). “COVID19 is_”: The Perpetuation of

Association for Information Science and Technology, 58(1), 218-229.

Iyengar, S., & Kinder, D. R. (2010). News that matters: Television and American opinion.
University of Chicago Press.

Johnston, L. (1996). Resisting change: information‐seeking and stereotype change. European
Journal of social psychology, 26(5), 799-825. https://doi.org/10.1002/(SICI)10990992(199609)26:5%3C799::AID-EJSP796%3E3.0.CO;2-O

Kray, L. J., Thompson, L., & Galinsky, A. (2001). Battle of the sexes: gender stereotype
confirmation and reactance in negotiations. Journal of personality and social

psychology, 80(6), 942. https://psycnet.apa.org/doi/10.1037/0022-3514.80.6.942

Lambrecht, A., & Tucker, C. (2019). Algorithmic Bias? An Empirical Study of Apparent

ot

Gender-Based Discrimination in the Display of STEM Career Ads. Management
Science, 65(7), 2966–2981. https://doi.org/10.1287/mnsc.2018.3093

tn

Lee, T. L., & Fiske, S. T. (2006). Not an outgroup, not yet an ingroup: Immigrants in the
stereotype content model. International Journal of Intercultural Relations, 30(6),

rin

751-768. https://doi.org/10.1016/j.ijintrel.2006.06.005
Lin, C., Gao, Y., Ta, N., Li, K., & Fu, H. (2023). Trapped in the search box: An examination

ep

of algorithmic bias in search engine autocomplete predictions. Telematics and
Informatics, 85, 102068. https://doi.org/10.1016/j.tele.2023.102068

Pr

MacKinnon, D. (2012). Introduction to statistical mediation analysis. Routledge.
Mayson, S. G. (n.d.). Assistant Professor of Law University of Georgia School of Law.

This preprint research paper has not been peer reviewed. Electronic copy available at: https://ssrn.com/abstract=4683734

pe
er
re
vie
we

and fairness in machine learning. ACM computing surveys (CSUR), 54(6), 1-35.

d

Mehrabi, N., Morstatter, F., Saxena, N., Lerman, K., & Galstyan, A. (2021). A survey on bias

Miller, B., & Record, I. (2017). Responsible epistemic technologies: A social-

epistemological analysis of autocompleted web search. New Media & Society, 19(12),
1945–1963. https://doi.org/10.1177/1461444816644805

Noble, S. U. (2018). Algorithms of Oppression: How Search Engines Reinforce Racism. In
Algorithms of Oppression. New York University Press.

https://doi.org/10.18574/nyu/9781479833641.001.0001

Oleinik, A. (2022). Relevance in Web search: between content, authority and popularity.

Quality & Quantity, 56(1), 173-194. https://doi.org/10.1007/s11135-021-01125-7
Olteanu, A., Diaz, F., & Kazai, G. (2020). When Are Search Completion Suggestions

Problematic? Proceedings of the ACM on Human-Computer Interaction, 4(CSCW2),

ot

1–25. https://doi.org/10.1145/3415242
Pechmann, C. (2001). A comparison of health communication models: Risk learning versus

tn

stereotype priming. Media Psychology, 3(2), 189-210.
https://doi.org/10.1207/S1532785XMEP0302_04

rin

Power, J. G., Murphy, S. T., & Coover, G. (1996). Priming prejudice: How stereotypes and
counter-stereotypes influence attribution of responsibility and credibility among

ep

ingroups and outgroups. Human communication research, 23(1), 36-58.
https://doi.org/10.1111/j.1468-2958.1996.tb00386.x

Pr

Roskos-Ewoldsen, D. R., Roskos-Ewoldsen, B., & Carpentier, F. R. D. (2002). Media
priming: A synthesis. In Media effects (pp. 107-130). Routledge.

This preprint research paper has not been peer reviewed. Electronic copy available at: https://ssrn.com/abstract=4683734

d

Roy, S., & Ayalon, L. (2020). Age and Gender Stereotypes Reflected in Google’s

pe
er
re
vie
we

“Autocomplete” Function: The Portrayal and Possible Spread of Societal Stereotypes.
The Gerontologist, 60(6), 1020–1028. https://doi.org/10.1093/geront/gnz172

Rudman, L. A., & Phelan, J. E. (2010). The effect of priming gender roles on women’s
implicit gender beliefs and career aspirations. Social psychology, 41(3).
https://doi.org/10.1027/1864-9335/a000027

Srull, T. K., & Wyer, R. S. (1989). Person memory and judgment. Psychological review,
96(1), 58. https://psycnet.apa.org/doi/10.1037/0033-295X.96.1.58
Sullivan, D. (2018). How Google autocomplete works in Search. Google.

https://blog.google/products/search/how-google-autocomplete-works-search/.

Tulving, E. (1983). Elements of episodic memory. New York: Oxford University Press.

Uber. (2023). Diversity, equity, and inclusion. https://www.uber.com/us/en/about/diversity/

ot

Uhlmann, E. L., & Cohen, G. L. (2007). “I think it, therefore it’s true”: Effects of selfperceived objectivity on hiring discrimination. Organizational Behavior and Human

tn

Decision Processes, 104(2), 207-223. https://doi.org/10.1016/j.obhdp.2007.07.001
Urman, A., Makhortykh, M., & Ulloa, R. (2022). Auditing the representation of migrants in

rin

image web search results. Humanities and Social Sciences Communications, 9(1),
130. https://doi.org/10.1057/s41599-022-01144-1

ep

Vlasceanu, M., & Amodio, D. M. (2022). Propagation of societal gender inequality by
internet search algorithms. Proceedings of the National Academy of Sciences,

Pr

119(29), e2204529119. https://doi.org/10.1073/pnas.2204529119

This preprint research paper has not been peer reviewed. Electronic copy available at: https://ssrn.com/abstract=4683734

d

Von Hippel, W., Sekaquaptewa, D., & Vargas, P. (1997). The linguistic intergroup bias as an

pe
er
re
vie
we

implicit indicator of prejudice. Journal of Experimental Social Psychology, 33(5),
490-509. https://doi.org/10.1006/jesp.1997.1332

Weber, R., & Crocker, J. (1983). Cognitive processes in the revision of stereotypic beliefs.
Journal of personality and social psychology, 45(5), 961.
https://psycnet.apa.org/doi/10.1037/0022-3514.45.5.961

Weber, M., Viehmann, C., Ziegele, M., & Schemer, C. (2020). Online hate does not stay

online–how implicit and explicit attitudes mediate the effect of civil negativity and
hate in user comments on prosocial behavior. Computers in human behavior, 104,
106192. https://doi.org/10.1016/j.chb.2019.106192

Wheeler, S. C., & DeMarree, K. G. (2009). Multiple mechanisms of prime‐to‐behavior
effects. Social and Personality Psychology Compass, 3(4), 566-581.

tn

ot

https://doi.org/10.1111/j.1751-9004.2009.00187.x

Appendix

Appendix A. Autosuggestions used in the experiments

rin

Specific autosuggestions are listed below, with (*) indicating items with bias.
Experiment 1: Bias Against Male Lapidaries

female jeweler lacks creativity*

male lapidary association

jeweler magazine

jewelry designers

female lapidary make bad decisions*

male jeweler lacks creativity*

female jeweler bad design*

male jeweler

female lapidary

man jeweler lacks creativity*

female jeweler complains a lot*

male jeweler arrogant*

female lapidary likes to argue*

male jewelry designer plagiarize*

lapidary machines

man lapidary lazy*

Pr

ep

Experiment 1: Bias Against Female Lapidaries

This preprint research paper has not been peer reviewed. Electronic copy available at: https://ssrn.com/abstract=4683734

female jewelry designer arrogant*

men lapidary unskilled*

jeweler association

male lapidary bad design*

female jewelry designer ugly works*

male lapidary bad at communication*

female jeweler

d

jeweler definition

pe
er
re
vie
we

jewelry designers

lapidary association

lapidary skills

male lapidary impatient*

female jeweler terrible attitude*

male jewelry designer copy*

how to be a lapidary

jewelry designer website

woman jewelry designer conceited*
female jeweler bad design*

male jeweler weird*

male lapidary clumsy*

woman jeweler arrogant*

weird male lapidary*

female lapidary impatient*

male jeweler bad design*

female lapidary clumsy*

male jeweler terrible attitude*

women lapidary association

jeweler jobs

jeweler jobs

man jeweler impatient*

woman jewelry designer

jeweler association

jewelry designer names

male lapidary lazy*

jewelry designer website

man lapidary dumb*

woman lapidary unskilled*

lapidary skills

jewelers

jewelers

female jeweler lacks creativity*

male jeweler terrible attitude*

number of lapidaries*

male jewelry designer ugly works*

woman lapidary dumb*

man jewelry designer conceited*

female jeweler weird*

man jewelry designer

female jeweler terrible attitude*
jeweler jobs
female jeweler

tn

female lapidary poor design*

ot

female lapidary can't do anything*

jeweler association
jeweler definition
jeweler jobs

man lapidary performance
male jeweler arrogant*
male jeweler bad design*

female jewelry designer copy*

male jeweler

woman lapidary poor performance*

men lapidary terrible*

jewelry designer salary

how to be a lapidary

jeweler definition

male lapidary careless*

jewelry designer job description

male lapidary

jeweler magazine

men lapidary association

female lapidary lazy*

male jeweler weird*

woman lapidary bad at communication*

male jewelry designer arrogant*

female jeweler weird*

jewelry designer job description

Pr

ep

rin

female jewelry designer plagiarize*

Experiment 2: Bias Against migrant Drivers

Experiment 2: Control

rideshare drivers

uber drivers

This preprint research paper has not been peer reviewed. Electronic copy available at: https://ssrn.com/abstract=4683734

Immigrant uber driver arrogant*

rideshare drivers

Immigrant rideshare driver rude*

lyft drivers’ account

foreign lyft drivers abuse*

uber driver’s license

rideshare driver community

d

lyft drivers

pe
er
re
vie
we

rideshare driver salary

uber driver login account

foreign uber driver charged for murder *
immigrant rideshare driver killer*
Immigrant rideshare driver impolite*
immigrant uber driver offensive*

lyft driver app download

uber driver apk download
rideshare driver login

uber driver requirements

Immigrant lyft driver

lyft driver salary

uber driver salary

uber driver application

rideshare driver requirements

lyft driver support

immigrant uber driver

rideshare driver requirements

illegal immigrant rideshare drivers*
uber driver’s license

lyft driver support phone number
rideshare driver lawyer

uber driver

rideshare driver loans

immigrant uber driver kicks out passenger*
immigrant lyft driver talk dirty*

rideshare driver salary
rideshare driver guess

rideshare driver lawyer

uber driver job description

immigrant lyft driver offensive*

uber driver support

Immigrant lyft driver leave passengers in the highway*

lyft driver login online

immigrant lyft driver killing*

lyft drivers' license

foreign lyft drivers impolite*

rideshare driver insurance

Immigrant lyft driver rude*

rideshare driver community

uber driver requirements

uber driver customer service number
rideshare drivers united

Immigrant uber driver leaves passenger*

uber driver login

immigrant uber driver weird*

lyft drivers united

tn

immigrant rideshare driver racial

ot

Immigrant lyft driver sexual harrassment*

lyft driver meaning

foreign rideshare drivers dangerous *
Immigrant lyft driver racial

Immigrant rideshare driver sexism*

rin

lyft drivers’ account

Immigrant rideshare driver incident
Immigrant rideshare driver talk dirty*
Immigrant lyft driver arrogant*

ep

lyft driver

lyft driver’s license
lyft driver support

foreign uber drivers battle*

Pr

immigrant uber driver killing*
uber driver login
immigrant rideshare driver illegal*

This preprint research paper has not been peer reviewed. Electronic copy available at: https://ssrn.com/abstract=4683734

d

rideshare driver login

pe
er
re
vie
we

foreign lyft driver unsocial*

Appendix B. The Regression model of biased autosuggestion on stereotypes
Independent Variable
Biased autosuggestions
against females
Biased autosuggestions
against females
Biased autosuggestions
against migrants
Biased autosuggestions
against migrants

Dependent
Variable
warmth

Estimate S.E.

p value

0.248

t
value
0.299 0.827

0.409

competence

-0.319

0.287

warmth

0.851

0.299 1.067
0.392 2.168

competence

0.581

0.379 1.531

0.127

0.031*

* p < .05; ** p < .01; *** p < .001

Appendix C. The mediating effects of warmth and competence stereotypes
Mediator

Hiring preference of
females
Hiring preference of
females
Hiring preference of
migrants
Hiring preference of
migrants

warmth

Estimate 95% CI
Lower
-0.035
-0.184

ot

Outcome Variable

95% CI
Upper
0.040

p
value
0.53

-0.215

0.040

0.37

warmth

0.005

-0.015

0.040

0.66

competence 0.010

-0.006

0.040

0.25

rin

tn

competence -0.051

Pr

ep

* p < .05; ** p < .01; *** p < .001

This preprint research paper has not been peer reviewed. Electronic copy available at: https://ssrn.com/abstract=4683734

