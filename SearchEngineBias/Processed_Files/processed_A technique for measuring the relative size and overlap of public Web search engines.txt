estimating
relative
size
overlap
public
web
search
engines
页码
12
technique
measuring
relative
size
overlap
public
web
search
engines
krishna
bharat
andrei
broder
digital
systems
research
center
130
lytton
avenue
palo
alto
ca
94301
u.s.a
bharat@pa.dec.com
broder@pa.dec.com
abstract
search
engines
among
useful
popular
services
web
users
eager
know
compare
one
largest
coverage
indexed
portion
web
many
pages
although
questions
debated
popular
technical
press
objective
evaluation
methodology
proposed
clear
answers
emerged
paper
describe
standardized
statistical
way
measuring
search
engine
coverage
overlap
random
queries
technique
require
privileged
access
database
can
implemented
third-party
evaluators
using
public
query
interfaces
present
results
experiments
showing
size
overlap
estimates
hotbot
altavista
excite
infoseek
percentages
total
joint
coverage
mid
1997
november
1997
method
provide
absolute
values
however
using
data
sources
estimate
november
1997
number
pages
indexed
hotbot
altavista
excite
infoseek
respectively
roughly
77m
100m
32m
17m
joint
total
coverage
160
million
pages
conjecture
size
static
public
web
november
200
million
pages
startling
finding
overlap
small
less
1.4
total
coverage
2.2
million
pages
indexed
four
engines
keywords
search
engines
coverage
web
page
sampling
introduction
search
engine
altavista
excite
hotbot
infoseek
lycos
among
useful
popular
services
web
naturally
subject
intense
scrutiny
popular
press
see
instance
articles
pc
computing
washington
post
within
scientific
community
see
instance
proceedings
asis
96
www6
etc
excellent
bibliography
maintained
traugott
koch
lists
60
publications
subject
search
service
comparisons
comprehensive
web
site
dedicated
search
engine
comparisons
http://www.searchenginewatch.com/
maintained
danny
sullivan
clearly
search
engine
can
index
entire
web
good
discussion
issue
appears
often
debated
topic
much
coverage
provide
typical
questions
one
largest
coverage
cover
pages
differ
ranking
low
overlap
many
pages
many
indexed
questions
scientific
public
interest
objective
direct
evaluation
methodologies
proposed
straightforward
way
get
answers
obtain
list
urls
within
engine
index
compute
sizes
intersections
lists
given
intense
competition
among
commercial
search
services
fact
list
highly
prized
proprietary
information
certainly
will
happen
furthermore
even
services
supply
third
party
list
urls
guarantee
mhtml
file
我的文档
wbia
website
readings
web
20graph
estimating
20the
20
2004
10
estimating
relative
size
overlap
public
web
search
engines
页码
12
represent
legitimate
urls
corresponding
pages
actually
fetched
still
index
published
approaches
estimating
coverage
based
number
hits
certain
queries
reported
services
better
variation
used
melee
indexing
coverage
analysis
mica
based
reported
count
pages
within
particular
domain
mica
uses
refinements
still
ultimately
dependent
accuracy
reported
numbers
unfortunately
self-reported
counts
necessarily
reliable
comparable
even
assuming
deliberate
over-estimation
guarantee
reported
counts
include
duplicate
documents
aliased
urls
documents
longer
existence
furthermore
method
allow
determination
overlap
different
approach
used
example
search
engine
watch
search
engine
ekg
observe
access
logs
selected
sites
determine
much
sites
visited
various
search
engine
robots
guarantee
engine
fetched
page
page
will
eventually
indexed
search
engines
tend
employ
various
filtering
policies
build
effective
index
attempt
resolve
questions
developed
standardized
statistical
way
measuring
search
engine
coverage
overlap
random
queries
technique
require
privileged
access
database
can
implemented
independent
third-party
evaluators
fairly
modest
computational
resources
four
engines
determine
relative
size
relative
size
intersection
within
days
time
spent
waiting
pages
fetched
method
subject
certain
statistical
biases
discuss
since
tend
favour
content-rich
pages
can
viewed
asset
rather
flaw
implemented
measurement
technique
described
paper
two
sets
experiments
involving
10
000
queries
show
mid
1997
approximate
sizes
hotbot
altavista
excite
infoseek
expressed
relative
joint
total
coverage
time
respectively
47
39
32
18
november
1997
48
62
20
17
method
provide
absolute
values
however
using
data
sources
estimate
november
number
pages
indexed
hotbot
altavista
excite
infoseek
respectively
roughly
77
million
100
million
32
million
17
million
joint
total
coverage
160
million
pages
conjecture
size
static
public
web
november
200
million
pages
startling
finding
overlap
small
less
1.4
total
coverage
2.2
million
pages
appeared
indexed
four
engines
next
section
overview
estimation
algorithm
detailed
implementation
described
section
section
discuss
sources
bias
technique
suggest
may
overcome
even
exploited
section
describes
detail
two
sets
experiments
estimate
sizes
overlaps
altavista
excite
hotbot
infoseek
finally
section
presents
conclusions
approach
2.1
overview
scheme
allows
third
party
measure
relative
sizes
overlaps
search
engine
indices
every
pair
engines
e1
e2
can
compute
relative
sizes
ratio
size
e1
size
e2
fraction
e1
database
indexed
e2
expressed
percentage
size
mhtml
file
我的文档
wbia
website
readings
web
20graph
estimating
20the
20
2004
10
estimating
relative
size
overlap
public
web
search
engines
页码
12
e1
generally
can
compute
fraction
e1
database
simultaneously
indexed
e2
e3
scheme
require
privileged
access
engine
database
ability
make
queries
idea
behind
approach
simple
consider
sets
size
12
units
respectively
let
size
intersection
see
fig
let
us
suppose
know
sizes
can
sample
uniformly
set
check
membership
set
sample
uniformly
will
find
samples
well
hence
size
approximately
times
size
intersection
similarly
will
find
size
approximately
times
size
will
lead
us
believe
times
size
fig
computing
size
ratios
overlap
estimates
formally
let
pr
represent
probability
element
belongs
set
let
pr
represent
conditional
probability
element
belongs
sets
given
belongs
pr
size
size
similarly
pr
size
size
therefore
size
size
pr
pr
implement
idea
need
two
procedures
sampling
procedure
picking
pages
uniformly
random
index
particular
engine
checking
procedure
determining
whether
particular
page
indexed
particular
engine
neither
procedure
can
implemented
perfectly
without
privileged
access
search
engine
databases
however
explain
can
construct
good
approximations
use
queries
made
via
public
interfaces
given
procedures
estimate
overlaps
relative
sizes
follows
overlap
estimate
fraction
e1
database
indexed
e2
estimated
fraction
urls
sampled
e1
found
e2
size
comparison
search
engines
e1
e2
ratio
size
e1
size
e2
estimated
fraction
urls
sampled
e2
found
e1
fraction
urls
sampled
e1
found
e2
2.2
alternatives
mhtml
file
我的文档
wbia
website
readings
web
20graph
estimating
20the
20
2004
10
estimating
relative
size
overlap
public
web
search
engines
页码
12
objective
evaluation
must
check
via
public
interface
whether
certain
test
urls
actually
indices
engines
considered
mere
fact
search
engine
encountered
url
looked
page
determinable
site
access
logs
sufficient
hence
checking
procedure
inherently
necessary
every
evaluation
scheme
however
principle
sampling
can
proceed
along
different
lines
instance
way
select
page
web
uniformly
random
choose
large
set
random
pages
page
test
indexed
search
engines
allow
us
estimate
relative
sizes
overlaps
search
engines
consideration
also
sizes
relative
entire
web
unfortunately
choosing
pages
uniformly
random
entire
web
practically
infeasible
require
either
collecting
valid
urls
web
requires
constructing
better
web
crawler
existing
one
use
sampling
methods
explore
entire
web
methods
based
random
walks
studied
theoretically
contexts
see
references
therein
easily
applicable
web
since
web
directed
graph
highly
non-uniform
degrees
many
small
cuts
precious
little
known
graph
structure
web
hence
length
random
walks
required
generate
distribution
close
uniform
may
extremely
large
since
sampling
random
web
directly
easy
use
search
engines
generate
page
samples
tempting
use
one
engine
say
e1
random
source
urls
estimate
sizes
two
search
engines
say
e2
e3
random
page
e1
check
whether
belongs
e2
whether
belongs
e3
given
enough
samples
infer
relative
sizes
e2
e3
however
strategy
work
search
engine
indices
truly
independent
built
random
samples
web
true
practice
two
engines
may
well
started
starting
points
taken
url
submissions
parties
may
use
policy
prioritizing
links
indexing
pages
engine
e1
used
source
positive
correlation
e1
index
e2
index
e2
will
unfairly
appear
bigger
others
hence
employ
strategy
described
section
2.1
implementation
implement
sampling
checking
via
queries
made
public
interface
procedures
make
use
precomputed
lexicon
web
words
associated
frequencies
web
lexicon
derived
analysing
standard
corpus
web
pages
associated
indexing
engine
consideration
process
expected
frequency
words
computed
desirable
corpus
web
based
words
used
internet
parlance
included
frequencies
reflect
pattern
occurrence
web
large
experiments
used
broad
crawl
roughly
300
000
documents
yahoo
hierarchy
build
lexicon
400
000
words
extremely
low
frequency
words
may
typographic
errors
included
lexicon
conjecture
search
engines
must
use
yahoo
one
starting
points
hence
lexicon
fair
whether
indeed
composition
word
distribution
lexicon
reflects
whole
web
unclear
general
choice
particular
lexicon
induces
certain
bias
discuss
instance
lexicon
may
heavily
biased
towards
english
principle
possible
choose
corpus
web
pages
another
language
construct
lexicon
accordingly
addition
can
impose
additional
constraints
restriction
hostname
com
obtain
statistics
particular
section
web
mhtml
file
我的文档
wbia
website
readings
web
20graph
estimating
20the
20
2004
10
estimating
relative
size
overlap
public
web
search
engines
页码
12
3.1
query
based
sampling
generate
random
url
search
engine
firing
random
query
selecting
random
url
result
set
practice
possible
fetch
entire
result
set
search
engines
usually
return
hundred
matches
fact
may
even
compute
remaining
matches
hence
experiments
considered
first
100
results
picked
random
page
among
urls
listed
search
engine
best
100
matches
depend
engine
ranking
strategy
introduces
ranking
bias
estimate
discuss
section
experimented
disjunctive
queries
conjunctive
queries
queries
tend
introduce
query
bias
towards
large
content
rich
pages
see
section
conjunctive
queries
one
can
try
pick
keywords
fewer
100
results
returned
thus
eliminating
ranking
bias
unfortunately
increases
query
bias
disjunctive
queries
made
random
sets
keywords
drawn
lexicon
used
sets
four
reduce
query
ranking
bias
words
need
chosen
frequencies
roughly
since
search
engines
prefer
infrequent
keywords
rank
results
compute
conjunctive
queries
pairs
random
keywords
used
sets
will
often
result
hits
keywords
paired
carefully
return
small
non-empty
set
results
done
follows
list
available
keywords
sorted
frequency
lower
upper
threshold
picked
iteratively
keywords
equidistant
thresholds
tend
give
100
results
conjunctive
query
keywords
contained
thresholds
randomly
sampled
resulting
set
keywords
sorted
frequency
keywords
equidistant
ends
list
paired
form
queries
given
random
query
one
two
schemes
url
obtained
designated
search
engine
selecting
random
result
page
top
100
result
pages
returned
search
engine
query
query
based
sampling
approach
subject
various
biases
pages
tend
higher
probability
selected
sample
gives
higher
weight
eventually
end
estimating
ratio
total
weight
pages
indexed
one
engine
total
weight
pages
indexed
another
however
bias
introduced
seems
reasonable
even
favourable
sense
tend
give
higher
weight
interesting
pages
namely
pages
rich
content
language
choice
discussed
section
3.2
query
based
checking
test
whether
page
given
url
chosen
explained
indexed
particular
search
engine
construct
query
meant
strongly
identify
page
call
query
strong
query
ideally
strong
query
will
uniquely
identify
page
result
page
search
engine
indexed
page
exactly
one
result
namely
url
question
practice
may
multiple
results
several
reasons
page
may
accessible
multiple
aliases
near-identical
versions
page
may
exist
mirrored
copies
page
may
present
sites
cases
page
may
devoid
content
strong
query
matches
page
will
match
many
pages
well
mhtml
file
我的文档
wbia
website
readings
web
20graph
estimating
20the
20
2004
10
estimating
relative
size
overlap
public
web
search
engines
页码
12
explain
cope
problems
strong
query
constructed
follows
page
fetched
web
analyse
contents
compute
conjunctive
query
composed
say
significant
terms
page
significance
taken
inversely
proportional
frequency
lexicon
words
found
lexicon
ignored
since
may
typographical
errors
tend
transient
words
might
discriminative
value
common
words
foreign
language
strong
query
sent
search
engines
turn
results
examined
one
result
urls
matches
query
url
query
url
noted
present
engine
database
matching
three
aspects
normalization
urls
translated
lowercase
optional
filenames
index
htm
home
htm
eliminated
relative
references
form
port
numbers
removed
well
hostnames
translated
ip
addresses
one
urls
involves
ip
address
actual
matching
done
several
ways
depending
strict
matching
requirement
full
url
comparison
case
page
deemed
present
page
normalized
url
returned
search
engine
consideration
high
similarity
case
retrieve
result
pages
compare
turn
page
looking
normalization
urls
necessary
page
similarity
say
95
deem
page
present
compensates
aliasing
mirroring
fast
page
similarity
technique
proposed
can
used
purpose
yet
implemented
approach
weak
url
comparison
case
hostname
comparison
page
deemed
present
page
host
matches
strong
query
compensates
reorganizations
particular
host
risk
overly
generous
non
zero
result
set
case
url
returned
strong
query
considered
match
note
might
turn
url
returned
search
engine
longer
points
version
indexed
source
engine
content
changed
discuss
filtering
dynamic
low-content
pages
pages
detected
none
search
engines
including
source
may
regarded
dynamic
web
pages
filtered
statistics
assumption
contain
changing
content
similarly
pages
actually
little
textual
content
results
ineffective
strong
query
strong
query
returns
large
number
matches
either
source
engine
tested
ignoring
pages
allows
us
focus
content
rich
pages
relatively
static
content
checking
step
introduces
checking
bias
discuss
estimates
weight
favour
pages
content
rich
relatively
static
although
representative
entire
web
reflects
part
web
users
tend
query
hence
meaningful
measure
search
engine
utility
already
explained
query
based
sampling
inherently
biased
towards
pages
rich
text
content
hence
effect
seems
inevitable
regardless
checking
method
used
bias
mhtml
file
我的文档
wbia
website
readings
web
20graph
estimating
20the
20
2004
10
estimating
relative
size
overlap
public
web
search
engines
页码
12
previous
section
identified
several
sources
bias
analyse
discuss
possible
counter-measures
implement
computing
measurements
however
classify
biases
follows
query
bias
accessibility
pages
via
queries
tends
vary
based
number
keywords
document
probability
inclusion
query
large
content
rich
documents
tend
better
chance
matching
query
general
query
bias
determined
choice
lexicon
method
generating
queries
nevertheless
appears
results
obtained
using
disjunctive
queries
fairly
similar
results
obtained
using
conjunctive
queries
see
table
trial
vs
trial
even
though
query
bias
different
conjecture
happens
proportion
pages
certain
probability
query
type
fairly
similar
sets
pages
consideration
words
even
though
pages
picked
uniformly
random
number
pages
index
found
index
proportional
size
intersection
divided
size
ranking
bias
search
engines
introduce
bias
ranking
pages
since
subset
pages
returned
query
served
search
engine
remaining
pages
effectively
sampled
checking
bias
method
use
actual
matching
policy
regard
dynamic
low
content
pages
influence
probability
samples
found
index
tested
experimental
bias
estimating
moving
target
content
particular
search
engine
might
change
experiments
pages
continuously
added
deleted
search
engines
might
also
decide
load
time-off
certain
queries
make
part
index
available
malicious
bias
unlikely
scenario
search
engine
might
rarely
never
serve
pages
engines
thus
completely
sabotaging
approach
statistical
sampling
error
estimating
measurement
finite
sample
certain
probability
sample
average
different
value
estimated
probability
can
easily
computed
standard
statistical
formulas
cases
used
enough
samples
keep
95
confidence
suitably
narrow
error
can
arbitrarily
reduced
using
samples
biases
can
alleviated
usually
trade-offs
remove
ranking
bias
frame
conjunctive
queries
return
less
say
200
documents
although
hard
guarantee
retrieve
documents
clearly
increases
query
bias
removing
query
bias
difficult
one
principle
compute
pincl
probability
inclusion
url
given
process
generating
urls
depends
probability
generation
various
queries
probability
matched
queries
pincl
urls
select
urls
equal
probability
since
case
due
query
bias
can
compensate
selecting
selection
probability
p0
pincl
p0
minimum
value
pincl
web
quantities
hard
estimate
practice
since
cases
selection
probability
will
low
process
will
take
large
number
trials
generate
needed
set
urls
mhtml
file
我的文档
wbia
website
readings
web
20graph
estimating
20the
20
2004
10
estimating
relative
size
overlap
public
web
search
engines
页码
12
privileged
access
search
engine
trivial
generate
random
urls
set
indexed
engine
thus
eliminating
ranking
sampling
bias
show
decrease
overlap
since
one
expect
high-content
pages
favoured
ranking
query
bias
likely
cross-indexed
preliminary
experiments
done
using
privileged
access
altavista
index
confirm
measurements
conducted
two
sets
measurements
first
set
june
july
1997
trials
second
set
november
1997
trials
trials
involved
term
disjunctive
queries
trials
involved
term
conjunctive
queries
cases
approximately
10
000
queries
except
trial
000
trial
queries
divided
among
search
engines
query
went
one
search
engines
random
url
selected
top
100
results
sample
url
check
containment
search
engines
case
examined
first
page
results
10
results
strong
query
potential
matches
search
engine
returned
10
results
test
discarded
since
deemed
strong
query
ineffective
engine
engine
source
urls
test
trials
june
july
1997
trials
november
1997
measured
inferred
overlap
relative
size
urls
size
size
also
measured
inferred
overlap
relative
size
urls
size
size
also
altavista
excite
hotbot
infoseek
ex
17
24
19
1.33
1.05
1.21
16
15
15
3.17
3.31
3.23
hb
37
38
37
0.87
0.77
0.84
39
38
39
1.39
1.17
1.28
17
16
16
2.03
2.25
2.1
12
18
15
4.08
2.77
3.32
hb
29
30
29
0.61
0.75
0.65
36
39
37
0.49
0.46
0.47
11
10
11
1.62
2.38
1.83
14
15
14
1.39
1.26
1.33
av
22
25
23
0.75
0.95
0.82
52
50
51
0.32
0.3
12
12
12
2.77
2.91
2.81
16
13
15
2.63
3.21
2.89
av
32
29
31
1.15
1.3
54
45
50
0.72
0.86
0.78
ex
17
22
19
1.64
1.34
1.53
17
18
17
2.04
2.18
2.11
av
34
36
31
0.49
0.44
0.48
50
50
50
0.24
0.36
0.3
ex
19
23
20
0.61
0.42
0.55
19
19
19
0.72
0.79
0.75
hb
34
37
35
0.36
0.34
0.36
44
44
44
0.38
0.31
0.35
1.2
0.31
table
overlap
size
estimates
static
pages
full
url
comparison
statistics
computed
various
inclusion
criteria
pages
static
pages
matching
criteria
full
url
match
hostname
match
url
considering
static
pages
matching
criterion
determined
many
tests
applicable
since
definition
least
one
search
engine
needed
contain
page
test
applicable
consistently
found
10
pages
sampled
dynamic
another
10
failed
produce
small
result
set
strong
query
hence
80
tests
actually
considered
static
pages
measurements
mhtml
file
我的文档
wbia
website
readings
web
20graph
estimating
20the
20
2004
10
estimating
relative
size
overlap
public
web
search
engines
页码
12
5.1
pairwise
overlap
relative
size
estimates
table
lists
measured
overlaps
computed
size
ratios
search
engines
two
sets
trials
case
also
list
statistics
trials
combined
results
shown
computed
full
url
matching
static
pages
discuss
section
5.2
felt
reliable
measurement
strategy
use
estimates
reflect
state
world
mid
1997
november
1997
search
engines
tend
grow
time
rebuild
indices
hence
neither
scenario
may
representative
current
status
leftmost
column
lists
source
engine
column
lists
engine
tested
containing
list
percentage
random
pages
found
sizes
size
size
compute
ratio
use
random
pages
engine
second
pages
engine
trial
overlap
inferred
ratio
method
explained
section
2.1
variation
trials
set
expected
variation
overlap
value
will
cause
variation
corresponding
size
ratio
cases
overlap
variation
appears
statistically
insignificant
significant
variation
first
set
trials
apparent
increase
excite
coverage
trial
trial
probably
due
different
biases
effect
disjunctive
conjunctive
queries
conjunctive
queries
query
bias
towards
large
content-rich
pages
might
indicate
excite
selectively
indexing
content-rich
pages
point
time
explanation
might
excite
installed
larger
index
interval
trials
15
days
observe
two
mildly
significant
variations
second
set
trials
trials
infoseek
indexed
altavista
pages
accessed
conjunctive
queries
disjunctive
queries
infoseek
altavista
indexed
hotbot
disjunctive
queries
first
variation
might
arise
infoseek
selectively
indexed
content
rich
pages
second
observation
may
due
ranking
bias
hotbot
part
towards
popular
pages
metric
content
length
in-degree
bias
visible
respect
pages
fetched
disjunctive
queries
generally
return
large
sets
general
interplay
ranking
biases
page
indexing
policies
search
engines
potential
produce
isolated
variations
overlap
hard
explain
however
overall
results
seem
fairly
consistent
5.2
comparison
measurement
strategies
considered
three
url
matching
criteria
full
url
comparison
hostname
matching
weak
url
comparison
considering
url
satisfying
strong
query
match
non
zero
result
set
addition
preferred
case
static
pages
also
consider
case
dynamic
pages
included
mentioned
previously
10
pages
observed
dynamic
hence
overlaps
considering
static
pages
alone
10
larger
pages
considered
affect
size
estimates
quite
surprisingly
size
ratios
seemed
unaffected
matching
criterion
well
weakened
url
matching
criterion
overlap
fractions
grew
correspondingly
strong
queries
often
list
large
files
dictionaries
result
set
hence
taking
non-zero
result
set
match
seems
overly
generous
hostname
matching
may
compensate
cases
url
naming
differences
due
aliases
believe
full
url
matching
dependable
scheme
even
though
tends
underestimate
overlap
little
5.3
absolute
estimates
pair-wise
size
estimates
listed
table
approximately
consistent
product
two
size
ratios
will
exactly
equal
corresponding
third
mhtml
file
我的文档
wbia
website
readings
web
20graph
estimating
20the
20
2004
10
estimating
relative
size
overlap
public
web
search
engines
页码
10
12
computed
ratio
values
close
enough
however
rank
engines
size
june
july
1997
observed
size
hotbot
size
altavista
size
excite
size
infoseek
nov
1997
observed
size
altavista
size
hotbot
size
excite
size
infoseek
overlaps
observed
rather
low
startling
finding
less
1.4
total
coverage
indexed
simultaneously
four
engines
reconcile
various
pair-wise
size
ratios
get
full
picture
computed
best
likelihood
estimates
engine
sizes
specifically
computed
estimates
engine
sizes
sum
squared
differences
resulting
estimates
pairwise
overlap
using
experimental
ratios
minimized
using
estimates
sizes
averaged
estimates
intersections
given
experimental
ratios
finally
normalized
data
total
coverage
search
engines
together
equals
100
final
numbers
presented
fig
fig
normalized
estimates
intersections
expressed
percentage
total
joint
coverage
can
see
fig
november
1997
1.4
urls
indexed
search
engines
estimated
common
maximum
coverage
search
engine
altavista
indexed
estimated
62
combined
set
urls
july
1997
hotbot
largest
47
combined
set
urls
four
engine
intersection
0.9
ratios
obtained
seem
consistent
estimates
sizes
search
engines
time
search
engine
watch
reported
following
search
engine
sizes
november
1997
altavista
100
million
pages
hotbot
80
million
excite
55
million
infoseek
30
million
pages
october
14
1997
press
release
altavista
also
states
100
million
page
database
hence
size
altavista
100
million
pages
total
coverage
search
engines
100
million
0.62
roughly
160
million
pages
november
1997
see
fig
similarly
estimate
four-engine
intersection
1.4
leads
us
estimate
roughly
2.25
million
pages
common
search
engines
november
1997
mhtml
file
我的文档
wbia
website
readings
web
20graph
estimating
20the
20
2004
10
estimating
relative
size
overlap
public
web
search
engines
页码
11
12
fig
absolute
size
estimates
november
1997
observe
search
engine
seems
indexed
roughly
constant
fraction
every
search
engine
example
trials
seem
altavista
indexed
50
every
search
engine
infoseek
indexed
15
forth
seems
suggest
indices
constructed
independently
fractions
general
representative
engine
coverage
web
large
assumption
altavista
indexed
50
web
november
1997
static
portion
web
estimated
least
200
million
pages
note
engines
bias
towards
well-connected
content-rich
pages
probability
altavista
indexed
arbitrary
page
web
likely
less
0.5
hence
true
size
static
web
probably
larger
200
million
documents
november
1997
range
estimate
smith
based
crawl
done
alexa
found
80
million
public
pages
january
1997
predicted
annual
doubling
rate
conclusion
paper
describe
first
attempt
measure
coverage
overlap
public
web
search
engines
using
statistically
sound
sampling
technique
estimation
scheme
works
basis
individual
url
containment
thus
can
estimate
intersections
engines
well
measurements
taken
november
1997
provided
size
ratios
consistent
third
party
measurements
reported
press
found
altavista
largest
search
engine
point
time
62
share
combined
set
urls
indexed
four
major
engines
consistent
50
coverage
three
search
engines
based
estimates
altavista
size
approximately
100
million
documents
conjecture
size
static
public
web
november
1997
least
200
million
documents
approach
search
engine
comparison
clear
statistical
objective
basis
although
gives
higher
weight
long
content
rich
pages
language
lexicon
bias
well
understood
principle
computable
every
page
web
thus
method
can
used
interested
party
estimate
coverage
publicly
available
engines
modifying
lexicon
suitably
method
can
biased
towards
estimating
coverage
particular
language
even
broad
topic
exploring
possibility
transferring
technology
third
party
interested
providing
periodic
evaluation
search
engine
coverage
mhtml
file
我的文档
wbia
website
readings
web
20graph
estimating
20the
20
2004
10
estimating
relative
size
overlap
public
web
search
engines
页码
12
12
references
brake
lost
cyberspace
new
scientist
june
28
1997
http://www.newscientist.com/keysites/networld/lost.html
brake
broder
glassman
manasse
zweig
syntactic
clustering
web
proc
6th
international
world
wide
web
conference
april
1997
pp
391
404
http://www6.nttlabs.com/papers/paper205/paper205.html.
sinclair
algorithms
random
generation
counting
markov
chain
approach
birkhauser
1993
smith
truth
web
crawling
towards
eternity
web
techniques
magazine
may
1997
http://www.webtechniques.com/features/1997/05/burner/burner.shtml
urls
literature
search
services
http://www.ub2.lu.se/desire/radar/lit-about-searchservices.html
alexa
http://www.alexa.com/
altavista
http://altavista.digital.com/
hotbot
http://www.hotbot.com/
metacrawler
http://www.metacrawler.com/
yahoo
http://www.yahoo.com/
search
engine
watch
http://searchenginewatch.com/size.htm
excite
size
estimate
http://www.excite.com/ice/size.html
melee
indexing
coverage
analysis
http://www.melee.com/mica/index.html
altavista
press
release
http://www.altavista.digital.com/av/content/pr101497.htm
vitae
krishna
bharat
member
research
staff
digital
equipment
corporation
systems
research
center
current
research
interests
include
web
content
discovery
retrieval
user
interface
issues
automating
tasks
web
speech
interaction
hand-held
devices
received
ph
computer
science
georgia
institute
technology
1996
worked
tool
infrastructure
support
building
distributed
user
interface
applications
andrei
broder
sc
technion
israel
institute
technology
sc
ph
computer
science
stanford
university
member
research
staff
digital
equipment
corporation
systems
research
center
palo
alto
california
main
interests
design
analysis
implementation
probabilistic
algorithms
supporting
data
structures
particular
context
web-scale
applications
mhtml
file
我的文档
wbia
website
readings
web
20graph
estimating
20the
20
2004
10