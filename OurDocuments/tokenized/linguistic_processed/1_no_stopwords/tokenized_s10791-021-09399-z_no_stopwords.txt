information
retrieval
journal
2022
25
26
https://doi.org/10.1007/s10791-021-09399-z
search
results
diversification
effective
fair
ranking
academic
search
graham
mcdonald1
craig
macdonald1
iadh
ounis1
received
25
july
2020
accepted
28
october
2021
published
online
december
2021
author
2021
abstract
providing
users
relevant
search
results
primary
focus
information
retrieval
research
however
focusing
relevance
alone
can
lead
undesirable
side
effects
example
small
differences
relevance
scores
documents
ranked
relevance
alone
can
result
large
differences
exposure
authors
relevant
documents
receive
likelihood
documents
will
seen
searchers
therefore
developing
fair
ranking
techniques
try
ensure
search
results
dominated
example
certain
information
sources
growing
interest
mitigate
biases
work
argue
generating
fair
rankings
can
cast
search
results
diversification
problem
across
number
assumed
fairness
groups
groups
can
represent
demographics
characteristics
information
sources
context
academic
search
trec
fair
ranking
track
aims
fair
unknown
groups
authors
evaluate
three
well-known
search
results
diversification
approaches
literature
generate
rankings
fair
multiple
assumed
fairness
groups
early-career
researchers
vs
highly-experienced
authors
experiments
2019
2020
trec
datasets
show
explicit
search
results
diversification
viable
approach
generating
effective
rankings
fair
information
sources
particular
show
building
xquad
diversification
fairness
component
can
result
significant
0.05
increase
50
experiments
fairness
exposure
authors
unknown
protected
groups
receive
keywords
fair
ranking
search
results
diversification
expected
exposure
academic
search
graham
mcdonald
graham.mcdonald@glasgow.ac.uk
craig
macdonald
craig.macdonald@glasgow.ac.uk
iadh
ounis
iadh.ounis@glasgow.ac.uk
university
glasgow
scotland
uk
13
vol
0123456789
information
retrieval
journal
2022
25
26
introduction
objective
information
retrieval
ir
system
traditionally
seen
maximise
fraction
results
presented
user
relevant
user
query
address
user
information
need
close
top
rank
position
possible
however
many
studies
shown
focusing
relevance
alone
measure
search
success
can
lead
undesirable
side
effects
can
negative
societal
impacts
baeza-yates
2018
epstein
et
al
2017
kay
et
al
2015
mehrotra
et
al
2018
interventions
computational
decision-support
systems
ir
systems
solve
societal
issues
abebe
et
al
2020
however
developing
systematic
interventions
can
support
broader
attempts
understanding
addressing
social
problems
therefore
recent
years
increased
interest
societal
implications
ir
systems
select
present
documents
users
potential
ir
systems
systematically
discriminate
particular
groups
people
pleiss
et
al
2017
ir
systems
machine
learned
models
can
encode
perpetuate
biases
exist
test
collections
use
zehlike
et
al
2017
bender
et
al
2021
moreover
search
engines
used
find
example
jobs
news
can
significant
negative
impact
information
sources
produce
relevant
content
often
unfairly
under-represented
search
results
therefore
imperative
ir
community
focuses
minimising
potentially
negative
human
social
economic
impact
biases
search
systems
culpepper
et
al
2018
particularly
disadvantaged
protected
groups
society
pedreschi
et
al
2008
one
way
mitigate
biases
receiving
increasing
attention
ir
community
develop
fair
ranking
strategies
try
ensure
certain
users
information
sources
discriminated
culpepper
et
al
2018
ekstrand
et
al
2019
olteanu
et
al
2019b
increasing
importance
topic
exemplified
text
retrieval
conference
trec
fair
ranking
track
biega
et
al
2020
defining
fairness
ranking
strategies
agree
singh
joachims
2018
one
definitive
definition
judgement
fairness
context
specific
work
take
view
search
engine
ranking
considered
fair
relevant
information
sources
given
fair
exposure
search
engine
users
following
singh
joachims
2018
consider
fair
exposure
mean
exposure
document
receives
proportional
relevance
document
respect
user
query
context
ir
system
presents
documents
user
ranked
decreasing
order
estimated
relevance
user
query
documents
placed
lower
ranking
will
receive
less
exposure
higher
ranked
documents
reduction
drop-off
exposure
document
position
posj
ranking
gets
can
estimated
user
model
encapsulates
position
bias
exposure
posj
log
pos
commonly
used
discounted
cumulative
gain
dcg
j√§rvelin
kek√§l√§inen
2002
measure
moreover
amount
exposure
document
receives
accumulates
repeated
instances
query
refer
sequence
rankings
therefore
work
definitions
fairness
adopt
disparate
treatment
disparate
impact
fairness
constraints
singh
joachims
2018
disparate
treatment
enforces
exposure
two
fairness
groups
g0
g1
authors
protected
societal
group
proportional
average
relevance
group
documents
defined
13
information
retrieval
journal
2022
25
26
exposure
g0
exposure
g1
g0
g1
doubly
stochastic
matrix
cell
ùêèi
probability
ranking
di
rank
average
utility
relevance
group
gk
calplaces
document
culated
gk
g1
di
gk
ùêÆi
individual
utility
scores
documents
group
gk
disparate
impact
constraint
builds
disparate
treatment
additional
constraint
clickthrough
rates
groups
determined
exposure
relevance
proportional
average
utility
disparate
impact
defined
ctr
g1
ctr
g0
g0
g1
average
clickthrough
rate
group
ctr
g0
defined
ctr
gk
ùêèi
ùêÆi
ùêØj
gk
gk
documents
utility
attention
exposure
drop-off
probability
document
clicked
calculated
using
click
model
richardson
et
al
2007
follows
click
document
examining
relevant
exposure
di
relevant
ùêèi
ùêØj
ùêÆi
experiments
view
disparate
treatment
disparate
impact
constraints
target
exposures
fairness
groups
g0
g1
two
different
fairness
constraints
measure
much
sequence
rankings
violates
constraints
many
approaches
recent
years
tried
ensure
items
documents
represent
particular
societal
groups
gender
ethnicity
receive
fair
exposure
within
single
ranking
however
queries
often
searched
repeatedly
either
user
period
time
multiple
users
static
ranking
produced
instance
query
inequalities
exposure
can
emerge
time
example
consider
fairness
policy
ensures
single
ranking
50
relevant
documents
authors
protected
societal
group
particular
query
highest
ranked
documents
authors
protected
group
although
single
ranking
considered
fair
time
documents
top-ranked
positions
cumulatively
receive
exposure
authors
protected
group
also
produced
relevant
documents
however
also
potential
compensate
under-exposure
documents
previous
rankings
search
engine
introduces
fair
ranking
policy
biega
et
al
2018
scenario
authors
receive
exposure
users
repeated
queries
addressed
context
academic
search
trec
fair
ranking
track
biega
et
al
2020
13
information
retrieval
journal
2022
25
26
fig
example
academic
search
engine
ui
figure
illustrates
10
blue-links
ux
semantic
scholar
search
engine
academic
search
addresses
scenario
search
engine
indexes
scientific
articles
research
papers
books
theses
published
academic
journals
proceedings
scientific
conferences
examples
search
engines
include
semantic
scholar
google
scholar2
cornell
university
search
engine
arxiv
typically
academic
search
engines
adhere
ten-blue-links
ux
presentation
strategy
presenting
user
results
query
fig
provides
illustration
user
interface
semantic
scholar
search
engine
academic
search
scenario
fair
ranking
dominated
single
author
institution
equally
relevant
papers
authors
institutions
moreover
author
institution
receive
disproportionately
high
low
exposure
time
compared
authors
institutions
produce
relevant
papers
example
response
query
information
retrieval
results
top
rank
positions
research
group
since
will
multiple
groups
produced
relevant
papers
moreover
query
repeated
time
different
relevant
information
sources
given
opportunity
appear
higher
ranked
positions
argue
generating
fair
ranking
towards
information
sources
can
cast
search
results
diversification
santos
et
al
2015
task
search
results
diversification
ir
system
aims
maximise
number
sub-topics
aspects
ambiguous
query
represented
within
results
list
postulate
fair
rankings
can
generated
viewing
characteristics
groups
aim
fair
latent
aspects
relevance
maximising
number
groups
represented
within
search
results
https://‚Äãseman‚Äãticsc‚Äãholar.‚Äãorg
https://‚Äãschol‚Äãar.‚Äãgoogle.‚Äãcom
https://‚Äãarxiv.‚Äãorg
13
information
retrieval
journal
2022
25
26
work
evaluate
three
well-known
search
results
diversification
approaches
literature
fair
ranking
strategies
experiments
2019
2020
trec
fair
ranking
track
datasets
show
explicit
search
results
diversification
particularly
effective
generating
rankings
provide
fair
exposure
authors
protected
societal
groups
definition
protected
groups
unknown
particular
show
leveraging
xquad
santos
et
al
2010
search
result
diversification
fair
ranking
strategy
can
result
significant
0.05
increase
50
experiments
fairness
exposure
authors
unknown
protected
groups
receive
exposure
evaluated
multiple
instances
repeated
query
indeed
tailored
xquad
search
result
diversification
model
proposed
assumed
fairness
groups
best
performing
system
submitted
trec
2019
fair
ranking
track
terms
fairness
official
trec
evaluation
groupings
moreover
work
show
diversifying
assumed
fairness
groups
model
topical
contents
documents
particularly
promising
approach
can
result
significantly
increased
group
fairness
relative
relevance
documents
group
compared
ranking
optimised
relevance
remainder
paper
follows
sect
discuss
prior
work
fairness
information
access
systems
introduce
fair
ranking
task
sect
defining
proposed
assumed
fairness
groups
sect
present
propose
cast
fair
ranking
search
result
diversification
task
sect
presenting
experimental
setup
sect
results
sect
concluding
remarks
follow
sect
related
work
section
firstly
discuss
work
related
fairness
classification
systems
search
engines
presenting
prior
work
search
results
diversification
fairness
previous
work
measuring
enforcing
fairness
information
access
systems
focused
fairness
machine
learning
classifiers
classifiers
might
deployed
decision-making
tasks
loan
parole
applications
chouldechova
2017
hardt
et
al
2016
kleinberg
et
al
2016
woodworth
et
al
2017
zafar
et
al
2017
discrimination
amongst
individuals
sections
society
can
serious
implications
discriminated
many
approaches
developing
fair
classifiers
focused
removing
bias
data
classifier
trained
hajian
domingo-ferrer
2013
kamiran
calders
2009
zemel
et
al
2013
external
resources
word
embeddings
bolukbasi
et
al
2016
however
majority
literature
fair
classification
focuses
enforcing
fairness
constraints
classifier
predictions
example
dwork
et
al
2012
calders
verwer
2010
pleiss
et
al
2017
woodworth
et
al
2017
zafar
et
al
2017
two
main
notions
fairness
classifiers
typically
try
integrate
firstly
individual
fairness
dwork
et
al
2012
classifier
probability
confidence
score
comparable
individuals
irrespective
classification
group
truly
belong
example
case
loan
repayment
subjects
individuals
classification
score
0.8
represent
likelihood
repayment
irrespective
actual
class
subject
belongs
second
notion
fairness
commonly
enforced
classification
systems
group
fairness
examples
group
fairness
include
statistical
parity
balancing
positive
negative
class
statistical
parity
calders
verwer
2010
kamiran
13
information
retrieval
journal
2022
25
26
calders
2009
kamishima
et
al
2011
equal
percentages
protected
groups
classified
belonging
positive
class
differently
balancing
positive
negative
class
kleinberg
et
al
2016
average
prediction
score
positive
negative
class
protected
groups
ethical
implications
potential
effects
society
arise
search
engines
recognised
many
years
see
belkin
robertson
1976
variations
queries
issued
different
demographic
groups
can
result
example
differences
satisfaction
levels
older
younger
users
mehrotra
et
al
2017
however
much
less
work
encoding
measuring
fairness
search
engines
compared
classification
systems
castillo
2018
lately
integrating
fairness
ranking
algorithms
received
attention
literature
example
inaugural
facts-ir
workshop
olteanu
et
al
2019a
trec
fair
ranking
track
biega
et
al
2020
indeed
recent
strategic
workshop
information
retrieval
lorne
culpepper
et
al
2018
fairness
search
systems
identified
one
important
emerging
topics
ir
research
four
main
differences
ways
fairness
implemented
evaluated
search
systems
compared
classification
systems
ekstrand
et
al
2019
firstly
evaluating
search
system
requires
user
model
example
usefulness
search
result
can
depend
results
user
previously
looked
moreover
probability
user
will
view
particular
document
will
also
vary
depending
position
document
appears
ranking
far
ranked
list
user
prepared
look
relevant
documents
secondly
search
queries
can
repeated
within
multiple
search
sessions
provides
opportunity
compensate
unfairness
results
previous
instances
query
thirdly
desired
outcome
search
system
relevance
utility
subjective
notion
can
confounded
intentions
system
personalisation
results
fourthly
search
engines
multiple
sets
stakeholders
fairness
concerns
example
information
consumers
users
want
fairness
access
information
whereas
information
producers
want
fair
opportunity
discovered
users
mehrotra
et
al
2018
work
fairness
ranking
systems
investigated
latent
biases
search
engines
white
2013
baeza-yates
2018
de-arteaga
et
al
2019
correcting
biases
learning
rank
scenarios
singh
joachims
2019
yadav
et
al
2019
morik
et
al
2020
however
recently
also
interest
developing
ranking
algorithms
aim
enforce
group
fairness
fairness
constraints
require
ranker
assign
certain
portion
top
rank
positions
members
protected
minority
classes
zehlike
et
al
2017
celis
et
al
2018
singh
joachims
2018
differently
constraint-based
approaches
rely
protected
groups
known
priori
work
propose
cast
fair
ranking
task
protected
groups
unknown
priori
search
results
diversification
task
indeed
gao
shah
2020
recently
showed
diversity
relevance
highly
correlated
statistical
parity
fairness
identifying
appropriate
method
evaluating
fairness
systems
output
ranked
results
developing
area
research
diaz
et
al
2020
early
work
developing
fair
ranking
metrics
focused
directly
applying
fairness
approaches
classification
statistical
parity
yang
stoyanovich
2017
group
fairness
sapiezynski
et
al
2019
biega
et
al
2018
proposed
fairness
evaluation
metric
akin
evaluating
individual
fairness
dwork
et
al
2012
approach
evaluated
position
bias
modelled
premises
attention
searchers
13
information
retrieval
journal
2022
25
26
distributed
fairly
information
producers
receive
attention
users
proportion
relevance
given
search
task
account
fact
single
ranking
can
achieve
individual
fairness
authors
introduced
amortized
fairness
attention
accumulated
series
rankings
work
interested
evaluating
fairness
exposure
authors
protected
groups
likely
receive
ranking
singh
joachims
2018
introduced
disparate
treatment
ratio
dtr
disparate
impact
ratio
dir
metrics
evaluate
scenario
therefore
select
use
metrics
evaluate
proposed
approaches
present
full
details
dtr
dir
sect
search
results
diversification
queries
submitted
web
search
engine
often
short
ambiguous
sp√§rck-jones
et
al
2007
therefore
often
desirable
diversify
search
results
include
relevant
documents
multiple
senses
aspects
query
two
main
families
search
result
diversification
approaches
namely
implicit
explicit
diversification
implicit
diversification
approaches
example
carbonell
goldstein
1998
chen
karger
2006
wang
zhu
2009
radlinski
et
al
2008
assume
documents
similar
content
will
cover
aspects
query
approaches
increase
coverage
aspects
ranking
demoting
lower
ranked
documents
similar
higher-ranked
documents
maximal
marginal
relevance
mmr
carbonell
goldstein
1998
one
first
implicit
diversification
approaches
mmr
aims
increase
amount
novel
information
ranked
list
selecting
documents
dissimilar
documents
already
selected
results
list
work
evaluate
mmr
fair
ranking
strategy
based
implicit
diversification
however
differently
mmr
deployed
search
result
diversification
carbonell
goldstein
1998
instead
evaluate
effectiveness
selecting
documents
information
sources
dissimilar
characteristics
provide
details
build
mmr
sect
5.1
explicit
diversification
approaches
santos
et
al
2010
radlinski
dumais
2006
agrawal
et
al
2009
dang
croft
2012
directly
model
query
aspects
aim
maximise
coverage
aspects
represented
search
results
example
explicit
query
aspect
diversification
santos
et
al
2010
xquad
uses
query
reformulations
represent
possible
information
needs
ambiguous
query
iteratively
generates
ranking
selecting
documents
maximise
novelty
diversity
search
results
dang
croft
dang
croft
2012
proposed
explicit
approach
called
pm-2
based
proportional
representation
intuition
pm-2
aspect
ambiguous
query
number
documents
relating
aspect
included
search
results
proportional
number
documents
relating
aspect
larger
ranked
list
documents
search
results
sampled
example
query
java
10
documents
list
ranked
documents
search
results
sampled
java
island
10
search
results
also
java
island
work
build
xquad
santos
et
al
2010
pm-2
dang
croft
2012
explicit
diversification
approaches
generate
fair
rankings
however
differently
work
santos
et
al
2010
dang
croft
2012
explicitly
diversify
characteristics
assumed
groups
wish
fair
provide
details
leverage
xquad
pm-2
sect
5.2
castillo
2018
argued
search
results
diversification
differs
fair
ranking
former
focuses
utility
searcher
latter
focuses
utility
sources
relevant
information
agree
intuitively
tasks
different
however
work
postulate
fair
rankings
also
provide
utility
search
engine
13
information
retrieval
journal
2022
25
26
table
examples
informational
queries
context
academic
search
queries
topics
trec
2019
fair
ranking
track
real
queries
semantic
scholar
academic
search
engine
roman
chamomile
oil
drones
bystander
effect
positive
psychology
academic
performance
cost
management
theory
users
can
generated
diversifying
set
assumed
groups
aim
fair
maximise
representation
groups
search
results
fair
ranking
task
section
introduce
fair
ranking
task
provide
formal
definition
problem
set
trec
fair
ranking
track
biega
et
al
2020
2021
previously
stated
sect
task
set
within
context
academic
search
response
informational
query
broder
2002
may
multiple
relevant
documents
query
search
system
return
ranked
list
relevant
published
potentially
pre-published
research
papers
table
provides
examples
informational
queries
context
academic
search
queries
presented
table
queries
trec
2019
fair
ranking
track
test
collection
biega
et
al
2020
real
users
queries
query
logs
semantic
scholar
academic
search
engine
search
system
fair
information
producers
generic
topic-based
queries
generated
rankings
dominated
single
author
institution
moreover
author
institution
receive
disproportionately
high
low
amount
exposure
users
period
time
compared
relevant
work
authors
institutions
example
adapting
simplified
example
singh
joachims
2018
consider
ranking
six
documents
judged
relevant
search
engine
users
authors
documents
institution
authors
documents
institution
search
engine
estimated
relevance
scores
documents
institution
0.80
0.79
0.78
estimated
relevance
scores
documents
institution
0.77
0.76
0.75
following
singh
joachims
2018
allow
meaningful
argument
relative
difference
assume
estimated
relevance
scores
probabilities
documents
ranked
accordance
probability
ranking
principle
robertson
1977
according
position
bias
user
model
dcg
measure
exposure
drop-off
document
words
expect
users
position
ranking
exposure
posj
log
pos
start
top
ranking
consider
relevance
document
in-turn
ranking
relevant
document
appears
likely
user
will
stopped
reaching
relevant
document
example
ranking
documents
institution
will
receive
30
less
exposure
documents
institution
however
difference
average
estimated
relevance
documents
institution
institution
just
0.03
words
small
difference
estimated
relevance
can
lead
large
difference
exposure
opportunity
seen
13
information
retrieval
journal
2022
25
26
fig
illustration
exposure
exp
vs
estimated
relevance
est
rel
context
fair
ranking
task
fairness
search
results
evaluated
multiple
instances
repeated
query
users
documents
receive
moreover
ranking
displayed
users
time
query
issued
search
engine
disparity
exposure
will
increase
time
mind
fairness
ranking
systems
evaluated
sequences
queries
biega
et
al
2018
enable
system
address
potential
unfairness
might
present
results
previous
instance
repeated
query
ekstrand
et
al
2019
rankings
relevant
users
fair
information
produces
fair
ranking
task
addresses
scenario
response
repeated
instances
query
fair
ir
system
therefore
output
sequence
ranked
results
balances
trade-off
maximising
relevance
utility
results
user
minimising
unfairness
exposure
information
producers
get
sequence
queries
practice
three
main
approaches
ir
systems
typically
take
balancing
trade-off
namely
optimising
relevance
enforcing
fairness
constraints
zehlike
et
al
2017
celis
et
al
2018
deploying
fairness-focused
regularisation
mehrotra
et
al
2018
jointly
optimising
relevance
fairness
mehrotra
et
al
2018
figure
illustrates
unfair
exposure
documents
example
receive
can
addressed
within
context
fair
ranking
task
illustrated
fig
first
instance
query
returns
documents
ranked
previously
described
however
subsequent
instances
query
system
tries
compensate
unfairness
exposure
reordering
presentation
documents
user
illustration
four
instances
query
submitted
search
engine
average
cumulative
exposure
institutions
equal
hence
exposure
two
institutions
receive
equal
relative
relevances
judged
user
important
note
simplified
example
groups
wish
fair
known
however
fair
ranking
task
protected
groups
unknown
fair
ranking
task
therefore
defined
follows
query
qi
associated
set
candidate
documents
ri
generate
sequence
rankings
si
repeated
instances
query
qi
ri
generated
permutation
ri
th
13
10
information
retrieval
journal
2022
25
26
instance
qi
items
relevant
qi
get
fair
exposure
users
sequence
rankings
si
initial
set
candidate
documents
ri
query
qi
every
instance
qi
however
number
candidate
documents
associated
different
queries
can
vary
defining
fairness
groups
academic
search
fairness
section
provide
details
assumed
fairness
groups
propose
use
generating
fair
rankings
context
academic
search
information
sources
aim
fair
authors
papers
particular
aim
fair
members
sub-groups
unknown
groups
authors
group
defined
certain
demographic
characteristic
example
gender
grouping
include
sub-groups
male
authors
female
authors
potentially
additional
sub-groups
depending
definition
grouping
example
male
authors
female
authors
receive
fair
exposure
ranking
many
characteristics
authors
may
desirable
provide
fair
exposure
example
may
wish
fair
characteristic
experience
ensure
search
results
provide
fair
exposure
sub-groups
early
career
researcher
highly
experienced
professorial
fact
available
options
selecting
characteristics
groups
like
fair
potentially
infinite
moreover
characteristics
document
can
potentially
used
uncover
latent
author
characteristics
example
specific
topics
document
good
indicator
author
main
research
interests
therefore
approach
fairness
based
defining
fairness
groups
identifying
attributes
document
document
authors
publication
venue
topics
characteristics
argue
intuitively
desirable
fair
context
academic
search
note
practice
assumed
fairness
group
definitions
may
may
match
unknown
protected
groups
indeed
akin
official
vs
system
generated
sub-topics
search
result
diversification
santos
et
al
2015
generate
fair
rankings
respect
assumed
fairness
group
paper
ranked
need
list
scores
represent
amount
specific
instance
document
attribute
author
publication
venue
topic
represents
characteristic
wish
fair
experience
case
authors
popularity
exposure
case
publication
venues
aboutness
case
topics
high
low
score
intended
measure
good
bad
paper
indicator
representative
paper
particular
characteristic
assumed
fairness
group
example
considering
topics
score
represents
probability
document
particular
topic
proposed
approaches
present
section
outputs
list
scores
can
directly
used
input
diversification
approaches
present
later
sect
remainder
section
provide
details
define
three
proposed
approaches
generating
assumed
fairness
groupings
evaluating
effectiveness
search
results
diversification
generating
fair
rankings
context
academic
search
13
11
information
retrieval
journal
2022
25
26
4.1
author
experience
first
assumed
fairness
group
propose
aims
provide
fair
exposure
authors
different
stages
careers
early
career
researchers
vs
highly
experienced
researchers
intuitively
approach
aims
reduce
preponderance
individual
authors
top
ranking
given
query
hence
prolific
highly
experienced
authors
overwhelm
authors
ranking
relevant
work
produced
early
career
researchers
receive
fair
exposure
users
defining
fairness
group
need
score
represent
amount
experience
author
many
possible
signals
used
proxies
estimating
amount
experience
author
example
number
dates
author
publications
dates
trends
citations
work
estimate
author
experience
use
total
number
citations
author
collection
calculated
follows
citations
experience
da
document
authored
set
documents
da
author
citations
number
documents
cite
given
document
represented
list
author
experience
scores
one
authors
document
representation
can
used
input
search
results
diversification
approaches
evaluate
approaches
use
author
experience
assumed
fairness
group
diversification
denoted
subscript
sect
approach
group
characteristic
aiming
fair
authors
experience
sub-groups
assumed
fairness
group
gi
ga
early
career
researchers
highly
experienced
professorial
researchers
authors
high
experience
score
likely
senior
researchers
accumulated
citations
time
4.2
journal
exposure
second
assumed
fairness
group
propose
aims
provide
fair
exposure
papers
different
publication
venues
corpus
intuitively
approach
aims
surface
relevant
search
results
publication
venues
may
usually
underrepresented
search
systems
example
within
ir
research
field
search
results
particular
query
may
unfairly
dominated
papers
conference
proceedings
sigir
journals
output
lot
material
sources
smaller
journals
trec
notebooks
may
underrepresented
respect
relevance
utility
user
moreover
also
case
papers
published
well-known
venues
acm
digital
library
likely
unfairly
benefit
rich-get-richer
dynamics
compared
lesser-known
venues
therefore
journal
exposure
strategy
aims
provide
fair
exposure
papers
venues
underrepresented
search
results
approach
group
characteristic
aiming
fair
paper
exposure
publication
venues
given
document
publication
venues
https://‚Äãdl.‚Äãacm.‚Äãorg/
13
12
information
retrieval
journal
2022
25
26
journals
published
journal
coverage
score
coverage
venue
total
number
documents
collection
published
coverage
publication
venue
proposed
journal
exposure
assumed
fairness
group
represented
list
coverage
scores
one
venues
published
list
scores
input
diversification
approaches
evaluate
sub-groups
assumed
fairness
group
gi
ga
aim
fair
low
coverage
high
coverage
publication
venues
approaches
use
journal
exposure
assumed
fairness
group
diversification
denoted
subscript
sect
4.3
topical
grouping
third
final
assumed
fairness
group
propose
aims
provide
fair
exposure
different
authors
publish
papers
research
topics
intuition
grouping
query
results
may
dominated
example
author
primarily
publishes
work
particularly
popular
sub-topic
query
may
problematic
broadly
defined
queries
can
multiple
relevant
sub-topics
per
examples
presented
table
example
query
interactive
information
retrieval
iir
may
case
retrieved
results
dominated
documents
discuss
iir
user
studies
moreover
results
may
dominated
author
particularly
well-known
iir
user
studies
however
sub-topics
iir
also
likely
relevant
example
user
modelling
interaction
simulation
authors
publish
fields
may
under-exposed
expect
diversifying
rankings
topics
discussed
retrieved
documents
will
likely
give
exposure
under-exposed
authors
account
potential
disparity
exposure
different
sub-topics
within
relevant
search
results
build
topic
modelling
approach
generate
topical
groupings
based
textual
content
documents
note
topical
grouping
may
appropriate
approach
specific
narrowly
defined
queries
searcher
looking
papers
cite
however
previously
discussed
sect
majority
queries
trec
fair
ranking
task
query
logs
semantic
scholar
academic
search
engine
broadly-defined
informational
queries
generating
topical
groupings
use
topic
modelling
approach
identify
main
latent
topics
discusses
documents
text
topical
grouping
defined
probability
document
discusses
latent
topic
zi
set
latent
topics
discussed
documents
collection
topic
zi
can
seen
group
characteristic
wish
fair
approach
group
characteristic
aiming
fair
topics
paper
sub-groups
assumed
fairness
group
gi
ga
therefore
topics
discussed
papers
collection
mind
diversifying
topics
document
represented
top
topics
document
score
top
topic
zi
zi
document
score
topics
discussed
trec
fair
ranking
track
test
collection
paper
published
single
venue
therefore
work
one
non-zero
value
list
document
size
list
equal
number
publications
venues
collection
however
practice
often
case
paper
can
available
multiple
venues
example
acm
digital
library
arxiv
proposed
approach
handles
case
without
adaptation
13
13
information
retrieval
journal
2022
25
26
collection
words
document
associated
fixed
number
topics
probability
document
discusses
topics
varies
approaches
use
topical
assumed
fairness
group
diversification
denoted
subscript
sect
casting
fair
ranking
search
results
diversification
previously
discussed
sect
argue
generating
fair
ranking
towards
information
sources
can
cast
search
results
diversification
task
viewing
characteristics
groups
aim
fair
latent
aspects
relevance
maximising
number
groups
represented
within
top
rank
positions
search
results
objective
search
results
diversification
section
present
three
search
results
diversification
approaches
literature
build
propose
adapt
tailor
generate
fair
rankings
section
5.1
presents
implicit
diversification
approach
evaluate
sect
5.2
presents
two
explicit
diversification
approaches
evaluate
5.1
implicit
diversification
fairness
implicit
diversification
approach
fairness
leverage
well-known
maximal
marginal
relevance
carbonell
goldstein
1998
mmr
diversification
approach
iteration
algorithm
mmr
selects
remaining
documents
one
maximal
marginal
relevance
calculated
follows
def
mmr
arg
max
sim1
di
max
sim2
di
dj
di
dj
query
ranking
subset
documents
collection
candidate
documents
respect
relevance
subset
documents
already
selected
set
documents
selected
sim1
metric
measures
relevance
document
query
sim2
metric
measure
similarity
document
previously
selected
documents
leverage
mmr
fairness
component
define
dissimilarity
function
fairsim
two
document
representations
ùêùùê¢
ùêùùê£
output
one
proposed
approaches
presented
sect
follows
ai
aj
ai
aj
fairsim
ùêùùê¢
ùêùùê£
ai
aj
ai
aj
set
attributes
common
ùêùùê¢
ùêùùê£
ai
aj
absolute
difference
scores
particular
attribute
ai
aj
number
attributes
common
ùêùùê¢
ùêùùê£
di
dj
common
attributes
fairsim
ùêùùê¢
ùêùùê£
fairsim
designed
identify
extent
two
documents
represent
similar
fairness
sub-group
assumed
fairness
group
ga
practice
attribute
index
non-zero
value
however
deploying
fairsim
ùêùùê¢
ùêùùê£
author
experience
grouping
assume
index
nonzero
either
ùêùùê¢
ùêùùê£
non-zero
ùêùùê¢
ùêùùê£
13
information
retrieval
journal
2022
25
26
14
example
deploying
topical
groupings
presented
sect
4.3
document
can
discuss
many
topics
user
studies
user
modelling
score
represents
much
document
particular
topic
probability
observing
topic
given
document
di
zi
ùêùùê¢
ùêùùê£
three
common
topics
topic
scores
ùêùùê¢
0.3
0.3
0.3
0.1
fairsim
ùêùùê¢
ùêùùê£
0.3
0.2
0.3
0.2
0.3
0.2
ùêùùê£
0.2
0.2
0.2
however
scores
ùêùùê¢
0.3
0.3
0.3
ùêùùê£
0.1
0.1
0.1
0.2
words
documents
secfairsim
ùêùùê¢
ùêùùê£
0.3
0.1
0.3
0.1
0.3
0.1
ond
example
less
similar
documents
first
example
greater
difference
strongly
related
common
topics
practice
viewed
hybrid
approach
apposed
purely
implicit
diversification
approach
since
instead
calculating
similarity
entire
text
document
original
mmr
formulation
mmr
calculates
documents
similarities
based
characteristic
scores
output
proposed
assumed
fairness
groups
approaches
mmr
generates
fair
rankings
selecting
documents
dissimilar
previously
selected
documents
respect
characteristics
assumed
fairness
groups
5.2
explicit
diversification
fairness
first
explicit
diversification
approach
build
xquad
santos
et
al
2010
xquad
probabilistic
framework
explicit
search
result
diversification
guides
diversification
process
ambiguous
query
set
sub-queries
possible
interpretation
original
query
given
query
initial
ranking
xquad
builds
new
ranking
iteratively
selecting
highest
scored
document
following
probability
mixture
model
ùúÜp
estimated
relevance
document
respect
initial
query
diversity
respect
relevant
subtopic
queries
least
represented
xquad
objective
cover
many
interpretations
queries
search
results
also
ensuring
novelty
generate
fair
rankings
using
xquad
leverage
fact
given
sub-query
qi
qi
calculated
qi
qi
qi
qi
probability
document
relevant
sub-query
qi
qi
provides
measure
novelty
probability
qi
satisfied
documents
already
selected
view
documents
attributes
authors
publication
venues
topics
sub-queries
document
attribute
characteristic
score
measure
attribute
fairness
sub-group
coverage
calculate
relevance
novelty
document
respect
fairness
sub-group
gi
follows
gi
gi
gi
10
gi
probability
document
associated
group
gi
gi
associated
documents
already
gi
probability
selected
gi
obtained
using
gi
gi
directly
observable
13
15
information
retrieval
journal
2022
25
26
words
xquad
iteratively
adds
documents
prioritising
documents
belong
assumed
fairness
sub-groups
relatively
documents
belonging
gi
documents
belong
fairness
sub-groups
many
documents
belonging
partially
constructed
ranking
gi
example
deploying
topical
assumed
fairness
groups
relatively
documents
belong
latent
topic
interaction
simulation
documents
will
prioritised
selection
unless
relatively
many
documents
previously
selected
also
belong
assumed
fairness
group
case
documents
belong
another
less
rare
underrepresented
group
will
prioritised
coverage
assumed
fairness
groups
maximised
top
rank
positions
promoting
documents
belong
underrepresented
groups
now
move
discuss
second
explicit
diversification
approach
build
generating
fair
rankings
namely
pm-2
dang
croft
2012
pm-2
proportional
representation
approach
aims
generate
useful
diversified
ranked
list
search
results
given
size
sampling
documents
larger
list
documents
ranked
respect
relevance
user
query
aim
pm-2
generate
list
search
results
number
documents
relating
query
aspect
ai
included
search
results
proportional
number
documents
relating
aspect
larger
list
documents
search
results
sampled
words
query
java
90
documents
larger
ranked
list
documents
java
island
90
search
results
also
island
pm-2
selects
documents
add
ranking
follows
qa
dj
ai
qa
dj
ai
11
vi
vi
number
documents
discuss
aspect
ai
si
number
qa
2s
rank
positions
assigned
ai
proportional
popularity
ai
larger
list
documents
search
results
sampled
dj
ai
document
fairness
characteristic
score
aspect
ai
ai
aspect
already
selected
generating
fair
rankings
pm-2
view
documents
attributes
query
aspects
ai
view
proportionality
aspect
ai
fraction
documents
whole
document
collection
also
contain
aspect
replace
vi
equation
11
probability
ai
aspect
ai
collection
fraction
documents
collection
contain
ai
words
attributes
assumed
fairness
group
turn
documents
relatively
large
characteristic
score
attribute
also
characteristic
scores
many
attributes
prioritised
selection
ranking
allocated
portion
ranking
proportional
frequency
attribute
entire
collection
filled
documents
contain
ai
consequence
ensures
promotion
documents
contain
group
fairness
attributes
underrepresented
respect
proportionality
collection
experimental
setup
section
present
experimental
setup
evaluating
effectiveness
leveraging
search
results
diversification
generate
fair
rankings
search
results
aim
answer
following
research
questions
13
information
retrieval
journal
2022
25
26
16
table
per-query
statistics
relevant
non-relevant
candidate
documents
2019
2020
trec
fair
ranking
track
evaluation
queries
2019
collection
max
min
2020
collection
mean
std
max
min
mean
std
relevant
20
3.35
1.50
14
3.48
2.43
non-relevant
candidate
documents
25
32
2.48
6.83
3.48
2.73
299
312
10
20.58
24.07
22.66
23.66
rq1
leveraging
search
results
diversification
fairness
component
effective
generating
fair
rankings
rq2
family
search
results
diversification
explicit
vs
implicit
effective
fairness
component
rq3
diversifying
multiple
assumed
fairness
groupings
results
increased
fairness
evaluate
research
questions
test
collections
2019
2020
trec
fair
ranking
tracks
previously
stated
sect
appropriate
evaluate
fairness
ir
system
sequence
possibly
repeating
queries
allow
system
correct
potential
unfairness
results
previous
query
instances
trec
fair
ranking
track
designed
evaluate
scenario
within
context
academic
search
application
2019
2020
fair
ranking
track
test
collections
consist
documents
academic
paper
abstracts
sampled
semantic
scholar
s2
open
corpus
ammar
et
al
2018
allen
institute
artificial
intelligence
along
training
evaluation
queries
collections
constructed
7903
document
abstracts
however
collections
different
set
queries
approaches
evaluate
work
unsupervised
approaches
therefore
use
evaluation
queries
collections
task
setup
re-ranking
task
queries
associated
set
candidate
document
relevance
judgements
fairness
group
ground
truth
labels
number
candidate
documents
re-ranked
varies
per-query
ranging
312
table
provides
statistics
per-query
candidate
documents
evaluation
collections
4040
documents
relevance
judgements
635
evaluation
queries
2019
collection
4693
documents
relevance
judgements
200
evaluation
queries
2020
collection
experiments
evaluate
approaches
100
instances
queries
collections
include
relevance
assessments
two
unknown
evaluation
fairness
groups
groups
known
track
participants
influence
proposed
fairness
approaches
evaluation
fairness
groups
define
sub-groups
system
fair
first
evaluation
group
h-index
paper
authors
evaluation
group
evaluates
system
gives
fair
exposure
papers
authors
low
h-index
sub-group
h-index
15
high
h-index
sub-group
https://‚Äãallen‚Äãai.‚Äãorg/
13
17
information
retrieval
journal
2022
25
26
h-index
15
second
evaluation
group
international
monetary
fund7
imf
economic
development
level
countries
authors
affiliations
sub-groups
group
evaluates
system
gives
fair
exposure
papers
authors
less
developed
countries
developed
countries
h-index
imf
evaluation
groups
paper
can
authors
defined
sub-groups
case
experiments
assign
paper
low
h-index
sub-group
less
developed
country
sub-group
high
h-index
sub-group
developed
country
sub-group
example
case
h-index
fairness
sub-group
paper
three
authors
h-indices
three
authors
20
paper
assigned
low
h-index
fairness
sub-group
ground
truth
since
least
one
authors
h-index
15
noted
biega
et
al
2020
identifying
fairness
groups
generating
ground
truth
evaluation
difficult
task
since
attributes
authors
gender
prestige
readily
available
nevertheless
trec
fair
ranking
track
collections
despite
limitations
currently
public
ir
test
collections
enable
us
evaluate
approaches
emerging
important
culpepper
et
al
2018
topic
ir
index
corpus
use
terrier
org
information
retrieval
ir
platform
v5
macdonald
et
al
2012
ounis
et
al
2006
apply
standard
stopword
removal
porter
stemming
deploy
dph
et
al
2008
parameter
free
document
weighting
model
divergence
randomness
dfr
framework
relevance-oriented
baseline
explicit
fairness
component
deployed
approach
denoted
dph
sect
moreover
use
relevance
scores
dph
baseline
approach
relevance
component
diversification
approaches
evaluate
metrics
report
mean
disparate
treatment
ratio
denoted
dtr
mean
disparate
impact
ratio
denoted
dir
proposed
singh
joachims
2018
dtr
dir
measure
much
sequence
rankings
violates
disparate
treatment
disparate
impact
constraints
introduced
sect
respectively
two
groups
g0
g1
dtr
measures
extent
groups
exposures
proportional
utility
given
query
doubly
stochastic
matrix
estimates
probability
candidate
document
ranked
rank
position
distribution
rankings
maximal
utility
see
singh
joachims
2018
full
details
computed
dtr
defined
dtr
g0
g1
exposure
g0
g0
exposure
g1
g1
12
utility
group
gk
calculated
sum
binary
relevances
documents
di
gk
defined
gk
ui
gk
di
gk
13
following
singh
joachims
2018
estimate
exposure
drop-off
document
position
posj
ranking
using
position
bias
user
model
dcg
j√§rvelin
kek√§l√§inen
2002
exposure
posj
log
pos
https://‚Äãwww.‚Äãimf.‚Äãorg
threshold
imf
economic
development
level
used
separate
countries
less
developed
disclosed
trec
fair
ranking
track
organisers
13
information
retrieval
journal
2022
25
26
18
dir
measures
contribution
group
members
documents
overall
utility
group
defined
dir
g0
g1
ctr
g0
g0
ctr
g1
g1
14
ctr
sum
expected
click-through
rates
documents
group
gk
click-through
rate
document
di
estimated
exposure
di
di
relevant
dtr
dir
value
shows
groups
proportionate
exposure
impact
respectively
within
generated
rankings
values
less
greater
show
amount
one
groups
disadvantaged
rankings
respect
utility
relevance
documents
group
note
number
candidate
documents
associated
query
varies
per-query
basis
therefore
size
ranking
depth
dtr
dir
calculated
also
varies
per-query
test
statistical
significance
use
paired
t-test
query
instances
select
0.05
significance
threshold
apply
bonferroni
correction
dunn
1961
adjust
multiple
comparisons
approaches
perform
significantly
better
next
best
performing
system
assumed
fairness
groups
configuration
individual
metric
dtr
denoted
example
systems
diversify
author
experience
topical
assumed
fairness
groups
together
denoted
subscript
system
compared
next
best
performing
system
pairwise
manner
pm2at
vs
mmrat
specific
metric
dtr
significant
difference
systems
performance
best
performing
system
denoted
approaches
perform
significantly
better
dph
relevance-only
approach
individual
metric
denoted
results
section
report
results
experiments
evaluating
effectiveness
proposed
approaches
primarily
concerned
suitability
search
results
diversification
generating
rankings
provide
fair
exposure
unknown
protected
groups
words
protected
group
receive
exposure
proportional
average
relevance
group
respect
user
query
mind
metrics
report
section
namely
disparate
treatment
ratio
dtr
disparate
impact
ratio
dir
consider
exposure
authors
papers
sub-groups
protected
group
receive
proportion
relevance
utility
papers
important
note
metrics
dtr
dir
protected
group
two
sub-groups
low
h-index
high
h-index
score
1.0
denotes
sub-groups
receive
exposure
proportional
utility
relevance
documents
sub-group
values
less
greater
show
one
sub-groups
disadvantaged
rankings
respect
utility
relevance
documents
sub-group
table
presents
performance
diversification
approaches
fair
rankings
namely
mmr
xquad
pm-2
assumed
fairness
groups
author
experience
denoted
journal
exposure
denoted
topics
denoted
individually
combined
table
presents
proposed
approaches
performance
13
19
information
retrieval
journal
2022
25
26
table
mean
disparate
treatment
ratio
dtr
mean
disparate
impact
ratio
dir
approaches
h-index
imf
evaluation
groups
2019
2020
trec
fair
ranking
track
test
collections
2019
2020
h-index
dtr
imf
h-index
imf
dir
dtr
dir
dtr
dir
dtr
dir
1.99
1.61
0.28
0.44
0.32
1.91
3.76
0.61
4.90
1.99
0.88
0.28
1.43
0.48
0.44
2.04
0.91
1.91
1.10
1.01
0.47
0.45
single
groupings
mmra
5.63
xquada
5.24
pm2a
5.51
mmrj
5.38
xquadj
5.61
2.03
pm2j
5.60
2.05
0.84
0.30
mmrt
5.72
2.02
0.29
xquadt
5.37
2.04
0.91
1.00
5.66
paired
groupings
mmraj
5.34
2.02
0.92
0.29
2.04
0.77
0.29
pm2t
xquadaj
5.20
2.06
2.07
pm2aj
5.51
2.05
mmrat
5.43
2.02
xquadat
5.24
2.06
pm2at
5.49
2.01
mmrjt
5.31
2.05
xquadjt
5.22
2.05
pm2jt
5.52
2.05
5.33
2.05
5.17
2.07
5.51
fairness
component
dph
7.99
random
8.14
groupings
mmrajt
xquadajt
pm2ajt
0.73
0.73
0.80
0.61
0.82
0.29
0.29
0.29
0.32
0.30
0.29
0.32
0.28
0.79
0.29
0.68
0.30
0.74
0.30
0.76
0.29
0.75
0.31
2.05
0.73
0.30
4.05
3.03
1.19
1.39
0.11
0.21
4.77
4.95
1.99
1.99
1.43
5.14
1.95
1.42
5.25
1.96
1.51
5.00
1.95
1.54
4.68
4.48
0.47
0.45
0.45
1.96
1.54
5.00
1.95
1.51
0.45
4.65
1.97
1.19
0.47
4.73
2.00
1.20
0.48
5.13
1.96
1.31
4.81
1.94
1.39
0.47
0.45
4.77
1.99
4.62
1.93
4.61
4.73
1.10
0.49
0.45
1.99
1.16
1.96
1.18
0.47
0.46
5.13
1.96
1.29
0.47
4.63
1.98
1.19
0.47
4.60
2.00
1.13
0.47
5.13
1.96
1.31
0.47
6.83
7.37
3.92
2.91
2.19
1.97
0.18
0.33
1.31
table
show
results
assumed
fairness
groups
author
experience
journal
exposure
topical
groups
also
included
dph
relevance-only
baseline
random
permutation
result
set
candidate
set
documents
returned
relevance
retrieval
model
denoted
random
metric
approaches
significantly
better
next
best
performing
system
assumed
fairness
groups
configuration
pm2at
vs
mmrat
denoted
approaches
perform
significantly
better
relevance-only
dph
approach
denoted
terms
dtr
dir
official
trec
evaluation
groups
namely
h-index
imf
economic
level
denoted
imf
2019
2020
trec
fair
ranking
track
collections
addition
table
shows
results
dph
relevance-only
13
20
information
retrieval
journal
2022
25
26
baseline
random
permutation
result
set
returned
relevance-only
model
denoted
random
firstly
addressing
rq1
interested
whether
leveraging
search
results
diversification
fairness
component
effective
generating
fair
rankings
note
table
proposed
fair
diversification
approaches
result
fairer
exposure
authors
relevant
documents
relevance-only
dph
approach
random
permutation
approach
terms
dtr
dir
evaluation
fairness
groups
h-index
imf
2019
2020
collections
moreover
twelve
twenty
one
approaches
evaluate
result
significantly
fairer
levels
exposure
h-index
evaluation
fairness
grouping
2019
collection
evaluation
groupings
2020
collection
terms
dtr
dir
0.05
denoted
table
diversification
approaches
fairness
evaluate
work
use
dph
approach
estimating
relevance
shows
diversification
approaches
evaluate
leveraging
diversification
integrate
fairness
component
rankings
strategy
indeed
lead
protected
groups
receiving
fairer
exposure
in-line
utility
relevance
therefore
response
rq1
conclude
diversifying
assumed
fairness
groupings
can
indeed
result
fairer
rankings
actual
protected
groups
known
moving
rq2
addresses
families
search
results
diversification
implicit
explicit
effective
deploying
fairness
component
terms
dtr
xquad
explicit
diversification
consistently
results
rankings
fairest
terms
ensuring
protected
group
receives
exposure
proportional
overall
utility
documents
group
observation
true
xquad
deployed
either
2019
2020
collections
evaluated
either
evaluation
fairness
groupings
h-index
imf
2019
collection
xquadj
achieves
5.20
dtr
h-index
evaluation
grouping
xquadt
achieves
perfect
1.00
dtr
imf
evaluation
grouping
2020
collection
xquadt
achieves
4.48
dtr
h-index
evaluation
grouping
xquada
xquadat
achieve
1.10
dtr
imf
evaluation
grouping
note
1.10
dtr
achieved
xquada
xquadat
imf
fairness
grouping
2020
collection
49.7
increase
fairness
exposure
compared
2.19
dtr
dph
relevance-only
approach
deployed
2020
fair
ranking
collection
xquad
approaches
perform
significantly
better
terms
dtr
next
best
performing
diversification
approach
deployed
assumed
fairness
groupings
denoted
table
h-index
evaluation
group
xquadt
achieves
4.48
dtr
pm2t
mmrt
achieve
5.00
dtr
imf
evaluation
group
xquadat
achieves
1.10
dtr
pm2at
achieves
1.31
dtr
moreover
xquada
achieves
1.10
dtr
pm2a
achieves
1.43
dtr
however
note
terms
dtr
differences
diversification
approaches
deployed
assumed
fairness
groupings
significant
approaches
deployed
2019
trec
fair
ranking
track
collection
turning
attention
well
explicit
implicit
diversification
approaches
perform
terms
dir
note
table
approach
consistently
performs
best
evaluation
groups
trec
fair
ranking
note
size
equal
number
candidate
documents
associated
query
varies
per-query
basis
13
information
retrieval
journal
2022
25
26
21
collections
h-index
evaluation
grouping
mmra
pm2a
achieve
best
dir
score
2019
2020
collections
achieving
1.99
dir
1.91
dir
respectively
however
approaches
significantly
better
2.06
dir
2019
1.99
2020
dir
achieved
xquada
imf
evaluation
grouping
2019
collection
xquadaj
xquadat
best
performing
approaches
achieve
0.32
dir
however
perform
significantly
better
mmr
pm2
approaches
terms
dir
moreover
notably
none
fair
diversification
approaches
actually
perform
significantly
better
dph
relevance-only
approach
random
approach
imf
evaluation
grouping
2019
collection
deployed
2020
collection
xquadat
performs
best
terms
dir
imf
evaluation
grouping
0.49
dir
however
xquadat
significantly
better
mmrat
pm2a
terms
dir
imf
evaluation
grouping
2020
collection
findings
provide
evidence
approaches
evaluate
explicit
search
results
diversification
potentially
viable
diversification
approach
developing
fair
ranking
strategies
within
academic
search
context
finding
supported
observation
xquad
explicit
search
results
diversification
consistently
best
performing
approach
terms
dtr
evaluation
fairness
groupings
deployed
either
trec
fair
ranking
track
collections
therefore
response
rq2
conclude
explicit
search
results
diversification
appears
effective
approach
within
academic
search
context
ensuring
protected
groups
receive
fair
exposure
proportional
utility
relevance
users
measured
dtr
however
work
needs
done
identify
effective
diversification
approach
ensuring
members
protected
group
contribute
proportionate
amount
gain
protected
group
overall
exposure
individual
exposure
members
protected
group
measured
dir
lastly
addressing
rq3
conclude
experiments
diversifying
multiple
assumed
fairness
groups
lead
increased
fairness
can
seen
numbers
bold
table
three
four
best
performing
approaches
terms
dtr
diversify
single
assumed
fairness
group
namely
xquadt
imf
evaluation
grouping
2019
collection
h-index
evaluation
grouping
2020
collection
xquada
imf
grouping
2020
collection
moreover
terms
dir
mmra
pm2a
achieve
best
scores
h-index
evaluation
grouping
2019
2020
collection
remaining
best
performing
approaches
namely
xquadaj
xquadat
diversify
two
assumed
fairness
groups
however
none
approaches
perform
best
evaluation
fairness
groupings
trec
collections
diversify
three
assumed
fairness
groups
suggests
work
needed
adequately
integrate
multiple
assumed
fairness
groups
diversification
approach
expect
explicitly
diversifying
across
multiple
dimensions
yigit-sert
et
al
2021
groups
will
improve
however
leave
interesting
area
research
future
work
finally
note
experiments
diversifying
documents
authors
experience
seems
particularly
promising
approach
generating
fair
ranking
strategies
academic
search
five
six
best
performing
diversification
approaches
terms
dtr
dir
diversify
assumed
fairness
group
either
single
group
combination
one
assumed
fairness
group
mmra
xquada
pm2a
xquadaj
xquadat
note
however
approach
calculating
author
experience
first
reasonable
attempt
model
assumed
fairness
grouping
13
22
information
retrieval
journal
2022
25
26
remains
room
improvement
example
possible
lesser
known
researcher
author
highly
cited
paper
resource
paper
will
potentially
skew
system
view
author
experience
moreover
note
experiments
investigate
exposure
groups
receive
single
browsing
model
practice
variations
users
browsing
behaviour
will
potentially
lead
varying
exposures
individual
papers
authors
overall
group
paper
author
belong
furthermore
diversification
approaches
evaluate
work
deterministic
processes
next
logical
step
developing
diversification
approaches
fairness
seem
introduce
non-deterministic
element
proactively
compensate
exposure
protected
groups
however
leave
investigation
interesting
questions
future
work
conclusions
work
proposed
cast
task
generating
rankings
provide
fair
exposure
unknown
protected
groups
authors
search
results
diversification
task
leveraged
three
well-known
search
results
diversification
models
literature
fair
ranking
strategies
moreover
proposed
adapt
search
results
diversification
diversify
search
results
respect
multiple
assumed
fairness
group
definitions
early-career
researchers
vs
highly-experienced
authors
experiments
2019
2020
trec
fair
ranking
track
datasets
showed
leveraging
adequately
tailored
search
results
diversification
can
effective
approach
generating
fair
rankings
within
context
academic
search
moreover
found
explicit
search
results
diversification
performed
better
implicit
diversification
providing
fair
exposure
protected
author
groups
ensuring
group
exposure
in-line
utility
relevance
groups
papers
terms
disparate
treatment
ratio
dtr
xquad
explicit
search
results
diversification
effective
approach
generating
fair
rankings
trec
fair
ranking
track
evaluation
groupings
h-index
imf
approach
deployed
either
2019
2020
collections
work
provided
in-depth
analysis
search
results
diversification
can
effective
approach
addressing
important
topic
ensuring
fairness
exposure
results
search
systems
search
results
diversification
literature
broad
ranging
although
diversification
task
fairness
exposure
potentially
many
interesting
useful
approaches
can
build
similarities
tasks
improve
exposure
disadvantaged
under-represented
societal
groups
within
results
search
engines
summary
work
provided
foundation
future
work
integrating
fairness
ir
systems
in-particular
diversification-based
approaches
can
build
emerging
field
continues
develop
acknowledgements
wish
thank
associate
editor
three
peer
reviewers
thorough
comments
helpful
suggestions
funding
applicable
availability
data
material
datasets
available
trec
fair
ranking
track
nist
usa
assumed
fairness
groups
can
directly
calculated
datasets
code
availability
diversification
approaches
leverage
public
domain
13
information
retrieval
journal
2022
25
26
23
declarations
conflict
interest
none
open
access
article
licensed
creative
commons
attribution
4.0
international
license
permits
use
sharing
adaptation
distribution
reproduction
medium
format
long
give
appropriate
credit
original
author
source
provide
link
creative
commons
licence
indicate
changes
made
images
third
party
material
article
included
article
creative
commons
licence
unless
indicated
otherwise
credit
line
material
material
included
article
creative
commons
licence
intended
use
permitted
statutory
regulation
exceeds
permitted
use
will
need
obtain
permission
directly
copyright
holder
view
copy
licence
visit
http://‚Äãcreat‚Äãiveco‚Äãmmons.‚Äãorg/‚Äãlicen‚Äãses/‚Äãby/4.‚Äã0/.
references
abebe
barocas
kleinberg
levy
raghavan
robinson
2020
roles
computing
social
change
proceedings
fat
conference
fairness
accountability
transparency
barcelona
spain
january
27
30
2020
acm
pp
252
260
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1145/‚Äã
33510
95
33728
71
agrawal
gollapudi
halverson
ieong
2009
diversifying
search
results
proceedings
second
international
conference
web
search
web
data
mining
wsdm
2009
barcelona
spain
february
11
2009
acm
pp
14
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1145/‚Äã14987‚Äã59.‚Äã14987‚Äã66.
ammar
groeneveld
bhagavatula
beltagy
crawford
downey
dunkelberger
elgohary
feldman
ha
kinney
kohlmeier
lo
murray
ooi
peter
power
skjonsberg
wang
wilhelm
yuan
van
zuylen
etzioni
2018
construction
literature
graph
semantic
scholar
proceedings
2018
conference
north
american
chapter
association
computational
linguistics
human
language
technologies
naacl-hlt
2018
new
orleans
louisiana
usa
june
2018
volume
industry
papers
association
computational
linguistics
pp
84
91
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã18653/‚Äãv1/‚Äãn18-‚Äã3011.
baeza-yates
2018
bias
web
communication
acm
61
54
61
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1145/‚Äã
32095
81
belkin
robertson
1976
ethical
implications
theoretical
research
information
science
inthe
asis
annual
meeting
bender
gebru
mcmillan-major
shmitchell
2021
dangers
stochastic
parrots
can
language
models
big
proceedings
facct
21
2021
acm
conference
fairness
accountability
transparency
virtual
event
toronto
canada
march
10
2021
acm
pp
610
623
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1145/‚Äã34421‚Äã88.‚Äã34459‚Äã22.
biega
gummadi
weikum
2018
equity
attention
amortizing
individual
fairness
rankings
proceedings
41st
international
acm
sigir
conference
research
development
information
retrieval
sigir
2018
ann
arbor
mi
usa
july
08
12
2018
acm
pp
405
414
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1145/‚Äã32099‚Äã78.‚Äã32100‚Äã63.
biega
diaz
ekstrand
kohlmeier
2020
overview
trec
2019
fair
ranking
track
corr
arxiv
abs
2003
11650
biega
diaz
ekstrand
feldman
kohlmeier
2021
overview
trec
2020
fair
ranking
track
corr
arxiv
abs
2108
05135
bolukbasi
chang
zou
saligrama
kalai
2016
man
computer
programmer
woman
homemaker
debiasing
word
embeddings
proceedings
advances
neural
information
processing
systems
29
annual
conference
neural
information
processing
systems
2016
december
10
2016
barcelona
spain
pp
4349
4357
broder
2002
taxonomy
web
search
sigir
forum
36
10
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1145/‚Äã
792550
792552
calders
verwer
2010
three
naive
bayes
approaches
discrimination-free
classification
data
mining
knowledge
discovery
21
277
292
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1007/‚Äãs10618-‚Äã010-‚Äã0190-x
carbonell
goldstein
1998
use
mmr
diversity-based
reranking
reordering
documents
producing
summaries
proceedings
21st
annual
international
acm
sigir
conference
research
development
information
retrieval
august
24
28
1998
melbourne
australia
acm
pp
335
336
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1145/‚Äã290941.‚Äã291025.
13
24
information
retrieval
journal
2022
25
26
castillo
2018
fairness
transparency
ranking
sigir
forum
52
64
71
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã
1145
33087
74
33087
83
celis
straszak
vishnoi
2018
ranking
fairness
constraints
proceedings
45th
international
colloquium
automata
languages
programming
icalp
2018
july
13
2018
prague
czech
republic
lipics
vol
107
pp
28
28
15
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã4230/‚Äãlipics.‚Äã
icalp
2018
28
chen
karger
2006
less
probabilistic
models
retrieving
fewer
relevant
documents
proceedings
29th
annual
international
acm
sigir
conference
research
development
information
retrieval
seattle
washington
usa
august
11
2006
acm
pp
429
436
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1145/‚Äã11481‚Äã70.‚Äã11482‚Äã45
chouldechova
2017
fair
prediction
disparate
impact
study
bias
recidivism
prediction
instruments
big
data
153
163
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1089/‚Äãbig.‚Äã2016.‚Äã0047
culpepper
diaz
smucker
2018
research
frontiers
information
retrieval
report
third
strategic
workshop
information
retrieval
lorne
swirl
2018
sigir
forum
52
34
90
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1145/‚Äã32747‚Äã84.‚Äã32747‚Äã88
dang
croft
2012
diversity
proportionality
election-based
approach
search
result
diversification
proceedings
35th
international
acm
sigir
conference
research
development
information
retrieval
sigir
12
portland
usa
august
12
16
2012
acm
pp
65
74
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1145/‚Äã23482‚Äã83.‚Äã23482‚Äã96.
de-arteaga
romanov
wallach
chayes
borgs
chouldechova
geyik
kenthapadi
kalai
2019
bias
bios
case
study
semantic
representation
bias
high-stakes
setting
proceedings
conference
fairness
accountability
transparency
fat
2019
atlanta
ga
usa
january
29
31
2019
acm
pp
120
128
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1145/‚Äã
32875
60
32875
72
diaz
mitra
ekstrand
biega
carterette
2020
evaluating
stochastic
rankings
expected
exposure
proceedings
29th
acm
international
conference
information
knowledge
management
virtual
event
ireland
october
19
23
2020
acm
pp
275
284
https://‚Äãdoi.‚Äã
org
10
1145
33405
31
34119
62
dunn
1961
multiple
comparisons
among
means
journal
american
statistical
association
56
293
52
64
dwork
hardt
pitassi
reingold
zemel
2012
fairness
awareness
proceedings
innovations
theoretical
computer
science
conference
cambridge
ma
usa
january
10
2012
acm
pp
214
226
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1145/‚Äã20902‚Äã36.‚Äã20902‚Äã55.
ekstrand
burke
diaz
2019
fairness
discrimination
retrieval
recommendation
proceedings
42nd
international
acm
sigir
conference
research
development
information
retrieval
sigir
2019
paris
france
july
21
25
2019
acm
pp
1403
1404
https://‚Äã
doi
org
10
1145
33311
84
33313
80
epstein
robertson
lazer
wilson
2017
suppressing
search
engine
manipulation
effect
seme
acm
human-computer
interaction
cscw
42
42
22
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1145/‚Äã
31346
77
gao
shah
2020
toward
creating
fairer
ranking
search
engine
results
information
processing
management
57
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1016/j.‚Äãipm.‚Äã2019.‚Äã102138.
hajian
domingo-ferrer
2013
methodology
direct
indirect
discrimination
prevention
data
mining
ieee
transactions
knowledge
data
engineering
25
1445
1459
https://‚Äãdoi.‚Äã
org
10
1109
tkde
2012
72
hardt
price
srebro
2016
equality
opportunity
supervised
learning
proceedings
neural
information
processing
systems
annual
conference
december
10
2016
barcelona
spain
pp
3315
3323
macdonald
ounis
peng
santos
2008
university
glasgow
trec
2008
experiments
blog
enterprise
relevance
feedback
tracks
terrier
proceedings
seventeenth
text
retrieval
conference
trec
2008
gaithersburg
maryland
usa
november
18
21
2008
nist
special
publication
vol
500
277
http://‚Äãtrec.‚Äãnist.‚Äãgov/‚Äãpubs/‚Äãtrec17/‚Äãpapers/‚Äãuglas‚Äãgow.‚Äãblog.‚Äã
ent
rf
rev
pdf
j√§rvelin
kek√§l√§inen
2002
cumulated
gain-based
evaluation
ir
techniques
acm
transactions
information
systems
20
422
446
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1145/‚Äã582415.‚Äã582418.
kamiran
calders
2009
classifying
without
discriminating
proceedings
2nd
international
conference
computer
control
communication
ieee
pp
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1109/‚Äã
ic4
2009
49091
97
kamishima
akaho
sakuma
2011
fairness-aware
learning
regularization
approach
proceedings
11th
international
conference
data
mining
workshops
vancouver
bc
13
information
retrieval
journal
2022
25
26
25
canada
december
11
2011
ieee
computer
society
pp
643
650
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1109/‚Äãicdmw.‚Äã
2011
83
kay
matuszek
munson
2015
unequal
representation
gender
stereotypes
image
search
results
occupations
proceedings
33rd
annual
acm
conference
human
factors
computing
systems
chi
2015
seoul
republic
korea
april
18
23
2015
acm
pp
3819
3828
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1145/‚Äã27021‚Äã23.‚Äã27025‚Äã20.
kleinberg
mullainathan
raghavan
2016
inherent
trade-offs
fair
determination
risk
scores
corr
arxiv
abs
1609
05807
macdonald
mccreadie
santos
ounis
2012
puppy
maturity
experiences
developing
terrier
proceedings
sigir
2012
workshop
open
source
information
retrieval
osir
sigir
2012
portland
oregon
usa
16th
august
2012
university
otago
dunedin
new
zealand
pp
60
63
mehrotra
anderson
diaz
sharma
wallach
yilmaz
2017
auditing
search
engines
differential
satisfaction
across
demographics
proceedings
26th
international
conference
world
wide
web
companion
perth
australia
april
2017
acm
pp
626
633
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1145/‚Äã30410‚Äã21.‚Äã30541‚Äã97.
mehrotra
mcinerney
bouchard
lalmas
diaz
2018
towards
fair
marketplace
counterfactual
evaluation
trade-off
relevance
fairness
satisfaction
recommendation
systems
proceedings
27th
acm
international
conference
information
knowledge
management
cikm
2018
torino
italy
october
22
26
2018
acm
pp
2243
2251
https://‚Äãdoi.‚Äã
org
10
1145
32692
06
32720
27
morik
singh
hong
joachims
2020
controlling
fairness
bias
dynamic
learningto-rank
proceedings
43rd
international
acm
sigir
conference
research
development
information
retrieval
sigir
2020
virtual
event
china
july
25
30
2020
acm
pp
429
438
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1145/‚Äã33972‚Äã71.‚Äã34011‚Äã00
olteanu
garcia-gathright
de
rijke
ekstrand
2019a
proceedings
facts-ir
corr
arxiv
abs
1907
05755
olteanu
garcia-gathright
de
rijke
ekstrand
roegiest
lipani
et
al
2019
facts-ir
fairness
accountability
confidentiality
transparency
safety
information
retrieval
sigir
forum
53
20
43
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1145/‚Äã34585‚Äã53.‚Äã34585‚Äã56.
ounis
amati
plachouras
macdonald
lioma
2006
terrier
high
performance
scalable
information
retrieval
platform
proceedings
sigir
2006
workshop
open
source
information
retrieval
osir
sigir
2006
seattle
wa
usa
august
2006
pp
18
25
pedreschi
ruggieri
turini
2008
discrimination-aware
data
mining
proceedings
14th
acm
sigkdd
international
conference
knowledge
discovery
data
mining
las
vegas
nevada
usa
august
24
27
2008
acm
pp
560
568
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1145/‚Äã14018‚Äã90.‚Äã14019‚Äã59.
pleiss
raghavan
wu
kleinberg
weinberger
2017
fairness
calibration
proceedings
advances
neural
information
processing
systems
conference
december
2017
long
beach
ca
usa
pp
5680
5689
radlinski
dumais
2006
improving
personalized
web
search
using
result
diversification
proceedings
29th
annual
international
acm
sigir
conference
research
development
information
retrieval
seattle
washington
usa
august
11
2006
acm
pp
691
692
https://‚Äã
doi
org
10
1145
11481
70
11483
20
radlinski
kleinberg
joachims
2008
learning
diverse
rankings
multi-armed
bandits
proceedings
twenty-fifth
international
conference
machine
learning
helsinki
finland
june
2008
acm
acm
international
conference
proceeding
series
vol
307
pp
784
791
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1145/‚Äã13901‚Äã56.‚Äã13902‚Äã55.
richardson
dominowska
ragno
2007
predicting
clicks
estimating
click-through
rate
new
ads
proceedings
16th
international
conference
world
wide
web
www
2007
banff
alberta
canada
may
12
2007
acm
pp
521
530
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1145/‚Äã12425‚Äã72.‚Äã12426‚Äã
43
robertson
1977
probability
ranking
principle
ir
journal
documentation
santos
peng
macdonald
ounis
2010
explicit
search
result
diversification
sub-queries
proceedings
32nd
european
conference
information
retrieval
milton
keynes
uk
march
28
31
2010
proceedings
springer
lecture
notes
computer
science
vol
5993
pp
87
99
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1007/‚Äã978-3-‚Äã642-‚Äã12275-0_‚Äã11.
santos
macdonald
ounis
2015
search
result
diversification
foundations
trends
information
retrieval
90
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1561/‚Äã15000‚Äã00040.
sapiezynski
zeng
robertson
mislove
wilson
2019
quantifying
impact
user
attentionon
fair
group
representation
ranked
lists
companion
2019
world
wide
web
13
26
information
retrieval
journal
2022
25
26
conference
www
2019
san
francisco
ca
usa
may
13
17
2019
acm
pp
553
562
https://‚Äãdoi.‚Äã
org
10
1145
33085
60
33175
95
singh
joachims
2018
fairness
exposure
rankings
proceedings
24th
acm
sigkdd
international
conference
knowledge
discovery
data
mining
kdd
2018
london
uk
august
19
23
2018
acm
pp
2219
2228
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1145/‚Äã32198‚Äã19.‚Äã32200‚Äã88.
singh
joachims
2019
policy
learning
fairness
ranking
corr
arxiv
abs
1902
04056
sp√§rck-jones
robertson
sanderson
2007
ambiguous
requests
implications
retrieval
tests
systems
theories
acm
sigir
forum
41
17
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1145/‚Äã13289‚Äã64.‚Äã13289‚Äã65
wang
zhu
2009
portfolio
theory
information
retrieval
proceedings
32nd
annual
international
acm
sigir
conference
research
development
information
retrieval
sigir
2009
boston
ma
usa
july
19
23
2009
acm
pp
115
122
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1145/‚Äã15719‚Äã41.‚Äã
15719
63
white
2013
beliefs
biases
web
search
proceedings
36th
international
acm
sigir
conference
research
development
information
retrieval
sigir
13
dublin
ireland
july
28
august
01
2013
acm
pp
12
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1145/‚Äã24840‚Äã28.‚Äã24840‚Äã53.
woodworth
gunasekar
ohannessian
srebro
2017
learning
non-discriminatory
predictors
corr
arxiv
abs
1702
06081
yadav
du
joachims
2019
fair
learning-to-rank
implicit
feedback
corr
arxiv
abs
1911
08054
yang
stoyanovich
2017
measuring
fairness
ranked
outputs
proceedings
29th
international
conference
scientific
statistical
database
management
chicago
il
usa
june
27
29
2017
acm
pp
22
22
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1145/‚Äã30855‚Äã04.‚Äã30855‚Äã26.
yigit-sert
altingovde
macdonald
ounis
ulusoy
2021
explicit
diversification
search
results
across
multiple
dimensions
educational
search
journal
association
information
science
technology
72
315
330
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1002/‚Äãasi.‚Äã24403.
zafar
valera
gomez-rodriguez
gummadi
2017
fairness
beyond
disparate
treatment
disparate
impact
learning
classification
without
disparate
mistreatment
proceedings
26th
international
conference
world
wide
web
www
2017
perth
australia
april
2017
acm
pp
1171
1180
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1145/‚Äã30389‚Äã12.‚Äã30526‚Äã60.
zehlike
bonchi
castillo
hajian
megahed
baeza-yates
2017
fa
ir
fair
top-k
ranking
algorithm
proceedings
2017
acm
conference
information
knowledge
management
cikm
2017
singapore
november
06
10
2017
acm
pp
1569
1578
https://‚Äãdoi.‚Äãorg/‚Äã
10
1145
31328
47
31329
38
zemel
wu
swersky
pitassi
dwork
2013
learning
fair
representations
proceedings
30th
international
conference
machine
learning
icml
2013
atlanta
ga
usa
16
21
june
2013
jmlr
org
jmlr
workshop
conference
proceedings
vol
28
pp
325
333
http://‚Äãproce‚Äãedings.‚Äãmlr.‚Äãpress/‚Äãv28/‚Äãzemel‚Äã13.‚Äãhtml.
publisher
note
springer
nature
remains
neutral
regard
jurisdictional
claims
published
maps
institutional
affiliations
13