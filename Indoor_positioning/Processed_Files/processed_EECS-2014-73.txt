improving
user
experiences
indoor
navigation
using
augmented
reality
nahush
bhanage
electrical
engineering
computer
sciences
university
california
berkeley
technical
report
ucb
eecs-2014-73
http://www.eecs.berkeley.edu/pubs/techrpts/2014/eecs-2014-73.html
may
14
2014copyright
2014
author
rights
reserved
permission
make
digital
hard
copies
part
work
personal
classroom
use
granted
without
fee
provided
copies
made
distributed
profit
commercial
advantage
copies
bear
notice
full
citation
first
page
copy
otherwise
republish
post
servers
redistribute
lists
requires
prior
specific
permission
acknowledgement
like
express
sincere
gratitude
appreciation
faculty
advisors
prof
björn
hartmann
dr
don
wroblewski
industrial
advisor
jiajian
chen
qualcomm
research
silicon
valley
ph
student
advisor
ben
zhang
continuous
support
motivation
throughout
project
also
like
thank
colleagues
xuanyu
zhong
chun-yuan
yang
without
project
reality
finally
like
extend
appreciation
test
users
citris
invention
lab
university
california
berkeley
time
constructive
feedback
university
california
berkeley
college
engineering
master
engineering
spring
2014
electrical
engineering
computer
sciences
visual
computing
computer
graphics
improving
user
experiences
indoor
navigation
using
augmented
reality
nahush
narendra
bhanage
masters
project
paper
fulfills
master
engineering
degree
requirement
approved
capstone
project
advisor
signature
__________________________
date
____________
prof
björn
hartmann
electrical
engineering
computer
sciences
faculty
committee
member
signature
__________________________
date
____________
dr
donald
wroblewski
fung
institute
engineering
leadership
pg
1improving
user
experiences
indoor
navigation
using
augmented
reality
nahush
narendra
bhanage
electrical
engineering
computer
sciences
university
california
berkeley
may
2014
pg
2abstract
indoor
positioning
systems
help
localization
objects
spaces
inside
building
global
positioning
system
gps
cellular
network
don
work
effectively
systems
can
much
useful
just
localizing
objects
augmented
relevant
information
user
interface
paper
demonstrates
prototype
one
use
case
indoor
positioning
system
can
made
useful
rendering
relevant
3d
graphics
mobile
display
also
describes
application
development
process
right
target
user
interviews
interactive
high-fidelity
prototype
development
android
localization
achieved
creating
location
api
simulator
using
orientation
sensors
phone
tablet
relevant
graphical
information
determined
based
user
context
selection
rendered
using
opengl
top
live
camera
stream
user
studies
indicated
overlaying
points
interest
camera
view
significantly
enhanced
user
experience
indoor
navigation
localization
can
made
even
robust
help
object
detection
techniques
summarize
strong
untapped
potential
augmented
reality
techniques
context
indoor
navigation
attempted
demonstrate
application
solution
generic
can
easily
configured
used
indoor
space
malls
hospitals
museums
etc
pg
3acknowledgements
like
express
sincere
gratitude
appreciation
faculty
advisors
prof
björn
hartmann
dr
don
wroblewski
industrial
advisor
jiajian
chen
qualcomm
research
silicon
valley
ph
student
advisor
ben
zhang
continuous
support
motivation
throughout
project
also
like
thank
colleagues
xuanyu
zhong
chun-yuan
yang
without
project
reality
finally
like
extend
appreciation
test
users
citris
invention
lab
university
california
berkeley
time
constructive
feedback
pg
4table
contents
introduction
literature
review
2.1
technology
2.2
industry
landscape
11
2.3
sets
us
apart
15
methodology
15
3.1
targeting
specific
user
scenario
16
3.2
developing
mockup
user
interface
16
3.3
developing
interactive
prototype
19
results
user
study
28
conclusion
30
references
32
pg
5list
figures
figure
qualcomm
izat
12
figure
google
indoor
navigation
10
12
figure
place
lab
ui
13
13
figure
place
lab
architecture
12
13
figure
navvis
ui
14
14
figure
infsoft
ui
15
14
figure
balsamiq
ui
apprentice
mode
17
figure
balsamiq
ui
visitor
mode
17
figure
balsamiq
ui
navigation
mode
18
figure
10
balsamiq
ui
calendar
mode
18
figure
11
modules
application
19
figure
12
website
simulated
location
api
20
figure
13
opengl
rendering
pipeline
16
21
figure
14
interactive
prototype
basic
mode
selection
23
figure
15
interactive
prototype
device
selection
world
mode
23
figure
16
interactive
prototype
visitor
mode
24
pg
6figure
17
interactive
prototype
apprentice
mode
25
figure
18
interactive
prototype
device
selection
navigation
mode
25
figure
19
interactive
prototype
navigation
mode
26
figure
20
interactive
prototype
calendar
mode
27
figure
21
interactive
prototype
google
calendar
afinia
27
figure
22
user
study
average
feature
ranks
28
figure
23
user
study
comparison
augmented
lab
documented
instructions
29
figure
24
user
study
reasons
choosing
augmented
lab
29
pg
71
introduction
indoor
positioning
refers
locating
objects
spaces
inside
building
global
positioning
system
gps
work
accurately
indoors
due
signal
attenuation
reflection
caused
roofs
walls
hence
situations
gps
based
location
tracking
produce
useful
results
result
popular
indoor
positioning
systems
work
technologies
wi-fi
bluetooth
radio
beacons
accurate
gps
furthermore
accurate
location
determination
indoor
spaces
numerous
interesting
applications
integrated
augmented
reality
indoor
navigation
systems
started
incorporating
augmented
reality
techniques
visually
help
user
navigating
indoors
user
experience
critical
indoor
navigation
systems
relevant
large
indoor
spaces
malls
museums
airports
etc
displaying
location
2d
map
necessarily
give
good
user
experience
need
clear
visual
indicators
create
appealing
convenient
experience
users
indoor
navigation
systems
maps
can
useful
tracking
location
person
object
whereas
augmented
reality
lot
relevant
information
can
displayed
along
location
information
strong
untapped
potential
augmented
reality
techniques
respect
indoor
navigation
indoor
navigation
systems
can
useful
variety
interesting
applications
apart
localizing
object
user
indoors
instance
british
museum
visitor
orients
phone
towards
particular
painting
relevant
information
history
artist
images
similar
paintings
etc
pops
screen
possible
relative
location
museum
known
pg
8in
paper
demonstrate
augmented
reality
can
enhance
utility
indoor
positioning
systems
literature
review
section
gives
overview
various
technologies
used
indoor
positioning
systems
existing
landscape
key
players
market
followed
methodology
section
describes
targeted
specific
user
scenario
technologies
used
develop
augmented
reality
based
prototype
discuss
user
study
results
results
section
finally
conclusion
section
summarizes
paper
briefly
discusses
possible
future
work
area
literature
review
2.1
technology
section
gives
overview
popular
technologies
used
indoor
positioning
systems
global
positioning
system
gps
wi-fi
bluetooth
infrared
gps
satellite
based
gps
suitable
positioning
outdoors
mentioned
work
well
relatively
closed
environment
due
signal
attenuation
reflections
across
different
indoor
surfaces
reduce
signal
accuracy
bluetooth
bluetooth
wireless
technology
standard
used
exchanging
data
short
distances
uses
radio
waves
range
2.4
2.483
ghz
positioning
algorithm
based
estimating
pg
9the
power
radio
wave
signals
received
device
using
bluetooth
highly
secure
cost
effective
low
power
consumption
however
certain
drawbacks
works
short
distances
hence
large
number
receivers
required
cover
wide
area
runs
device
discovery
procedure
localization
attempt
thereby
increasing
latency
10
30
seconds
localization
systems
based
bluetooth
explained
detail
infrared
infrared
systems
highly
accurate
short-ranged
positioning
solutions
one
commonly
used
positioning
techniques
device
localized
help
unique
ir
signal
emitted
every
ten
seconds
badge
ir
sensors
placed
different
locations
capture
signals
communicate
central
location
management
server
however
systems
high
installation
maintenance
costs
wi-fi
wi-fi
commonly
used
technology
indoor
positioning
wi-fi
access
points
usually
installed
indoor
spaces
access
point
works
medium
range
25
50
meters
ideal
indoor
positioning
device
location
estimated
using
vectorization
tracking
relative
location
access
points
floor
table
shows
comparative
analysis
based
accuracy
coverage
power
consumption
cost
pg
10system
accuracy
coverage
power
cost
consumption
gps
10
good
outdoor
poor
indoor
high
high
bluetooth
indoor
low
high
infrared
indoor
low
medium
wi-fi
building
level
indoor
high
low
table
comparison
commonly
used
technologies
localization
2.2
industry
landscape
extensive
landscape
study
indoor
navigation
domain
sheds
light
existing
products
dominate
market
studied
compared
prominent
indoor
navigation
systems
qualcomm
izat
google
indoor
maps
place
lab
intel
research
navvis
infsoft
qualcomm
indoor
location
technology
qualcomm
indoor
location
technology
izat
chip-based
platform
facilitates
delivery
location-aware
networks
qualcomm
atheros
802
11ac
802
11n
access
point
solutions
include
advanced
wi-fi
based
calculations
localize
devices
indoors
accuracy
meters
access
points
conjunction
server
component
interact
form
cohesive
indoor
positioning
system
figure
shows
different
components
qualcomm
izat
system
pg
11figure
qualcomm
izat
google
indoor
maps
google
indoor
maps
activated
10
000
floor
plans
throughout
world
10
indoor
spaces
include
airports
malls
museums
etc
indoor
navigation
algorithm
based
wi-fi
access
points
mobile
towers
determine
user
location
11
figure
shows
snapshot
google
indoor
navigation
solution
figure
google
indoor
navigation
10
pg
12place
lab
intel
research
place
lab
architecture
developed
research
purposes
consists
three
key
elements
shown
figure
radio
beacons
installed
various
places
indoors
databases
containing
beacon
location
information
clients
estimate
location
data
place
lab
provides
location
based
known
positions
access
points
provided
database
cached
detecting
device
place
lab
entirely
dependent
availability
beacon
locations
without
estimate
anything
current
location
12
figure
shows
place
lab
user
interface
figure
gives
overview
architecture
figure
place
lab
ui
13
figure
place
lab
architecture
12
navvis
navvis
positioning
system
works
large
database
images
indoor
places
generates
3d
model
place
user
needs
take
picture
surroundings
navvis
compares
images
database
compute
user
current
location
orientation
also
smart
enough
analyze
picture
provided
user
changes
pg
13in
indoor
space
update
database
accordingly
14
figure
shows
navvis
user
interface
action
figure
navvis
ui
14
infsoft
infsoft
makes
use
multiple
wireless
technologies
wi-fi
bluetooth
gps
localize
object
indoors
implements
augmented
reality
overlay
device
camera
view
relevant
navigational
information
shown
figure
15
figure
infsoft
ui
15
pg
142.3
sets
us
apart
similar
navvis
infsoft
system
leverages
augmented
reality
render
relevant
information
user
interface
however
unlike
existing
systems
solution
overlays
points
interest
live
camera
stream
based
user
context
navvis
infsoft
just
arrows
rendered
screen
help
user
navigation
application
wide
range
functionalities
based
user
preferences
described
following
sections
provides
rich
user
experience
enhancing
interactivity
virtual
objects
screen
another
differentiator
solution
provides
generic
framework
can
easily
tailored
applied
almost
indoor
space
methodology
decided
develop
android
application
augmented
lab
demonstrate
usefulness
combining
augmented
reality
indoor
positioning
needed
access
existing
indoor
positioning
api
accurately
determine
smartphone
location
2d
map
indoor
space
application
accommodate
indoor
positioning
api
industrial
sponsor
qualcomm
research
silicon
valley
started
working
project
hoping
use
indoor
positioning
platform
izat
however
due
licensing
hurdles
get
access
izat
simulate
indoor
positioning
api
serve
purpose
application
development
process
sub-divided
following
chronological
stages
pg
153.1
targeting
specific
user
scenario
targeted
specific
user
scenario
project
got
access
citris
invention
lab
university
california
berkeley
students
work
3d
printers
laser
cutting
tools
devices
recognize
frequently
used
devices
lab
important
use-cases
relevant
users
conducted
initial
user
interviews
lab
managers
students
lab
visitors
interviews
identified
two
types
potential
users
students
faculty
use
devices
visitors
take
lab
tour
check
different
devices
demo
products
consequently
determined
four
broad
use-cases
learning
use
devices
lab
apprentice
mode
taking
tour
see
cool
demo
products
visitor
mode
navigating
different
devices
room
navigation
mode
checking
devices
currently
used
calendar
mode
3.2
developing
mockup
user
interface
based
feedback
interviewees
designed
low
fidelity
prototype
using
balsamiq
user
interface
generator
helps
build
simple
interfaces
without
writing
code
back
user
tasks
simple
selecting
one
four
modes
based
preference
pointing
phone
tablet
towards
particular
device
lab
application
detects
device
location
relative
user
user
interface
primarily
shows
relevant
graphics
text
overlaid
top
camera
view
overlaid
content
depends
selected
mode
case
apprentice
mode
user
can
go
interactive
step
by-step
guide
explaining
use
particular
device
figure
shows
apprentice
mode
pg
16in
mockup
balsamiq
ui
assuming
phone
pointed
towards
3d
printer
user
switches
visitor
mode
interactive
gallery
pictures
3d
models
finished
products
created
designed
using
lab
devices
rendered
screen
shown
figure
figure
balsamiq
ui
apprentice
mode
figure
balsamiq
ui
visitor
mode
switched
navigation
mode
3d
arrows
text
labeling
devices
view
overlaid
camera
view
shown
figure
finally
calendar
mode
application
graphically
using
3d
arrows
shows
devices
currently
used
scheduled
used
soon
user
can
apply
filters
using
checkboxes
shown
figure
10
pg
17figure
balsamiq
ui
navigation
mode
figure
10
balsamiq
ui
calendar
mode
round
user
testing
mockup
ui
validate
understanding
use
cases
testers
managers
device
users
lab
functionality
perspective
test
users
seemed
excited
application
received
feedback
related
certain
ui
elements
basic
ideas
validated
started
implementing
actual
prototype
android
platform
pg
183.3
developing
interactive
prototype
figure
11
modules
application
figure
11
shows
modules
application
broadly
categorized
three
sections
position
orientation
section
roughly
determines
phone
location
orientation
augmented
reality
section
renders
relevant
graphics
top
camera
view
user
interactivity
section
gels
everything
together
provides
rich
interactive
experience
help
gesture
control
rest
section
discusses
module
detail
link
source
code
https://github.com/axzhong3/arvisionmap)
mentioned
get
access
qualcomm
proprietary
indoor
location
api
created
simulated
location
api
work-around
issue
shown
figure
12
designed
website
http://augmentedrealitymap.appspot.com/)
highlights
particular
location
google
maps
initial
location
point
citris
invention
lab
pg
19university
california
berkeley
can
manually
move
four
directions
different
devices
lab
marked
map
website
maintains
current
coordinates
json
javascript
object
notation
popular
data
interchange
format
meanwhile
application
continuously
every
10
seconds
fetches
coordinates
latitude
longitude
website
using
http
client
android
create
json
object
parses
coordinate
values
website
separate
thread
handles
location
fetching
mechanism
main
ui
thread
can
handle
functionalities
application
figure
12
website
simulated
location
api
pg
20once
phone
location
indoor
space
determined
using
simulated
api
compute
orientation
relative
magnetic
north
using
accelerometer
magnetometer
orientation
sensors
android
provides
easy
api
read
sensor
events
obtain
azimuth
roll
pitch
values
using
location
api
orientation
values
can
determine
device
lab
lies
front
user
phone
tablet
like
augmented
reality
system
base
view
application
camera
view
graphics
text
overlaid
top
initially
used
android
camera
api
interact
camera
hardware
phone
tablet
access
live
image
stream
however
switched
camera
api
provided
opencv
open
source
computer
vision
library
cross
platform
library
deals
real-time
image
processing
envisage
using
object
detection
techniques
future
make
localization
even
robust
hence
decided
work
opencv
camera
api
image
returned
api
forms
lowest
layer
application
used
opengl
es
2.0
render
graphics
android
opengl
graphics
library
render
graphic
3d
shapes
textures
figure
13
16
gives
overview
opengl
rendering
pipeline
implemented
following
rendering
stages
objects
shown
screen
figure
13
opengl
rendering
pipeline
16
pg
21shaders
essentially
programs
define
render
render
vertex
shaders
define
transformations
vertices
2d
3d
shape
also
used
map
custom
textures
3d
objects
fragment
shaders
used
define
color
value
pixel
implemented
custom
vertex
fragment
shaders
render
3d
shapes
shaders
generic
reused
drawing
multiple
objects
dynamically
screen
depending
projection
view
matrices
projection
view
matrices
different
objects
rendered
determined
based
location
information
provided
location
api
orientation
sensor
readings
position
color
attributes
graphical
shapes
determined
drawn
top
live
camera
stream
one
challenge
faced
flexibly
writing
text
top
opengl
layer
opengl
really
easy
method
render
text
screen
solved
problem
using
android
framelayout
stacking
textviews
top
opengl
layer
turn
stacked
camera
view
mentioned
content
goes
camera
view
depends
mode
selected
user
application
launched
default
mode
world
mode
displays
textures
captions
different
devices
lab
locations
devices
object
space
directly
mapped
corresponding
locations
map
figure
12
application
showcases
drop-down
menu
contains
world
mode
navigation
mode
calendar
mode
shown
figure
14
pg
22figure
14
interactive
prototype
basic
mode
selection
enhance
user
interactivity
implemented
mechanism
allows
user
select
device
long
press
corresponding
caption
long
press
handled
using
android
gesture
api
selected
device
determined
approximating
camera
field
view
angle
phone
current
orientation
world
mode
long
press
caption
results
dialog
box
asks
user
select
either
visitor
mode
apprentice
mode
shown
figure
15
figure
15
interactive
prototype
device
selection
world
mode
pg
23the
visitor
mode
particular
device
gallery
3d
graphical
models
products
designed
created
using
device
mode
basically
gives
idea
user
exactly
can
device
graphical
models
rendered
using
opengl
shaders
described
user
can
rotate
model
view
different
angles
well
pinch-zoom
user
interactivity
implemented
using
android
gesture
touch
apis
figure
16
shows
t-rex
model
created
using
afinia
3d
printer
figure
16
interactive
prototype
visitor
mode
apprentice
mode
implemented
using
android
viewpager
viewpager
basically
group
swipe-able
pages
mode
instruction
how-to-use
guide
displayed
viewpager
page
figure
17
shows
one
instructions
laser
cutting
tool
pg
24figure
17
interactive
prototype
apprentice
mode
user
can
select
navigation
mode
main
drop-down
menu
figure
14
get
graphical
navigational
information
screen
required
device
can
selected
using
another
drop-down
menu
appears
specifically
mode
shown
figure
18
figure
18
interactive
prototype
device
selection
navigation
mode
pg
25once
user
selects
device
looking
flat
graphical
arrow
points
towards
selected
device
rendered
screen
arrow
rendered
using
opengl
vertex
fragment
shaders
figure
19
shows
navigation
mode
afinia
3d
printer
figure
19
interactive
prototype
navigation
mode
finally
user
can
select
calendar
mode
main
drop-down
menu
check
current
availability
google
calendar
particular
device
can
see
figure
20
user
can
select
one
three
checkboxes
see
devices
currently
available
occupied
scheduled
used
soon
devices
marked
3d
arrows
rendered
using
opengl
shaders
different
colors
depending
status
user
can
also
long
press
caption
device
see
google
calendar
book
slot
accordingly
pg
26been
implemented
using
android
webview
facilitates
opening
urls
application
shown
figure
21
figure
20
interactive
prototype
calendar
mode
figure
21
interactive
prototype
google
calendar
afinia
pg
274
results
user
study
conducted
another
user
study
time
interactive
prototype
ten
users
citris
invention
lab
uc
berkeley
randomly
selected
study
conducted
afinia
3d
printer
lab
sample
set
consisted
lab
administrators
undergraduate
graduate
students
experience
working
afinia
asked
try
different
functionalities
application
answer
questions
related
usability
highlights
follows
test
users
asked
rank
different
functionalities
based
practicality
usefulness
apprentice
calendar
modes
turned
popular
features
figure
22
shows
average
ranking
feature
highest
rank
average
feature
ranking
3.5
2.8
2.4
2.5
2.2
1.8
1.5
0.5
interactivity
device
gallery
3d
flowchart
device
status
access
google
explore
details
navigation
models
apprentice
lookup
calendars
world
navigation
visitor
calendar
calendar
features
figure
22
user
study
average
feature
ranks
pg
28the
users
also
asked
prefer
using
application
instead
traditional
instructions
form
documents
can
see
figure
23
80
users
preferred
using
application
remaining
20
preferred
documented
instructions
since
find
apprentice
mode
detailed
enough
suggested
adding
links
videos
explaining
use
tools
user
preference
among
augmented
lab
documented
instructions
20
80
augmented
lab
documented
instructions
figure
23
user
study
comparison
augmented
lab
documented
instructions
reasons
choosing
augmented
lab
10
10
30
40
10
easier
look
procedure
flow
easier
capture
details
interactive
engaging
includes
functionalities
need
figure
24
user
study
reasons
choosing
augmented
lab
pg
29the
users
also
asked
improvement
suggestions
general
feedback
respect
functionality
usability
application
observed
device
captions
camera
view
kind
shaky
stabilized
couple
users
suggested
also
focus
smaller
tools
like
screw
driver
navigation
mode
since
harder
locate
compared
larger
ones
like
3d
printer
users
also
recommended
maintaining
checklist
apprentice
mode
experienced
users
need
go
entire
flowchart
overall
users
quite
excited
visual
appeal
varied
functionalities
application
thought
provided
rich
interactive
user
experience
conclusion
future
work
include
replacing
simulated
location
api
qualcomm
indoor
positioning
system
izat
also
implement
computer
vision
techniques
detect
objects
visible
camera
view
point
localization
approach
entirely
based
location
api
orientation
sensor
readings
integrating
object
detection
current
approach
make
localization
extremely
robust
giving
inch-level
accuracy
now
device
detected
based
location
orientation
apprentice
mode
shows
static
images
explains
use
device
able
implement
highly
accurate
object
detection
algorithm
can
get
rid
static
images
apprentice
mode
render
text
3d
arrows
accurately
pointing
different
parts
device
pg
30we
identified
two
approaches
object
detection
context
first
approach
add
markers
different
devices
lab
detect
images
taken
camera
marker
basically
indicator
distinct
pattern
color
shape
easy
detect
image
advantage
approach
need
implement
complex
machine
learning
algorithms
train
images
since
need
search
known
distinct
markers
however
approach
really
flexible
case
huge
indoor
space
large
number
objects
feasible
add
markers
object
also
lot
markers
beats
purpose
since
detection
won
trivial
anymore
another
approach
implementing
full-fledged
object
detection
using
opencv
based
haar
training
haar
training
used
train
sample
images
necessary
task
machine
learning
based
object
detection
task
detection
accuracy
depends
well
system
trained
based
large
set
sample
images
approach
complex
training
extremely
time
consuming
however
much
scalable
flexible
compared
using
markers
summarize
strong
untapped
potential
augmented
reality
context
indoor
navigation
attempted
demonstrate
certain
extent
application
explored
four
representative
modes
apprentice
navigation
visitor
calendar
extended
based
different
user
scenarios
strength
approach
completely
generic
can
tuned
work
indoor
space
malls
hospitals
museums
airports
etc
pg
31references
hui
liu
darabi
banerjee
jing
liu
nov
2007
survey
wireless
indoor
positioning
techniques
systems
ieee
transactions
vol
37
pp
1067
1080
author
unknown
date
unknown
augmented
reality
museum
learning
online
available
http://www.pocket-lint.com/news/125475-the-british-museum-and-
samsung-bring-augmented-reality-to-museum-learning
author
unknown
date
unknown
bluetooth
wavelength
frequency
online
available
http://www.ehow.com/info_8722444_bluetooth-wavelength-frequency.html
zahid
farid
rosdiadee
nordin
mahamod
ismail
date
unknown
recent
advances
wireless
indoor
localization
techniques
system
journal
computer
networks
communications
vol
2013
subhan
hasbullah
rozyyev
bakhsh
indoor
positioning
bluetooth
networks
using
fingerprinting
lateration
approach
inproceedings
international
conference
information
science
applications
icisa
11
april
2011
perez
iglesias
barral
escudero
indoor
person
localization
system
rssi
bluetooth
fingerprinting
proceedings
19th
international
conference
systems
signals
image
processing
iwssip
12
pp
40
43
april
2012
manh
le
dimitris
saragas
oct
2009
indoor
navigation
system
handheld
devices
worcester
polytechnic
institute
electronic
project
collection
e-project-102209
164024
evennou
marx
2006
advanced
integration
wifi
inertial
navigation
systems
indoor
mobile
positioning
eurasip
appl
signal
process
2006
164
164
pg
329
author
unknown
date
unknown
qualcomm
indoor
location
online
available
http://www.qualcomm.com/connect/analyst-relations/briefing-center/indoor-location
10
author
unknown
date
unknown
indoor
maps
availability
online
available
https://support.google.com/gmm/answer/1685827?hl=en
11
author
unknown
date
unknown
google
indoor
maps
online
available
http://www.smh.com.au/digital-life/smartphone-apps/inside-out-google-launches-
indoor-maps-20130312-2fxz2
html
12
lamarca
chawathe
consolvo
hightower
smith
scott
sohn
howard
hughes
potter
tabert
powledge
borriello
schilit
may
2005
place
lab
device
positioning
using
radio
beacons
wild
proceedings
third
international
conference
pervasive
computing
13
author
unknown
date
unknown
augmented
blog
online
available
http://augmentedblog.wordpress.com/tag/indoor/
14
author
unknown
date
unknown
improving
positioning
indoors
imaging
data
online
available
http://phys.org/news/2012-09-positioning-indoors-imaging.html#jcp
15
author
unknown
date
unknown
infsoft
indoor
navigation
online
available
http://www.infsoft.com/indoor-navigation/
16
kevin
brothaler
defining
vertices
shaders
opengl
es
android
quick
start
guide
dallas
texas
pragmatic
bookshelf
2013
pg
33