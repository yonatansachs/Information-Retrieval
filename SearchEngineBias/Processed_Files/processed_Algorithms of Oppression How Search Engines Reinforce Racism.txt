2019
global
media
journal
canadian
edition
volume
11
issue
pp
117
120
issn
1918
5901
english
issn
1918
591x
français
algorithms
oppression
search
engines
reinforce
racism
safiya
umoja
new
york
new
york
university
press
2018
256
pp
isbn
978
4798
3364
book
review
abakar
malloum
université
ottawa
canada
big
data
et
la
numérisation
de
exclusion
sociale
idée
selon
laquelle
internet
serait
une
révolution
sociale
et
cognitive
et
qu
il
permettrait
une
ère
de
démocratie
généralisée
barlow
1996
serre
2015
laisse
le
plus
souvent
dans
ombre
la
dynamique
de
transfert
des
représentations
entre
les
cyberespaces
et
le
monde
réel
il
une
relation
de
détermination
mutuelle
entre
la
technique
les
applications
et
les
valeurs
que
portent
ses
concepteur
trice
ex
ingenieur
es
et
ses
contrôleur
euse
les
géants
du
numérique
telle
est
la
thèse
générale
de
sofya
umoja
noble
dans
algorithms
oppression
search
engines
reinforce
racism
noble
est
professeure
adjointe
en
études
de
information
université
de
californie
sa
recherche
indique-t-elle
est
concentrée
sur
unveiling
many
ways
african
american
people
contained
constrained
classification
systems
google
commercial
search
engine
library
databases
2018
est
donc
dans
le
contexte
de
ce
programme
que
auteure
marie
les
perspectives
issues
du
féminisme
noir
et
les
concepts
fournis
par
les
études
bibliothéconomiques
afin
de
mettre
en
lumière
des
pratiques
exclusion
et
de
marginalisation
numériques
algorithmic
redlining
dont
sont
victimes
des
personnes
issues
de
certaines
catégories
sociales
notamment
les
femmes
les
personnes
noires
et
les
personnes
issues
des
communautés
latino-américaines
selon
noble
le
tournant
du
numérique
que
certains
appellent
le
capitalisme
de
la
surveillance
coïncidant
avec
le
contrôle
de
information
publique
par
des
entités
privées
au
premier
chef
desquelles
google
est
opéré
conjointement
la
capitalisation
des
préjugés
sociaux
qui
sont
devenus
sources
de
profits
commerciaux
et
par-là
des
valeurs
consommables
ainsi
par
exemple
quand
cherche
black
girl
dans
google
des
termes
oppressifs
comme
big
booty
black
girls
2018
67
apparaissent
en
premier
parce
que
des
sites
pornographiques
payent
google
pour
que
ces
réponses
qui
sont
en
fait
des
annonces
ads
affichent
en
tête
des
résultats
possibles
une
requête
partant
ailleurs
de
cet
usage
commercial
des
préjugés
les
deux
premiers
chapitres
du
livre
démasquent
le
processus
par
lequel
les
catégories
oppressives
combattues
par
women
people
color
2018
26
sont
reproduites
et
renforcées
par
le
biais
des
résultats
de
recherche
google
google
search
ainsi
quand
entre
2009
2015
noble
cherchait
dans
google
search
les
termes
women
need
elle
recevait
les
suggestions
suivantes
put
places
know
place
controlled
disciplined
2018
15
idem
quand
noble
cherchait
les
termes
black
girls
il
en
résultait
ce
qui
suit
black
girls
pussy
free
black
girls
chats
black
girls
big
booty
2018
19
la
demi-question
black
people
elle
reçu
les
réponses
suivantes
angry
loud
mean
attractive
lazy
annoying
confident
sassy
2018
21
la
demi-question
white
women
provoquait
les
termes
plus
positifs
tels
que
pretty
beautiful
mean
easy
insecure
skinny
pefect
ibid
quant
abakar
malloum
118
google
image
search
le
terme
professor
style
représentait
quasi
totalement
des
images
hommes
blancs
en
costume
le
problème
selon
noble
ne
se
trouve
pas
exactement
dans
le
fait
que
ces
résultats
reflètent
un
transfert
dans
le
numérique
de
oppression
dont
font
objet
ces
groupes
sociaux
il
serait
plutôt
particulièrement
dérangeant
parce
que
ces
résultats
sont
considérés
comme
étant
pour
une
grande
majorité
internautes
objectifs
et
neutres
simple
mirror
collective
2018
36
comme
le
soutient
noble
le
miroir
de
la
société
est
ni
simple
ni
neutre
il
est
un
lieu
de
pouvoir
et
de
domination
au
sein
duquel
google
search
est
un
outil
de
normalisation
comme
été
la
bibliothèque
du
congrès
américain
nous
reviendrons
de
ceux
qui
sont
déjà
overracialized
hypersexualized
ibid
cette
oppression
numérique
selon
auteure
est
pas
le
fait
une
machine
anomique
comme
insinuait
la
campagne
de
nations
unies
en
2013
2018
15
encore
moins
le
simple
fruit
une
erreur
glitch
ou
bug
dans
le
système
internet
elle
est
plutôt
le
fait
une
triple
rencontre
entre
idéologie
néolibérale
une
absence
de
protections
légales
et
des
pratiques
oppressives
profondément
enracinées
dans
les
institutions
sociales
et
universitaires
titre
exemple
aux
etats-unis
où
les
protections
se
font
toujours
attendre
trouve
de
greater
encroachments
personal
information
privacy
vulnerable
communities
individuals
less
likely
find
recourse
12018
22
cette
absence
relative
de
état
dans
la
protection
des
internautes
américains
permet
des
sites
tels
que
mugshots
com
et
unpublisharrest
com
de
proposer
aux
plus
offrants
la
possibilité
être
effacés
across
major
search
engines
2018
124
comme
constaté
kandis
la
coiffeuse
afro-américaine
dont
entrevue
est
au
cœur
de
la
conclusion
du
livre
internet
est
en
train
de
redéfinir
valuable
value
lies
2018
175
par
ailleurs
il
existe
certains
endroits
où
des
exemples
de
protections
semblent
émerger
en
france
par
exemple
les
lois
interdisent
la
vente
en
ligne
objets
nazis
google
filtrant
ses
résultats
conformément
aux
dispositifs
légaux
2018
42
de
même
les
législations
relatives
au
right
forgotten
mises
en
place
dans
espace
de
union
européenne
limitent
le
contrôle
de
google
sur
les
données
personnelles
des
internautes
est
en
prenant
le
contre-pied
de
la
thèse
de
la
neutralité
du
net
que
le
chapitre
trois
de
noble
expose
comment
cette
fausse
neutralité
et
objectivité
peut
mener
des
conséquences
tragiques
comme
le
massacre
raciste
2015
de
neuf
afro-américain
es
lors
une
prière
église
où
assaillant
dylann
rooff
allegedly
used
google
search
development
racial
attitudes
noble
2018
11
et
133
pour
noble
idée
que
internet
est
un
outil
politiquement
neutre
est
la
base
de
la
conception
que
les
internautes
se
font
des
résultats
de
leur
recherche
sur
google
résultats
compris
les
préjugés
commercialisés
que
ces
mêmes
internautes
considèrent
comme
une
représentation
neutre
objective
et
donc
naturelle
de
la
société
mais
ces
pratiques
oppressives
dans
lesquelles
google
et
consorts
sont
devenus
maitres
numériques
sont-elles
nouvelles
cette
question
noble
la
traite
dans
le
chapitre
cinq
pour
débouter
une
autre
fausse
neutralité
celle
de
la
science
de
information
notamment
la
traditional
library
information
science
lis
noble
2018
137
tel
que
explique
noble
cette
science
de
classification
est
non
seulement
impliquée
dans
la
conception
du
google
search
mais
aussi
et
surtout
dans
la
longue
histoire
de
people
conceptualized
represented
noble
2018
135
travers
les
systèmes
de
classification
bibliothécaire
les
classifications
qu
elles
soient
numériques
ou
non
sont
politiquement
chargées
car
elles
sont
la
fois
les
produits
de
leur
temps
et
porteuses
de
la
vision
du
monde
de
la
classe
dominante
sur
le
plan
historique
le
cas
de
la
classification
est
particulièrement
pertinent
en
amérique
du
nord
où
la
taxinomie
scientifique
servi
la
légitimation
de
exclusion
sociale
et
politique
des
autochtones
des
femmes
et
des
afro-americain
es
est
en
ce
sens
que
noble
expose
les
relations
étroites
entre
les
pratiques
oppressives
de
google
et
une
tradition
scientifique
compromise
dans
les
nominations
namings
des
asiatiques
comme
yellow
peril
des
juifs
comme
jewish
question
des
afroaméricain
es
comme
negroes
et
des
femmes
comme
women
accountants
par
la
bibliothèque
abakar
malloum
119
nationale
ainsi
si
les
violences
numériques
dans
les
catégorisations
et
les
collectes
de
données
nous
renvoient
aux
pratiques
incrustées
dans
les
gestions
de
la
connaissance
et
de
information
noble
ne
peut
que
réitérer
importance
des
réglementations
publiques
du
numérique
qui
manquent
de
façon
criante
aux
états-unis
un
pays
où
le
sujet
est
hotly
contested
noble
2018
160
ouvrage
de
noble
est
sans
conteste
un
fort
appel
nuancer
les
hypothèses
selon
lesquelles
les
cyberespaces
sont
un
havre
de
liberté
il
nous
faut
selon
noble
se
résoudre
affronter
la
réalité
social
inequality
will
solved
app
noble
2018
165
les
entités
privées
qui
contrôlent
internet
et
nos
diverses
applications
sont
essentiellement
orientées
vers
le
profit
leurs
algorithmes
sont
avant
tout
des
machines
faire
de
argent
le
tout
informé
par
une
vision
néolibérale
du
monde
une
des
premières
choses
qui
sera
déplorée
par
certain
lecteur
trice
peut-être
est
le
fait
que
comme
auteure
le
reconnaît
dès
introduction
la
plupart
des
pratiques
numériques
oppressives
analysées
dans
le
livre
étaient
déjà
plus
actualité
au
moment
même
de
la
publication
google
search
ne
suggère
plus
des
réponses
oppressives
aux
termes
femme
personne
noire
etc
en
effet
les
algorithmes
de
google
search
semblent
avoir
changé
de
stratégies
ou
espace
de
recherche
selon
le
terme
consacré
en
informatique
ainsi
en
2020
quand
nous
faisons
la
requête
woman
google
se
contente
de
citer
des
passages
des
livres
des
films
ou
des
chansons
populaires
en
guise
des
suggestions
par
exemple
woman
heart
deep
ocean
secrets
renvoie
une
scène
du
film
titanic
empêche
cette
formule
demeure
teintée
des
préjugés
combattus
par
les
femmes
ce
qui
confirme
actualité
de
la
thèse
générale
de
auteure
la
réalité
virtuelle
américaine
est
originaire
de
la
société
américaine
où
les
dispositifs
culturels
et
scientifiques
ont
pour
longtemps
été
complices
des
pratiques
oppressives
envers
certaines
catégories
sociales
google
pagerank
est
un
produit
de
ces
dispositifs
il
nous
faut
toutefois
noter
aussi
certains
raccourcis
méthodologiques
dans
la
manière
dont
auteure
traite
les
résultats
de
google
search
dans
la
mesure
où
ceux-ci
sont
centraux
la
thèse
ainsi
pour
pouvoir
attribuer
les
résultats
racistes
et
sexistes
aux
intentions
humaines
ou
affirmer
que
racism
fundamental
application
program
interface
api
internet
noble
2018
il
nous
semble
indispensable
expliquer
comment
cet
algorithme
spécifique
de
classification
google
search
procède
pour
produire
ces
résultats
car
sans
cela
fait
abstraction
des
dimensions
importantes
de
classification
algorithmique
telle
que
la
boite
noire
ou
par
exemple
le
fait
que
selon
jenna
burrel
rarely
one
concrete
sense
particular
classification
arrived
inputs
2016
non
seulement
il
est
souvent
difficile
de
prévoir
les
sorties
outputs
comme
le
souligne
burrel
mais
comme
gregory
chaitin
fameusement
démontré
dans
tout
processus
computationnel
il
une
dissymétrie
entre
les
entrées
données
utilisées
par
les
algorithmes
inputs
et
les
sorties
résultats
outputs
et
de
là
peut
spéculer
qu
il
se
passe
la
même
chose
entre
les
intentions
des
concepteur
trices
et
les
résultats
entendus
un
autre
aspect
épistémologiquement
important
du
constat
de
chaitin
est
que
dans
le
processus
mathématique
algorithmique
de
la
pure
rationalisation
même
il
des
aléas
randomness
area
mathematical
truth
absolutely
structure
structure
will
ever
able
appreciate
detail
2004
cet
élément
irrationalité
maximally
unknowable
dans
le
fonctionnement
de
algorithme
ne
conduit
nullement
une
neutralité
idéologique
de
la
machine
un
algorithme
est
avant
tout
un
discours
sur
le
monde
quelle
que
soit
intentionnalité
derrière
par
exemple
un
algorithme
une
caméra
de
surveillance
ou
de
classification
des
humains
doit
contenir
une
définition
de
ce
qu
un
être
humain
physiquement
cette
définition
peut
donc
déboucher
sur
exclusion
inclusion
sur
des
bases
idéologiques
racistes
et
sexistes
économiques
sécuritaires
etc
mais
une
évaluation
éthique
de
cet
algorithme
nécessite
de
analyser
en
passant
par
un
certain
nombre
de
paliers
distincts
de
sa
constitution
algorithme
la
partie
purement
théorique
le
code
langage
choisi
pour
exécution
du
programme
les
données
la
disposition
de
ce
programme
les
liens
des
sites
dans
le
cas
de
google
le
contexte
etc
abakar
malloum
120
en
outre
un
arrêt
sur
algorithme
lui-même
aurait
utilement
mené
auteure
examiner
le
remplacement
par
google
search
en
2011
de
son
algorithme
par
un
nouvel
algorithme
panda
qui
réduisit
fortement
les
possibilités
qu
avaient
certains
sites
ceux
qui
sont
de
faible
qualité
selon
google
se
placer
en
tête
des
résultats
ce
qui
aurait
du
même
coup
projeté
plus
de
clarté
sur
la
classification
savoir
pourquoi
et
comment
les
termes
comme
black
girl
et
woman
etc
venaient
avec
ces
résultats
et
ensuite
peut
être
de
proposer
aux
programmeur
euses
chez
google
et
aux
législateur
trice
de
types
intervention
que
noble
appelle
si
justement
de
ses
vœux
bibliographie
barlow
john
1996
declaration
independence
cyberspace
hache
une
édition
électronique
burrell
jenna
2016
machine
thinks
understanding
opacity
machine
learning
algorithms
dans
big
data
society
12
chaitin
gregory
2004
leibniz
randomness
halting
probability
ibm
watson
research
center
yorktown
heights
serres
michel
2015
2012
petite
poucette
paris
le
pommier
reviewer
abakar
malloum
doctoral
candidate
school
political
studies
university
ottawa
ottawa
canada
citing
book
review
malloum
abakar
2019
review
book
algorithms
oppression
search
engines
reinforce
racism
global
media
journal
canadian
edition
11
117
120