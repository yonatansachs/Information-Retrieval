transparency
fairness
data
protection
neutrality
data
management
challenges
face
new
regulation
serge
abiteboul
inria
ecole
normale
supérieure
france
julia
stoyanovich
new
york
university
usa
data
revolution
continues
transform
every
sector
science
industry
government
due
incredible
impact
data-driven
technology
society
becoming
increasingly
aware
imperative
use
data
algorithms
responsibly
accordance
laws
ethical
norms
article
discuss
three
recent
regulatory
frameworks
european
union
general
data
protection
regulation
gdpr
new
york
city
automated
decisions
systems
ads
law
net
neutrality
principle
aim
protect
rights
individuals
impacted
data
collection
analysis
frameworks
prominent
examples
global
trend
governments
starting
recognize
need
regulate
data-driven
algorithmic
technology
goal
article
bring
regulatory
frameworks
attention
data
management
community
underscore
technical
challenges
raise
community
well
equipped
address
main
takeaway
article
legal
ethical
norms
incorporated
data-driven
systems
afterthought
rather
must
think
terms
responsibility
design
viewing
systems
requirement
ccs
concepts
information
systems
data
management
systems
social
professional
topics
computing
technology
policy
technology
audits
applied
computing
law
additional
key
words
phrases
transparency
fairness
data
protection
neutrality
responsible
data
science
acm
reference
format
serge
abiteboul
julia
stoyanovich
2019
transparency
fairness
data
protection
neutrality
data
man
agement
challenges
face
new
regulation
data
information
quality
11
article
15
june
2019
pages
https://doi.org/10.1145/3310231
introduction
data
revolution
continues
transform
every
sector
science
industry
government
due
incredible
impact
data-driven
technology
society
becoming
increasingly
aware
imperative
use
data
algorithms
responsibly
accordance
laws
ethical
work
supported
part
national
science
foundation
nsf
grant
1741047
agence
nationale
de
la
recherche
anr
grant
headwork
authors
addresses
abiteboul
inria
ens
paris
serge
abiteboul
institut
national
de
recherche
en
informatique
et
au
tomatique
école
normale
supérieure
psl
university
75005
paris
france
email
serge.abiteboul@inria.fr
stoyanovich
department
computer
science
engineering
tandon
school
engineering
new
york
university
370
jay
street
brooklyn
ny
11201
usa
email
stoyanovich@nyu.edu
permission
make
digital
hard
copies
part
work
personal
classroom
use
granted
without
fee
provided
copies
made
distributed
profit
commercial
advantage
copies
bear
notice
15
full
citation
first
page
copyrights
components
work
owned
others
acm
must
honored
abstracting
credit
permitted
copy
otherwise
republish
post
servers
redistribute
lists
requires
prior
specific
permission
fee
request
permissions
permissions@acm.org
2019
association
computing
machinery
1936
1955
2019
06
art15
15.00
https://doi.org/10.1145/3310231
acm
journal
data
information
quality
vol
11
article
15
publication
date
june
2019
15
abiteboul
stoyanovich
norms
goal
article
underscore
technical
challenges
raised
recent
legal
regulatory
frameworks
data
management
community
well-equipped
address
discuss
three
recent
frameworks
european
union
general
data
protection
regula
tion
gdpr
european
union
2016
new
york
city
automated
decisions
systems
ads
law
new
york
city
council
2017
net
neutrality
principle
frameworks
prominent
examples
global
trend
governments
starting
recognize
need
regulate
data-driven
algorithmic
technology
gdpr
nyc
ads
law
aim
protect
rights
individuals
impacted
data
collection
analysis
net
neutrality
principle
ensures
services
treated
equitably
yet
despite
focus
organizations
rights
individuals
also
figure
prominently
neutrality
debate
one
imperatives
indi
viduals
able
enjoy
freedom
choice
expression
on-line
will
give
legal
context
neutrality
discussing
eu
regulation
2015
2120
european
parliament
council
2015
indian
net
neutrality
regulatory
framework
government
india
ministry
communications
2018
ongoing
regulatory
debate
net
neutrality
goal
article
bring
regulatory
frameworks
attention
data
man
agement
community
main
takeaway
article
legal
norms
incorporated
data-driven
systems
afterthought
rather
must
think
terms
responsibility
design
viewing
systems
requirement
1.1
general
data
protection
regulation
european
union
recently
enacted
sweeping
regulatory
framework
known
general
data
protection
regulation
gdpr
european
union
2016
regulation
adopted
april
2016
became
enforceable
two
years
later
may
25
2018
gdpr
aims
protect
rights
freedoms
natural
persons
regard
personal
data
processed
moved
exchanged
article
gdpr
broad
scope
applies
processing
personal
data
wholly
partly
automated
means
article
private
sector
public
sector
personal
data
broadly
construed
refers
information
relating
identified
identifiable
natural
person
called
data
subject
article
article
focus
following
salient
points
regulation
lawful
processing
data
predicated
data
subject
informed
consent
stating
whether
personal
data
can
used
purpose
articles
data
subject
right
correct
errors
data
right
rectification
article
16
withdraw
data
system
right
erasure
article
17
move
data
one
data
processor
another
right
portability
article
20
data
subject
right
informed
collection
use
data
primary
focus
gdpr
protecting
rights
data
subjects
giving
insight
control
collection
processing
personal
data
providing
sight
response
right
informed
requires
technical
methods
algorithmic
data
transparency
will
discuss
section
will
also
discuss
challenges
inherent
giving
individuals
ability
erase
move
data
section
1.2
new
york
city
algorithmic
decision
systems
law
new
york
city
recently
passed
law
new
york
city
council
2017
requiring
task
force
put
place
survey
current
use
automated
decision
systems
ads
defined
computerized
implementations
algorithms
including
derived
machine
learning
data
processing
artificial
intelligence
techniques
used
make
assist
https://gdpr-info.eu/issues/right-to-be-informed/.
acm
journal
data
information
quality
vol
11
article
15
publication
date
june
2019
transparency
fairness
data
protection
neutrality
15
making
decisions
city
agencies
task
force
working
develop
set
recommendations
enacting
algorithmic
transparency
agencies
will
propose
procedures
requesting
receiving
explanation
algorithmic
decision
affecting
individual
section
interrogating
automated
decision
systems
bias
discrimination
members
legally
protected
groups
addressing
instances
person
harmed
based
membership
groups
sections
assessing
automated
decision
systems
function
used
archiving
systems
together
data
use
sections
contrast
gdpr
broad
scope
nyc
ads
law
regulates
city
agencies
use
algorithms
data
directly
apply
private
companies
however
government
agencies
often
procure
systems
components
industry
partners
law
will
likely
impact
industry
practices
new
york
first
city
pass
law
kind
expect
municipalities
follow
similar
legal
frameworks
recommendations
near
future
primary
focus
nyc
ads
law
algorithmic
transparency
turn
achieved
without
data
transparency
stoyanovich
howe
2018
discussed
sec
tion
1.1
transparency
also
implicit
requirement
gdpr
stemming
right
informed
will
discuss
role
data
management
community
can
play
enabling
data
transparency
section
nyc
ads
law
requires
fair
equitable
treatment
individuals
mandating
ads
safeguard
bias
discrimination
provide
transparency
regard
will
discuss
fairness
section
will
propose
research
directions
data
management
community
complementary
rich
rapidly
expanding
body
work
fairness
machine
learning
1.3
net
neutrality
principle
net
neutrality
principle
internet
service
providers
isps
discriminate
charge
differently
based
message
source
content
provider
destination
user
content
concept
articulated
wu
2003
according
net
neutrality
isp
block
throttle
video
streams
youtube
nega
tive
discrimination
enable
free
access
facebook
package
kind
positive
discrimina
tion
september
2018
report
northeastern
university
university
massachusetts
amherst
found
telecommunications
companies
indeed
slowing
internet
traffic
two
sites
particular
along
popular
apps
kharif
2018
molavi
kakhki
et
al
2015
course
limits
non-discrimination
blocking
pornographic
mate
rial
young
internet
users
filtering
hate
speech
countries
guaranteeing
quality
emergency
services
european
union
net
neutrality
guaranteed
eu
regulation
2015
2120
euro
pean
parliament
council
2015
although
different
countries
may
interpret
regulation
differently
example
forms
zero-rating
practice
providing
internet
access
financial
cost
means
positive
discrimination
legal
eu
countries
others
since
2018
india
perhaps
world
strongest
net
neutrality
rules
government
india
ministry
communications
2018
general
countries
adopting
net
neutrality
regulations
notable
exception
united
states
federal
communi
cations
commission
fcc
issued
open
internet
order
2015
reclassifying
internet
access
previously
classified
information
service
common
carrier
telecommunications
service
acm
journal
data
information
quality
vol
11
article
15
publication
date
june
2019
15
abiteboul
stoyanovich
thereby
enforcing
form
net
neutrality
however
2017
chairmanship
ajit
pai
fcc
officially
repealed
net
neutrality
rules
algorithmic
data
transparency
propublica
story
machine
bias
algorithm
used
sentencing
defendants
angwin
et
al
2016
amplified
calls
make
algorithms
transparent
accountable
kroll
et
al
2017
transparency
accountability
intrinsically
linked
trust
particular
impor
tance
algorithmic
systems
integrated
government
processes
assisting
humans
decision-making
tasks
sometimes
even
replacing
humans
transparency
government
core
democratic
value
compels
us
develop
technological
solutions
increase
government
efficiency
can
made
transparent
public
narrow
interpretation
algorithmic
transparency
requires
source
code
system
made
publicly
available
significant
step
toward
transparency
long
posted
code
readable
well-documented
complete
rarely
sufficient
one
reasons
particular
relevance
data
management
community
meaningful
transparency
algo
rithmic
processes
achieved
without
transparency
data
stoyanovich
howe
2018
data
transparency
can
achieve
one
immediate
interpretation
term
context
predictive
analytics
includes
making
training
validation
datasets
publicly
available
however
data
made
open
whenever
possible
much
sensitive
shared
directly
data
transparency
tension
privacy
individuals
included
dataset
light
may
adopt
following
alterna
tive
interpretation
data
transparency
addition
releasing
training
validation
datasets
whenever
possible
vendors
make
publicly
available
summaries
relevant
statistical
prop
erties
datasets
can
aid
interpreting
decisions
made
using
data
applying
state-of-the-art
methods
preserve
privacy
individuals
differential
privacy
dwork
roth
2014
appropriate
privacy-preserving
synthetic
datasets
can
released
lieu
real
datasets
expose
certain
features
data
ping
et
al
2017
important
aspect
data
transparency
interpretability
surfacing
statistical
properties
dataset
methodology
used
produce
ultimately
substantiating
fitness
use
context
specific
automated
decision
system
task
consideration
specific
use
particularly
important
datasets
increasingly
used
outside
original
context
intended
data
management
community
can
begin
addressing
challenges
building
significant
body
work
data
profiling
see
abedjan
et
al
2017
recent
tutorial
eye
new
legal
requirements
interpretability
rests
making
explicit
interactions
program
data
acts
property
important
automated
decision
system
interrogated
systematic
bias
discrimination
asked
explain
algorithmic
decision
affects
individual
example
suppose
system
scores
ranks
individuals
access
service
individual
enters
data
receives
result
say
score
42
number
alone
provides
information
scored
way
compares
others
can
potentially
improve
outcome
prominent
example
system
kind
opaque
extremely
impactful
fico
credit
scoring
system
citron
pasquale
2014
data
management
research
community
well-positioned
contribute
developing
new
methods
interpretability
new
contributions
can
naturally
build
rich
body
work
data
provenance
see
herschel
et
al
2017
recent
survey
recent
work
explaining
classifiers
ribeiro
et
al
2016
auditing
black
box
models
using
causal
framework
datta
et
al
2016
automatically
generating
nutritional
labels
data
models
yang
et
al
2018
acm
journal
data
information
quality
vol
11
article
15
publication
date
june
2019
transparency
fairness
data
protection
neutrality
15
fairness
can
agree
algorithmic
decision-making
fair
even
agree
definition
fairness
isn
algorithm
design
data
problem
indeed
machine-learning
data-mining
research
communities
actively
working
methods
enabling
fairness
specific
algorithms
outputs
particular
focus
classifi
cation
problems
see
example
dwork
et
al
2012
feldman
et
al
2015
friedler
et
al
2016
hajian
domingo-ferrer
2013
kamiran
et
al
2013
kleinberg
et
al
2017
romei
ruggieri
2014
proceedings
recently
established
acm
conference
fairness
ac
countability
transparency
acm
fat
important
approaches
focus
solely
final
step
data
science
lifecycle
thus
limited
assumption
input
datasets
clean
reliable
data-driven
algorithmic
decision
making
usually
requires
multiple
pre-processing
stages
ad
dress
messy
input
render
ready
analysis
jagadish
et
al
2014
pre-processing
includes
data
cleaning
integration
querying
ranking
often
source
algorithmic
bias
kirkpatrick
2017
stoyanovich
et
al
2017
reasoning
sources
bias
mitigating
unfairness
upstream
final
step
data
analysis
potentially
impactful
example
much
research
goes
ensuring
statistical
parity
requirement
de
mographics
receiving
particular
outcome
positive
negative
classification
identical
demographics
population
whole
suppose
input
binary
classifier
contains
900
men
100
women
known
women
represent
50
over-all
population
achieving
statistical
parity
amounts
enforcing
50
50
gender
balance
among
positively
classified
individuals
else
equal
woman
input
classifier
far
likely
receive
positive
classification
man
alterna
tive
observe
following
input
classifier
produced
sql
query
relaxing
query
make
input
balanced
000
men
500
women
effective
way
mitigate
lack
statistical
parity
output
classifier
relax
query
upstream
easy
construct
additional
examples
show
bias
may
introduced
data
cleaning
data
integration
querying
ranking
upstream
final
stage
data
analy
sis
therefore
meaningful
detect
mitigate
effects
data
lifecycle
stages
occur
see
mitchell
et
al
2018
discussion
definitions
bias
corresponding
assumptions
made
defining
fairness
measures
members
data
management
community
interested
topic
may
consider
growing
body
work
impossibility
results
show
different
notions
fairness
enforced
simultaneously
require
explicit
trade-offs
chouldechova
2017
friedler
et
al
2016
kleinberg
et
al
2017
negative
results
per
se
surprising
fairness
subjective
context-dependent
highly
politicized
concept
global
consensus
fair
unlikely
emerge
context
algorithmic
decision
making
otherwise
think
example
decade-long
debate
interplay
disparate
treatment
disparate
impact
recent
examples
include
ricci
de
stefano3
ongoing
lawsuit
regarding
use
race
harvard
university
admissions
said
productive
way
move
forward
data
science
context
develop
methods
can
instrumented
different
alternative
fairness
notions
can
support
principled
transparent
trade
offs
notions
https://www.fatconference.org/.
https://en.wikipedia.org/wiki/ricci_v._destefano.
https://www.nytimes.com/2018/10/13/us/harvard-affirmative-action-asian-students.html.
acm
journal
data
information
quality
vol
11
article
15
publication
date
june
2019
15
abiteboul
stoyanovich
moving
removing
personal
data
4.1
right
forgotten
right
forgotten
originally
motivated
desire
individuals
perpetually
stigmatized
something
past
pressure
despicable
social
phenomena
revenge
porn
turned
recently
laws
2006
argentina
since
european
union
part
gdpr
particular
article
17
gdpr
states
data
subjects
right
request
erasure
personal
data
can
large
number
reasons
passing
law
primarily
resulted
high
number
requests
search
engines
dereference
web
pages
turned
controversial
number
reasons
including
also
dereferencing
google
opaque
company
effect
acquired
will
questionable
power
adjudicate
furthermore
advocated
wikimedia
among
others
right
forgotten
sometimes
conflicts
rights
public
right
information
addition
search
engines
right
forgotten
affects
companies
keep
personal
data
prominent
example
facebook
many
years
impossible
delete
data
pertains
user
account
user
may
close
account
reopen
time
later
find
data
originally
now
possible
request
deletion
data
pertaining
account
facebook
however
user
proof
deletion
indeed
occurred
important
technical
issue
clear
relevance
data
management
community
deletion
information
systems
typically
meant
accumulate
data
deletion
must
permanent
deep
sense
effects
must
propagate
data
dependen
cies
start
difficult
guarantee
copies
every
piece
deleted
data
actually
deleted
data
deleted
remaining
database
may
become
inconsis
tent
may
example
include
dangling
pointers
additionally
production
systems
typically
include
strong
provenance
mechanism
means
tracking
use
arbitrary
data
item
one
deleted
reasoning
dependencies
data
item
derived
data
products
although
much
attention
data
management
community
years
devoted
tracking
reasoning
provenance
primarily
relational
contexts
workflows
see
herschel
et
al
2017
recent
survey
still
important
work
done
making
methods
practically
feasible
sufficiently
general
accommodate
current
legal
requirements
important
direction
best
knowledge
still
unexplored
con
cerns
ascertaining
effects
deletion
downstream
processes
purely
relational
include
kinds
data
analysis
tasks
like
data
mining
predictive
analytics
requests
deletion
may
also
conflict
laws
requirements
keep
certain
transaction
data
period
time
requirements
fault
tolerance
recover
ability
deleted
pieces
data
also
erased
caches
backups
requesting
functionality
gives
immediate
nightmares
systems
engineers
charge
production
data
management
system
millions
lines
code
terabytes
legacy
data
likely
swer
done
solution
see
redeveloping
system
scratch
right-to-be-forgotten-by-design
understanding
impact
deletion
requests
ability
offer
guarantees
system
resilience
performance
developing
appropriate
primitives
protocols
practical
use
another
call
action
data
management
community
4.2
interoperability
portability
article
20
gdpr
right
data
portability
stipulates
data
subject
right
receive
personal
data
vendor
transfer
data
another
vendor
main
goals
acm
journal
data
information
quality
vol
11
article
15
publication
date
june
2019
transparency
fairness
data
protection
neutrality
15
provision
keep
data
subject
informed
data
vendor
prevent
vendor
lock-in
enables
user
unhappy
service
leave
competing
service
best
serves
needs
without
reconstruct
entire
data
history
also
allows
user
select
applications
choice
cooperate
best
advantage
even
come
different
vendors
response
data
portability
regulation
users
concerns
google
twitter
microsoft
facebook
teamed
data
transfer
project
aims
facilitate
content
transfer
applications
course
easy
task
company
provide
service
facilitates
departure
customers
spite
commendable
behavior
companies
engage
data
transfer
project
role
regulators
impose
data
portability
interoperability
requirements
interoperability
database
applications
old
topic
one
can
imagine
unlimited
num
ber
possibilities
whatsapp
call
talk
skype
one
certainly
acquires
different
flavor
consider
interoperating
applications
billions
users
millions
transactions
per
second
data
portability
noted
devil
detail
export
format
stable
structured
facilitate
reuse
also
data
can
exported
issue
obviously
includes
data
user
volunteered
service
also
include
data
vendor
gathered
behavior
user
time
user
waking
morning
include
data
service
inferred
home
address
user
job
address
another
issue
portability
target
system
user
may
want
port
photos
service
service
issue
service
able
incorporate
much
data
possible
service
now
user
may
want
integrate
photos
personal
information
system
abiteboul
et
al
2015
system
must
able
integrate
information
large
panel
domains
brings
us
fields
data
integration
lenzerini
2002
knowledge
representation
neutrality
already
mentioned
net
neutrality
now
legally
required
countries
yet
detecting
net
neutrality
violations
enforce
law
easy
task
indeed
simply
measuring
performance
internet
communications
easy
measurement
results
may
depend
location
source
target
context
applications
competing
bandwidth
factors
indeed
different
measures
provided
network
traffic
typically
diverge
evaluation
net
neutrality
relying
hard-to-obtain
measures
challeng
ing
research
topic
molavi
kakhki
et
al
2015
primarily
interest
networks
internet
measurement
communities
less
data
management
beyond
net
neutrality
new
forms
neutrality
emerging
device
neutrality
smart-phone
blocking
certain
apps
favoring
others
platform
neutrality
particular
web
service
providing
neutral
recommendation
instance
app
stores
like
google
play
apple
app
store
tend
refuse
reference
certain
services
perhaps
competing
company
services
research
needed
able
verify
new
facets
neutrality
particular
easy
check
whether
recommendation
engine
like
google
search
booking
enforcing
transparent
editorial
policies
whether
results
comprehensive
impartial
based
solely
relevance
example
observed
search
engines
tend
favor
friendly
services
competitors
https://en.m.wikipedia.org/wiki/european_union_vs._google.
acm
journal
data
information
quality
vol
11
article
15
publication
date
june
2019
15
abiteboul
stoyanovich
takeaways
article
discussed
several
recent
regulatory
frameworks
aim
protect
rights
individuals
ensure
equitable
treatment
services
bring
transparency
data-driven
algorithmic
processes
industry
government
goal
bring
regulatory
frameworks
attention
data
management
community
underscore
technical
challenges
raise
community
well-equipped
address
important
takeaway
article
legal
norms
incorporated
data-driven
systems
afterthought
rather
must
think
terms
responsibility
design
viewing
systems
requirement
also
stress
enacting
algorithmic
data
transparency
fairness
data
protection
neutrality
will
require
significant
cultural
shift
making
shift
must
accept
objectives
efficiency
accuracy
utility
primary
goal
must
balanced
equitable
treatment
members
historically
disadvantaged
groups
accountability
transparency
individuals
affected
algorithmic
decisions
general
public
article
focused
explicit
regulation
industry
stakeholders
government
entities
case
gdpr
net
neutrality
laws
government
oversight
case
nyc
ads
law
another
implicit
regulatory
mechanism
can
achieved
empowering
users
user
associations
providing
data
literacy
education
precise
formation
different
products
services
work
better
educated
users
can
choose
better
solutions
including
effective
ways
protect
private
data
users
can
also
easily
understand
explanations
provided
algorithmic
system
user
associations
can
help
individuals
make
informed
choices
support
via
class
actions
lawsuits
case
disputes
references
ziawasch
abedjan
lukasz
golab
felix
naumann
2017
data
profiling
tutorial
proceedings
acm
interna
tional
conference
management
data
sigmod
17
1747
1751
doi
https://doi.org/10.1145/3035918.3054772
serge
abiteboul
benjamin
andré
daniel
kaplan
2015
managing
digital
life
commun
acm
58
apr
2015
32
35
doi
https://doi.org/10.1145/2670528
julia
angwin
jeff
larson
surya
mattu
lauren
kirchner
2016
machine
bias
risk
assessments
criminal
sen
tencing
propublica
may
2016
retrieved
https://www.propublica.org/article/machine-bias-risk-assessments-
in-criminal-sentencing
alexandra
chouldechova
2017
fair
prediction
disparate
impact
study
bias
recidivism
prediction
instruments
retrieved
http://arxiv.org/abs/1703.00056.
danielle
citron
frank
pasquale
2014
scored
society
due
process
automated
predictions
washington
law
rev
89
2014
retrieved
http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2376209.
anupam
datta
shayak
sen
yair
zick
2016
algorithmic
transparency
via
quantitative
input
influence
theory
experiments
learning
systems
ieee
symposium
security
privacy
sp
16
598
617
doi
https://doi.org/
10.1109
sp
2016.42
cynthia
dwork
moritz
hardt
toniann
pitassi
omer
reingold
richard
zemel
2012
fairness
awareness
proceedings
conference
innovations
theoretical
computer
science
214
226
doi
https://doi.org/10.1145/
2090236.2090255
cynthia
dwork
aaron
roth
2014
algorithmic
foundations
differential
privacy
found
trends
theoret
comput
sci
2014
211
407
doi
https://doi.org/10.1561/0400000042
michael
feldman
sorelle
friedler
john
moeller
carlos
scheidegger
suresh
venkatasubramanian
2015
certifying
removing
disparate
impact
proceedings
21st
acm
sigkdd
international
conference
knowledge
discovery
data
mining
259
268
doi
https://doi.org/10.1145/2783258.2783311
sorelle
friedler
carlos
scheidegger
suresh
venkatasubramanian
2016
im
possibility
fairness
retrieved
http://arxiv.org/abs/1609.07236.
government
india
ministry
communications
2018
dot
letter
net
neutrality
regulatory
framework
dated
31
07
2018
retrieved
http://www.dot.gov.in/net-neutrality.
acm
journal
data
information
quality
vol
11
article
15
publication
date
june
2019
transparency
fairness
data
protection
neutrality
15
sara
hajian
josep
domingo-ferrer
2013
methodology
direct
indirect
discrimination
prevention
data
mining
ieee
trans
knowl
data
eng
25
2013
1445
1459
doi
https://doi.org/10.1109/tkde.2012.72
melanie
herschel
ralf
diestelkämper
houssem
ben
lahmar
2017
survey
provenance
form
vldb
26
2017
881
906
doi
https://doi.org/10.1007/s00778-017-0486-1
jagadish
johannes
gehrke
alexandros
labrinidis
yannis
papakonstantinou
jignesh
patel
raghu
ramakrishnan
cyrus
shahabi
2014
big
data
technical
challenges
commun
acm
57
2014
86
94
doi
https://doi.org/
10.1145
2611567
faisal
kamiran
indre
zliobaite
toon
calders
2013
quantifying
explainable
discrimination
removing
illegal
discrimination
automated
decision
making
knowl
info
syst
35
2013
613
644
doi
https://doi.org/10.1007/
s10115-012-0584-8
olga
kharif
september
2018
youtube
netflix
videos
found
slowed
wireless
carriers
bloomberg
sept
2018
retrieved
https://www.bloomberg.com/news/articles/2018-09-04/youtube-and-netflix-throttled-by-carriers-
research-finds
keith
kirkpatrick
2017
algorithm
data
commun
acm
60
jan
2017
21
23
doi
https://doi.org/10.
1145
3022181
jon
kleinberg
sendhil
mullainathan
manish
raghavan
2017
inherent
trade-offs
fair
determination
risk
scores
proceedings
8th
innovations
theoretical
computer
science
conference
itcs
17
43
43
23
doi
https://doi.org/10.4230/lipics.itcs.2017.43
joshua
kroll
joanna
huey
solon
barocas
edward
felten
joel
reidenberg
david
robinson
harlan
yu
2017
accountable
algorithms
univ
penn
law
rev
165
2017
retrieved
http://papers.ssrn.com/sol3/papers.cfm?
abstract_id
2765268
maurizio
lenzerini
2002
data
integration
theoretical
perspective
proceedings
21st
acm
sigmod-sigact
sigart
symposium
principles
database
systems
pods
02
acm
new
york
ny
233
246
doi
https://doi.org/10.
1145
543613.543644
shira
mitchell
eric
potash
solon
barocas
2018
prediction-based
decisions
fairness
catalogue
choices
sumptions
definitions
retrieved
https://arxiv.org/abs/1811.07867.
arash
molavi
kakhki
abbas
razaghpanah
anke
li
hyungjoon
koo
rajesh
golani
david
choffnes
phillipa
gill
alan
mislove
2015
identifying
traffic
differentiation
mobile
networks
proceedings
internet
measurement
conference
imc
15
acm
new
york
ny
239
251
doi
https://doi.org/10.1145/2815675.2815691
haoyue
ping
julia
stoyanovich
bill
howe
2017
datasynthesizer
privacy-preserving
synthetic
datasets
pro
ceedings
29th
international
conference
scientific
statistical
database
management
42
42
doi
https://doi.org/10.1145/3085504.3091117
marco
túlio
ribeiro
sameer
singh
carlos
guestrin
2016
trust
explaining
predictions
classifier
proceedings
22nd
acm
sigkdd
international
conference
knowledge
discovery
data
mining
1135
1144
doi
https://doi.org/10.1145/2939672.2939778
andrea
romei
salvatore
ruggieri
2014
multidisciplinary
survey
discrimination
analysis
knowl
eng
rev
29
2014
582
638
doi
https://doi.org/10.1017/s0269888913000039
julia
stoyanovich
bill
howe
2018
follow
data
algorithmic
transparency
starts
data
transparency
re
trieved
https://ai.shorensteincenter.org/ideas/2018/11/26/follow-the-data-algorithmic-transparency-starts-with-
data-transparency
julia
stoyanovich
bill
howe
serge
abiteboul
gerome
miklau
arnaud
sahuguet
gerhard
weikum
2017
fides
wards
platform
responsible
data
science
proceedings
29th
international
conference
scientific
sta
tistical
database
management
26
26
doi
https://doi.org/10.1145/3085504.3085530
european
parliament
council
2015
regulation
eu
2015
2120
retrieved
https://eur-lex.europa.eu/
legal-content
en
txt
uri
celex
32015r2120
european
union
2016
regulation
eu
2016
679
general
data
protection
regulation
gdpr
retrieved
https
gdpr-info
eu
new
york
city
council
2017
int
1696
local
law
relation
automated
decision
systems
used
agencies
retrieved
https://laws.council.nyc.gov/legislation/int-1696-2017/.
tim
wu
2003
network
neutrality
broadband
discrimination
telecommun
high
technol
law
2003
ke
yang
julia
stoyanovich
abolfazl
asudeh
bill
howe
jagadish
gerome
miklau
2018
nutritional
label
rankings
proceedings
international
conference
management
data
sigmod
18
1773
1776
doi
https
doi
org
10.1145
3183713.3193568
received
december
2018
accepted
december
2018
acm
journal
data
information
quality
vol
11
article
15
publication
date
june
2019