toward
two-sided
fairness
framework
search
recommendation
jiqun
liu
jiqunliu@ou.edu
university
oklahoma
norman
ok
usa
abstract
artificial
intelligence
ai
assisted
search
recommender
sys
tems
become
ubiquitous
workplaces
everyday
lives
understanding
accounting
fairness
gained
increasing
attention
design
evaluation
systems
growing
body
computing
research
measuring
system
fairness
biases
associated
data
algorithms
impact
human
biases
go
beyond
traditional
machine
learning
ml
pipelines
still
remain
understudied
perspective
paper
seek
develop
two-sided
fairness
framework
charac
terizes
data
algorithmic
biases
also
highlights
cognitive
perceptual
biases
may
exacerbate
system
biases
lead
unfair
decisions
within
framework
also
analyze
interactions
human
system
biases
search
rec
ommendation
episodes
built
upon
two-sided
framework
research
synthesizes
intervention
intelligent
nudging
strategies
applied
cognitive
algorithmic
debiasing
also
proposes
novel
goals
measures
evaluating
performance
sys
tems
addressing
proactively
mitigating
risks
associated
biases
data
algorithms
bounded
rationality
pa
per
uniquely
integrates
insights
regarding
human
biases
system
biases
cohesive
framework
extends
concept
fairness
human-centered
perspective
extended
fair
ness
framework
better
reflects
challenges
opportunities
users
interactions
search
recommender
systems
vary
ing
modalities
adopting
two-sided
approach
information
system
design
potential
enhancing
effectiveness
online
debiasing
usefulness
boundedly
rational
users
engaging
information-intensive
decision-making
ccs
concepts
information
systems
users
interactive
retrieval
keywords
two-sided
fairness
human
bias
system
bias
information
retrieval
recommender
system
permission
make
digital
hard
copies
part
work
personal
classroom
use
granted
without
fee
provided
copies
made
distributed
profit
commercial
advantage
copies
bear
notice
full
citation
first
page
copyrights
components
work
owned
others
acm
reference
format
jiqun
liu
2023
toward
two-sided
fairness
framework
search
recommendation
acm
sigir
conference
human
information
inter
action
retrieval
chiir
23
march
19
23
2023
austin
tx
usa
acm
new
york
ny
usa
11
pages
https://doi.org/10.1145/3576840.3578332
introduction
artificial
intelligence
ai
assisted
search
recommender
systems
become
ubiquitous
workplaces
everyday
lives
play
significant
role
human
decision-making
activities
however
underlying
algorithms
data
unfair
skewed
toward
particular
community
group
people
leading
biased
judgments
problematic
decisions
instance
compas
software
used
courts
united
states
estimate
risk
person
recommit
another
crime
likely
higher
false
positive
rates
predicting
recidivism
african
american
offenders
also
ai
systems
built
upon
medical
usage
data
mainly
collected
men
falsely
underestimate
risk
heart
attack
faced
women
aggravates
gender
inequality
health
ai-assisted
retrieval
algorithms
bert
12
22
behind
web
search
engines
face
similar
problems
picking
biases
data
providers
algorithm
designers
users
way
child
mimics
bad
behavior
parents
given
sociotechnical
challenges
growing
body
computing
research
strives
measure
system-side
fairness
mitigate
risks
biases
embedded
algorithms
training
data
56
increasing
research
efforts
give
rise
series
relevant
workshops
grants
emerging
communities
acm
facct
1.1
biased
systems
boundedly
rational
users
existing
research
achieved
significant
progresses
mea
suring
mitigating
system
bias
broad
range
application
scenarios
impact
human
bias
goes
beyond
traditional
ma
chine
learning
ml
pipelines
still
remains
understudied
according
kahneman
39
human
bias
refers
systematic
deviations
human
behavior
predictions
rational
normative
models
contrast
assumptions
many
simulated
user
models
peo
ple
boundedly
rational
decisions
often
affected
series
biases
mental
shortcuts
72
thus
interacting
author
must
honored
abstracting
credit
permitted
copy
otherwise
republish
post
servers
redistribute
lists
requires
prior
specific
permission
fee
request
permissions
permissions@acm.org
chiir
23
march
19
23
2023
austin
tx
usa
2023
copyright
held
owner
author
publication
rights
licensed
acm
acm
isbn
979
4007
0035
23
03
15.00
https://doi.org/10.1145/3576840.3578332
https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-
sentencing
https://www.forbes.com/sites/carmenniethammer/2020/03/02/ai-bias-could-put-
womens-lives-at-riska-challenge-for-regulators
https://www.nytimes.com/2019/11/11/technology/artificial-intelligence-bias.html
https://facctconference.org/.
chiir
23
march
19
23
2023
austin
tx
usa
liu
search
recommender
systems
user
may
dispropor
tionately
impacted
retrieved
results
recommended
items
trigger
behavioral
impact
existing
cognitive
biases
heuristics
causing
unexpected
unfair
outcomes
example
users
certain
misleading
beliefs
regarding
vaccines
vulnerable
related
misinformation
presented
search
engine
result
pages
serps
leading
ill-informed
undesired
med
ical
decisions
online
shoppers
tend
quickly
accept
immediate
mediocre
recommendations
encountering
several
bad-quality
products
recommended
system
low
reference
levels
differing
data
algorithmic
biases
human
biases
tend
individualized
context-dependent
40
75
closely
associated
people
previous
similar
experiences
case-based
decision
making
29
however
system
bias
human
bias
result
unfair
decisions
negative
societal
impacts
identify
mitigate
risks
potential
biases
sides
fundamental
open
challenge
information
retrieval
ir
recommender
systems
rs
communities
1.2
two-sided
fairness
perspective
address
gap
re-conceptualize
fairness
ai
user-centered
perspective
propose
two-sided
fairness
frame
work
deconstructs
impact
system
bias
human
bias
interactive
search
recommendation
ai-assisted
de
cision
making
aligned
objectives
chiir
perspective
paper
track
work
seeks
present
novel
insights
iden
tify
open
questions
conceptual
methodological
evaluation
levels
extend
concept
fairness
cover
effects
measurements
human
bias
system
bias
embedded
data
algorithms
well
possible
interactions
propose
new
two-sided
evaluation
methods
can
examine
performance
search
recommender
systems
addressing
proactively
reducing
impacts
human
system
biases
synthesize
empirically
tested
re-ranking
interven
tion
nudging
techniques
potentially
miti
gate
risks
one
types
biases
accomplishing
goals
paper
makes
three
fold
contributions
integrates
interdisciplinary
insights
ir
recommendation
ai
fairness
cognitive
psychol
ogy
offers
balanced
psychologically
realistic
approach
measuring
evaluating
fairness
users
interactions
intelligent
information
systems
ii
highlights
available
tools
recommendation
re-ranking
system
intervention
intel
ligent
nudging
techniques
mitigating
risks
system
human
biases
information-intensive
tasks
iii
proposes
novel
evaluation
metrics
measure
performance
systems
re
ducing
system
human
biases
employed
tested
broader
scope
search
recommendation
scenarios
addition
paper
also
identifies
new
fundamental
em
pirical
issues
emerge
extended
fairness
concept
potential
inspire
substantive
discussions
significant
progresses
field
extending
scope
fairness
going
beyond
mainstream
studies
algorithmic
fairness
section
presents
extended
definition
fairness
sets
con
straints
system
bias
human
bias
users
interactions
systems
extended
concept
fairness
system
will
evaluated
based
performance
reducing
biases
inherited
data
algorithms
also
ability
protecting
users
risks
contextual
triggers
cognitive
perceptual
biases
two-sided
fairness
framework
incorporates
features
biases
sides
speaks
new
challenges
understanding
supporting
boundedly
rational
users
inter
acting
potentially
biased
systems
2.1
notions
system
fairness
search
recommender
systems
employed
grow
ing
user
population
main
channel
information
access
varying
tasks
including
ones
sensitive
environments
health
information
seeking
hiring
job
application
63
80
financial
decision
making
thus
underlying
biased
data
unfair
algorithm
affect
information
pre
sentation
also
lead
unfair
distributions
economic
socio-technical
resources
address
inspired
classic
research
fairness
psychology
philosophy
14
37
researchers
proposed
series
fairness
definitions
focusing
varying
levels
fac
tors
employed
constraints
mitigate
bias
discrimination
retrieval
recommendation
algorithms
ac
cording
56
existing
fairness
definitions
can
grouped
three
categories
individual
fairness
group
fairness
sub
group
fairness
individual
fairness
requires
systems
give
similar
predictions
individual
users
content
genera
tors
similar
characteristics
regardless
differences
protected
sensitive
attributes
gender
ethnicity
popu
larity
13
23
45
group
fairness
concept
focuses
potential
biases
sensitive
groups
communities
emphasizes
groups
treated
equally
23
24
45
subgroup
fair
ness
combines
features
fairness
concepts
measures
whether
fairness
constraint
holds
large
set
subgroups
41
42
existing
fairness
concepts
measures
seek
mitigate
prevent
varying
types
observable
unfairness
re
trieved
contents
recommended
items
especially
respect
certain
protected
attributes
however
potential
risks
implicit
unfairness
generated
combination
system
output
user
biases
still
remain
unclear
2.2
human
bias
bounded
rationality
differing
simplified
simulated
agents
seeking
maximized
utility
real-life
users
often
operates
impact
cognitive
perceptual
biases
attempt
satisfice
achieve
good
enough
results
rather
optimize
39
72
human
biases
satisficing
strategies
covered
theoretical
umbrella
bounded
rationality
drive
users
unconsciously
make
bi
ased
judgments
regarding
retrieved
information
recommended
items
unfair
decisions
sensitive
environments
current
fair
ness
metrics
constraints
focusing
biases
data
retrieval
algorithms
recommendation
mechanisms
widely
applied
toward
two-sided
fairness
framework
search
recommendation
chiir
23
march
19
23
2023
austin
tx
usa
standardized
offline
experiments
independent
user
characteristics
design
thus
extending
existing
fairness
con
cepts
cover
human
biases
essential
especially
scenarios
algorithmically
fair
systems
still
result
prac
tically
unfair
information
use
decisions
instance
users
may
click
save
search
results
consistent
pre-search
expectations
opinions
certain
cognitive
author
ities
despite
diverse
set
topics
perspectives
content
generators
included
serp
confirmation
bias
70
ad
dition
diverse
recommended
items
ranked
similar
positions
may
receive
significantly
different
amounts
actual
attention
due
divergence
users
remembered
experiences
similar
products
reference
dependence
51
given
challenge
critical
enrich
fairness
concept
user
dimensions
evaluate
performance
search
recommender
systems
identifying
preventing
mitigating
negative
effect
hu
man
bias
methodological
level
adopting
certain
intervention
nudging
techniques
cognitive
debiasing
may
ad
dress
immediate
biased
judgments
current
interactions
also
generate
sustained
impacts
future
information
searching
recommendation
assessments
52
53
87
2.3
interaction
human
bias
system
bias
human
bias
system
bias
can
interact
dif
ferent
stages
users
interactions
ir
recommender
sys
tems
search
initiation
query
reformulation
brows
ing
clicking
evaluation
information
items
products
instance
ge
et
al
28
studied
interactions
users
interests
anchoring
level
personalized
e-commerce
recom
mendations
particular
based
interaction
logs
gathered
alibaba
taobao
transactions
researchers
measured
self
reinforcement
effect
users
interests
caused
narrowed
exposure
recommended
product
types
mutual
reinforce
ment
users
initial
preferences
customized
rec
ommendations
tailored
according
in-situ
behaviors
lead
echo
chamber
effect
ir
evaluation
scholer
et
al
69
inves
tigated
dynamic
thresholds
external
assessors
document
judgments
associations
sequence
presenting
documents
varying
relevance
results
indicate
initially
encountered
high-quality
documents
may
heighten
user
refer
ence
level
relevance
leading
underestimated
relevance
levels
subsequent
document
judgments
addition
human-system
interactions
azzopardi
also
argues
information
searchers
may
experience
mixed
effects
multiple
cognitive
biases
search
evaluation
interacting
set
algorithmically
fair
re
sults
different
users
may
significantly
different
chances
making
biased
judgments
due
differences
pre-interaction
references
expectations
remembered
experiences
in-situ
perceived
gains
efforts
users
biases
system
biases
may
re
inforce
implicit
feedback
learning
rank
ltr
personalized
recommendation
processes
human
biases
difficult
observe
often
act
unconsciously
still
cause
unfair
decisions
tangible
consequences
people
different
beliefs
knowledge
bases
prior
experiences
figure
two-sided
bias
structure
users
interactions
search
recommender
systems
make
matter
worse
users
biases
often
purposely
exploited
increasing
engagements
profits
especially
online
shopping
social
media
feeds
marketing
promotions
33
77
86
leading
unseen
unfairness
compared
widely
discussed
protected
tributes
cf
18
factors
associated
human
biases
usually
hidden
fast
judgments
intuitive
decisions
closely
re
lated
local
contexts
search
intention
domain
knowledge
cog
nitive
load
individual
characteristics
short-term
memory
span
thus
understanding
achieving
human-centered
fairness
empirically
challenging
also
equally
important
reaching
system
fairness
especially
ai
machine
learning
components
19
era
information
ubiquity
two-sided
fairness
framework
built
upon
discussions
section
proposes
two-sided
fairness
framework
takes
consideration
features
ef
fects
measurements
human
bias
system
bias
extended
fairness
concept
can
inspire
inform
balanced
user-aware
approach
evaluating
fairness
search
rec
ommender
systems
figure
illustrates
biases
human
system
sides
may
operate
different
stages
user
interactions
given
mainstream
fairness
research
focusing
algorithmic
fairness
ai
ml
framework
presents
balanced
approach
addressing
two-sided
biases
different
stages
pre-interaction
interaction
post-interaction
emphasis
impacts
human
biases
note
work
discusses
major
types
human
system
biases
especially
ones
empirically
examined
search
recommendation
contexts
able
exhaust
possible
biases
comprehensive
list
human
bias
offered
benson
3.1
pre-interaction
stage
many
conditions
triggers
human
bias
system
bias
formed
long
users
interactions
systems
actually
occur
system
side
biases
data
employed
training
cognitive
bias
cheat
sheet
https://betterhumans.pub/cognitive-bias-cheat-sheet-
55a472476b18
chiir
23
march
19
23
2023
austin
tx
usa
liu
ml-based
algorithms
ltr
adaptive
recommendation
may
re
sult
biased
algorithmic
outcomes
biases
training
data
may
originate
biased
sampling
curation
processes
creates
non-representative
samples
well
existing
histori
cal
bias
socio-technical
problems
reality
74
data
bias
unfairness
may
also
occur
due
human
prejudice
stereotyping
based
upon
sensitive
attributes
56
addition
part
data
bias
result
biased
behaviors
interactions
across
varying
recommendation
platforms
search
interfaces
61
instance
users
may
spend
time
clicks
results
items
ranked
top
serps
consistent
expectations
generate
skewed
feedback
data
rein
force
existing
biases
relevance
usefulness
estimations
55
human
side
users
pre-search
expectations
interests
preferences
well
beliefs
knowledge
base
affected
remembered
prior
experiences
similar
scenarios
cases
cbdt
29
individual
characteristics
example
users
may
choose
avoid
certain
information
sources
vendors
due
previous
negative
experience
similar
scenarios
also
users
lack
certain
domain
knowledge
may
skip
unfamiliar
seemingly
ambiguous
results
serps
60
cognitive
factors
usually
shape
reference
levels
based
users
evaluate
available
options
interactions
retrieved
results
rec
ommended
queries
products
well
search
continuation
stopping
reference
dependence
bias
79
divergent
reference
levels
users
interacting
similar
result
lists
tend
perceive
evaluate
information
gains
search
efforts
differently
re
sulting
distinct
search
tactics
judgments
decision-making
strategies
15
51
addition
pre-interaction
factors
also
affect
extent
user
vulnerable
negative
impact
potential
biases
interactions
instance
medical
expert
may
less
likely
influenced
vac
cine
misinformation
ranked
top
positions
serps
compared
novice
searchers
field
computer
scientist
familar
personalized
recommendation
algorithms
may
possess
high
level
algorithm
awareness
cf
34
sensitive
biased
recommendations
personalized
systems
inves
tigating
pre-interaction
factors
associated
human
biases
will
allow
researchers
better
understand
users
different
backgrounds
prior
interaction
experiences
may
signifi
cantly
different
likelihood
achieving
optimal
utility
desired
outcomes
facing
similar
sets
information
recommen
dations
3.2
interaction
stage
system
side
biased
algorithmic
decision
music
recom
mendations
provide
fair
representation
new
artists
global
economy
search
results
mainly
focuses
small
set
developed
economies
happen
data
biases
inherited
training
built-in
biases
embedded
algo
rithms
56
existing
research
system
algorithmic
fairness
fairness
often
broadly
defined
absence
prejudice
fa
voritism
towards
individual
group
based
intrinsic
acquired
traits
context
decision-making
67
according
35
general
rule
fairness
can
written
represents
predicted
results
binary
variable
indicates
data
point
represents
protected
group
member
goal
equalized-odds
fairness
constraint
probability
item
positive
category
correctly
assigned
positive
label
probability
item
negative
class
incorrectly
put
positive
category
stay
regardless
protected
membership
labels
56
81
instance
level
actual
relevance
quality
contents
products
produced
popular
new
providers
obtain
equalized
likelihood
exposure
similar
rank
positions
also
searching
controversial
topic
users
access
fairly
distributed
information
sources
diverse
perspectives
equalized-odds
fairness
measure
also
adjusted
ac
cording
specific
application
scenarios
fairness
requirements
example
equalized-opportunity
fairness
focuses
positive
labels
requires
probability
item
positive
class
labeled
positive
outcome
equal
protected
unprotected
group
members
35
constraint
can
written
similar
rules
can
also
applied
group
subgroup
fairness
research
equal
true
positive
false
positive
rates
achieved
ml-based
predictions
groups
different
pro
tected
attribute
labels
mitigating
restricting
behind-the-scenes
algorithmic
biases
result
fairer
presentation
infor
mation
recommendations
accessed
users
apart
abstracted
biases
predictions
researchers
also
explored
potential
system
biases
interface
design
information
pre
sentation
60
68
trigger
users
misapplication
mental
shortcuts
heuristics
39
75
thereby
cause
obstacles
inferential
thinking
information
evaluation
differing
data
algorithmic
biases
external
la
beling
relatively
straightforward
human
biases
emerge
operate
interactions
often
difficult
measure
re
searchers
design
diverse
experimental
conditions
assigned
triggers
cognitive
biases
controlled
lab
settings
39
85
challenging
measure
biases
users
real-time
interactions
search
recommender
systems
ill-defined
complex
tasks
however
critical
study
human
bias
incite
discussions
human-side
fairness
users
may
end
implicitly
disadvantaged
positions
interactions
systems
due
cognitive
perceptual
biases
triggered
certain
contextual
factors
system
outputs
individual
traits
figure
presents
hypothetical
example
search
recommendation
iteration
query
question
illustrate
interrelated
hu
man
biases
operate
interaction
sessions
instance
interacting
retrieved
products
information
items
users
may
prefer
examine
click
ones
confirm
pre-interaction
expectations
beliefs
less
likely
chal
lenge
existing
status
quo
mind
confirmation
status
quo
bias
66
reduce
probability
cognitive
dis
sonance
47
knowledge
restructuring
addition
initially
toward
two-sided
fairness
framework
search
recommendation
chiir
23
march
19
23
2023
austin
tx
usa
figure
interrelated
human
biases
within
interactions
encountered
results
recommended
items
used
ref
erence
anchoring
points
users
evaluation
following
items
especially
terms
perceived
gains
costs
involved
browsing
examination
reference
dependence
thus
user
encounters
high-quality
item
beginning
iter
ation
highly
relevant
document
five-start
product
good
price
user
may
form
relatively
high
reference
level
in-situ
expectation
mind
result
slight
drop
item
qual
ity
small
increases
efforts
dwell
time
number
clicks
recommendations
examined
may
lead
major
decrease
interaction
satisfaction
following
browsing
clicking
activ
ities
loss
aversion
bias
threshold
priming
51
69
79
also
users
may
choose
avoid
search
results
framed
ambiguous
unfamiliar
risky
option
risk
aversion
framing
effect
43
54
62
however
user
starts
low
ref
erence
level
expectation
perceptions
evaluations
subsequent
items
may
change
completely
despite
nature
items
stay
decoy
effect
refers
scenarios
people
change
preference
two
existing
options
presented
third
option
decoy
asymmetrically
dominated
78
88
ir
crowdsourcing
labeling
eickhoff
25
examined
impact
decoy
document
users
thresholds
strategies
standard
relevance
judgments
instance
convenient
store
customer
may
find
difficult
decide
apple
banana
afternoon
snack
however
rotten
apple
decoy
placed
next
existing
apple
customer
may
find
apple
favorable
option
perceived
gain
compared
decoy
reference
figure
shows
may
difficult
predict
user
preference
document
document
associated
two
different
subtopics
respectively
however
symmetrically
dom
inated
document
presented
topic
similar
likely
user
will
give
higher
score
target
document
ir
user
may
compare
target
decoy
results
multiple
dimensions
relevance
usefulness
perceived
credibility
readability
essence
decoy
effect
person
preference
two
options
altered
completely
adding
decoy
option
without
changing
nature
existing
options
similar
impacts
decoy
also
empirically
confirmed
online
recommendation
e-commerce
settings
71
86
differing
human
biases
introduced
rank
position
bias
83
easier
observe
surface
interactions
discussed
wide
range
ir
particularly
unbiased
ltr
rs
experiments
20
32
knowledge
regarding
rank
position
bias
widely
applied
simulating
user
mod
els
underlying
offline
evaluation
metrics
users
attention
likelihood
clicking
examination
often
assumed
decreasing
rank
serp
recommendation
evaluations
17
58
however
actual
effect
rank
position
bias
may
moderated
form
modality
search
results
rec
ommendations
instance
researchers
found
compared
organic
search
results
vertical
results
recommendations
news
images
may
appear
visually
salient
reduce
impact
rank
positions
probability
examination
clicking
82
discussed
human
biases
triggered
series
pre-interaction
factors
within-interaction
factors
rank
position
decoy
items
initially
encountered
items
distance
similarity
results
triggered
human
biases
lead
significant
deviations
users
behaviors
judgments
optimal
desired
results
consequently
unfair
decisions
outcomes
may
occur
users
vulnerable
certain
biases
contextual
triggers
ones
extending
existing
fairness
concepts
two-sided
fairness
framework
seek
highlight
characterize
assess
human
side
unfairness
search
recommender
systems
3.3
post-interaction
stage
post-interaction
stage
mixed
effect
system
biases
human
biases
may
result
biased
information
evaluation
use
unfair
decisions
undesired
outcomes
system
side
bi
ased
algorithmic
decision
come
black-box
re-ranking
recommendation
model
training
data
generated
pre
within-interaction
stages
learning
algorithms
modified
scrutinized
human
side
addition
within-interaction
biases
users
may
subject
influence
whole-session
cognitive
biases
making
decisions
based
remembered
experiences
instance
evaluating
comparing
performances
multiple
queries
systems
users
heavily
influenced
peak
point
end
most-recent
point
experience
sessions
evaluated
sensitive
actual
time
duration
interaction
peak
end
rule
duration
neglect
36
51
64
memory-related
biases
may
lead
significant
divergence
users
retrospec
tive
satisfaction-based
judgments
assessment
system
designers
lead
unfair
evaluations
systems
interaction
experiences
whole-session
contexts
3.4
two-sided
fairness
goals
system-side
fairness
goal
can
adapted
current
fairness
objectives
ai
ml
fairness
indicated
sub-section
3.2
despite
difference
specific
measures
common
underlying
goal
achieve
equal
true
positive
false
positive
prediction
rates
protected
unprotected
group
members
identified
pre-defined
protected
attributes
prediction
results
chiir
23
march
19
23
2023
austin
tx
usa
liu
usually
associated
critical
decisions
societal
impacts
healthcare
hiring
house
mortgage
approval
48
56
regarding
human-side
fairness
can
adopt
similar
approach
write
represents
desired
accessible
optimal
outcome
individual
group
represents
set
attributes
contex
tual
features
associated
human
biases
indicates
user
belongs
protected
group
vulnerable
certain
cognitive
perceptual
biases
represents
actual
outcome
utility
information
use
decision-making
human-side
fairness
goal
users
similar
intentions
teracting
search
recommender
systems
backgrounds
similar
chance
obtaining
desired
outcomes
interaction
regardless
actual
vulnerability
human
biases
triggered
group
membership
variable
can
written
t1
predicting
desired
outcomes
estimating
optimal
comes
based
nature
tasks
problems
moti
vate
users
engage
systems
t2
estimating
real-time
risk
cognitive
perceptual
biases
individuals
groups
based
knowledge
user
characteristics
features
system
outputs
t3
learning
bias-aware
user
models
characterize
users
information
evaluation
use
decision-making
patterns
impact
biases
among
tasks
t1
will
offer
ground
truth
labels
eval
uating
fairness
probability
obtaining
desired
optimal
outcomes
well-structured
tasks
clearly-defined
goals
labels
also
extracted
users
annotations
task
goals
t2
will
generate
protected
attribute
labels
classify
individuals
multiple
categories
among
human-centered
fairness
needs
achieved
accomplishing
t2
developing
bias-aware
interventions
will
enhance
equal
access
quality
infor
mation
facilitate
unbiased
judgments
encountered
informa
tion
thereby
contribute
completion
t1
models
built
t3
will
allow
us
predict
potential
biased
judgments
de
cisions
based
estimated
risks
biases
individual
traits
represents
user
estimated
vulnerability
potential
human
bias
without
loss
generality
sume
every
binary
variable
probability
user
vulnerable
determined
function
three
variables
individual
characteristics
user
prior
experiences
expectations
beliefs
triggers
sys
tem
outputs
explained
previous
sub-sections
different
human
biases
may
involve
diverse
mechanisms
probabilities
triggered
39
thus
represented
separate
functions
addition
researchers
system
designers
also
explore
interplay
varying
biases
different
stages
inves
tigate
addressing
certain
human
biases
mitigate
increase
risk
encountering
biases
query
reformulation
judg
ment
results
recommendations
well
post-interaction
decision-making
3.5
two-sided
fairness
human-centered
system
evaluation
based
goals
defined
researchers
can
evaluate
performance
search
recommender
systems
fulfilling
sociated
fairness
constraints
27
81
84
regarding
system
fairness
predictions
output
ranked
results
customized
recommendations
systems
can
evaluated
according
measures
specified
sub-section
3.2
instance
making
algorithmic
decisions
music
recommendations
critical
assess
probabilities
rank
positions
recommending
rele
vant
musics
equal
across
artists
varying
backgrounds
57
addition
active
approach
system
fairness
constraint
may
also
achieved
unawareness
algorithm
can
considered
fair
protected
attribute
explicitly
adopted
making
decisions
31
human
side
evaluation
needs
built
upon
series
preparation
work
specifically
one
complete
following
tasks
assessing
human-centered
fairness
in-situ
contextual
triggers
models
researchers
proactively
identify
biased
behaviors
problematic
decisions
actually
occur
human-centered
fairness
constraints
evaluating
serps
ranked
list
recommended
items
measure
explicit
biases
associated
pro
tected
sensitive
attributes
also
estimate
risk
triggering
varying
types
human
biases
introduced
figure
depending
specific
systems
user
interacts
nature
motivating
tasks
weights
human-side
fairness
system-side
fairness
tailored
varying
evaluation
preferences
3.6
two-sided
fair
ranking
intervention
intelligent
nudging
previous
ir
ml
human-computer
interaction
hci
studies
series
re-ranking
intervention
nudging
techniques
developed
system
bias
mitigation
cognitive
debiasing
help
enhance
two-sided
fairness
system
algorithmic
side
bias
mitigation
methods
developed
ml
pipeline
can
grouped
three
categories
stages
pre
processing
in-processing
post-processing
56
pre-processing
category
covers
techniques
used
reducing
removing
bias
discrimination
datasets
employed
training
ranking
recommendation
algorithms
10
instance
researchers
can
apply
preferential
sampling
methods
address
discrimination
search
recommendation
logs
ensure
fair
representation
samples
diverse
communities
populations
training
rankers
in-processing
group
includes
techniques
modifying
learning
algorithms
removing
biases
interaction
model
training
processes
11
instance
ir
researchers
can
ad
just
ltr
algorithms
counterfactual
methods
mitigate
possible
biases
noise
learned
historical
data
user
behaviors
search
sessions
rank
position
bias
38
toward
two-sided
fairness
framework
search
recommendation
chiir
23
march
19
23
2023
austin
tx
usa
figure
enhancing
two-sided
fairness
post-processing
methods
applied
training
allow
sys
tems
reassign
labels
created
potentially
biased
black-box
models
21
human-centered
fairness
side
series
intelligent
interven
tion
nudging
techniques
proposed
empirically
tested
search
recommendation
diverse
set
hci
sce
narios
instance
systems
transform
digital
information
add
visual
aids
interfaces
reduce
perceived
ambiguity
increase
saliency
certain
information
16
73
also
effective
nudging
debiasing
achieved
changing
de
cision
structure
altering
starting
anchoring
options
proactively
adjust
ranking
structure
lead
negative
decoy
effects
re-arranging
evaluation
sequences
prevent
potential
priming
effects
reference
dependence
bias
16
69
76
addition
researchers
leverage
power
cognitive
au
thority
query
priming
techniques
designing
in-situ
inter
ventions
nudging
users
toward
effective
search
terms
paths
52
87
apart
individual-level
factors
researchers
also
explored
effect
social
factors
users
attitudes
behaviors
friends
colleagues
know
deci
sion
59
adding
changing
social
consequences
demonstrated
effective
technique
promoting
green
lifestyle
health
diet
30
46
may
also
leveraged
encouraging
critical
thinking
active
reflection
possible
biased
judgments
recommendations
acceptance
diverse
opinions
perspectives
due
diverse
nature
human
biases
spe
cific
intervention
nudging
methods
need
customized
adjusted
real-time
according
involved
user
characteristics
in-situ
estimated
risks
individual
biases
also
possible
interactions
mutual-reinforcements
multiple
biases
need
considered
designing
set
nudging
techniques
based
discussions
figure
summarizes
tasks
associated
enhancing
two-sided
fairness
similar
three
stage
structure
data
algorithmic
debiasing
human-side
fair
ness
can
also
achieved
enhanced
multiple
stages
specifi
cally
systems
proactively
estimate
potential
risks
biases
based
knowledge
users
learned
previous
interac
tion
data
structure
current
serp
recommendation
list
estimated
risk
levels
systems
can
decide
specific
actions
re-ranking
adaptive
intervention
digital
nudging
take
following
interactions
addition
biased
behaviors
judgments
occur
systems
can
adjust
ranking
algorithms
recommendation
strategies
accordingly
correct
biased
re
sults
remove
contextual
triggers
cause
biases
user
interaction
completed
system
may
still
provide
post-interaction
interventions
summarize
present
possible
biases
extracted
whole-session
interactions
im
plicit
feedback
order
least
partially
address
human
bias
decision-making
making
personal
health
decision
choosing
recommended
products
purchase
deciding
applicant
interview
hire
practical
applications
potential
challenges
interacting
information
systems
making
decisions
uncertainty
users
protected
bias
discrimination
emerge
system
biases
associated
sensitive
attributes
also
negative
impact
human
biases
triggered
individual
traits
contextual
factors
two-sided
fairness
framework
applied
broad
range
search
recommendation
interaction
scenarios
4.1
practical
applications
two-sided
fairness
concept
offers
new
perspective
evalu
ating
users
interactions
systems
varying
modalities
instance
evaluating
fairness
conversational
search
recommendation
systems
apart
observable
biases
system
responses
researchers
also
investigate
signals
cognitive
biases
utterances
interactions
addition
systems
can
predict
clarify
potential
biases
misleading
beliefs
unrealistic
expectations
regarding
certain
products
users
promoting
recommended
questions
asking
clarifying
questions
analyzing
users
reactions
potential
bias
identified
system
push
certain
reminders
alerts
user
unfair
decision
made
similarly
traditional
recommenda
tion
scenarios
systems
can
proactively
analyze
item
list
recommended
estimate
risk
cognitive
biases
triggered
individual
item
reference
dependence
confir
mation
status
quo
bias
combination
biases
loss
risk
aversion
decoy
effect
information
user
built-in
recommendation
algorithms
systems
can
develop
adaptively
adjust
models
predict
users
vulnerability
different
types
biases
provided
personalized
solutions
instance
system
apply
reinforcement
learning
rl
based
approach
can
offer
iteratively
optimized
ranking
recommendations
based
identified
bias
states
represented
varying
estimated
risks
biases
moment
similarly
two-sided
fairness
approach
also
em
ployed
measuring
mitigating
algorithmic
human
biases
social
media
platforms
instance
systems
include
affordance
components
allow
proactively
identify
triggered
cognitive
biases
may
increase
user
chance
receiving
accepting
certain
health
misinformation
predict
ing
identifying
biased
behavior
judgments
may
need
involve
two
models
global
model
captures
dismantles
structure
recommendations
triggering
biases
information
evaluation
identifying
removing
potential
decoy
results
trigger
acceptance
low-quality
irrelevant
infor
mation
personalized
model
covers
individual
character
istics
assessing
risk
human
bias
extracting
in-situ
reference
points
expectations
past
similar
experiences
chiir
23
march
19
23
2023
austin
tx
usa
liu
on-going
interactions
estimate
perceived
gains
costs
interactions
apart
system-initiated
intervention
intelligent
nudg
ing
addressing
two-sided
biases
particularly
human
biases
also
achieved
enhancing
users
algorithmic
literacy
awareness
44
65
instance
librarians
traditional
information
gatekeepers
can
design
implement
education
pro
grams
tools
community
members
familiar
search
recommendation
algorithms
vulnerable
bias
discrimination
emerging
system
human
biases
library
information
science
lis
professionals
may
provide
proactive
support
users
engaging
complex
black-box
recommender
systems
help
understand
decisions
algorithms
impacts
real-time
behaviors
feedback
scope
focus
recommendations
addition
incorporating
two-sided
fairness
framework
practices
information
search
education
improve
users
awareness
potential
biases
interacting
results
search
recommender
systems
facilitate
effective
fair
decision
making
4.2
potential
challenges
two-sided
fairness
framework
can
extend
scope
promoting
fairness
ir
rs
beyond
applying
approach
also
involves
additional
challenges
need
studied
addressed
many
potential
challenges
associated
preparation
tasks
completed
estimating
human
biases
see
section
3.5
specifically
regarding
t1
prediction
results
will
serve
ground
truth
label
measuring
fairness
equal
probabil
ity
achieving
desired
optimal
outcomes
challenging
mainly
three
reasons
predicting
desired
outcomes
requires
knowledge
user
intentions
nature
motivating
task
difficult
obtain
real-time
interactions
according
existing
relevant
research
49
scenarios
motivating
tasks
complex
ill-defined
users
selves
may
clear
goal
desired
outcome
leading
difficulty
evaluating
fairness
human
side
contrast
pre-defined
protected
attributes
fairness
goals
algorith
mic
side
users
intentions
desired
outcomes
may
change
time
calls
adaptive
context-dependent
approach
assessing
fairness
apart
technical
difficulties
predicting
desired
outcomes
estimating
risks
biases
t2
require
information
users
background
prior
expe
riences
similar
problems
may
lead
ethical
issues
privacy
concerns
address
challenge
system
designers
protect
restrict
usage
interaction
history
data
human
bias
data
model
training
fairness
evaluation
enable
users
aware
control
collec
tion
usage
processing
data
regarding
potential
cognitive
perceptual
biases
addition
certain
restrictions
regulations
implemented
better
managing
data
reuse
replication
experiments
human-centered
fairness
evaluation
respect
t3
learning
accurate
useful
bias-aware
user
models
may
require
data
regarding
user
behaviors
within
outside
interactive
information
systems
users
offline
purchase
decisions
supermarkets
effect
changing
reference
prices
decoy
options
users
existing
understanding
pref
erences
foreign
policy
topic
reading
political
science
textbook
addition
challenges
data
collection
users
may
difficulty
labeling
biased
behav
iors
naturalistic
settings
cognitive
biases
operate
unconsciously
information
evaluation
decision-making
sce
narios
causing
obstacles
training
testing
bias-aware
user
models
also
since
fairness
decisions
may
also
affected
factors
outside
search
recommendations
users
ex
isting
biases
beliefs
available
support
domain
experts
time
constraints
changing
ranking
algorithms
recommendation
mechanisms
interface
presentations
may
guarantee
successful
transition
information
fairness
tangible
fairness
task
performances
decision-making
new
questions
directions
two-sided
fairness
framework
propose
series
new
questions
directions
encouraging
discussions
related
problems
inspiring
future
research
user-centered
fairness
evaluation
5.1
understanding
biases
different
sources
basis
measuring
promoting
fairness
researchers
need
investigate
biases
varying
sources
characterize
implicit
interactions
among
can
start
addressing
following
research
questions
rqs
rq1
different
user
biases
triggered
previ
ous
experiences
system
outputs
individual
character
istics
users
interactions
search
recommender
systems
rq2
user
biases
interact
system
biases
dif
ferent
phases
interactions
query
reformulation
browsing
examination
search
results
recommen
dations
clicking
evaluation
rq3
extent
distribution
user
biases
vary
across
different
tasks
systems
addressing
first
three
rqs
require
researchers
con
duct
extensive
user
studies
carefully
examine
connections
individual
biases
users
tasks
systems
particularly
critical
differentiate
individual
biases
in-situ
natural
pref
erences
enhance
users
awarenss
potential
risks
without
intervening
tasks
challenging
especially
different
types
biases
correlated
generat
ing
mixed
effect
judgments
information
items
post
interaction
decision-making
knowledge
learned
rqs
will
offer
empirical
basis
estimating
risks
biases
real-time
interactions
5.2
evaluating
two-sided
fairness
human-sided
fairness
evaluation
work
defines
fairness
goal
without
specifying
individual
fairness
measures
determining
specific
measures
require
answers
least
two
rqs
toward
two-sided
fairness
framework
search
recommendation
chiir
23
march
19
23
2023
austin
tx
usa
rq4
different
user
biases
lead
biased
judgments
unfair
decisions
rq5
can
evaluate
system
fairness
addressing
negative
impact
human
biases
different
desired
outcomes
intentions
varying
types
differing
algorithmic
debiasing
goal
can
quan
tified
beforehand
protected
attributes
defined
different
human
biases
may
coupled
varying
types
behaviors
desired
outcomes
require
customized
fairness
measures
constraints
system
training
evaluation
therefore
rq4
rq5
highlight
connections
human
fairness
measures
user
behaviors
decisions
goals
interactions
aiming
clarify
role
human
biases
interaction
processes
findings
two
rqs
may
result
bias-aware
user
model
characterizes
user
search
behavior
decision-making
patterns
varying
biases
separate
fairness
metrics
evaluation
varying
intentions
desired
outcomes
5.3
enhancing
two-sided
fairness
moving
towards
enhancing
two-sided
fairness
researchers
need
examine
usefulness
appropriateness
available
tools
hand
aligned
discussions
presented
section
4.1
propose
following
two
rqs
starting
point
direction
research
rq6
can
enhance
two-sided
fairness
address
varying
types
biases
using
re-ranking
intervention
intelligent
nudging
techniques
rq7
can
enhance
two-sided
fairness
ad
dress
varying
types
biases
improving
users
algo
rithmic
literacy
awareness
human
system
biases
differing
previously
asked
causal-inference
questions
rq1
rq4
rq6
rq7
closely
related
application-oriented
practical
questions
may
yield
highly
contextual-dependent
answers
field
studies
instance
effectiveness
specific
interventions
nudging
techniques
algorithmic
literacy
ed
ucation
programs
may
vary
significantly
across
different
types
systems
populations
varying
background
therefore
studying
two
rqs
may
also
involve
fairness
issue
unique
traits
needs
challenges
different
community
members
groups
fully
considered
equally
represented
testing
intervention
tools
education
programs
also
practical
application
researchers
system
designers
balance
autonomy
users
role
recommendations
evaluate
broad
range
approaches
enhancing
two-sided
fairness
users
in-situ
reminders
possible
biased
judgments
suggestions
search
tactics
proactive
re-ranking
recom
mendations
based
estimated
risks
5.4
ethical
challenges
data
reusability
similar
user-centered
evaluation
studies
research
two
sided
fairness
will
involve
sensitive
expensive
time-consuming
process
collecting
labels
signals
regarding
user
features
case
human-side
biases
fairness
result
researchers
need
face
set
ethical
practical
challenges
exploration
problem
space
may
start
two
rqs
rq8
can
measure
promote
two-sided
fairness
also
protect
users
private
information
regarding
indi
vidual
biases
previous
experiences
rq9
can
effectively
reuse
data
regarding
two
sided
biases
fairness
amortizing
true
cost
user
experiments
rq8
address
adding
additional
privacy
protection
constraints
model
training
system
outputs
design
pun
ishments
significantly
reducing
evaluation
score
risk
bias
data
leakage
captured
regarding
rq9
researchers
need
develop
standard
framework
guiding
data
curation
sharing
assessing
reusability
behavior
annotation
datasets
collected
individual
user
studies
26
50
effective
data
reuse
allow
researchers
develop
meta-evaluate
effectiveness
two-sided
fairness
measures
across
varying
dtasets
systems
populations
5.5
user
people
interacting
information
apart
specific
rqs
new
directions
presented
long-term
vision
studying
users
people
interacting
information
rather
agents
operating
systems
discon
nected
specific
tasks
socio-technical
contexts
main
idea
behind
vision
expect
people
leave
specific
contexts
interacting
search
recommender
systems
act
users
way
assumed
instead
peo
ple
interactions
information
systems
characterized
evaluated
contexts
aligned
idea
two-sided
fairness
framework
goes
beyond
traditional
system
fairness
measures
sets
clear
bound
aries
algorithms
users
investigate
concept
human-centered
fairness
reconnect
users
biases
factors
contexts
problematic
situations
sense
studying
implementing
two-sided
fairness
evaluation
will
expand
scope
research
fairness
ir
rs
human-ai
interaction
general
also
contribute
general
efforts
bringing
users
interacting
information
systems
back
contexts
human-centered
computing
research
conclusion
artificial
intelligence
ai
assisted
search
recommender
sys
tems
become
ubiquitous
workplaces
everyday
lives
understanding
accounting
fairness
gained
increasing
attention
design
evaluation
systems
growing
body
computing
research
measuring
system
fairness
biases
associated
data
algorithms
im
pact
human
biases
go
beyond
traditional
machine
learning
ml
pipelines
still
remain
understudied
address
challenge
study
extends
concept
fairness
cover
effects
measurements
human
bias
system
bias
embedded
data
algorithms
well
possible
interactions
also
propose
new
two-sided
evaluation
goals
meth
ods
can
examine
performance
search
recommender
systems
addressing
proactively
reducing
impacts
human
system
biases
addition
paper
synthesizes
rele
vant
re-ranking
intervention
nudging
techniques
chiir
23
march
19
23
2023
austin
tx
usa
liu
potentially
mitigate
risks
one
types
biases
identifies
technical
ethical
challenges
well
new
directions
future
fairness-oriented
evaluation
research
ir
rs
hope
new
insights
perspectives
questions
presented
two-sided
fairness
problem
can
incite
fruitful
discussions
chiir
community
also
encourage
information
researchers
scientists
push
boundaries
fairness
evaluation
research
human-centered
perspective
acknowledgments
work
supported
national
science
foundation
nsf
award
iis-2106152
references
deena
abul-fottouh
melodie
yunju
song
anatoliy
gruzd
2020
examining
algorithmic
biases
youtube
recommendations
vaccine
videos
international
journal
medical
informatics
140
2020
104175
aman
agarwal
ivan
zaitsev
xuanhui
wang
cheng
li
marc
najork
thorsten
joachims
2019
estimating
position
bias
without
intrusive
interven
tions
proceedings
twelfth
acm
international
conference
web
search
data
mining
474
482
qingyao
ai
tao
yang
huazheng
wang
jiaxin
mao
2021
unbiased
learning
rank
online
offline
acm
transactions
information
systems
tois
39
2021
29
elliot
aronson
1969
theory
cognitive
dissonance
current
perspective
advances
experimental
social
psychology
vol
elsevier
34
alejandro
barredo
arrieta
natalia
díaz-rodríguez
javier
del
ser
adrien
ben
netot
siham
tabik
alberto
barbado
salvador
garcía
sergio
gil-lópez
daniel
molina
richard
benjamins
et
al
2020
explainable
artificial
intelligence
xai
concepts
taxonomies
opportunities
challenges
toward
responsible
ai
formation
fusion
58
2020
82
115
leif
azzopardi
2021
cognitive
biases
search
review
reflection
cognitive
biases
information
retrieval
proceedings
2021
conference
human
information
interaction
retrieval
27
37
aakriti
bajracharya
utsab
khakurel
barron
harvey
danda
rawat
2023
recent
advances
algorithmic
biases
fairness
financial
services
survey
proceedings
future
technologies
conference
springer
809
822
abigail
bakke
2020
everyday
googling
results
observational
study
applications
teaching
algorithmic
literacy
computers
composition
57
2020
102577
nicholas
belkin
2016
people
interacting
information
acm
sigir
forum
vol
49
acm
new
york
ny
usa
13
27
10
rachel
ke
bellamy
kuntal
dey
michael
hind
samuel
hoffman
stephanie
houde
kalapriya
kannan
pranay
lohia
jacquelyn
martino
sameep
mehta
aleksandra
mojsilovic
et
al
2019
ai
fairness
360
extensible
toolkit
de
tecting
mitigating
algorithmic
bias
ibm
journal
research
development
63
2019
11
richard
berk
hoda
heidari
shahin
jabbari
matthew
joseph
michael
kearns
jamie
morgenstern
seth
neel
aaron
roth
2017
convex
framework
fair
regression
arxiv
preprint
arxiv
1706.02409
2017
12
rishabh
bhardwaj
navonil
majumder
soujanya
poria
2021
investigating
gender
bias
bert
cognitive
computation
13
2021
1008
1018
13
asia
biega
krishna
gummadi
gerhard
weikum
2018
equity
attention
amortizing
individual
fairness
rankings
41st
international
acm
sigir
conference
research
development
information
retrieval
405
414
14
reuben
binns
2018
fairness
machine
learning
lessons
political
philoso
phy
conference
fairness
accountability
transparency
pmlr
149
159
15
tyler
brown
jiqun
liu
2022
reference
dependence
approach
enhancing
early
prediction
session
behavior
satisfaction
proceedings
22nd
acm
ieee
joint
conference
digital
libraries
16
ana
caraban
evangelos
karapanos
daniel
gonçalves
pedro
campos
2019
23
ways
nudge
review
technology-mediated
nudging
human-computer
interaction
proceedings
2019
chi
conference
human
factors
com
puting
systems
15
17
olivier
chapelle
donald
metlzer
ya
zhang
pierre
grinspan
2009
expected
reciprocal
rank
graded
relevance
proceedings
18th
acm
conference
information
knowledge
management
621
630
18
jiahao
chen
nathan
kallus
xiaojie
mao
geoffry
svacha
madeleine
udell
2019
fairness
unawareness
assessing
disparity
protected
class
unobserved
proceedings
conference
fairness
accountability
transparency
339
348
19
alexandra
chouldechova
aaron
roth
2020
snapshot
frontiers
fairness
machine
learning
commun
acm
63
2020
82
89
20
andrew
collins
dominika
tkaczyk
akiko
aizawa
joeran
beel
2018
posi
tion
bias
recommender
systems
digital
libraries
international
conference
information
springer
335
344
21
brian
alessandro
cathy
neil
tom
lagatta
2017
conscientious
classifi
cation
data
scientist
guide
discrimination-aware
classification
big
data
2017
120
134
22
jacob
devlin
ming-wei
chang
kenton
lee
kristina
toutanova
2018
bert
pre-training
deep
bidirectional
transformers
language
understanding
arxiv
preprint
arxiv
1810.04805
2018
23
cynthia
dwork
moritz
hardt
toniann
pitassi
omer
reingold
richard
zemel
2012
fairness
awareness
proceedings
3rd
innovations
theoretical
computer
science
conference
214
226
24
cynthia
dwork
christina
ilvento
2018
group
fairness
composition
proceedings
2018
conference
fairness
accountability
transparency
fat
2018
25
carsten
eickhoff
2018
cognitive
biases
crowdsourcing
proceedings
eleventh
acm
international
conference
web
search
data
mining
162
170
26
maria
gäde
marijn
koolen
mark
hall
toine
bogers
vivien
petras
2021
manifesto
resource
re-use
interactive
information
retrieval
proceedings
2021
conference
human
information
interaction
retrieval
141
149
27
ruoyuan
gao
yingqiang
ge
chirag
shah
2022
fair
fairness-aware
information
retrieval
evaluation
journal
association
information
science
technology
2022
28
yingqiang
ge
shuya
zhao
honglu
zhou
changhua
pei
fei
sun
wenwu
ou
yongfeng
zhang
2020
understanding
echo
chambers
e-commerce
recom
mender
systems
proceedings
43rd
international
acm
sigir
conference
research
development
information
retrieval
2261
2270
29
itzhak
gilboa
david
schmeidler
1995
case-based
decision
theory
quarterly
journal
economics
110
1995
605
639
30
diogo
gonçalves
pedro
coelho
luis
martinez
paulo
monteiro
2021
nudging
consumers
toward
healthier
food
choices
field
study
effect
social
norms
sustainability
13
2021
1660
31
nina
grgic-hlaca
muhammad
bilal
zafar
krishna
gummadi
adrian
weller
2016
case
process
fairness
learning
feature
selection
fair
decision
making
nips
symposium
machine
learning
law
vol
barcelona
spain
32
huifeng
guo
jinkai
yu
qing
liu
ruiming
tang
yuzhou
zhang
2019
pal
position-bias
aware
learning
framework
ctr
prediction
live
recommender
systems
proceedings
13th
acm
conference
recommender
systems
452
456
33
calin
gurau
2015
effect
marketing
promotions
customers
cogni
tive
biases
proceedings
international
conference
marketing-from
information
decision
babes
bolyai
university
48
34
kevin
hamilton
karrie
karahalios
christian
sandvig
motahhare
eslami
2014
path
understanding
effects
algorithm
awareness
chi
14
extended
abstracts
human
factors
computing
systems
631
642
35
moritz
hardt
eric
price
nati
srebro
2016
equality
opportunity
supervised
learning
advances
neural
information
processing
systems
29
2016
36
chia-fen
hsu
lee
propp
larissa
panetta
shane
martin
stella
dentakos
mag
gie
toplak
john
eastwood
2018
mental
effort
discomfort
testing
peak-end
effect
cognitively
demanding
task
plos
one
13
2018
e0191479
37
ben
hutchinson
margaret
mitchell
2019
50
years
test
un
fairness
lessons
machine
learning
proceedings
conference
fairness
ac
countability
transparency
49
58
38
rolf
jagerman
harrie
oosterhuis
maarten
de
rijke
2019
model
intervene
comparison
counterfactual
online
learning
rank
user
interactions
proceedings
42nd
international
acm
sigir
conference
research
development
information
retrieval
15
24
39
daniel
kahneman
2003
maps
bounded
rationality
psychology
behavioral
economics
american
economic
review
93
2003
1449
1475
40
daniel
kahneman
stewart
paul
slovic
paul
slovic
amos
tversky
1982
judgment
uncertainty
heuristics
biases
cambridge
university
press
41
michael
kearns
seth
neel
aaron
roth
zhiwei
steven
wu
2018
prevent
ing
fairness
gerrymandering
auditing
learning
subgroup
fairness
international
conference
machine
learning
pmlr
2564
2572
42
michael
kearns
seth
neel
aaron
roth
zhiwei
steven
wu
2019
empiri
cal
study
rich
subgroup
fairness
machine
learning
proceedings
conference
fairness
accountability
transparency
100
109
43
miles
kimball
1993
standard
risk
aversion
econometrica
journal
econometric
society
1993
589
611
44
abby
koenig
2020
algorithms
know
know
using
student
journals
uncover
algorithmic
literacy
awareness
computers
composition
58
2020
102611
45
matt
kusner
joshua
loftus
chris
russell
ricardo
silva
2017
counterfac
tual
fairness
advances
neural
information
processing
systems
30
2017
toward
two-sided
fairness
framework
search
recommendation
chiir
23
march
19
23
2023
austin
tx
usa
46
loni
ledderer
marianne
kjær
emilie
kirstine
madsen
jacob
busch
toinette
fage-butler
2020
nudging
public
health
lifestyle
interventions
systematic
literature
review
metasynthesis
health
education
behavior
47
2020
749
764
47
kwan
min
lee
younbo
jung
clifford
nass
2011
can
user
choice
alter
experimental
findings
human-computer
interaction
similarity
attraction
versus
cognitive
dissonance
social
responses
synthetic
speech
intl
journal
human-computer
interaction
27
2011
307
322
48
michelle
seng
ah
lee
luciano
floridi
2021
algorithmic
fairness
mortgage
lending
absolute
conditions
relational
trade-offs
minds
machines
31
2021
165
191
49
jiqun
liu
2021
deconstructing
search
tasks
interactive
information
retrieval
systematic
review
task
dimensions
predictors
information
processing
management
58
2021
102522
50
jiqun
liu
2022
toward
cranfield-inspired
reusability
assessment
interactive
information
retrieval
evaluation
information
processing
management
59
2022
103007
51
jiqun
liu
fangyuan
han
2020
investigating
reference
dependence
effects
user
search
interaction
satisfaction
behavioral
economics
perspective
proceedings
43rd
international
acm
sigir
conference
research
development
information
retrieval
1141
1150
52
jiqun
liu
yiwei
wang
soumik
mandal
chirag
shah
2019
exploring
immediate
short-term
effects
peer
advice
cognitive
authority
web
search
behavior
information
processing
management
56
2019
1010
1025
53
ramona
ludolph
peter
schulz
2018
debiasing
health-related
judgments
decision
making
systematic
review
medical
decision
making
38
2018
13
54
david
malenka
john
baron
sarah
johansen
jon
wahrenberger
jonathan
ross
1993
framing
effect
relative
absolute
risk
journal
general
internal
medicine
10
1993
543
548
55
jiaxin
mao
yiqun
liu
noriko
kando
cheng
luo
min
zhang
shaoping
ma
2018
investigating
result
usefulness
mobile
search
european
conference
information
retrieval
springer
223
236
56
ninareh
mehrabi
fred
morstatter
nripsuta
saxena
kristina
lerman
aram
galstyan
2021
survey
bias
fairness
machine
learning
acm
com
puting
surveys
csur
54
2021
35
57
alessandro
melchiorre
navid
rekabsaz
emilia
parada-cabaleiro
stefan
brandl
oleg
lesota
markus
schedl
2021
investigating
gender
fairness
recommen
dation
algorithms
music
domain
information
processing
management
58
2021
102666
58
alistair
moffat
justin
zobel
2008
rank-biased
precision
measurement
retrieval
effectiveness
acm
transactions
information
systems
tois
27
2008
27
59
robert
münscher
max
vetter
thomas
scheuerle
2016
review
taxon
omy
choice
architecture
techniques
journal
behavioral
decision
making
29
2016
511
524
60
alamir
novin
eric
meyers
2017
making
sense
conflicting
science
infor
mation
exploring
bias
search
engine
result
page
proceedings
2017
conference
conference
human
information
interaction
retrieval
175
184
61
alexandra
olteanu
carlos
castillo
fernando
diaz
emre
kiciman
2019
social
data
biases
methodological
pitfalls
ethical
boundaries
frontiers
big
data
2019
13
62
lihong
peng
yi
guo
dehua
hu
2021
information
framing
effect
public
intention
receive
covid-19
vaccination
china
vaccines
2021
995
63
manish
raghavan
solon
barocas
jon
kleinberg
karen
levy
2020
mitigating
bias
algorithmic
hiring
evaluating
claims
practices
proceedings
2020
conference
fairness
accountability
transparency
469
481
64
donald
redelmeier
joel
katz
daniel
kahneman
2003
memories
colonoscopy
randomized
trial
pain
104
2003
187
194
65
michael
ridley
danica
pawlick-potts
2021
algorithmic
literacy
role
libraries
information
technology
libraries
40
2021
66
william
samuelson
richard
zeckhauser
1988
status
quo
bias
decision
making
journal
risk
uncertainty
1988
59
67
nripsuta
ani
saxena
karen
huang
evan
defilippis
goran
radanovic
david
parkes
yang
liu
2019
fairness
definitions
fare
examining
public
attitudes
towards
algorithmic
definitions
fairness
proceedings
2019
aaai
acm
conference
ai
ethics
society
99
106
68
christoph
schneider
markus
weinmann
jan
vom
brocke
2018
digital
nudging
guiding
online
user
choices
interface
design
commun
acm
61
2018
67
73
69
falk
scholer
diane
kelly
wan-ching
wu
hanseul
lee
william
webber
2013
effect
threshold
priming
need
cognition
relevance
calibration
assessment
proceedings
36th
international
acm
sigir
conference
research
development
information
retrieval
623
632
70
christina
schwind
jürgen
buder
2012
reducing
confirmation
bias
evaluation
bias
preference-inconsistent
recommendations
effective
computers
human
behavior
28
2012
2280
2290
71
intan
sherlin
ferry
siswadhi
elex
sarmigi
2020
analysing
decoy
effect
online
product
purchasing
preference
experimental
study
6th
annual
international
conference
management
research
aicmar
2019
atlantis
press
125
130
72
herbert
simon
1955
behavioral
model
rational
choice
quarterly
journal
economics
69
1955
99
118
73
cass
sunstein
2016
council
psychological
advisers
annual
review
psychology
67
2016
713
737
74
harini
suresh
john
guttag
2019
framework
understanding
un
intended
consequences
machine
learning
arxiv
preprint
arxiv
1901.10002
2019
75
richard
thaler
2016
behavioral
economics
past
present
future
american
economic
review
106
2016
1577
1600
76
georgios
theocharous
jennifer
healey
sridhar
mahadevan
michele
saad
2019
personalizing
human
cognitive
biases
adjunct
publication
27th
conference
user
modeling
adaptation
personalization
13
17
77
samuel
trethewey
2019
medical
misinformation
social
media
cognitive
bias
pseudo-peer
review
good
intentions
hypothesis
circulation
140
14
2019
1131
1133
78
jennifer
trueblood
jonathan
pettibone
2017
phantom
decoy
effect
perceptual
decision
making
journal
behavioral
decision
making
30
2017
157
167
79
amos
tversky
daniel
kahneman
1991
loss
aversion
riskless
choice
reference-dependent
model
quarterly
journal
economics
106
1991
1039
1061
80
elmira
van
den
broek
anastasia
sergeeva
marleen
huysman
2019
hiring
algorithms
ethnography
fairness
practice
2019
81
sahil
verma
julia
rubin
2018
fairness
definitions
explained
2018
ieee
acm
international
workshop
software
fairness
fairware
ieee
82
chao
wang
yiqun
liu
min
zhang
shaoping
ma
meihong
zheng
jing
qian
kuo
zhang
2013
incorporating
vertical
results
search
click
models
proceedings
36th
international
acm
sigir
conference
research
development
information
retrieval
503
512
83
xuanhui
wang
nadav
golbandi
michael
bendersky
donald
metzler
marc
najork
2018
position
bias
estimation
unbiased
learning
rank
personal
search
proceedings
eleventh
acm
international
conference
web
search
data
mining
610
618
84
yifan
wang
weizhi
ma
min
zhang
yiqun
liu
shaoping
ma
2022
survey
fairness
recommender
systems
acm
journal
acm
jacm
2022
85
roberto
weber
colin
camerer
2006
behavioral
experiments
economics
experimental
economics
2006
187
86
chunhua
wu
koray
cosguner
2020
profiting
decoy
effect
case
study
online
diamond
retailer
marketing
science
39
2020
974
995
87
yusuke
yamamoto
takehiro
yamamoto
2018
query
priming
promoting
critical
thinking
web
search
proceedings
2018
conference
human
information
interaction
retrieval
12
21
88
tao
zhang
david
zhang
2007
agent-based
simulation
consumer
purchase
decision-making
decoy
effect
journal
business
research
60
2007
912
922