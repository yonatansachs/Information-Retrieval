fairness
vs
personalization
towards
equity
epistemic
utility
jennifer
chien
uc
san
diego
usa
david
danks
uc
san
diego
usa
applications
personalized
recommender
systems
rapidly
expanding
encompassing
social
media
online
shopping
search
engine
results
systems
oï¬€er
eï¬ƒcient
way
navigate
vast
array
items
available
however
alongside
growth
increased
recognition
potential
algorithmic
systems
exhibit
perpetuate
biases
risking
arxiv
2309
11503v1
cs
ir
sep
2023
unfairness
personalized
domains
work
explicate
inherent
tension
personalization
conventional
implementations
fairness
alternative
propose
equity
achieve
fairness
context
epistemic
utility
provide
mapping
goals
practical
implementations
detail
policy
recommendations
across
key
stakeholders
forge
path
towards
achieving
fairness
personalized
systems
additional
key
words
phrases
fairness
personalization
recommender
systems
equity
epistemic
utility
epistemic
harms
policy
acm
reference
format
jennifer
chien
david
danks
2023
fairness
vs
personalization
towards
equity
epistemic
utility
september
2023
11
pages
introduction
personalized
algorithmic
systems
increasingly
deployed
broad
range
sectors
algorithms
hold
potential
provide
appropriate
outputs
individual
basis
personalizing
based
preferences
values
needs
environmental
conditions
prominently
recommender
systems
now
widely
used
provide
useful
recommendations
individual
given
domain
time
seen
signiï¬cant
increase
recognition
algorithms
can
exhibit
biases
produce
unfair
unjust
outcomes
many
diï¬€erent
potential
sources
bias
algorithms
models
hence
many
diï¬€erent
responses
may
appropriate
required
algorithm
development
deployment
eï¬€orts
now
typically
recognize
possibility
algorithmic
bias
need
often
something
mitigate
contend
two
desiderata
algorithms
personalization
fairness
stand
signiï¬cant
tension
high
level
personalization
fundamentally
treating
individual
distinct
ways
goal
give
output
individual
rather
tailor
outputs
speciï¬c
situation
contrast
fairness
fundamentally
treating
individuals
similarly
algorithm
sense
everyone
course
high-level
gloss
tension
far
quick
example
fairness
allows
diï¬€erential
treatment
outcomes
long
based
morally
legally
defensible
grounds
nonetheless
high-level
observations
point
towards
tension
contend
continues
hold
look
deeper
speciï¬cally
analyze
fairness
context
personalized
systems
using
notion
epistemic
utility
essentially
beneï¬t
agent
receives
epistemic
improvement
reduction
uncertainty
provide
practical
policy
guidance
achieve
fair
personalized
systems
authors
addresses
jennifer
chien
jjchien@ucsd.edu
uc
san
diego
usa
david
danks
ddanks@ucsd.edu
uc
san
diego
usa
2023
manuscript
submitted
acm
manuscript
submitted
acm
jennifer
chien
david
danks
preliminaries
recommender
system
consider
recommender
system
uses
algorithmic
approach
provide
ordering
prioritization
items
based
relevance
user
form
personalization
often
based
preferences
past
behavior
similarities
users
overarching
goal
improving
user
experience
engagement
group
fairness
algorithmic
fairness
typically
framed
metric
parity1
across
two
relevantly
comparable
entities
diï¬€erence
deemed
socially
legally
culturally
irrelevant
instance
group
fairness
may
deï¬ned
demographic
parity
meaning
equality
likelihood
given
outcome
conditioned
group
gender
age
disability
formally
ğ‘¦Ë†
ğ‘”ğ‘–
ğ‘¦Ë†
ğ‘”ğ‘–
total
number
groups
ğ‘¦Ë†
likelihood
given
outcome
epistemic
utility
deï¬ne
epistemic
utility
value
usefulness
information
terms
improving
knowledge
understanding
beliefs
encompasses
epistemic
beneï¬ts
gained
acquiring
accurate
reliable
relevant
information
beneï¬ts
course
enhance
decision-making
prediction
problem-solving
overall
intellectual
development
epistemic
utility
refers
beneï¬ts
terms
agent
epistemic
state
even
improvements
immediately
lead
improved
outcomes
thereby
captures
intrinsic
value
acquiring
knowledge
understanding
underscores
role
information
valuable
resource
intellectual
growth
social
mobility
production
captures
motivational
value
information
people
behavior
related
work
work
closely
related
eï¬€orts
understand
fairness
recommender
systems
many
deï¬ne
fairness
parity
performance
measure
across
sensitive
attribute
10
methods
individual
notions
fairness
similarly
require
domain-speciï¬c
similarity
function
focus
trade-oï¬€s
individual
group
fairness
11
12
contrast
start
position
fairness
requires
equity
across
individuals
rather
deï¬ned
solely
comparisons
approach
enables
us
account
cases
unfairness
everyone
worse
oï¬€
including
situations
non-comparative
injustices
one
group
speciï¬cally
prior
work
aimed
ensure
proportional
representation
exposure
often
e-commerce
settings
measures
disparate
exposure
visibility
still
require
access
sensitive
group
attributes
10
calibration
expected
proportions
predicted
classes
match
observed
available
data
implements
group
fairness
without
explicit
knowledge
sensitive
attribute
status
13
14
15
16
17
however
application
domains
news
can
contribute
hegemonic
regimes
representation
making
limited
applications
less
diversity
valued
users
17
additionally
fairness
deï¬nitions
target
disparities
utility
compare
average
sensitive
attribute
group
performance
rather
providing
assurances
individuals
entire
population
whole
11
18
19
20
concerns
unfairness
personalized
algorithms
connected
research
epistemic
injustice
21
core
concern
latter
work
epistemic
limitations
may
impair
agent
ability
recognize
respond
within
tolerance
legally
permissible
four-ï¬fths
rule
manuscript
submitted
acm
fairness
vs
personalization
towards
equity
epistemic
utility
injustice
example
individual
concept
racial
discrimination
might
fail
detect
occurrence
despite
suï¬€ering
harms
injustice
happens
individual
also
epistemic
inability
recognize
understand
respond
personalized
systems
can
readily
lead
diï¬€erent
individuals
diï¬€erent
information
fact
one
goal
systems
expect
individuals
develop
diï¬€erent
concepts
result
hence
personalized
systems
can
signiï¬cantly
raise
risks
epistemic
injustice
research
over-personalization
information
access
similarly
closely
related
inï¬‚uence
personalization
ï¬lter
bubbles
echo
chambers
denied
purely
technical
systems
22
23
24
considering
human
interactions
inï¬‚uence
becomes
somewhat
complex
part
due
signiï¬cant
variability
users
engage
site
accept
reject
information
perceive
impartiality
content
receive
25
26
27
28
29
research
adopts
sociotechnical
approach
deï¬ne
scope
problem
taking
account
concept
epistemic
utility
making
reasonable
assessments
human
eï¬€ort
core
tension
personalization
standard
approaches
fairness
fairness
often
deï¬ned
metric
parity
across
similar
groups
individuals
determining
similarity
across
units
remains
open
question
search
settings
one
might
start
grouping
together
individuals
similar
values
interests
fairness
grounds
may
expected
similar
disambiguation
content
recommendation
experience
however
determining
values
can
diï¬ƒcult
operationalize
explicit
implicit
preferences
may
conï¬‚icting
diï¬ƒcult
collect
30
addition
level
granularity
measure
values
remains
unknown
section
construct
arguments
user
similarity
values
diï¬ƒcult
impractical
perhaps
even
impossible
determine
thereby
making
similarity-based
fairness
deï¬nitions
diï¬ƒcult
deploy
conceptually
impossible
sensitive
attributes
problematic
coarse
proxies
values
simplest
approach
constructing
similar
groups
fairness
considerations
use
sensitive
attributes
race
ethnicity
gender
age
religious
aï¬ƒliation
disability
etc
however
approach
assumes
individuals
sensitive
attributes
face
similar
struggles
lived
experiences
discrimination
prejudice
also
relevantly
similar
values
practice
approach
likely
result
treatment
minority
groups
monoliths
perhaps
even
homogeneous
problematic
instrumental
failures
insuï¬ƒcient
speciï¬city
complexity
also
intrinsic
treatment
single
sensitive
attribute
representative
values
additionally
conditional
groupings
ensure
parity
guarantees
average
member
group
individual
necessarily
individual
exists
therefore
enabling
unfairness
anyone
doesn
satisfy
assumptions
taking
intersectional
approach
considering
subgroups
sensitive
attributes
may
better
approximate
similarity
values
consider
example
race
gender
meaning
groups
black
women
white
men
still
considers
entire
group
people
homogeneously
thereby
rendering
plight
example
black
women
singular
experience
extreme
considering
possible
sub-groups
across
sensitive
attributes
faces
practical
challenges
subgroup
becomes
impractically
small
data
availability
purposes
thereby
reifying
sensitive
attributes
constant
struggle
relative
popularity
public
consciousness
31
user
search
history
noisy
underdetermines
values
can
vary
temporally
alternative
approach
use
individual
behavior
determine
relevant
group
fairness
considerations
instance
context
manuscript
submitted
acm
jennifer
chien
david
danks
search
engine
condition
exact
search
history
unfortunately
approach
faces
three
open
challenges
highlight
context
search
though
problems
naturally
generalize
systems
use
observed
behavior
personalize
basis
unobserved
inferred
features
first
search
behaviors
equally
informative
example
search
query
may
made
due
diï¬€erent
situational
demands
homework
third
party
question
may
arise
diï¬€erent
motivations
devil
advocate
vs
searching
validative
supporting
arguments
hence
speciï¬c
history
search
queries
may
may
informative
individual
values
history
alone
suï¬ƒcient
second
even
search
behaviors
genuine
noisy
indicators
totality
individual
interests
values
example
individual
agent
might
search
topic
already
suï¬ƒcient
information
may
still
core
value
generally
consider
two
users
identical
search
histories
given
point
time
conditioning
search
history
imply
receive
similar
experiences
however
highly
unlikely
individuals
exact
sets
values
interests
multiple
sets
values
interests
consistent
observed
behavior
space
values
underdetermined
evidence
therefore
since
queries
subject
limitations
observational
data
missing
contextual
information
conditioning
search
history
alone
potential
greatly
under-specify
individual
values
finally
search
history
provides
guarantees
stability
time
consider
two
individuals
user
history
adding
diï¬€erent
element
user
search
history
lead
placed
fundamentally
diï¬€erent
groups
generally
point
time
inï¬nitely
many
ways
search
history
progress
thereby
making
impossible
guarantee
fairness
time
two
individuals
let
alone
fairness
groupings
sensitive
time
search
history
therefore
may
ever
converge
fair
groupings
limit
echoes
similar
problem
fairness
research
fairness
constraints
round
deployment
ensure
long-term
aggregate
parity
metric
32
rendered
particular
fairness
metrics
obsolete
instability
points
ambiguity
extent
fairness
must
provide
guarantees
temporally
different
approach
5.1
personalization
delving
notion
system
tailored
person
needs
let
us
deï¬ne
personalization
given
search
engine
companies
may
strive
deliver
service
maximizes
epistemic
utility
convenience
order
avoid
wasting
time
resources
eroding
consumer
patience
search
engine
providers
may
optimize
disambiguate
queries
eï¬ƒciently
possible
increases
eï¬ƒciency
can
made
leveraging
accessible
information
user
may
include
search
history
publicly
available
data
social
media
proï¬les
inferred
disclosed
demographic
information
accurately
disambiguate
user
query
motivates
following
deï¬nition
deï¬nition
5.1
inï¬nite
personalization
consider
platform
recommends
relevant
content
user
tailored
previous
history
time
since
space
possible
information
large
piece
content
ğ‘ğ‘–
system
calculates
probabilities
ğ‘ğ‘–
estimating
likelihood
relevance
deï¬ne
inï¬nite
personalization
phenomena
system
allowed
produce
extremely
ï¬ne-grained
personalization
formally
exists
ğ‘ğ‘–
ğ‘ğ‘–
ğ‘ğ‘–
meaning
exists
content
arbitrarily
improbable
recommend
particular
piece
content
ğ‘ğ‘–
user
even
user
add
queries
search
history
manuscript
submitted
acm
fairness
vs
personalization
towards
equity
epistemic
utility
instance
user
search
history
exclusively
composed
cats
inputs
bengal
toys
search
engine
receives
recommendations
bengal
cat
toys
consider
system
exhibiting
inï¬nite
personalization
user
can
take
queries
dogs
anything
else
still
receive
recommendation
bengal
dog
toys
searching
bengal
toys
deï¬ned
personalization
eï¬€ects
extreme
case
now
deï¬ne
fairness
equity
provide
motivation
outcome
target
5.2
equity
ensuring
parity
across
similar
groups
fairness
guarantees
made
across
deemed
suï¬ƒciently
similar
equity-based
approach
however
centers
around
every
individual
achieving
desired
outcome
approaches
promote
social
cohesion
collective
liberation
address
long-standing
inequities
poverty
public
health
social
mobility
overall
well-being
moreover
tackle
concerns
regarding
temporal
stability
robustness
establishing
consistent
criterion
deployment
phase
equity-based
approaches
lend
audits
legislation
transparency
deï¬ne
singular
outcome
requirement
users
open
challenge
however
metrics
deï¬ne
equity
respect
metric
targets
diï¬€erent
kind
unfairness
equity
across
quality
information
targets
unfairness
one
person
gets
utility
query
compared
diï¬€erent
query
another
person
example
type
equity
requires
equalize
number
recommendations
quality
information
provided
given
query
however
infeasible
control
quantity
information
known
given
topic
thus
given
inï¬nitely
many
distinct
queries
user
can
make
ensuring
query
number
relevant
articles
require
perfect
knowledge
equity
speed
access
information
targets
unfairness
one
person
receives
relevant
information
faster
another
equalizes
utility
every
user
either
slowing
acting
intentionally
uncooperatively
queries
easily
disambiguated
speeding
service
slower
queries
infeasible
former
fails
maximize
overall
utility
sacriï¬ces
function
name
fairness
turn
renders
adoption
stakeholders
subject
capitalistic
pressures
even
unlikely
latter
also
infeasible
directly
control
disambiguation
rate
therefore
speed
queries
others
generally
information
inï¬nitely
shareable
resource
providing
information
one
person
deprive
someone
else
beneï¬t
information
therefore
speed
access
information
poor
target
equity-based
intervention
contrast
equity
epistemic
utility
targets
unfairness
personalized
access
information
resources
motivated
intuition
although
directly
control
availability
information
disambiguation
rate
everyone
baseline
access
information
thus
propose
upper
bound
number
queries
access
piece
information
means
information
exist
users
able
access
exerting
reasonable
amount
eï¬€ort
require
queries
accessibility
disambiguation
users
provided
exact
service
provide
soft
guarantee
everyone
able
achieve
base-level
epistemic
utility
without
requiring
grouping
comparison
individuals
basis
values
needs
histories
epistemic
utility
particularly
internet
recognized
universal
human
right
article
19
universal
declaration
human
rights
33
stating
everyone
right
freedom
seek
receive
impart
information
ideas
media
regardless
frontiers
manuscript
submitted
acm
jennifer
chien
david
danks
deï¬nition
5.2
ğœ–-equity
fairness
given
user
history
deï¬ne
ğœ–-equity
fairness
upper
bound
number
additions
search
history
given
content
ğ‘ğ‘–
adding
queries
history
will
result
ğ‘ğ‘–
enabling
user
obtain
relevant
content
consider
case
relevant
content
exist
scope
focus
purely
access
embracing
equity
fundamental
principle
fairness
presents
range
complex
challenges
challenges
encompass
deï¬ning
baseline
level
equity
users
determining
pertinent
factors
contribute
establishing
baseline
deliberating
whether
considerations
domain-speciï¬c
universally
applicable
rather
proposing
singular
standard
propose
adopting
heuristic
operationalization
prioritizes
disadvantaged
terms
knowledge
understanding
intention
argue
strictly
prioritarian
perspective
incremental
advancements
can
achieve
ultimate
goal
equity
long-term
thus
advocate
equity
guiding
concept
achieve
equality
inductively
reaching
fairness
limit
established
deï¬nitions
inï¬nite
personalization
ğœ–-equity
fairness
next
ï¬‚esh
tension
two
inherent
conflict
trade-offs
inï¬nite
personalization
posit
comes
cost
ğœ–-equity
fairness
explicitly
inï¬nite
personalization
relevance
probability
information
ğ‘ğ‘–
user
can
less
due
eï¬€ects
personalization
indexing
re-ranking
eï¬ƒcient
navigation
across
vast
space
information
however
violates
ğœ–-equity
fairness
information
will
eï¬€ectively
rendered
unreachable
within
ï¬xed
window
queries
provide
examples
trade-oï¬€s
search
engine
personalization
prioritizes
results
relative
user
input
query
prior
history
given
topic
orthogonal
user
past
history
personalization
may
rank
desired
items
far
beyond
average
expected
typical
number
results
given
user
explores
rendering
practically
infeasible
reach
social
media
serves
many
functions
dissemination
news
information
entertainment
social
connection
personalization
extreme
may
contribute
propagation
mis
disinformation
echo
chambers
ï¬lter
bubbles
radicalization
social
disconnection
github
copilot
developed
openai
focuses
code
completion
providing
suggestions
code
lines
entire
functions
directly
integrated
interactive
development
environments
personalization
potential
provide
codebase-speciï¬c
suggestions
completion
may
also
infringe
coder
ability
construct
novel
functionality
google
bard
language
model
synthesizing
insights
settings
wide
range
opinions
perspectives
right
answer
augmentation
search-engine
information
retrieval
may
facilitate
eï¬ƒcient
ordering
disambiguation
search
results
may
also
infringe
access
seemingly
irrelevant
information
chatgpt
general-purpose
large
language
model
llm
designed
engage
human-like
conversations
answer
wide
range
questions
personalization
extreme
case
may
lead
conversational
loops
conversations
remain
within
scope
single
topic
rather
ï¬‚exibility
move
topics
despite
user
prompt
request
list
several
examples
use
llms
due
relevance
personalization
information
synthesis
curation
appeals
human
language
usability
acknowledge
many
open
relevant
problems
related
personalization
contribution
exacerbation
representational
harms
scope
work
focus
systems
can
impact
access
information
manuscript
submitted
acm
fairness
vs
personalization
towards
equity
epistemic
utility
key
takeaway
list
personalization
necessitates
unfairness
inequity
fairness
achievable
personalized
systems
rather
emphasize
personalization
without
consideration
fairness
can
readily
lead
systems
deny
individuals
base-level
expected
epistemic
utility
policy
goals
examples
implementations
conceptual
analysis
provides
guidance
best
think
fairness
context
personalized
algorithms
provide
guidance
achieve
fairer
less
biased
systems
turn
practical
recommendations
start
considering
key
stakeholders
associated
roles
table
creates
lexicon
clariï¬es
expected
function
stakeholder
stakeholders
wide
range
actions
available
can
lead
fairer
personalized
systems
see
table
actions
include
wide
range
governance
mechanisms
ranging
hard
regulation
soft
social
norms
emphasize
single
response
ï¬x
unfairness
personalized
systems
inevitably
many
interdependent
actions
will
likely
need
taken
order
make
progress
problem
moreover
means
intended
exhaustive
rather
provide
grounded
starting
point
emphasizes
necessity
cross-stakeholder
collaborations
manuscript
submitted
acm
jennifer
chien
david
danks
stakeholder
role
government
develop
guidelines
principles
procedures
regulations
standards
safe
sustainable
deployment
may
hold
power
create
structural
supporting
systems
directly
within
government
ï¬nancially
support
external
systems
enforcement
regulations
may
also
enact
means
operationalizing
policy
hosting
interdisciplinary
research
summits
sending
representatives
build
collaborations
stakeholders
better
inform
outputs
stakeholder
may
also
set
roles
norms
stakeholder
responsibilities
consequences
civil
society
conduct
evaluations
investigations
algorithms
software
developed
others
stakeholder
may
serve
external
third-party
entity
conducting
unbiased
evaluations
performance
compliance
policy
may
responsible
developing
novel
methods
measurement
industry
implement
technical
methods
tools
technological
innovations
usually
manifesting
consumer-facing
service
product
may
subject
practical
implementation
constraints
ï¬nancial
competition
legislative
particular
product
may
theoretically
feasible
may
practically
viable
sustainable
company
produce
responsibilities
may
also
include
foreseeing
adequately
mitigating
harms
deployed
products
directly
indirectly
aï¬€ected
academia
broad
develop
implement
technical
theoretical
conceptual
knowledge
without
direct
consideration
proï¬ts
results
can
include
work
builds
upon
understanding
implications
evaluation
methods
downstream
impacts
sociotechnical
approaches
stakeholder
potential
act
unbiased
actor
developing
best-practices
sustainable
long-term
practices
potentially
direct
cost
proï¬ts
considering
environmental
social
cultural
norms
inï¬‚uences
general
public
provide
input
feedback
criticism
opinions
direction
alignment
values
research
innovation
via
implicit
explicit
signals
order
communities
groups
individuals
public
support
lack
thereof
can
collected
across
multitude
avenues
granularities
including
ï¬nancial
support
interest
engagement
collective
action
protests
organizations
projects
table
stakeholder
roles
define
expected
roles
stakeholders
clarity
responsibilities
enumerated
table
note
responsibilities
restrictive
many
ways
one
stakeholder
may
overlap
even
take
responsibilities
another
instance
company
develops
policy
user
privacy
competitors
self-imposed
constraints
data
collection
may
impact
product
performance
however
design
value
receives
public
support
can
become
standard
competitive
service
without
intervention
government
civil
society
manuscript
submitted
acm
fairness
vs
personalization
towards
equity
epistemic
utility
goal
example
implementation
operationalization
mitigation
industry
academia
develop
algorithms
facilitate
connections
disjoint
parts
data
manifold
might
analogous
connecting
diï¬€erent
parts
internet
together
links
done
creating
arbitrary
injections
fabricate
similarities
covariances
links
disjoint
parts
training
data
government
construct
structural
incentives
ï¬nancial
prestige
recognition
standards
achieving
baseline
levels
interconnectivity
ensure
equitable
access
audit
industry
academia
civil
society
develop
measures
quantify
epistemic
utility
users
using
range
behaviors
data
tool
use
experienced
frustration
time
complete
task
etc
produce
formal
domain-speciï¬c
representations
distributions
utility
non-uniform
distributions
indicators
threats
fairness
measure
utility
study
barriers
utility
non-users
left
platform
civil
society
report
utility
distributions
non-users
compare
already
using
service
academia
deï¬ning
measuring
downstream
impact
may
essential
thorough
quantiï¬cation
disparities
unfairness
downstream
impacts
social
inï¬‚uences
platform
usage
can
inï¬‚uenced
individual
experience
government
regulation
timing
structure
fairness
audits
personalized
systems
including
guidance
composition
internal
external
stakeholders
transparency
industry
civil
society
disclosure
aforementioned
distributions
utility
across
various
groups
users
reports
include
comments
whether
distributions
problematic
proposed
solutions
timeline
government
clear
consequences
reparations
users
aï¬€ected
throughout
improvement
continued
negligence
general
public
active
engagement
feedback
reports
inform
appropriate
consequences
informed
public
dis
favor
individual
control
industry
academia
design
control
mechanisms
degree
exploration
query
serving
recommendations
may
include
prompting
users
additional
input
producing
prediction
alternatively
allowing
users
reset
history
set
manual
preferences
personalization
ï¬lters
government
regulation
enforcement
satisfaction
compliance
general
public
participation
feedback
norm
setting
features
available
accessible
services
determine
embedded
values
degree
reasonableness
feasible
realistic
users
education
awareness
industry
academia
government
general
public
workshops
training
sessions
can
facilitate
comprehension
dangers
limitations
better
calibrate
users
appropriate
expectations
functionality
workshops
can
include
education
rights
advocate
instance
companies
fail
comply
can
people
ï¬le
grievances
can
aggregated
collectively
analyzed
industry
academia
civil
society
development
interactive
tools
enable
visualization
comparison
individual
utility
compared
general
population
relevantly
comparable
manuscript
submitted
acm
civil
society
government
regulation
continued
measurement
ensure
tools
ï¬‚ag
anomalous
data
ensure
improvement
within
time-frame
create
publicly
release
reports
corrections
adjustments
investigations
made
remedy
grievances
table
example
policy
interventions
goals
stakeholder
although
separate
actions
stakeholders
emphasize
goals
require
collaborations
contributions
across
multiple
stakeholders
achieve
solutions
10
jennifer
chien
david
danks
references
zeynep
tufekci
recommendation
algorithms
run
world
apr
2019
url
https://www.wired.com/story/how-recommendation-
gurkan
solmaz
jesmin
jahan
tithi
juan
miguel
de
joya
algorithmic
fairness
oct
2020
url
https://selects.acm.org/selectio
elizabeth
anne
watkins
michael
mckenna
jiahao
chen
four-ï¬fths
rule
disparate
impact
woeful
tale
epistemic
trespassing
algorithmic
fairness
arxiv
preprint
arxiv
2202.09519
2022
cynthia
dwork
et
al
fairness
awareness
proceedings
3rd
innovations
theoretical
computer
science
conference
2012
pp
214
226
rishabh
mehrotra
et
al
towards
fair
marketplace
counterfactual
evaluation
trade-oï¬€
relevance
fairness
satisfaction
recommendation
systems
proceedings
27th
acm
international
conference
information
knowledge
management
2018
pp
2243
2251
nasim
sonboli
et
al
opportunistic
multi-aspect
fairness
personalized
re-ranking
proceedings
28th
acm
conference
user
modeling
adaptation
personalization
2020
pp
239
247
weiwen
liu
et
al
personalized
fairness-aware
re-ranking
microlending
proceedings
13th
acm
conference
recommender
systems
2019
pp
467
471
ludovico
boratto
gianni
fenu
mirko
marras
interplay
upsampling
regularization
provider
elizabeth
gÃ³mez
et
al
winner
takes
geographic
imbalance
provider
un
fairness
educational
fairness
recommender
systems
user
modeling
user-adapted
interaction
31.3
2021
pp
421
455
recommender
systems
proceedings
44th
international
acm
sigir
conference
research
development
information
retrieval
2021
pp
1808
1812
10
abhisek
dash
et
al
umpire
also
player
bias
private
label
product
recommendations
ecommerce
marketplaces
proceedings
2021
acm
conference
fairness
accountability
transparency
2021
pp
873
884
11
ziwei
zhu
xia
hu
james
caverlee
fairness-aware
tensor-based
recommendation
proceedings
27th
acm
international
conference
information
knowledge
management
2018
pp
1153
1162
12
bora
edizel
et
al
fairecsys
mitigating
algorithmic
bias
recommender
systems
international
journal
data
science
analytics
2020
pp
197
213
13
himan
abdollahpouri
et
al
calibrated
recommendations
minimum-cost
ï¬‚ow
problem
proceedings
sixteenth
acm
international
conference
web
search
data
mining
2023
pp
571
579
14
himan
abdollahpouri
et
al
user-centered
evaluation
popularity
bias
recommender
systems
proceedings
29th
acm
conference
user
modeling
adaptation
personalization
2021
pp
119
129
15
bruna
wundervald
cluster-based
quotas
fairness
improvements
music
recommendation
systems
16
diego
corrÃªa
da
silva
marcelo
garcia
manzato
frederico
araÃºjo
durÃ£o
exploiting
personalized
calibra
17
yashar
deldjoo
et
al
fairness
recommender
systems
research
landscape
future
directions
user
international
journal
multimedia
information
retrieval
10.1
2021
pp
25
32
tion
metrics
fairness
recommendation
expert
systems
applications
181
2021
115112
modeling
user-adapted
interaction
2023
pp
50
18
yashar
deldjoo
et
al
recommender
systems
fairness
evaluation
via
generalized
cross
entropy
arxiv
preprint
arxiv
1908.06708
2019
manuscript
submitted
acm
fairness
vs
personalization
towards
equity
epistemic
utility
19
11
yashar
deldjoo
tommaso
di
noia
felice
antonio
merra
adversarial
machine
learning
recommender
systems
aml-recsys
proceedings
13th
international
conference
web
search
data
mining
2020
pp
869
872
20
yunqi
li
et
al
user-oriented
fairness
recommendation
proceedings
web
conference
2021
2021
pp
624
632
21
miranda
fricker
epistemic
injustice
power
ethics
knowing
oxford
university
press
2007
22
cÃ©dric
courtois
laura
slechten
lennert
coenen
challenging
google
search
ï¬lter
bubbles
social
political
information
disconforming
evidence
digital
methods
case
study
telematics
informatics
35.7
2018
pp
2006
2015
23
william
dutton
et
al
searching
ï¬lter
bubbles
echo
chambers
society
internet
24
efrat
nechushtai
seth
lewis
kind
news
gatekeepers
want
machines
filter
bub
networks
information
communication
changing
lives
2019
228
bles
fragmentation
normative
dimensions
algorithmic
recommendations
computers
human
behavior
90
2019
pp
298
307
25
tawanna
dillahunt
christopher
brooks
samarth
gulati
detecting
visualizing
ï¬lter
bubbles
google
bing
proceedings
33rd
annual
acm
conference
extended
abstracts
human
factors
computing
systems
2015
pp
1851
1856
26
axel
ekstrÃ¶m
diederick
niehorster
erik
olsson
self-imposed
ï¬lter
bubbles
selective
attention
exposure
online
search
computers
human
behavior
reports
2022
100226
27
mykola
makhortykh
mariÃ«lle
wijermars
can
ï¬lter
bubbles
protect
information
freedom
discussions
algorithmic
news
recommenders
eastern
europe
digital
journalism
2021
pp
25
28
jaime
teevan
people
recall
recognize
reuse
search
results
acm
transactions
information
systems
tois
26.4
2008
pp
27
29
kelly
shelton
council
post
value
search
results
rankings
nov
2017
url
https://www.forbes.com/sites/forbesagencycouncil/2017/10/30/th
30
tessa
es
charlesworth
mahzarin
banaji
patterns
implicit
explicit
attitudes
iv
change
stability
2007
2020
psychological
science
33.9
2022
pp
1347
1371
31
youjin
kong
intersectionally
fair
ai
algorithms
really
fair
women
color
philosophical
analysis
2022
acm
conference
fairness
accountability
transparency
2022
pp
485
494
32
lily
hu
yiling
chen
short-term
intervention
long-term
fairness
labor
market
proceedings
2018
world
wide
web
conference
2018
pp
1389
1398
33
url
https://www.unesco.org/en/right-information.
manuscript
submitted
acm
figure
acm-jdslogo
png
available
png
format
http://arxiv.org/ps/2309.11503v1