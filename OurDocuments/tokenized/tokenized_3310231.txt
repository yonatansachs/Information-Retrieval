transparency
fairness
data
protection
neutrality
data
management
challenges
in
the
face
of
new
regulation
serge
abiteboul
inria
ecole
normale
supérieure
france
julia
stoyanovich
new
york
university
usa
the
data
revolution
continues
to
transform
every
sector
of
science
industry
and
government
due
to
the
incredible
impact
of
data-driven
technology
on
society
we
are
becoming
increasingly
aware
of
the
imperative
to
use
data
and
algorithms
responsibly
in
accordance
with
laws
and
ethical
norms
in
this
article
we
discuss
three
recent
regulatory
frameworks
the
european
union
general
data
protection
regulation
gdpr
the
new
york
city
automated
decisions
systems
ads
law
and
the
net
neutrality
principle
which
aim
to
protect
the
rights
of
individuals
who
are
impacted
by
data
collection
and
analysis
these
frameworks
are
prominent
examples
of
global
trend
governments
are
starting
to
recognize
the
need
to
regulate
data-driven
algorithmic
technology
our
goal
in
this
article
is
to
bring
these
regulatory
frameworks
to
the
attention
of
the
data
management
community
and
to
underscore
the
technical
challenges
they
raise
and
that
we
as
community
are
well
equipped
to
address
the
main
takeaway
of
this
article
is
that
legal
and
ethical
norms
cannot
be
incorporated
into
data-driven
systems
as
an
afterthought
rather
we
must
think
in
terms
of
responsibility
by
design
viewing
it
as
systems
requirement
ccs
concepts
information
systems
data
management
systems
social
and
professional
topics
computing
technology
policy
technology
audits
applied
computing
law
additional
key
words
and
phrases
transparency
fairness
data
protection
neutrality
responsible
data
science
acm
reference
format
serge
abiteboul
and
julia
stoyanovich
2019
transparency
fairness
data
protection
neutrality
data
man
agement
challenges
in
the
face
of
new
regulation
data
and
information
quality
11
article
15
june
2019
pages
https://doi.org/10.1145/3310231
introduction
the
data
revolution
continues
to
transform
every
sector
of
science
industry
and
government
due
to
the
incredible
impact
of
data-driven
technology
on
society
we
are
becoming
increasingly
aware
of
the
imperative
to
use
data
and
algorithms
responsibly
in
accordance
with
laws
and
ethical
this
work
was
supported
in
part
by
national
science
foundation
nsf
grant
no
1741047
and
by
agence
nationale
de
la
recherche
anr
grant
headwork
authors
addresses
abiteboul
inria
ens
paris
serge
abiteboul
institut
national
de
recherche
en
informatique
et
au
tomatique
école
normale
supérieure
psl
university
75005
paris
france
email
serge.abiteboul@inria.fr
stoyanovich
department
of
computer
science
and
engineering
tandon
school
of
engineering
new
york
university
370
jay
street
brooklyn
ny
11201
usa
email
stoyanovich@nyu.edu
permission
to
make
digital
or
hard
copies
of
all
or
part
of
this
work
for
personal
or
classroom
use
is
granted
without
fee
provided
that
copies
are
not
made
or
distributed
for
profit
or
commercial
advantage
and
that
copies
bear
this
notice
and
15
the
full
citation
on
the
first
page
copyrights
for
components
of
this
work
owned
by
others
than
acm
must
be
honored
abstracting
with
credit
is
permitted
to
copy
otherwise
or
republish
to
post
on
servers
or
to
redistribute
to
lists
requires
prior
specific
permission
and
or
fee
request
permissions
from
permissions@acm.org
2019
association
for
computing
machinery
1936
1955
2019
06
art15
15.00
https://doi.org/10.1145/3310231
acm
journal
of
data
and
information
quality
vol
11
no
article
15
publication
date
june
2019
15
abiteboul
and
stoyanovich
norms
the
goal
of
this
article
is
to
underscore
the
technical
challenges
raised
by
recent
legal
and
regulatory
frameworks
which
the
data
management
community
is
well-equipped
to
address
we
discuss
three
recent
frameworks
the
european
union
general
data
protection
regula
tion
gdpr
the
european
union
2016
the
new
york
city
automated
decisions
systems
ads
law
the
new
york
city
council
2017
and
the
net
neutrality
principle
these
frameworks
are
prominent
examples
of
global
trend
governments
are
starting
to
recognize
the
need
to
regulate
data-driven
algorithmic
technology
the
gdpr
and
the
nyc
ads
law
aim
to
protect
the
rights
of
individuals
who
are
impacted
by
data
collection
and
analysis
while
the
net
neutrality
principle
ensures
that
services
are
being
treated
equitably
yet
despite
the
focus
on
organizations
rights
of
individuals
also
figure
prominently
in
the
neutrality
debate
one
of
the
imperatives
is
that
indi
viduals
should
be
able
to
enjoy
freedom
of
choice
and
expression
on-line
we
will
give
some
legal
context
on
neutrality
by
discussing
the
eu
regulation
2015
2120
the
european
parliament
and
council
2015
the
indian
net
neutrality
regulatory
framework
government
of
india
ministry
of
communications
2018
and
the
ongoing
regulatory
debate
on
net
neutrality
in
the
our
goal
in
this
article
is
to
bring
these
regulatory
frameworks
to
the
attention
of
the
data
man
agement
community
the
main
takeaway
of
this
article
is
that
legal
norms
cannot
be
incorporated
into
data-driven
systems
as
an
afterthought
rather
we
must
think
in
terms
of
responsibility
by
design
viewing
it
as
systems
requirement
1.1
the
general
data
protection
regulation
the
european
union
recently
enacted
sweeping
regulatory
framework
known
as
the
general
data
protection
regulation
or
the
gdpr
the
european
union
2016
the
regulation
was
adopted
in
april
2016
and
became
enforceable
about
two
years
later
on
may
25
2018
the
gdpr
aims
to
protect
the
rights
and
freedoms
of
natural
persons
with
regard
to
how
their
personal
data
is
processed
moved
and
exchanged
article
the
gdpr
is
broad
in
scope
and
applies
to
the
processing
of
personal
data
wholly
or
partly
by
automated
means
article
both
in
the
private
sector
and
in
the
public
sector
personal
data
is
broadly
construed
and
refers
to
any
information
relating
to
an
identified
or
identifiable
natural
person
called
the
data
subject
article
in
this
article
we
focus
on
the
following
salient
points
of
the
regulation
lawful
processing
of
data
is
predicated
on
the
data
subject
informed
consent
stating
whether
their
personal
data
can
be
used
and
for
what
purpose
articles
the
data
subject
has
right
to
correct
any
errors
in
their
data
right
to
rectification
article
16
to
withdraw
their
data
from
the
system
right
to
erasure
article
17
and
to
move
data
from
one
data
processor
to
another
right
to
portability
article
20
the
data
subject
has
the
right
to
be
informed
about
the
collection
and
use
of
their
data
the
primary
focus
of
the
gdpr
is
on
protecting
the
rights
of
data
subjects
by
giving
them
insight
into
and
control
over
the
collection
and
processing
of
their
personal
data
providing
in
sight
in
response
to
the
right
to
be
informed
requires
technical
methods
for
algorithmic
and
data
transparency
which
we
will
discuss
in
section
we
will
also
discuss
the
challenges
inherent
in
giving
individuals
an
ability
to
erase
or
move
their
data
in
section
1.2
the
new
york
city
algorithmic
decision
systems
law
new
york
city
recently
passed
law
the
new
york
city
council
2017
requiring
that
task
force
be
put
in
place
to
survey
the
current
use
of
automated
decision
systems
ads
defined
as
computerized
implementations
of
algorithms
including
those
derived
from
machine
learning
or
other
data
processing
or
artificial
intelligence
techniques
which
are
used
to
make
or
assist
in
https://gdpr-info.eu/issues/right-to-be-informed/.
acm
journal
of
data
and
information
quality
vol
11
no
article
15
publication
date
june
2019
transparency
fairness
data
protection
neutrality
15
making
decisions
in
city
agencies
the
task
force
is
working
to
develop
set
of
recommendations
for
enacting
algorithmic
transparency
by
the
agencies
and
will
propose
procedures
for
requesting
and
receiving
an
explanation
of
an
algorithmic
decision
affecting
an
individual
section
interrogating
automated
decision
systems
for
bias
and
discrimination
against
members
of
legally
protected
groups
and
addressing
instances
in
which
person
is
harmed
based
on
membership
in
such
groups
sections
and
assessing
how
automated
decision
systems
function
and
are
used
and
archiving
the
systems
together
with
the
data
they
use
sections
and
in
contrast
to
the
gdpr
which
is
very
broad
in
scope
the
nyc
ads
law
only
regulates
city
agencies
in
their
use
of
algorithms
and
data
and
does
not
directly
apply
to
private
companies
however
because
government
agencies
often
procure
systems
and
components
from
industry
partners
the
law
will
likely
impact
industry
practices
further
while
new
york
is
the
first
city
to
pass
law
of
this
kind
we
expect
other
municipalities
to
follow
with
similar
legal
frameworks
or
recommendations
in
the
near
future
the
primary
focus
of
the
nyc
ads
law
is
on
algorithmic
transparency
which
in
turn
cannot
be
achieved
without
data
transparency
stoyanovich
and
howe
2018
as
we
discussed
in
sec
tion
1.1
transparency
is
also
an
implicit
requirement
of
the
gdpr
stemming
from
the
right
to
be
informed
we
will
discuss
the
role
that
the
data
management
community
can
play
in
enabling
data
transparency
in
section
the
nyc
ads
law
further
requires
fair
and
equitable
treatment
of
individuals
mandating
that
ads
safeguard
against
bias
and
discrimination
and
provide
transparency
in
this
regard
we
will
discuss
fairness
in
section
and
will
propose
some
research
directions
for
the
data
management
community
that
are
complementary
to
the
rich
and
rapidly
expanding
body
of
work
on
fairness
in
machine
learning
1.3
the
net
neutrality
principle
net
neutrality
is
the
principle
that
internet
service
providers
isps
should
not
discriminate
or
charge
differently
based
on
the
message
source
the
content
provider
its
destination
the
user
or
its
content
the
concept
was
articulated
in
wu
2003
according
to
net
neutrality
an
isp
cannot
block
or
throttle
video
streams
from
youtube
nega
tive
discrimination
or
enable
free
access
to
facebook
out
of
package
kind
of
positive
discrimina
tion
september
2018
report
from
northeastern
university
and
the
university
of
massachusetts
amherst
found
that
telecommunications
companies
are
indeed
slowing
internet
traffic
to
and
from
those
two
sites
in
particular
along
with
other
popular
apps
kharif
2018
molavi
kakhki
et
al
2015
of
course
there
are
limits
to
the
non-discrimination
such
as
blocking
pornographic
mate
rial
for
young
internet
users
filtering
hate
speech
in
some
countries
or
guaranteeing
quality
for
emergency
services
in
the
european
union
net
neutrality
is
guaranteed
by
eu
regulation
2015
2120
the
euro
pean
parliament
and
council
2015
although
different
countries
may
interpret
the
regulation
differently
for
example
some
forms
of
zero-rating
the
practice
of
providing
internet
access
with
out
financial
cost
as
means
of
positive
discrimination
are
legal
in
some
eu
countries
but
not
in
others
since
2018
india
has
perhaps
the
world
strongest
net
neutrality
rules
government
of
india
ministry
of
communications
2018
in
general
more
and
more
countries
are
adopting
net
neutrality
regulations
with
notable
exception
in
the
united
states
the
federal
communi
cations
commission
fcc
issued
its
open
internet
order
in
2015
reclassifying
internet
access
previously
classified
as
an
information
service
as
common
carrier
telecommunications
service
acm
journal
of
data
and
information
quality
vol
11
no
article
15
publication
date
june
2019
15
abiteboul
and
stoyanovich
thereby
enforcing
some
form
of
net
neutrality
however
in
2017
under
the
chairmanship
of
ajit
pai
the
fcc
officially
repealed
net
neutrality
rules
algorithmic
and
data
transparency
propublica
story
on
machine
bias
in
an
algorithm
used
for
sentencing
defendants
angwin
et
al
2016
amplified
calls
to
make
algorithms
more
transparent
and
accountable
kroll
et
al
2017
transparency
and
accountability
are
intrinsically
linked
with
trust
and
are
of
particular
impor
tance
when
algorithmic
systems
are
integrated
into
government
processes
assisting
humans
in
their
decision-making
tasks
and
sometimes
even
replacing
humans
transparency
of
government
is
core
democratic
value
which
compels
us
to
develop
technological
solutions
that
both
increase
government
efficiency
and
can
be
made
transparent
to
the
public
narrow
interpretation
of
algorithmic
transparency
requires
that
the
source
code
of
system
be
made
publicly
available
this
is
significant
step
toward
transparency
as
long
as
the
posted
code
is
readable
well-documented
and
complete
but
it
is
rarely
sufficient
one
of
the
reasons
for
this
of
particular
relevance
to
the
data
management
community
is
that
meaningful
transparency
of
algo
rithmic
processes
cannot
be
achieved
without
transparency
of
data
stoyanovich
and
howe
2018
what
is
data
transparency
and
how
can
we
achieve
it
one
immediate
interpretation
of
this
term
in
the
context
of
predictive
analytics
includes
making
the
training
and
validation
datasets
publicly
available
however
while
data
should
be
made
open
whenever
possible
much
of
it
is
sensitive
and
cannot
be
shared
directly
that
is
data
transparency
is
in
tension
with
the
privacy
of
individuals
who
are
included
in
the
dataset
in
light
of
this
we
may
adopt
the
following
alterna
tive
interpretation
of
data
transparency
in
addition
to
releasing
training
and
validation
datasets
whenever
possible
vendors
should
make
publicly
available
summaries
of
relevant
statistical
prop
erties
of
the
datasets
that
can
aid
in
interpreting
the
decisions
made
using
this
data
while
applying
state-of-the-art
methods
to
preserve
the
privacy
of
individuals
such
as
differential
privacy
dwork
and
roth
2014
when
appropriate
privacy-preserving
synthetic
datasets
can
be
released
in
lieu
of
real
datasets
to
expose
certain
features
of
the
data
ping
et
al
2017
an
important
aspect
of
data
transparency
is
interpretability
surfacing
the
statistical
properties
of
dataset
the
methodology
that
was
used
to
produce
it
and
ultimately
substantiating
its
fitness
for
use
in
the
context
of
specific
automated
decision
system
or
task
this
consideration
of
specific
use
is
particularly
important
because
datasets
are
increasingly
used
outside
the
original
context
for
which
they
were
intended
the
data
management
community
can
begin
addressing
these
challenges
by
building
on
the
significant
body
of
work
on
data
profiling
see
abedjan
et
al
2017
for
recent
tutorial
with
an
eye
on
the
new
legal
requirements
interpretability
rests
on
making
explicit
the
interactions
between
the
program
and
the
data
on
which
it
acts
this
property
is
important
both
when
an
automated
decision
system
is
interrogated
for
systematic
bias
and
discrimination
and
when
it
is
asked
to
explain
an
algorithmic
decision
that
affects
an
individual
for
example
suppose
that
system
scores
and
ranks
individuals
for
access
to
service
if
an
individual
enters
her
data
and
receives
the
result
say
score
of
42
then
this
number
alone
provides
no
information
about
why
she
was
scored
in
this
way
how
she
compares
to
others
and
what
she
can
do
to
potentially
improve
her
outcome
prominent
example
of
system
of
this
kind
which
is
both
opaque
and
extremely
impactful
is
the
fico
credit
scoring
system
in
the
citron
and
pasquale
2014
the
data
management
research
community
is
well-positioned
to
contribute
to
developing
new
methods
for
interpretability
these
new
contributions
can
naturally
build
on
rich
body
of
work
on
data
provenance
see
herschel
et
al
2017
for
recent
survey
on
recent
work
on
explaining
classifiers
ribeiro
et
al
2016
and
auditing
black
box
models
using
causal
framework
datta
et
al
2016
and
on
automatically
generating
nutritional
labels
for
data
and
models
yang
et
al
2018
acm
journal
of
data
and
information
quality
vol
11
no
article
15
publication
date
june
2019
transparency
fairness
data
protection
neutrality
15
fairness
we
can
all
agree
that
algorithmic
decision-making
should
be
fair
even
if
we
do
not
agree
on
the
definition
of
fairness
but
isn
this
about
algorithm
design
why
is
this
data
problem
indeed
the
machine-learning
and
data-mining
research
communities
are
actively
working
on
methods
for
enabling
fairness
of
specific
algorithms
and
their
outputs
with
particular
focus
on
classifi
cation
problems
see
for
example
dwork
et
al
2012
feldman
et
al
2015
friedler
et
al
2016
hajian
and
domingo-ferrer
2013
kamiran
et
al
2013
kleinberg
et
al
2017
romei
and
ruggieri
2014
and
proceedings
of
the
recently
established
acm
conference
on
fairness
ac
countability
and
transparency
acm
fat
while
important
these
approaches
focus
solely
on
the
final
step
in
the
data
science
lifecycle
and
are
thus
limited
by
the
assumption
that
input
datasets
are
clean
and
reliable
data-driven
algorithmic
decision
making
usually
requires
multiple
pre-processing
stages
to
ad
dress
messy
input
and
render
it
ready
for
analysis
jagadish
et
al
2014
this
pre-processing
which
includes
data
cleaning
integration
querying
and
ranking
is
often
the
source
of
algorithmic
bias
kirkpatrick
2017
stoyanovich
et
al
2017
and
so
reasoning
about
sources
of
bias
and
mitigating
unfairness
upstream
from
the
final
step
of
data
analysis
is
potentially
more
impactful
for
example
much
research
goes
into
ensuring
statistical
parity
requirement
that
the
de
mographics
of
those
receiving
particular
outcome
positive
or
negative
classification
are
identical
to
the
demographics
of
the
population
as
whole
suppose
that
the
input
to
binary
classifier
contains
900
men
and
100
women
but
that
it
is
known
that
women
represent
50
of
the
over-all
population
and
so
achieving
statistical
parity
amounts
to
enforcing
50
50
gender
balance
among
the
positively
classified
individuals
that
is
all
else
being
equal
woman
in
the
input
to
the
classifier
is
far
more
likely
to
receive
positive
classification
than
man
an
alterna
tive
is
to
observe
the
following
if
the
input
to
the
classifier
was
produced
by
sql
query
and
if
relaxing
the
query
would
make
the
input
more
balanced
000
men
and
500
women
then
more
effective
way
to
mitigate
the
lack
of
statistical
parity
in
the
output
of
the
classifier
is
to
relax
the
query
upstream
it
is
easy
to
construct
additional
examples
that
show
how
bias
may
be
introduced
during
data
cleaning
data
integration
querying
and
ranking
upstream
from
the
final
stage
of
data
analy
sis
therefore
it
is
meaningful
to
detect
and
mitigate
these
effects
in
the
data
lifecycle
stages
in
which
they
occur
see
mitchell
et
al
2018
for
discussion
of
the
definitions
of
bias
and
of
the
corresponding
assumptions
made
when
defining
fairness
measures
members
of
the
data
management
community
who
are
interested
in
this
topic
may
consider
growing
body
of
work
on
impossibility
results
which
show
that
different
notions
of
fairness
cannot
be
enforced
simultaneously
and
so
require
explicit
trade-offs
chouldechova
2017
friedler
et
al
2016
kleinberg
et
al
2017
these
are
not
negative
results
per
se
nor
are
they
surprising
fairness
is
subjective
context-dependent
and
highly
politicized
concept
global
consensus
on
what
is
fair
is
unlikely
to
emerge
in
the
context
of
algorithmic
decision
making
or
otherwise
think
for
example
of
the
decade-long
debate
about
the
interplay
between
disparate
treatment
and
disparate
impact
for
which
recent
examples
include
by
ricci
de
stefano3
and
the
ongoing
lawsuit
regarding
the
use
of
race
in
harvard
university
admissions
that
being
said
productive
way
to
move
forward
in
the
data
science
context
is
to
develop
methods
that
can
be
instrumented
with
different
alternative
fairness
notions
and
that
can
support
principled
and
transparent
trade
offs
between
these
notions
https://www.fatconference.org/.
https://en.wikipedia.org/wiki/ricci_v._destefano.
https://www.nytimes.com/2018/10/13/us/harvard-affirmative-action-asian-students.html.
acm
journal
of
data
and
information
quality
vol
11
no
article
15
publication
date
june
2019
15
abiteboul
and
stoyanovich
moving
and
removing
personal
data
4.1
the
right
to
be
forgotten
the
right
to
be
forgotten
is
originally
motivated
by
the
desire
of
individuals
to
not
be
perpetually
stigmatized
by
something
they
did
in
the
past
under
pressure
from
despicable
social
phenomena
such
as
revenge
porn
it
was
turned
recently
into
laws
in
2006
in
argentina
and
since
then
in
the
european
union
as
part
of
the
gdpr
in
particular
article
17
of
the
gdpr
states
that
data
subjects
have
the
right
to
request
erasure
of
their
personal
data
and
that
they
can
do
so
for
large
number
of
reasons
the
passing
of
this
law
primarily
resulted
in
high
number
of
requests
to
search
engines
to
dereference
web
pages
this
turned
out
to
be
controversial
for
number
of
reasons
including
also
that
the
dereferencing
by
google
is
very
opaque
and
that
this
company
in
effect
acquired
against
its
own
will
questionable
power
to
adjudicate
furthermore
as
is
advocated
by
wikimedia
among
others
the
right
to
be
forgotten
sometimes
conflicts
with
other
rights
such
as
the
public
right
to
information
in
addition
to
search
engines
the
right
to
be
forgotten
affects
companies
that
keep
personal
data
prominent
example
is
facebook
where
for
many
years
it
was
impossible
to
delete
data
that
pertains
to
user
account
user
may
close
an
account
then
reopen
it
some
time
later
and
find
all
her
data
as
it
was
originally
it
is
now
possible
to
request
the
deletion
of
all
data
pertaining
to
an
account
from
facebook
however
the
user
has
no
proof
that
the
deletion
indeed
occurred
an
important
technical
issue
of
clear
relevance
to
the
data
management
community
is
that
of
deletion
of
information
in
systems
that
are
typically
meant
to
accumulate
data
this
deletion
must
be
both
permanent
and
deep
in
the
sense
that
its
effects
must
propagate
through
data
dependen
cies
to
start
it
is
difficult
to
guarantee
that
all
copies
of
every
piece
of
deleted
data
have
actually
been
deleted
further
when
some
data
is
deleted
the
remaining
database
may
become
inconsis
tent
and
may
for
example
include
dangling
pointers
additionally
production
systems
typically
do
not
include
strong
provenance
mechanism
and
so
they
have
no
means
of
tracking
the
use
of
an
arbitrary
data
item
one
to
be
deleted
and
reasoning
about
the
dependencies
on
that
data
item
in
derived
data
products
although
much
attention
of
the
data
management
community
has
over
the
years
been
devoted
to
tracking
and
reasoning
about
provenance
primarily
in
relational
contexts
and
in
workflows
see
herschel
et
al
2017
for
recent
survey
there
is
still
important
work
to
be
done
on
making
these
methods
both
practically
feasible
and
sufficiently
general
to
accommodate
the
current
legal
requirements
an
important
direction
that
is
to
the
best
of
our
knowledge
still
unexplored
con
cerns
ascertaining
the
effects
of
deletion
on
downstream
processes
that
are
not
purely
relational
but
include
other
kinds
of
data
analysis
tasks
like
data
mining
or
predictive
analytics
requests
for
deletion
may
also
conflict
with
other
laws
such
as
requirements
to
keep
certain
transaction
data
for
some
period
of
time
or
with
requirements
for
fault
tolerance
and
recover
ability
should
the
deleted
pieces
of
data
also
be
erased
from
caches
and
backups
requesting
this
functionality
gives
immediate
nightmares
to
systems
engineers
in
charge
of
production
data
management
system
with
millions
of
lines
of
code
and
terabytes
of
legacy
data
the
likely
an
swer
is
this
cannot
be
done
the
only
solution
see
is
redeveloping
the
system
from
scratch
with
right-to-be-forgotten-by-design
understanding
the
impact
of
deletion
requests
on
our
ability
to
offer
guarantees
on
system
resilience
and
performance
and
developing
appropriate
primitives
and
protocols
for
practical
use
is
another
call
to
action
for
the
data
management
community
4.2
interoperability
and
portability
article
20
of
the
gdpr
right
to
data
portability
stipulates
data
subject
right
to
receive
her
personal
data
from
vendor
and
to
transfer
her
data
to
another
vendor
the
main
goals
of
this
acm
journal
of
data
and
information
quality
vol
11
no
article
15
publication
date
june
2019
transparency
fairness
data
protection
neutrality
15
provision
are
both
to
keep
the
data
subject
informed
about
what
data
vendor
has
about
her
and
to
prevent
vendor
lock-in
this
enables
user
who
is
unhappy
with
service
to
leave
for
competing
service
that
best
serves
her
needs
without
having
to
reconstruct
her
entire
data
history
this
also
allows
user
to
select
applications
of
her
choice
and
have
them
cooperate
to
her
best
advantage
even
if
they
come
from
different
vendors
in
response
to
data
portability
regulation
and
to
users
concerns
google
twitter
microsoft
and
facebook
teamed
up
in
the
data
transfer
project
that
aims
to
facilitate
content
transfer
between
applications
of
course
it
is
not
an
easy
task
for
company
to
provide
service
that
facilitates
the
departure
of
its
customers
this
is
why
in
spite
of
commendable
behavior
of
companies
that
engage
in
the
data
transfer
project
it
is
the
role
of
regulators
to
impose
data
portability
and
interoperability
requirements
interoperability
of
database
applications
is
an
old
topic
but
one
can
imagine
an
unlimited
num
ber
of
possibilities
such
as
having
whatsapp
call
talk
to
skype
one
and
it
certainly
acquires
different
flavor
when
we
consider
interoperating
applications
with
billions
of
users
and
millions
of
transactions
per
second
for
data
portability
it
should
be
noted
that
the
devil
is
in
the
detail
the
export
format
should
be
stable
and
structured
to
facilitate
reuse
also
which
data
can
be
exported
is
an
issue
obviously
it
includes
all
data
that
the
user
volunteered
to
the
service
but
should
it
also
include
data
the
vendor
gathered
from
the
behavior
of
the
user
the
time
the
user
is
waking
up
in
the
morning
should
it
include
data
the
service
inferred
what
is
the
home
address
of
the
user
her
job
address
another
issue
with
portability
is
the
target
system
user
may
want
to
port
her
photos
from
service
to
service
the
issue
is
then
for
service
to
be
able
to
incorporate
as
much
data
as
possible
from
service
now
the
user
may
want
to
integrate
her
photos
in
personal
information
system
abiteboul
et
al
2015
such
system
must
be
able
to
integrate
information
from
large
panel
of
domains
this
brings
us
to
the
fields
of
data
integration
lenzerini
2002
and
knowledge
representation
neutrality
as
already
mentioned
net
neutrality
is
now
legally
required
in
some
countries
yet
detecting
net
neutrality
violations
to
enforce
the
law
is
not
an
easy
task
indeed
simply
measuring
the
performance
of
internet
communications
is
not
easy
measurement
results
may
depend
on
the
location
of
the
source
of
the
target
of
the
context
other
applications
competing
for
the
same
bandwidth
and
on
other
factors
indeed
different
measures
provided
for
network
traffic
typically
diverge
the
evaluation
of
net
neutrality
relying
on
such
hard-to-obtain
measures
is
challeng
ing
research
topic
molavi
kakhki
et
al
2015
which
is
primarily
of
interest
to
the
networks
and
internet
measurement
communities
and
less
so
to
data
management
but
beyond
net
neutrality
new
forms
of
neutrality
are
emerging
such
as
device
neutrality
is
my
smart-phone
blocking
certain
apps
and
favoring
others
and
platform
neutrality
is
this
particular
web
service
providing
neutral
recommendation
for
instance
app
stores
like
google
play
and
the
apple
app
store
tend
to
refuse
to
reference
certain
services
perhaps
because
they
are
competing
with
the
company
own
services
research
is
needed
to
be
able
to
verify
these
new
facets
of
neutrality
in
particular
it
is
not
easy
to
check
whether
recommendation
engine
like
google
search
or
booking
is
enforcing
only
transparent
editorial
policies
and
whether
other
than
that
their
results
are
comprehensive
impartial
and
based
solely
on
relevance
for
example
it
has
been
observed
that
search
engines
tend
to
favor
some
friendly
services
over
competitors
https://en.m.wikipedia.org/wiki/european_union_vs._google.
acm
journal
of
data
and
information
quality
vol
11
no
article
15
publication
date
june
2019
15
abiteboul
and
stoyanovich
takeaways
in
this
article
we
discussed
several
recent
regulatory
frameworks
that
aim
to
protect
the
rights
of
individuals
to
ensure
equitable
treatment
of
services
and
to
bring
transparency
to
data-driven
algorithmic
processes
in
industry
and
in
government
our
goal
was
to
bring
these
regulatory
frameworks
to
the
attention
of
the
data
management
community
and
to
underscore
the
technical
challenges
they
raise
and
that
we
as
community
are
well-equipped
to
address
an
important
takeaway
of
this
article
is
that
legal
norms
cannot
be
incorporated
into
data-driven
systems
as
an
afterthought
rather
we
must
think
in
terms
of
responsibility
by
design
viewing
it
as
systems
requirement
we
also
stress
that
enacting
algorithmic
and
data
transparency
fairness
data
protection
and
neutrality
will
require
significant
cultural
shift
in
making
this
shift
we
must
accept
that
the
objectives
of
efficiency
accuracy
and
utility
cannot
be
the
primary
goal
but
that
they
must
be
balanced
with
equitable
treatment
of
members
of
historically
disadvantaged
groups
and
with
accountability
and
transparency
to
individuals
affected
by
algorithmic
decisions
and
to
the
general
public
in
this
article
we
focused
on
explicit
regulation
of
industry
stakeholders
by
government
entities
in
the
case
of
the
gdpr
and
the
net
neutrality
laws
and
on
government
oversight
in
the
case
of
the
nyc
ads
law
another
implicit
regulatory
mechanism
can
be
achieved
by
empowering
users
and
user
associations
by
providing
them
with
data
literacy
education
and
with
precise
in
formation
on
how
different
products
and
services
work
better
educated
users
can
choose
better
solutions
including
more
effective
ways
to
protect
their
private
data
such
users
can
also
more
easily
understand
explanations
provided
to
them
by
an
algorithmic
system
user
associations
can
help
individuals
make
informed
choices
and
support
them
via
class
actions
lawsuits
in
the
case
of
disputes
references
ziawasch
abedjan
lukasz
golab
and
felix
naumann
2017
data
profiling
tutorial
in
proceedings
of
the
acm
interna
tional
conference
on
management
of
data
sigmod
17
1747
1751
doi
https://doi.org/10.1145/3035918.3054772
serge
abiteboul
benjamin
andré
and
daniel
kaplan
2015
managing
your
digital
life
commun
acm
58
apr
2015
32
35
doi
https://doi.org/10.1145/2670528
julia
angwin
jeff
larson
surya
mattu
and
lauren
kirchner
2016
machine
bias
risk
assessments
in
criminal
sen
tencing
propublica
may
2016
retrieved
from
https://www.propublica.org/article/machine-bias-risk-assessments-
in-criminal-sentencing
alexandra
chouldechova
2017
fair
prediction
with
disparate
impact
study
of
bias
in
recidivism
prediction
instruments
retrieved
from
http://arxiv.org/abs/1703.00056.
danielle
citron
and
frank
pasquale
2014
the
scored
society
due
process
for
automated
predictions
washington
law
rev
89
2014
retrieved
from
http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2376209.
anupam
datta
shayak
sen
and
yair
zick
2016
algorithmic
transparency
via
quantitative
input
influence
theory
and
experiments
with
learning
systems
in
ieee
symposium
on
security
and
privacy
sp
16
598
617
doi
https://doi.org/
10.1109
sp
2016.42
cynthia
dwork
moritz
hardt
toniann
pitassi
omer
reingold
and
richard
zemel
2012
fairness
through
awareness
in
proceedings
of
the
conference
on
innovations
in
theoretical
computer
science
214
226
doi
https://doi.org/10.1145/
2090236.2090255
cynthia
dwork
and
aaron
roth
2014
the
algorithmic
foundations
of
differential
privacy
found
trends
theoret
comput
sci
2014
211
407
doi
https://doi.org/10.1561/0400000042
michael
feldman
sorelle
friedler
john
moeller
carlos
scheidegger
and
suresh
venkatasubramanian
2015
certifying
and
removing
disparate
impact
in
proceedings
of
the
21st
acm
sigkdd
international
conference
on
knowledge
discovery
and
data
mining
259
268
doi
https://doi.org/10.1145/2783258.2783311
sorelle
friedler
carlos
scheidegger
and
suresh
venkatasubramanian
2016
on
the
im
possibility
of
fairness
retrieved
from
http://arxiv.org/abs/1609.07236.
government
of
india
ministry
of
communications
2018
dot
letter
on
net
neutrality
regulatory
framework
dated
31
07
2018
retrieved
from
http://www.dot.gov.in/net-neutrality.
acm
journal
of
data
and
information
quality
vol
11
no
article
15
publication
date
june
2019
transparency
fairness
data
protection
neutrality
15
sara
hajian
and
josep
domingo-ferrer
2013
methodology
for
direct
and
indirect
discrimination
prevention
in
data
mining
ieee
trans
knowl
data
eng
25
2013
1445
1459
doi
https://doi.org/10.1109/tkde.2012.72
melanie
herschel
ralf
diestelkämper
and
houssem
ben
lahmar
2017
survey
on
provenance
what
for
what
form
what
from
vldb
26
2017
881
906
doi
https://doi.org/10.1007/s00778-017-0486-1
jagadish
johannes
gehrke
alexandros
labrinidis
yannis
papakonstantinou
jignesh
patel
raghu
ramakrishnan
and
cyrus
shahabi
2014
big
data
and
its
technical
challenges
commun
acm
57
2014
86
94
doi
https://doi.org/
10.1145
2611567
faisal
kamiran
indre
zliobaite
and
toon
calders
2013
quantifying
explainable
discrimination
and
removing
illegal
discrimination
in
automated
decision
making
knowl
info
syst
35
2013
613
644
doi
https://doi.org/10.1007/
s10115-012-0584-8
olga
kharif
september
2018
youtube
netflix
videos
found
to
be
slowed
by
wireless
carriers
bloomberg
sept
2018
retrieved
from
https://www.bloomberg.com/news/articles/2018-09-04/youtube-and-netflix-throttled-by-carriers-
research-finds
keith
kirkpatrick
2017
it
not
the
algorithm
it
the
data
commun
acm
60
jan
2017
21
23
doi
https://doi.org/10.
1145
3022181
jon
kleinberg
sendhil
mullainathan
and
manish
raghavan
2017
inherent
trade-offs
in
the
fair
determination
of
risk
scores
in
proceedings
of
the
8th
innovations
in
theoretical
computer
science
conference
itcs
17
43
43
23
doi
https://doi.org/10.4230/lipics.itcs.2017.43
joshua
kroll
joanna
huey
solon
barocas
edward
felten
joel
reidenberg
david
robinson
and
harlan
yu
2017
accountable
algorithms
univ
penn
law
rev
165
2017
retrieved
from
http://papers.ssrn.com/sol3/papers.cfm?
abstract_id
2765268
maurizio
lenzerini
2002
data
integration
theoretical
perspective
in
proceedings
of
the
21st
acm
sigmod-sigact
sigart
symposium
on
principles
of
database
systems
pods
02
acm
new
york
ny
233
246
doi
https://doi.org/10.
1145
543613.543644
shira
mitchell
eric
potash
and
solon
barocas
2018
prediction-based
decisions
and
fairness
catalogue
of
choices
as
sumptions
and
definitions
retrieved
from
https://arxiv.org/abs/1811.07867.
arash
molavi
kakhki
abbas
razaghpanah
anke
li
hyungjoon
koo
rajesh
golani
david
choffnes
phillipa
gill
and
alan
mislove
2015
identifying
traffic
differentiation
in
mobile
networks
in
proceedings
of
the
internet
measurement
conference
imc
15
acm
new
york
ny
239
251
doi
https://doi.org/10.1145/2815675.2815691
haoyue
ping
julia
stoyanovich
and
bill
howe
2017
datasynthesizer
privacy-preserving
synthetic
datasets
in
pro
ceedings
of
the
29th
international
conference
on
scientific
and
statistical
database
management
42
42
doi
https://doi.org/10.1145/3085504.3091117
marco
túlio
ribeiro
sameer
singh
and
carlos
guestrin
2016
why
should
trust
you
explaining
the
predictions
of
any
classifier
in
proceedings
of
the
22nd
acm
sigkdd
international
conference
on
knowledge
discovery
and
data
mining
1135
1144
doi
https://doi.org/10.1145/2939672.2939778
andrea
romei
and
salvatore
ruggieri
2014
multidisciplinary
survey
on
discrimination
analysis
knowl
eng
rev
29
2014
582
638
doi
https://doi.org/10.1017/s0269888913000039
julia
stoyanovich
and
bill
howe
2018
follow
the
data
algorithmic
transparency
starts
with
data
transparency
re
trieved
from
https://ai.shorensteincenter.org/ideas/2018/11/26/follow-the-data-algorithmic-transparency-starts-with-
data-transparency
julia
stoyanovich
bill
howe
serge
abiteboul
gerome
miklau
arnaud
sahuguet
and
gerhard
weikum
2017
fides
to
wards
platform
for
responsible
data
science
in
proceedings
of
the
29th
international
conference
on
scientific
and
sta
tistical
database
management
26
26
doi
https://doi.org/10.1145/3085504.3085530
the
european
parliament
and
council
2015
regulation
eu
2015
2120
retrieved
from
https://eur-lex.europa.eu/
legal-content
en
txt
uri
celex
32015r2120
the
european
union
2016
regulation
eu
2016
679
general
data
protection
regulation
gdpr
retrieved
from
https
gdpr-info
eu
the
new
york
city
council
2017
int
no
1696
local
law
in
relation
to
automated
decision
systems
used
by
agencies
retrieved
from
https://laws.council.nyc.gov/legislation/int-1696-2017/.
tim
wu
2003
network
neutrality
broadband
discrimination
telecommun
high
technol
law
2003
ke
yang
julia
stoyanovich
abolfazl
asudeh
bill
howe
jagadish
and
gerome
miklau
2018
nutritional
label
for
rankings
in
proceedings
of
the
international
conference
on
management
of
data
sigmod
18
1773
1776
doi
https
doi
org
10.1145
3183713.3193568
received
december
2018
accepted
december
2018
acm
journal
of
data
and
information
quality
vol
11
no
article
15
publication
date
june
2019