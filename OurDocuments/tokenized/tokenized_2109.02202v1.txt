fairness
via
ai
bias
reduction
in
medical
information
shiri
dori-hacohen
university
of
connecticut
aucode
usa
roberto
montenegro
seattle
children
hospital
usa
fabricio
murai
universidade
federal
de
minas
gerais
brazil
scott
hale
meedan
usa
keen
sung
aucode
usa
michela
blain
university
of
washington
school
of
medicine
usa
arxiv
2109
02202v1
cs
ai
sep
2021
jennifer
edwards-johnson
michigan
state
university
college
of
human
medicine
usa
additional
key
words
and
phrases
fairness
in
ai
health
misinformation
bias
reduction
introduction
most
fairness
in
ai
research
focuses
on
exposing
biases
in
ai
systems
broader
lens
on
fairness
reveals
that
ai
can
serve
greater
aspiration
rooting
out
societal
inequities
from
their
source
speciﬁcally
we
focus
on
inequities
in
health
information
and
aim
to
reduce
bias
in
that
domain
using
ai
the
ai
algorithms
under
the
hood
of
search
engines
and
social
media
many
of
which
are
based
on
recommender
systems
have
an
outsized
impact
on
the
quality
of
medical
and
health
information
online
therefore
embedding
bias
detection
and
reduction
into
these
recommender
systems
serving
up
medical
and
health
content
online
could
have
an
outsized
positive
impact
on
patient
outcomes
and
wellbeing
in
this
position
paper
we
oﬀer
the
following
contributions
we
propose
novel
framework
of
fairness
via
ai
inspired
by
insights
from
medical
education
sociology
and
antiracism
we
deﬁne
new
term
bisinformation
which
is
related
to
but
distinct
from
misinformation
and
encourage
researchers
to
study
it
we
propose
using
ai
to
study
detect
and
mitigate
biased
harmful
and
or
false
health
information
that
disproportionately
hurts
minority
groups
in
society
and
we
suggest
several
pillars
and
pose
several
open
problems
in
order
to
seed
inquiry
in
this
new
space
while
part
of
this
work
speciﬁcally
focuses
on
the
health
domain
the
fundamental
computer
science
advances
and
contributions
stemming
from
research
eﬀorts
in
bias
reduction
and
fairness
via
ai
have
broad
implications
in
all
areas
of
society
fairness
via
ai
the
vast
majority
of
fairness
in
ai
work
focuses
on
exposing
the
bias
in
ai
system
in
order
to
showcase
where
the
ai
system
is
biased
however
ai
systems
will
continue
to
be
biased
so
long
as
the
data
they
are
receiving
are
biased
according
to
bias
in
bias
out
principle
16
so
long
as
signiﬁcant
structural
inequalities
exist
in
the
real
world
ai
systems
will
continue
to
replicate
and
exacerbate
them
the
dominant
fairness
in
ai
approach
then
risks
engaging
in
sisyphean
task
of
minimizing
bias
in
ai
with
attempts
to
debias
ai
datasets
models
and
algorithms
continually
needing
to
be
ﬁxed
as
they
learn
biased
outcomes
and
are
bound
to
hit
ceiling
of
fairness
that
of
real
world
settings
that
are
inherently
biased
under
this
approach
our
highest
aspiration
in
designing
ai
systems
seems
to
be
one
of
avoidance
tweaking
our
models
to
refrain
from
adding
to
society
ills
and
inequities
authors
addresses
shiri
dori-hacohen
shiridh@uconn.edu
university
of
connecticut
aucode
usa
roberto
montenegro
seattle
children
hospi
tal
usa
fabricio
murai
universidade
federal
de
minas
gerais
brazil
scott
hale
meedan
usa
keen
sung
aucode
usa
michela
blain
university
of
washington
school
of
medicine
usa
jennifer
edwards-johnson
michigan
state
university
college
of
human
medicine
usa
dori-hacohen
et
al
rooted
in
insights
from
medical
education
sociology
and
antiracism
we
oﬀer
broader
lens
on
fairness
revealing
that
ai
can
serve
far
greater
aspiration
enabling
important
restorative
work
and
rooting
out
societal
inequities
from
their
source
with
deeper
and
more
meaningful
impact
in
this
position
paper
we
therefore
reverse
the
traditional
direction
of
fairness
rather
than
aiming
to
achieve
fairness
in
or
of
ai
we
propose
focusing
on
fairness
via
ai
with
this
approach
one
can
use
ai
to
study
detect
mitigate
and
remedy
situations
that
are
inherently
unequal
unjust
and
unfair
in
society
with
this
ambitious
yet
grounded
approach
our
potential
impact
is
unbounded
and
can
accelerate
progress
towards
more
fair
equal
and
just
world
in
other
words
we
can
use
ai
to
thoughtfully
carefully
and
ethically
debias
the
world
rather
than
simply
trying
to
debias
ai
speciﬁcally
the
ai
algorithms
under
the
hood
of
search
engines
and
social
media
many
of
which
are
based
on
recommender
systems
have
an
outsized
impact
on
the
quality
of
information
available
online
therefore
embedding
bias
detection
and
reduction
directly
into
these
recommender
systems
could
have
an
outsized
positive
impact
on
the
information
ecosystem
bisinformation
we
coin
the
term
bisinformation
to
represent
biased
information
referring
to
unique
and
challenging
aspect
of
the
information
landscape
we
are
particularly
interested
in
health
bisinformation
where
bias
and
language
misuse
have
detrimental
impact
on
patient
outcomes
though
the
term
can
easily
apply
in
any
ﬁeld
bisinformation
may
overlap
with
but
is
not
identical
to
misinformation
the
use
of
biased
language
or
inappropriate
social
identiﬁers
in
medical
context
for
example
can
be
harmful
even
if
strictly
true
consider
the
case
of
referring
to
the
prevalence
of
an
illness
in
racial
category
without
contextualizing
it
in
social
or
structural
determinants
of
health
ssdoh
such
as
systemic
racism
or
income
inequities
17
on
the
other
hand
certain
types
of
bisinformation
are
in
fact
also
form
of
misinformation
such
as
the
long-debunked
salt
gene
hypothesis
19
to
the
best
of
our
knowledge
no
studies
have
computationally
studied
health
bisinformation
at
large
scale
medical
bisinformation
and
misinformation
as
an
illustration
of
societal
inequities
in
dire
need
of
the
fair
ness
via
ai
approach
consider
the
ﬁeld
of
medicine
and
medical
education
the
ﬁeld
is
marred
by
long
and
painful
history
of
overt
and
covert
forms
of
social
injustice
bias
and
racism
as
illustrated
by
the
american
medical
associa
tion
recent
pledge
to
take
action
to
confront
systemic
racism
14
22
studies
continue
to
demonstrate
that
physicians
possess
implicit
biases
in
number
of
diﬀerent
areas
such
as
race
ethnicity
gender
sex
age
weight
substance
use
and
mental
illness
this
comes
into
play
signiﬁcantly
in
medical
institutions
which
continue
to
teach
biased
medicine
in
preclinical
years
see
23
many
educators
for
example
continue
to
inappropriately
use
race
as
proxy
for
genet
ics
or
ancestry
or
even
as
risk
factor
for
numerous
health
outcomes
often
erroneously
associated
with
race
while
ignoring
ssdoh
11
17
many
educators
continue
to
inappropriately
use
gender
and
sex
terms
and
perpetuate
the
idea
that
sex
and
gender
are
binary
and
stagnant
versus
ﬂuid
likewise
most
medical
educators
are
unaware
of
the
numerous
biases
in
the
types
of
images
they
use
in
their
lectures
or
assessment
materials
as
well
13
by
equat
ing
social
identiﬁers
to
biology
without
social
or
structural
context
medical
educators
are
unknowingly
perpetuating
curriculum
that
can
have
an
adverse
eﬀect
on
health
outcomes
15
bias
reduction
in
curricular
and
assessment
content
is
critical
for
educating
future
physicians
in
accurate
evidence-based
medicine
12
21
but
is
manual
costly
and
time
consuming
eﬀort
sota
ai
and
nlp
approaches
can
be
used
to
scale
up
these
eﬀorts
signiﬁcantly1
naturally
bisinformation
and
misinformation
that
persist
in
the
medical
establishment
are
also
disseminated
and
extensively
present
in
online
medical
resources
websites
and
news
articles
and
social
media
with
large
negative
ef
fects
on
historically
underserved
populations
also
reinforcing
biased
narratives
and
stereotypes
about
minority
groups
montenegro
dori-hacohen
and
sung
have
recently
been
awarded
grant
from
the
national
board
of
medical
examiners
stemmler
fund
to
reduce
bias
in
medical
curricular
content
using
nlp
and
ml
approaches
fairness
via
ai
bias
reduction
in
medical
information
recommender
systems
play
an
outsized
role
in
serving
up
such
content
online
but
improving
these
systems
to
reduce
bias
will
prove
extremely
challenging
if
we
don
understand
the
underlying
mechanisms
in
which
such
bias
is
perpet
uated
and
disseminated
prior
work
has
suggested
that
controversy
online
is
highly
unevenly
distributed
and
that
population-sensitive
model
is
needed
in
order
to
properly
model
this
10
we
hypothesize
that
the
same
approach
may
be
needed
in
the
computational
study
of
bisinformation
and
misinformation
for
example
the
covid-19
pandemic
and
its
associated
infodemic
has
brought
health
mis
and
disinformation
to
the
forefront
of
national
and
scientiﬁc
atten
tion
however
trust
in
the
medical
establishment
may
be
understandably
low
among
african-americans
and
other
minority
groups
recent
work
suggests
moreover
that
health
mis
and
disinformation
is
qualitatively
distinct
in
diﬀerent
population
groups
20
to
cite
just
one
example
covid-19
vaccine
hesitancy
has
been
demonstrated
to
be
higher
among
racial
and
ethnic
minorities
18
pillars
open
problems
few
guiding
pillars
underlie
and
drive
our
fairness
via
ai
research
agenda
which
we
encourage
others
to
adopt
first
we
argue
that
fairness
via
ai
is
more
eﬀective
and
impactful
marshalling
of
research
resources
than
standard
fairness
in
ai
work
important
though
the
latter
may
be
second
we
argue
that
collaboration
across
disciplinary
ﬁelds
is
critically
needed
in
order
to
eﬀectively
and
ethically
study
and
understand
society
biggest
challenges
to
say
nothing
of
mitigating
them
researchers
in
other
ﬁelds
including
but
in
no
way
not
limited
to
the
social
sciences
have
immense
expertise
in
studying
and
addressing
societal
inequities
computer
scientists
cannot
and
should
not
go
this
alone
finally
we
argue
that
biased
information
interacts
with
false
information
in
complex
ways
that
must
be
studied
carefully
in
order
to
reduce
bias
in
recommender
systems
and
other
information
delivery
systems
such
as
search
engines
with
these
pillars
ﬁrmly
in
mind
we
pose
the
following
open
questions
q1
what
are
eﬀective
approaches
to
identify
societal
problems
that
are
in
most
need
of
and
lend
themselves
to
the
fairness
via
ai
framework
q2
which
existing
and
or
novel
ai
approaches
need
to
be
deployed
and
developed
in
order
to
address
such
societal
issues
q3
how
can
we
encourage
collaboration
across
disciplinary
boundaries
in
order
to
leverage
hard-won
insights
from
other
ﬁelds
and
infuse
our
fairness
research
with
them
q4
speciﬁcally
with
respect
to
bisinformation
several
research
questions
arise
how
and
where
does
bisinformation
spread
online
is
information
including
mis
and
bisinformation
dis
tributed
and
disseminated
diﬀerentially
among
diverse
population
groups
if
so
how
which
categories
or
types
of
bisinformation
and
misinformation
are
most
problematic
and
harmful
and
thus
deserving
the
most
diligent
fact
checking
and
countermessaging
eﬀorts
in
other
words
how
should
we
triage
mis
and
bisinformation
combining
best
practices
in
the
public
health
and
fact
checking
spheres
with
state-of-the-art
computational
approaches
conclusions
in
this
position
paper
we
introduced
novel
fairness
via
ai
framework
coined
new
term
bisinformation
to
describe
biased
information
and
demonstrated
that
is
is
overlapping
with
yet
distinct
from
misinformation
brieﬂy
dis
cussed
the
documented
presence
of
bisinformation
in
medical
curricula
and
posit
that
this
extends
to
other
information
environments
such
as
online
and
posed
several
open
questions
to
guide
research
agendas
on
the
subject
dori-hacohen
et
al
acknowledgements
this
material
is
based
in
part
upon
work
supported
by
the
national
science
foundation
under
grant
no
1951091
any
opinions
ﬁndings
and
conclusions
or
recommendations
expressed
in
this
material
are
those
of
the
author
and
do
not
neces
sarily
reﬂect
the
views
of
the
national
science
foundation
references
kimberly
acquaviva
and
matthew
mintz
2010
perspective
are
we
teaching
racial
proﬁling
the
dangers
of
subjective
determinations
of
race
and
ethnicity
in
case
presentations
academic
medicine
85
2010
702
705
sarah
ali-khan
tomasz
krakowski
rabia
tahir
and
abdallah
daar
2011
the
use
of
race
ethnicity
and
ancestry
in
human
genetic
research
the
hugo
journal
2011
47
63
dwayne
brandon
lydia
isaac
and
thomas
laveist
2005
the
legacy
of
tuskegee
and
trust
in
medical
care
is
tuskegee
responsible
for
race
diﬀerences
in
mistrust
of
medical
care
journal
of
the
national
medical
association
97
2005
951
lundy
braun
anne
fausto-sterling
duana
fullwiley
evelynn
hammonds
alondra
nelson
william
quivers
susan
reverby
and
alexandra
shields
2007
racial
categories
in
medical
practice
how
useful
are
they
plos
medicine
2007
e271
asif
doja
dylan
bould
chantalle
clarkin
kaylee
eady
stephanie
sutherland
and
hilary
writer
2016
the
hidden
and
informal
curriculum
across
the
continuum
of
training
cross-sectional
qualitative
study
medical
teacher
38
2016
410
418
keisa
fallin-bennett
2015
implicit
bias
against
sexual
minorities
in
medicine
cycles
of
professional
inﬂuence
and
the
role
of
the
hidden
curriculum
academic
medicine
90
2015
549
552
chloë
fitzgerald
and
samia
hurst
2017
implicit
bias
in
healthcare
professionals
systematic
review
bmc
medical
ethics
18
2017
18
linda
hunt
nicole
truesdell
and
meta
kreiner
2013
genes
race
and
culture
in
clinical
care
racial
proﬁling
in
the
management
of
chronic
illness
medical
anthropology
quarterly
27
2013
253
271
jaiswal
loschiavo
and
dc
perlman
2020
disinformation
misinformation
and
inequality-driven
mistrust
in
the
time
of
covid-19
lessons
unlearned
from
aids
denialism
aids
and
behavior
24
2020
2776
2780
10
myungha
jang
shiri
dori-hacohen
and
james
allan
2017
modeling
controversy
within
populations
in
proceedings
of
the
acm
sigir
international
conference
on
theory
of
information
retrieval
amsterdam
the
netherlands
association
for
computing
machinery
new
york
ny
usa
141
149
https://doi.org/10.1145/3121050.3121067
ictir
17
11
reena
karani
lara
varpio
win
may
tanya
horsley
john
chenault
karen
hughes
miller
and
bridget
brien
2017
commentary
racism
and
bias
in
health
professions
education
how
educators
faculty
developers
and
researchers
can
make
diﬀerence
academic
medicine
92
11s
2017
s1
s6
12
tao
le
vikas
bhushan
matthew
sochat
kimberly
kallianos
yash
chavda
andrew
harrison
zureick
and
mehboob
kalani
2018
first
aid
for
the
usmle
step
2018
mcgraw-hill
medical
13
heidi
lempp
and
clive
seale
2004
the
hidden
curriculum
in
undergraduate
medical
education
qualitative
study
of
medical
students
perceptions
of
teaching
bmj
329
7469
2004
770
773
14
madara
2020
america
health
care
crisis
is
much
deeper
than
covid-19
https://www.ama-assn.org/about/leadership/america-s-health-care-crisis-much-deeper-covid
15
maria
athina
tina
martimianakis
barret
michalec
justin
lam
carrie
cartmill
janelle
taylor
and
frederic
haﬀerty
2015
humanism
the
hidden
curriculum
and
educational
reform
scoping
review
and
thematic
analysis
academic
medicine
90
11
2015
s5
s13
16
sandra
mayson
2018
bias
in
bias
out
yale
lj
128
2018
2218
17
jonathan
metzl
and
dorothy
roberts
2019
structural
competency
meets
structural
racism
race
politics
and
the
structure
of
medical
knowledge
in
the
social
medicine
reader
volume
ii
third
edition
duke
university
press
170
187
18
long
nguyen
amit
joshi
david
drew
jordi
merino
wenjie
ma
chun-han
lo
sohee
kwon
kai
wang
mark
graham
lorenzo
polidori
cristina
menni
carole
sudre
adjoa
anyane-yeboa
christina
astley
erica
warner
christina
hu
somesh
selvachandran
richard
davies
denis
nash
paul
franks
jonathan
wolf
sebastien
ourselin
claire
steves
tim
spector
andrew
chan
and
on
behalf
of
the
cope
consor
tium
2021
racial
and
ethnic
diﬀerences
in
covid-19
vaccine
hesitancy
and
uptake
medrxiv
2021
https://doi.org/10.1101/2021.02.25.21252402
arxiv
https://www.medrxiv.org/content/early/2021/02/28/2021.02.25.21252402.full.pdf
19
anne
pollock
2012
the
slavery
hypothesis
beyond
genetic
determinism
in
medicating
race
duke
university
press
107
130
20
amit
prasad
2021
anti-science
misinformation
and
conspiracies
covid
19
post-truth
and
science
technology
studies
sts
science
technology
and
society
2021
https://doi.org/10.1177/09717218211003413
21
kelsey
ripp
and
lundy
braun
2017
race
ethnicity
in
medical
education
an
analysis
of
question
bank
for
step
of
the
united
states
medical
licensing
examination
teaching
and
learning
in
medicine
29
2017
115
122
22
angela
saini
2019
superior
the
return
of
race
science
beacon
press
23
jennifer
tsai
laura
ucik
nell
baldwin
christopher
hasslinger
and
paul
george
2016
race
matters
examining
and
rethinking
race
portrayal
in
preclinical
medical
education
academic
medicine
91
2016
916
920
this
figure
sample-franklin
png
is
available
in
png
format
from
http://arxiv.org/ps/2109.02202v1