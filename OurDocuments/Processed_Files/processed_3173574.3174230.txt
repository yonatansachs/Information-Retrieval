chi
2018
paper
chi
2018
april
21
26
2018
montréal
qc
canada
qualitative
exploration
perceptions
algorithmic
fairness
allison
woodruff1
sarah
fox2
steven
rousso-schindler3
jeff
warshaw4
google
woodruff@acm.org
google
human
centered
design
engineering
university
washington
sefox@uw.edu
department
anthropology
csu
long
beach
steven.rousso-schindler@csulb.edu
google
jeffwarshaw@google.com
abstract
raise
awareness
illustrate
potential
wide-ranging
algorithmic
systems
increasingly
shape
information
people
consequences
researchers
press
pointed
exposed
well
influence
decisions
number
specific
instances
algorithmic
unfairness
employment
finances
opportunities
19
58
example
predictive
policing
19
43
cases
algorithmic
systems
may
less
favorable
online
housing
marketplace
27
28
online
ads
certain
groups
individuals
sparking
substantial
13
17
20
29
82
image
search
results
49
64
discussion
algorithmic
fairness
public
policy
circles
academia
press
broaden
discussion
cases
demonstrate
algorithmic
un
fairness
exploring
members
potentially
affected
complex
industry-wide
issue
bias
can
result
many
communities
feel
algorithmic
fairness
conducted
causes
example
data
sets
reflect
structural
bias
workshops
interviews
44
participants
several
society
human
prejudice
product
decisions
populations
traditionally
marginalized
categories
race
disadvantage
certain
populations
unintended
class
united
states
concept
consequences
complicated
interactions
among
multiple
algorithmic
fairness
largely
unfamiliar
learning
technical
systems
accordingly
many
players
algorithmic
un
fairness
elicited
negative
feelings
ecosystem
including
limited
policy
makers
connect
current
national
discussions
racial
injustice
companies
advocates
researchers
shared
economic
inequality
addition
concerns
responsibility
opportunity
pursue
fairness
potential
harms
society
participants
also
algorithmic
fairness
therefore
appears
wicked
indicated
algorithmic
fairness
lack
thereof
problem
72
diverse
stakeholders
yet
substantially
affect
trust
company
product
clear
agreement
problem
statement
solution
human
computer
interaction
hci
community
related
author
keywords
disciplines
course
highly
interested
influencing
algorithmic
fairness
algorithmic
discrimination
positive
action
issues
25
example
acm
classification
keywords
established
tradition
conducting
research
inform
computers
society
miscellaneous
public
policy
societal-scale
challenges
50
84
well
providing
companies
information
can
best
introduction
serve
users
indeed
recent
work
plane
et
al
scholars
thought
leaders
observed
increasing
discrimination
online
advertising
positioned
role
influence
algorithms
society
pointing
informing
public
policy
well
company
initiatives
67
mediate
perception
knowledge
world
well
affect
chances
opportunities
life
building
tradition
goal
research
17
38
54
55
63
76
79
academics
explore
ethical
pragmatic
aspects
public
perception
regulators
long
refuted
presumption
algorithmic
fairness
end
conducted
algorithms
wholly
objective
observing
algorithms
qualitative
study
several
populations
can
reflect
amplify
human
structural
bias
introduce
traditionally
marginalized
likely
affected
complex
biases
10
18
33
35
38
46
64
algorithmic
un
fairness
specifically
black
african
american
hispanic
latinx
low
socioeconomic
status
participants
united
states
research
questions
centered
around
participants
interpretations
work
licensed
creative
commons
experiences
algorithmic
un
fairness
well
attribution-noncommercial-noderivs
international
4.0
license
ascription
accountability
ethical
pragmatic
expectations
stakeholders
order
draw
robust
chi
2018
april
21
26
2018
montreal
qc
canada
conclusions
participants
interpret
highly
2018
copyright
held
owner
author
contextual
issues
explored
broad
spectrum
acm
isbn
978
4503
5620
18
04
https://doi.org/10.1145/3173574.3174230
different
types
algorithmic
unfairness
using
scenarios
make
discussion
concrete
paper
656
page
chi
2018
paper
chi
2018
april
21
26
2018
montréal
qc
canada
findings
indicate
concept
algorithmic
image
search
predictive
search
results
may
reinforce
un
fairness
initially
mostly
unfamiliar
participants
exaggerate
societal
bias
negative
stereotypes
related
often
perceived
algorithmic
systems
limited
race
gender
sexual
orientation
49
62
64
others
impact
still
deeply
concerned
algorithmic
raised
concerns
potential
use
facebook
activity
unfairness
often
expected
companies
address
compute
non-regulated
credit
scores
especially
may
regardless
source
company
response
disproportionately
disadvantage
less
privileged
populations
algorithmic
unfairness
substantially
impact
user
trust
17
82
edelman
et
al
ran
experiments
airbnb
findings
can
inform
variety
stakeholders
reported
applications
guests
distinctively
policy
makers
corporations
bolster
widely
african
american
names
16
less
likely
espoused
notion
algorithmic
fairness
societally
accepted
relative
identical
guests
distinctively
important
goal
stakeholders
across
ecosystem
white
names
28
edelman
luca
also
found
non-black
regulator
industry
practitioner
pursue
full
hosts
able
charge
approximately
12
recognition
importance
ethical
motivations
black
hosts
holding
location
rental
characteristics
findings
also
suggest
algorithmic
fairness
can
good
quality
constant
27
colley
et
al
found
pokémon
go
business
practice
readers
may
search
advantaged
urban
white
non-hispanic
populations
arguments
motivate
persuade
companies
take
steps
example
potentially
attracting
tourist
commerce
improve
algorithmic
fairness
many
good
neighborhoods
15
johnson
et
al
found
reasons
companies
care
fairness
including
geolocation
inference
algorithms
exhibited
substantially
limited
ethical
moral
imperatives
legal
worse
performance
underrepresented
populations
requirements
regulatory
risk
public
relations
rural
users
47
brand
risk
paper
provide
additional
motivation
public
awareness
accompanied
increased
illustrating
user
trust
important
legal
regulatory
attention
example
upcoming
understudied
pragmatic
incentive
companies
across
european
union
general
data
protection
regulation
technology
sector
pursue
algorithmic
fairness
based
contains
article
automated
individual
decision
findings
outline
three
best
practices
pursuing
making
39
yet
algorithmic
fairness
poses
many
legal
algorithmic
fairness
complexities
challenges
law
regulation
background
still
nascent
stages
rapidly
changing
field
algorithmic
fairness
investigate
systems
adherence
emerging
legal
taking
algorithmic
fairness
draw
seek
regulatory
ethical
standards
algorithmic
fairness
extend
emerging
strands
thought
within
fields
testing
transparency
called
science
technology
studies
sts
hci
mathematics
14
77
wide
range
techniques
proposed
related
disciplines
research
algorithmic
fairness
scrutinize
algorithms
model
interpretability
encompasses
wide
range
issues
example
audits
expert
analysis
reverse
engineering
cases
considering
discrete
decisions
impact
22
42
76
77
investigation
complicated
however
individuals
fair
division
algorithms
explored
myriad
potential
causes
unfairness
prejudice
structural
51
52
cases
exploring
broader
patterns
bias
choice
training
data
complex
interactions
human
related
groups
traditionally
marginalized
behavior
machine
learning
models
unforeseen
supply
society
focus
tends
towards
latter
demand
effects
online
bidding
processes
etc
particular
relevance
investigation
perspective
sometimes
impenetrable
opaque
nature
machine
taken
critical
algorithm
studies
articulates
learning
systems
12
38
fact
existing
offline
increasing
influence
algorithms
society
largely
discrimination
problems
may
cases
exacerbated
focuses
understanding
algorithms
object
social
harder
investigate
manifest
online
concern
17
38
54
55
63
76
79
countering
popular
systems
77
new
bigotries
based
just
claims
algorithmic
authority
data-driven
decisions
immutable
characteristics
subtle
features
may
may
lead
increased
objectivity
many
scholars
arise
difficult
detect
traditional
observed
algorithms
can
reflect
amplify
introduce
discriminatory
processes
bias
10
18
33
35
38
46
64
opacity
complexity
complicate
expert
articles
academic
venues
well
popular
press
analysis
may
also
make
difficult
chronicled
specific
instances
unjust
prejudicial
stakeholders
understand
consequences
algorithmic
treatment
people
based
categories
like
race
sexual
systems
many
proposed
mechanisms
scrutinizing
orientation
gender
algorithmic
systems
algorithms
make
certain
assumptions
public
algorithmically
aided
decision-making
example
perez
regulators
stakeholders
however
research
reported
microsoft
tay
artificial
intelligence
found
perception
algorithmic
systems
can
vary
chatbot
suffered
coordinated
attack
led
exhibit
substantially
individual
factors
well
platform
21
racist
behavior
65
researchers
also
reported
end
users
often
fundamental
questions
misconceptions
technical
details
operation
paper
656
page
chi
2018
paper
chi
2018
april
21
26
2018
montréal
qc
canada
11
31
69
85
86
effect
may
exacerbated
less
different
technological
experts
87
privileged
populations
86
example
studies
taking
perspective
orient
workshop
found
participants
aware
algorithmic
attendees
experts
technology
experienced
curation
facebook
news
feed
31
69
daily
lives
framing
speaks
sets
gathering
online
behavioral
data
use
knowledges
different
less
inferencing
86
underestimate
prevalence
scale
technological
experts
data
gathering
use
practical
applications
1980s
hci
scholars
jungk
müllert
first
85
86
participants
often
emphasize
role
described
future
workshop
format
social
human
decision-making
algorithmic
systems
engagement
involved
organization
events
example
misattributing
algorithmic
curation
members
public
meant
better
address
issues
facebook
news
feed
actions
taken
friends
democratic
concern
48
similar
political
roots
family
31
framing
algorithms
calculator-like
tools
participatory
design
method
focused
actively
support
human
decision-making
86
including
members
public
under-represented
despite
existing
research
algorithmic
literacy
stakeholders
processes
design
early
examples
little
research
explored
understandings
algorithmic
work
1980s
aimed
support
worker
un
fairness
currently
little
insight
autonomy
appreciation
traditional
expertise
light
general
public
particular
people
affected
introduction
digitized
work
practices
algorithmic
unfairness
might
perceive
rare
cases
automation
labor
example
pelle
ehn
exception
plane
et
al
surveyed
broad
population
design
scholar
longtime
proponent
participatory
us
including
near-census
representative
panel
regarding
design
collaborated
scandinavian
graphic
designers
responses
online
behavioral
advertising
oba
union
produce
software
system
meant
better
scenarios
used
race
targeting
variable
job
ad
incorporate
skilled
practices
compared
67
overall
almost
half
respondents
viewed
management-initiated
programs
30
scenarios
moderate
severe
problem
black
contemporary
participatory
initiatives
taken
respondents
finding
higher
severity
offer
concerns
outside
work
governmental
contexts
complementary
novel
exploration
algorithmic
exploring
alternative
food
systems
23
24
understanding
un
fairness
explore
much
wider
range
promote
play
among
neurodiverse
children
80
potential
types
algorithmic
unfairness
take
still
others
developed
design
workshop
means
qualitative
approach
allows
us
deeply
explore
issues
examining
critical
theory
material
practice
like
smaller
population
complementary
plane
making
tinkering
70
used
craft
imagine
et
al
narrow
quantitative
exploration
larger
alternative
near
futures
might
yield
equitable
representative
sample
67
focus
social
arrangements
75
populations
likely
affected
algorithmic
unfairness
rather
general
public
build
legacy
participatory
programs
workshop
method
reporting
use
workshop
format
research
taking
workshop
format
draw
traditions
instrument
toward
understanding
participants
within
just
beyond
hci
includes
programs
perceive
algorithmic
un
fairness
also
might
participatory
action
research
participatory
design
elect
construct
platforms
differently
due
living
labs
within
context
hci
design
research
potentially
sensitive
nature
subject
matter
looked
workshop
approaches
often
seek
invite
members
dialogical
approaches
like
participatory
design
public
engage
practices
design
exploring
helpful
technique
collaboratively
working
values
beliefs
around
technology
complex
ideas
machine
learning
developing
positing
alternative
techniques
outcomes
noting
open
environment
sharing
feelings
opinions
see
collaborative
situated
nature
approach
rosner
et
discussions
subsequent
ideas
informing
al
describe
design
workshop
inviting
treatment
development
technology
policy
well
collaboration
interdisciplinary
localized
communication
diverse
users
future
imaginative
practice
74
engagements
rely
methodology
careful
collaboration
researcher
order
better
understand
members
marginalized
subject
partner
across
sites
like
academic
industrial
communities
perceive
algorithmic
un
fairness
research
centers
community
groups
conducted
participatory
design
workshops
members
goals
work
relatedly
research
public
various
communities
throughout
san
francisco
bay
understanding
science
argues
assuming
single
area
conducted
individual
follow-up
interviews
correct
understanding
science
technology
select
participants
workshops
interviews
took
emphasizing
members
public
place
july
september
2016
excluded
democratic
decision-making
technology
interpretations
technology
may
paper
656
page
chi
2018
paper
chi
2018
april
21
26
2018
montréal
qc
canada
participants
slightly
emphasizing
involved
care
service
recruited
44
adults
responded
screener
professions
skills
expertise
often
underrecognized
survey
administered
national
research
recruitment
firm
technology
cultures
57
71
respondent
database
including
san
francisco
bay
area
residents
participants
compensated
participants
east
bay
san
time
living
wage
area
francisco
wide
range
ages
18
65
recruiting
focused
inviting
individuals
occupations
public
transportation
driver
retail
traditionally
marginalized
either
categories
manager
special
education
instructor
community
activities
socioeconomic
status
race
organized
coordinator
tasker
line
cook
laborer
correctional
peace
participants
five
workshops
follows
two
workshops
officer
office
assistant
theater
assistant
based
socioeconomic
status
described
one
workshop
workshop
participants
identified
black
group
participated
hour
workshop
african
american
women
one
workshop
black
following
agenda
icebreaker
activity
group
discussion
african
american
mixed
race
men
women
one
algorithmic
un
fairness
meal
design
activity
workshop
hispanic
latinx
men
women
centered
around
three
cases
concluding
group
work
qualitative
non-representative
expect
discussion
attendance
workshop
constituencies
focused
comprise
roughly
11
participants
researchers
acted
facilitators
40
50
us
population
visual
anthropologist
focused
documentation
participants
aware
google
involvement
primary
factors
considering
socioeconomic
status
study
workshops
took
place
google
location
current
household
income
education
level
selected
workshops
took
care
encourage
participants
annual
household
income
less
collaborative
interpretation
problem-solving
living
wage
home
county
amount
discussion
among
participants
make
space
determined
coarse
approximation
glasmeier
participants
share
ideas
opinions
additionally
living
wage
model
livingwage
mit
edu
accessed
july
recognizing
emotional
complexity
topic
august
2016
factoring
amount
considered
explained
might
sensitive
material
total
number
adults
household
number
participants
feel
free
stop
participating
sit
adults
contributing
income
number
dependent
activity
step
room
children
household
number
children
outside
household
cared
financially
start
day
asked
participants
take
part
respondent
participants
also
earned
icebreaker
activity
inspired
anti-racism
scholar
peggy
college
defined
years
course
mcintosh
invisible
knapsack
exercise
56
78
meant
taking
without
receiving
associate
bachelor
begin
discuss
issues
discrimination
power
degree
secondary
factors
contributing
socioeconomic
privilege
non-confrontational
manner
initial
status
determination
also
considered
respondent
activity
researchers
gave
brief
description
current
occupation
location
residence
algorithms
algorithmic
un
fairness
broad
discussion
focus
understanding
respondent
current
revolved
around
participant
questions
interpretation
economic
situation
well
near
term
opportunity
algorithmic
un
fairness
whether
participants
knew
advancement
based
proximate
resources
prior
workshop
ever
experienced
sharing
general
feelings
note
remainder
workshops
recruitment
workshop
used
term
algorithmic
discrimination
focused
inviting
people
color
based
rather
algorithmic
un
fairness
algorithmic
responses
recruitment
screener
secondary
fairness
often
used
term
academic
literature
consideration
also
looked
respondent
occupation
experience
study
well
work
institution
suggests
user
research
context
fairness
us
census
bureau
estimates
july
2016
black
may
construed
overly
narrowly
example
african
american
population
constitutes
13.3
43
million
people
emphasizing
equality
rather
justice
therefore
total
us
population
323.1
million
people
hispanic
latino
preferred
use
algorithmic
discrimination
population
17.8
57.5
million
people
population
two
races
2.6
https://www.census.gov/quickfacts,
accessed
august
conversations
participants
2017
able
find
estimated
percentage
us
population
meets
living
wage
standard
poverty
rate
2015
bulk
day
focused
series
three
13.5
43.1
million
people
approximately
51
black
scenario-based
design
activities
began
scenario
hispanic
68
since
living
wage
exceeds
poverty
threshold
describing
case
understood
instance
expect
substantially
13.5
meet
living
wage
algorithmic
unfairness
invited
participants
standard
61
fact
number
seems
likely
closer
29
americans
pew
identified
living
lower-class
household
37
share
initial
reactions
brief
group
discussion
overall
suggests
populations
focused
although
discussion
also
occasionally
introduced
small
qualitative
sample
conservatively
comprise
nearly
40
various
complexities
example
suggesting
different
us
population
likely
slightly
50
potential
causes
unfairness
asked
participants
paper
656
page
chi
2018
paper
chi
2018
april
21
26
2018
montréal
qc
canada
spend
10
minutes
working
individually
come
data
workshops
interviews
closely
ideas
might
decision
reviewing
text
videos
performing
affinity
maker
technology
company
charge
responding
clusterings
textual
quotations
video
clips
identify
scenario
told
participants
free
express
emergent
themes
producing
short
films
synthesizing
ideas
using
means
communication
found
key
themes
using
visual
ethnographic
approach
66
comfortable
drawing
story
writing
performing
iteratively
revising
refining
categories
keeping
examples
given
worked
recorded
general
inductive
approach
analytic
process
yielded
ideas
came
back
together
group
went
small
number
summary
categories
describe
around
table
share
discuss
everyone
ideas
findings
section
scenarios
discussed
represented
wide
range
limitations
issues
scenarios
based
internet-related
note
several
limitations
study
methodology
products
services
also
encouraged
discussion
considered
interpreting
work
first
due
domains
discussion
often
branched
focus
traditionally
marginalized
populations
areas
algorithmic
unfairness
might
occur
gather
data
privileged
populations
first
scenario
described
man
visiting
newspaper
think
experience
algorithmic
fairness
second
website
seeing
ads
high-paying
jobs
sample
statistically
representative
woman
visiting
website
saw
ads
low-wage
populations
explored
findings
report
work
second
scenario
results
predictive
viewed
deep
exploration
sample
beliefs
search
feature
suggests
possible
search
terms
attitudes
generalizing
populations
user
types
search
box
interpreted
whole
third
choice
scenarios
well
choice
stereotyping
black
men
children
criminals
use
term
algorithmic
discrimination
third
final
scenario
asked
participants
consider
appropriate
given
focus
may
influenced
practice
excluding
businesses
neighborhoods
participants
framings
fairness
may
high
crime
rates
online
restaurant
reviewing
yielded
different
results
finally
touch
map
application
completed
three
scenarios
socioeconomic
status
ethnicity
work
include
concluded
workshop
broad
group
discussion
detail
research
team
consisted
college
reflecting
back
ideas
emerged
throughout
educated
european-american
researchers
describe
day
experience
workshop
whole
participants
experiences
words
interpretations
may
lack
context
nuance
may
interviews
readily
available
diverse
research
workshops
completed
conducted
follow
team
interviews
approximately
one
hour
length
11
participants
appeared
particularly
engaged
findings
workshop
discussions
interviews
semi-structured
section
describe
main
findings
emerged
questions
focused
gaining
understanding
analysis
participant
concerns
opinions
policy
ideas
unfamiliar
unfathomable
analysis
participants
aware
concept
interviews
video-recorded
transcribed
algorithmic
un
fairness
participating
study
analysis
used
general
inductive
approach
83
although
described
reported
relies
detailed
readings
raw
data
derive
themes
personal
experiences
heard
relevant
evaluation
objectives
case
primary
media
however
participants
reported
extensive
evaluation
objective
inform
technical
policy
experience
discrimination
daily
lives
approaches
algorithmic
fairness
learning
connected
personal
stories
concept
participants
interpretation
algorithmic
fairness
algorithmic
un
fairness
participants
ascription
accountability
ethical
personal
experiences
discrimination
pragmatic
expectations
stakeholders
especially
participants
reported
extensive
negative
experience
companies
accordingly
focused
issues
discrimination
stereotyping
unfair
treatment
time
participants
jointly
analyzed
racial
profiling
law
enforcement
commonly
raised
example
participants
described
experiences
driving
black
pulled
police
inspired
20
reported
experiment
simulated
men
race
particularly
driving
affluent
visiting
times
india
website
likely
simulated
women
see
ad
career
coaching
service
200k
executive
neighborhoods
black
residents
53
participants
positions
also
raised
number
issues
related
social
environmental
justice
white
privilege
societal
inspired
62
advantages
conferred
caucasians
gentrification
forcing
inspired
73
people
low
incomes
homes
food
deserts
paper
656
page
chi
2018
paper
chi
2018
april
21
26
2018
montréal
qc
canada
lack
access
grocery
stores
healthy
food
one
discovery
american
express
ve
already
labeled
low
income
person
p43
impoverished
areas
proximity
low
income
neighborhoods
pollution
environmental
hazards
p28
hire
eric
holder
tamp
racism
participants
also
shared
number
experiences
airbnb
shopping
black
receiving
poor
service
facilitator
think
airbnb
retail
establishments
followed
monitored
p28
laughs
staff
suspect
may
steal
36
targeted
p29
well
something
already
done
african
american
man
direct
mail
unsolicited
advertisements
sent
physical
creating
p28
attorney
general
united
states
hire
mail
predatory
lending
disadvantageous
former
attorney
general
biggest
lawyer
united
states
opportunities
stereotyped
angry
handle
racism
airbnb
black
employment-related
discrimination
many
reactions
algorithmic
unfairness
viewed
pervasive
issues
framed
even
though
participants
aware
opportunities
daily
experiences
often
young
algorithmic
unfairness
prior
study
learning
age
elicited
strong
negative
feelings
evoking
experiences
mother
taking
us
daycare
remember
getting
discrimination
settings
example
participants
pulled
city
police
officer
arresting
taking
jail
sister
go
place
drew
connections
algorithmic
unfairness
children
age
time
scared
didn
know
national
dialogues
racial
injustice
economic
actually
handcuffs
stayed
day
inequality
well
lost
opportunities
personal
car
behind
registration
wasn
even
advancement
elementary
school
yet
going
preschool
quite
traumatizing
believe
african
searched
things
popped
american
city
learn
roles
angry
fact
makes
angry
right
now
just
looking
possibly
happen
young
age
things
now
just
somebody
wants
know
anticipated
re
even
shocking
anymore
p435
thug
type
thug
suggested
people
like
feel
like
police
taking
tell
daughter
eight
months
mom
advantage
getting
away
killing
brown
black
people
womb
already
racially
profiled
traffic
stop
p20
country
infuriating
matter
re
following
around
grocery
store
like
going
steal
people
typed
someone
types
something
p11
show
certain
facts
adjectives
judgments
positive
negative
connotations
just
whatever
happened
lot
environmental
racism
neighborhood
factually
reported
p23
grew
impoverished
lots
police
brutality
just
set
way
us
fail
p11
destiny
destination
life
based
mathematics
something
don
put
prior
awareness
algorithmic
unfairness
everything
worked
planned
based
something
algorithmic
unfairness
described
totally
control
seems
little
harsh
like
re
sent
algorithm
sets
back
participants
reported
aware
times
just
fair
p04
experienced
naturally
participants
may
also
experienced
aware
participants
also
drew
connections
personal
stories
participants
said
familiar
concept
life
experiences
example
objected
heavily
media
example
small
number
participants
stereotyping
negative
online
characterizations
raised
concerns
targeted
low
income
marginalized
groups
online
ads
information
ads
discussed
turning
location
history
personalized
based
demographic
characteristics
similar
avoid
racial
profiling
racially
motivated
advertising
concerns
raised
67
86
similarly
also
felt
couple
participants
also
discussed
experiences
unfair
personalize
ads
information
based
computer
systems
making
unfair
job
scholarship
online
behavior
people
similar
decisions
several
participants
also
described
stories
characteristics
first
glance
may
appear
heard
press
regarding
companies
contrast
plane
et
al
finding
online
behavioral
airbnb
facebook
google
nextdoor
others
advertising
seen
significantly
less
problematic
explicit
demographic
targeting
67
seems
likely
constantly
bombarded
can
get
low
income
credit
card
can
get
low
finance
loan
didn
ask
loan
participants
underlying
concern
cases
relates
didn
ask
credit
card
plus
low
income
loan
use
demographic
characteristics
sensitive
traits
like
like
buy
house
like
buy
boat
personalize
information
like
finance
car
can
like
capital
p34
totally
unfair
p33
every
woman
accurate
re
just
basing
group
p22
ease
reading
followed
editing
conventions
consistent
applied
social
science
research
practices
described
16
didn
even
base
shown
ve
done
specifically
edited
quotes
remove
content
filler
words
past
re
just
basing
think
p23
false
starts
cases
re-punctuated
use
ellipses
indicate
substantial
omissions
paper
656
page
chi
2018
paper
chi
2018
april
21
26
2018
montréal
qc
canada
participants
oriented
algorithmic
unfairness
final
decision
maker
good
can
help
categorize
suggest
main
decision
maker
modern
incarnation
familiar
forms
discrimination
scary
p05
unwelcome
extension
offline
discrimination
online
arena
part
participants
interpreted
small
percentage
biases
algorithmic
decisions
low-impact
setup
everyone
win
since
beginning
civilization
always
hierarchy
technology
just
indicating
natural
imperfection
rather
subtle
bias
another
wheel
p37
researchers
argued
small
statistical
seems
like
technology
fascinating
time
differences
can
significant
cumulative
effects
alarming
seems
like
every
phase
people
taken
individuals
groups
thereby
perpetuating
always
done
something
wicked
p30
increasing
inequality
41
participants
appeared
interpret
algorithmic
type
system
small
statistical
disparities
benign
largely
considering
means
type
work
put
certain
type
natural
inevitable
impossible
fix
discrimination
actually
people
world
want
way
like
just
don
understand
sounds
fine
don
expect
perfection
course
p43
live
type
circumstances
p04
high
salience
representational
consequences
p12
deal
just
walking
street
participants
may
always
come
p14
daily
basis
previous
notion
wide-reaching
implications
p12
daily
basis
don
need
internet
underlying
algorithmic
systems
care
deeply
sites
trust
don
need
see
negative
connotation
come
every
time
walk
house
visible
results
systems
marginalized
wonder
re
going
make
back
re
safe
groups
portrayed
online
participants
aware
homes
need
feel
safe
especially
comes
google
concerned
skewed
representations
negative
site
trust
stereotypes
example
online
sexualization
women
p11
um-hm
draw
line
somewhere
get
home
ve
already
dealt
day
work
school
offensive
language
particular
ethnic
groups
like
want
come
home
don
want
deal
offenses
connected
broader
system
microaggressions
get
computer
shouldn
subjected
81
personal
stories
lives
racial
stereotypes
p29
type
two
black
teenagers
will
see
mugshots
although
parallels
life
experiences
may
black
boys
white
teenagers
will
see
playing
driven
initial
negative
responses
participants
shared
basketball
boy
scout
nuanced
pragmatic
perspectives
workshops
p28
negative
connotations
word
black
positive
unfolded
showing
appreciation
complexity
connotations
word
white
just
way
topic
discussed
just
really
happy
way
words
put
scale
impact
algorithmic
systems
ideas
p24
though
small
number
participants
expressed
belief
see
things
said
criminalizing
little
boy
large-scale
algorithmic
systems
underlie
many
aspects
just
broke
heart
didn
nothing
deserve
modern
society
many
participants
viewed
algorithmic
fact
society
thinks
just
something
computer
put
got
sisters
got
little
cousins
little
systems
small
scope
low
complexity
nieces
nephews
look
see
impact
especially
apparent
solutions
right
right
just
sickening
many
participants
proposed
scenarios
algorithmic
whole
bunch
human
beings
really
typed
unfairness
often
emphasized
manual
work
type
way
filter
stuff
like
cool
just
erase
p04
end
user
employees
technology
companies
echoing
types
manual
work
envisioned
participants
86
participants
especially
concerned
children
example
participants
proposed
filtering
might
affected
negative
representations
recommendation
processes
made
fair
lots
images
society
already
tells
young
black
boys
removing
algorithmic
processing
allowing
end
user
boys
color
re
thugs
re
gangster
go
content
participants
wouldn
want
son
look
teenage
boy
name
tended
favor
trust
human
decision-making
type
images
associations
comes
behind
name
algorithmic
decision-making
appears
contrast
son
young
black
boy
don
think
people
stereotyped
don
want
son
think
society
even
plane
et
al
results
67
due
variety
though
truth
society
label
re
young
factors
different
populations
studied
bears
black
boy
p11
investigation
participants
also
felt
popularity
algorithms
algorithm
person
just
mathematical
equation
benign
mirrors
world
pointing
social
media
just
information
somebody
chooses
information
certain
way
whatever
mean
choosing
can
amplify
societal
biases
increase
reach
whether
use
job
put
next
k-mart
stereotyping
messages
making
human
decisions
p39
just
talking
girlfriend
last
night
ridiculous
think
stick
suggestions
mean
happens
every
time
click
facebook
turn
news
radio
station
computer
makes
bad
decision
just
suggest
going
just
internet
general
type
discrimination
paper
656
page
chi
2018
paper
chi
2018
april
21
26
2018
montréal
qc
canada
going
main
reason
gotten
big
wrong
people
entitled
opinions
guess
way
social
media
middle
p04
going
online
free
speeching
whether
right
wrong
search
engine
fault
humanity
wouldn
blame
feeding
stuff
going
backwards
even
encouraging
company
people
read
stuff
feeding
thoughts
need
feed
p22
even
believed
cause
external
accountability
still
saw
technology
companies
participants
proposed
number
different
parties
might
responsibility
role
play
addressing
issue
responsible
algorithmic
unfairness
sometimes
consistent
extends
plane
et
al
finding
differing
opinions
likely
underlying
cause
many
participants
held
advertiser
ad
unfairness
three
commonly
proposed
causes
network
responsible
regardless
explicitly
non-diverse
population
programmers
named
perpetrator
67
believed
prejudiced
online
behavior
members
society
companies
readily
resolve
many
problems
news
media
number
ideas
suggest
chose
understanding
algorithmic
fairness
goes
beyond
think
people
work
companies
can
make
technical
worth
noting
many
potential
causes
change
tonight
wanted
just
matter
commonly
raised
technical
circles
lack
going
meticulously
put
everything
will
still
benefit
aspect
p29
diverse
training
data
inequitable
accuracy
classifying
members
different
categories
44
raised
rarely
occasionally
specific
contexts
participants
indicated
feel
companies
take
action
prevalent
arguments
inaction
many
participants
held
programmer
accountable
freedom
expression
concern
censoring
algorithm
discrimination
necessarily
content
credible
news
sources
belief
user
thought
programmers
ill-intended
rather
personally
responsible
making
good
choices
perception
programmers
predominantly
online
activity
order
shape
see
belief
privileged
white
males
understand
feasible
technological
solution
perspective
diverse
users
felt
diverse
hiring
practices
help
company
like
google
respect
free
speech
difficult
decision
people
create
technology
things
say
make
p44
stems
writer
p29
sometimes
people
want
see
kind
got
give
lack
diversity
may
able
input
certain
want
see
unfortunately
scary
p24
things
equation
don
know
reality
people
writing
apps
probably
unless
google
owns
news
companies
think
kind
community
need
selective
diverse
hands
p37
whatever
re
hiring
p20
don
know
going
really
go
actually
keep
facilitator
anybody
else
thoughts
writing
controversial
racial
issue
comes
regulate
algorithms
know
things
eventually
come
p24
think
kind
assumed
white
males
just
check
every
damn
time
something
happened
just
kind
p17
ivy
league
people
look
kind
monitor
don
even
know
actually
p21
laughs
going
say
rich
white
men
feasible
p43
p24
mean
else
laughs
however
positions
less
common
tended
arise
p21
make
us
racist
say
fairly
specific
situations
often
opposition
much
commonly
expressed
positions
companies
participants
also
often
thought
much
can
act
reduce
unfairness
stereotyping
racism
coming
outside
technology
companies
frequently
calling
role
curation
society
played
creating
problem
participants
mentioned
previous
section
participants
also
emphasized
news
media
source
bias
expressed
certain
expectations
companies
regardless
source
unfairness
section
discuss
really
like
company
racist
really
just
machine
stats
counting
numbers
counting
prominent
themes
regarding
expectations
curatorial
looking
based
re
looking
google
position
representation
voice
company
wants
look
problem
us
minds
can
really
turn
around
like
oh
google
journalistic
standards
p02
participants
tended
hold
technology
companies
p06
hear
re
saying
totally
everything
search
engines
journalistic
standards
instance
going
reason
popular
expected
perform
careful
manual
fact
checking
everybody
clicking
people
making
popular
people
although
resonating
findings
regarding
put
doesn
mean
true
underestimation
scale
participants
tended
propose
p02
yeah
problem
really
search
engine
people
searching
wouldn
blame
google
anything
just
manual
human-scale
approaches
show
proven
facts
going
clicks
machine
deciding
whether
right
rather
opinions
biased
content
participants
paper
656
page
chi
2018
paper
chi
2018
april
21
26
2018
montréal
qc
canada
indicated
news
media
always
meet
standard
feelings
betrayal
disappointment
anger
rather
sometimes
shows
harmful
biased
representations
companies
trusted
surfaced
societal
bias
prejudice
marginalized
populations
felt
technology
ve
used
google
lot
lifeline
almost
maybe
companies
compensate
even
offended
like
come
google
thought
better
p24
p10
allow
actual
fact
don
need
know
cousin
momma
said
just
include
go
google
like
company
expect
great
things
p07
truth
expect
facts
expect
see
stuff
like
p10
facts
don
want
child
see
great
company
p12
media
responsibility
google
responsibility
p28
just
need
news
makes
upset
see
however
participants
perceived
companies
time
person
pretty
much
news
protecting
unfairness
discrimination
greatly
brutalized
killed
prefer
just
official
enhanced
user
trust
strengthened
relationships
news
like
try
explore
make
companies
opinion
seems
like
opinion
already
kind
made
can
even
search
answers
p43
think
good
decision
google
decided
stop
running
tobacco
ads
stop
payday
loans
lets
think
responsibility
don
know
consumer
taking
feelings
report
like
just
news
reports
like
p12
consideration
tell
son
search
google
time
now
related
note
many
participants
suggested
feel
confident
may
watch
shoulder
good
pleased
p43
predictive
search
feature
suggest
negative
information
individuals
particularly
minors
also
discussion
suggested
negative
information
human-computer
interaction
researchers
often
make
counterbalanced
positive
information
reader
arguments
stakeholders
can
learn
sides
argument
reach
change
technology
better
serve
users
improve
conclusions
society
case
algorithmic
fairness
stakeholders
regulators
lawmakers
press
industry
voice
company
practitioners
many
others
opportunity
take
participant
responses
suggest
in-product
information
positive
action
technology
companies
particular
processed
algorithms
can
give
impression
tremendous
leverage
improve
algorithmic
fairness
company
generated
endorses
message
example
immediately
proximate
many
predictive
search
actively
suggests
content
within
user
technical
issues
arise
uniquely
positioned
interface
participants
felt
gave
diagnose
develop
effective
solutions
complex
appearance
content
originated
company
problems
difficult
outsiders
address
produced
feature
participants
also
felt
accordingly
hope
apparent
findings
feature
make
easy
users
find
can
directly
leveraged
wide
variety
stakeholders
content
even
encourage
searching
suggested
especially
decisions
relating
product
categories
users
generate
negative
searches
social
media
search
engines
focus
three
best
practices
findings
suggest
apply
companies
feel
like
encouraging
type
searching
just
toxic
p22
across
technology
sector
negative
connotations
wouldn
pop
include
fairness
value
product
design
wanted
see
something
negative
spell
p08
development
similar
considerations
privacy
fairness
can
included
consideration
throughout
clear
negative
just
let
actually
type
wanted
know
person
instead
offering
product
life
cycle
many
positive
steps
can
taken
things
p38
ensuring
diverse
training
data
machine
learning
models
ensuring
designers
aware
inequalities
inaction
posed
risk
appearing
endorse
others
systems
can
consider
appropriate
action
discrimination
signal
boosting
15
49
including
diverse
populations
user
testing
guys
facebook
pretty
much
promoting
hate
promoting
deceit
nothing
making
support
point
participants
cared
everybody
mad
p04
fairness
strong
ethical
expectations
companies
disappointed
companies
act
regardless
impact
user
trust
source
unfairness
greatly
valued
efforts
illustrated
preceding
sections
algorithmic
fairness
part
companies
ameliorate
societal
bias
make
connects
strong
emotions
many
cases
participants
products
inclusive
possible
therefore
likely
high
expectations
companies
will
ensure
measureable
gains
user
trust
engagement
can
result
fairness
products
consistent
philosophy
relationship
marketing
59
participants
linked
algorithmic
earlier
interview
told
participant
google
fairness
relationships
companies
expressing
established
policy
banned
ads
payday
loans
40
45
paper
656
page
chi
2018
paper
chi
2018
april
21
26
2018
montréal
qc
canada
incorporating
algorithmic
fairness
product
design
forward
will
result
strong
participation
multiple
findings
suggest
opportune
time
players
point
reinforced
lee
et
al
argument
companies
act
proactively
public
perception
algorithmic
service
design
support
multiple
stakeholder
complex
topic
still
evolving
algorithmic
fairness
perspectives
52
example
companies
can
partner
issues
challenging
technically
organizationally
community
groups
community
leaders
address
can
take
long
time
address
particularly
particular
challenges
airbnb
addressing
racism
mechanisms
already
place
strategically
platform
60
facebook
addressing
wise
take
positive
steps
additional
pressures
concerns
ethnic
affinity
marketing
29
apply
due
complexity
issues
also
wise
google
developing
policy
payday
proceed
thoughtfully
user
research
engage
lending
ads
40
45
research
underscores
stakeholders
represent
diverse
perspectives
discuss
importance
efforts
since
shows
traditional
turn
next
two
points
methods
user
testing
may
yield
complete
picture
different
groups
perspectives
computationally
design
user
studies
accommodate
diverse
socially
complex
issue
community
groups
leaders
perspectives
include
members
traditionally
experienced
considering
societal-scale
consequences
marginalized
populations
user
testing
workshop
representing
constituencies
range
issues
format
supported
encouraged
participants
exploration
well-positioned
contribute
discussions
development
diverse
nuanced
times
conflicting
positions
participants
reported
conclusions
future
work
empowering
take
perspective
decision-maker
one
way
make
social
change
bolster
pragmatic
technology
company
time
experience
arguments
corporations
good
demonstrating
reflects
value
challenges
user
research
societally
positive
actions
also
good
business
complex
computational
topics
complementing
work
practice
consider
example
green
gold
findings
suggest
participants
opinions
topic
effectively
argued
sustainable
business
practices
highly
contextual
often
varying
response
benefit
environment
can
yield
significant
situational
factors
specific
details
given
scenarios
financial
profit
32
paper
presented
novel
individual
factors
appears
resonate
variation
exploration
traditionally
marginalized
populations
reported
69
86
different
stakeholder
perspectives
perceive
algorithmic
fairness
findings
can
discussed
example
51
52
different
framings
inform
range
stakeholders
highlight
insight
fairness
example
emphasis
fair
division
company
handling
algorithmic
fairness
interacts
51
52
versus
social
justice
contextual
nature
may
significantly
user
trust
hope
insight
may
help
explain
research
topic
yields
results
provide
additional
motivation
companies
across
may
sometimes
appear
inconsistent
example
technology
sector
actively
pursue
algorithmic
fairness
many
findings
broadly
consistent
plane
et
future
work
fruitfully
explore
findings
al
objections
personalization
based
demographic
broader
population
noting
plane
et
al
study
offers
characteristics
expectation
technology
evidence
least
issues
may
resonate
companies
play
role
addressing
issues
caused
widely
67
also
suggest
exploring
concrete
external
forces
findings
differed
regards
actions
companies
can
take
regarding
algorithmic
fact
participants
appeared
favor
trust
fairness
making
specific
improvements
product
human
decision-making
algorithmic
decision-making
experiences
build
maintain
user
trust
finally
additional
research
yield
insights
account
suggest
research
stakeholders
across
variation
relatedly
caution
ecosystem
can
work
collectively
leverage
different
decontextualized
user
research
topic
may
yield
perspectives
skills
pursue
algorithmic
fairness
misleading
results
recommend
researchers
prepare
account
beliefs
knowledge
participants
acknowledgments
may
bring
research
environment
order
provide
thank
following
thoughtful
comments
inclusive
research
environment
participants
contributions
work
paul
aoki
ed
chi
charina
situations
will
also
valuable
use
ethnographic
choi
mark
chow
rena
coen
sunny
consolvo
jen
approaches
explore
participants
underlying
values
gennai
lea
kissner
brad
krueger
ali
lange
irene
tang
extrapolate
values
technological
implications
lynette
webb
jill
woelfer
anonymous
reviewers
see
26
additional
discussion
nature
analytic
references
knowledge
can
gained
ethnographic
studies
acm
us
public
policy
council
2017
statement
engage
community
groups
advocates
algorithmic
transparency
accountability
collaboratively
develop
solutions
common
retrieved
september
16
2017
wicked
problems
stakeholders
work
isolation
https://www.acm.org/binaries/content/assets/public-
address
complex
issues
posed
algorithmic
fairness
policy
2017_usacm_statement_algorithms
pdf
72
robust
understanding
goals
best
path
paper
656
page
10
chi
2018
paper
chi
2018
april
21
26
2018
montréal
qc
canada
airbnb
inc
airbnb
nondiscrimination
policy
häkkilä
kate
kuehl
valentina
nisi
nuno
jardim
retrieved
september
14
2017
nunes
nina
wenig
dirk
wenig
brent
hecht
https://www.airbnb.com/terms/nondiscrimination_polic
johannes
schöning
2017
geography
pokémon
go
beneficial
problematic
effects
places
mariam
asad
sarah
fox
christopher
le
movement
proceedings
2017
chi
dantec
2014
speculative
activist
technologies
conference
human
factors
computing
systems
proceedings
iconference
2014
chi
17
1179
1192
https://doi.org/10.9776/14074
https://doi.org/10.1145/3025453.3025495
paul
baker
amanda
potts
2013
white
16
anne
corden
roy
sainsbury
2006
using
people
thin
lips
google
perpetuation
verbatim
quotations
reporting
qualitative
social
stereotypes
via
auto-complete
search
forms
critical
research
university
york
york
uk
discourse
studies
10
187
204
17
tressie
mcmillan
cottom
2015
credit
scores
life
https://doi.org/10.1080/17405904.2012.744320
chances
algorithms
retrieved
september
15
solon
barocas
andrew
selbst
2016
big
data
2017
https://tressiemc.com/uncategorized/credit-
disparate
impact
california
law
review
104
671
scores-life-chances-and-algorithms
732
18
kate
crawford
2014
anxieties
big
data
david
beer
2009
power
algorithm
new
inquiry
participatory
web
cultures
technological
19
kate
crawford
2016
artificial
intelligence
white
unconscious
new
media
society
11
985
1002
guy
problem
new
york
times
https://doi.org/10.1177/1461444809336551
20
amit
datta
michael
carl
tschantz
anupam
hugh
beyer
karen
holtzblatt
1998
contextual
datta
2015
automated
experiments
ad
privacy
design
defining
customer-centered
systems
morgan
settings
proceedings
privacy
enhancing
kaufmann
publishers
inc
san
francisco
ca
usa
technologies
pets
2015
92
112
danah
boyd
kate
crawford
2012
critical
https://doi.org/10.1515/popets-2015-0007
questions
big
data
information
communication
21
michael
devito
jeremy
birnholtz
jeffery
society
15
662
679
hancock
platforms
people
perception
using
https://doi.org/10.1080/1369118x.2012.678878
affordances
understand
self-presentation
social
danah
boyd
karen
levy
alice
marwick
2014
media
proceedings
20th
acm
conference
networked
nature
algorithmic
discrimination
computer-supported
cooperative
work
social
data
discrimination
collected
essays
seeta
computing
cscw
17
740
754
peña
gangadharan
virginia
eubanks
solon
22
nicholas
diakopoulos
2015
algorithmic
barocas
eds
open
technology
institute
new
accountability
digital
journalism
398
415
america
foundation
washington
53
57
https://doi.org/10.1080/21670811.2014.976411
10
engin
bozdag
2013
bias
algorithmic
filtering
23
carl
disalvo
thomas
lodato
laura
fries
beth
personalization
ethics
information
technology
15
schechter
thomas
barnwell
2011
collective
209
227
https://doi.org/10.1007/s10676-013-9321-
articulation
issues
design
practice
codesign
185
197
11
taina
bucher
2017
algorithmic
imaginary
https://doi.org/10.1080/15710882.2011.630475
exploring
ordinary
affects
facebook
algorithms
24
carl
disalvo
illah
nourbakhsh
david
holstius
ayça
information
communication
society
20
30
44
akin
marti
louw
2008
neighborhood
12
jenna
burrell
2016
machine
thinks
networks
project
case
study
critical
understanding
opacity
machine
learning
algorithms
engagement
creative
expression
big
data
society
12
participatory
design
proceedings
tenth
https://doi.org/10.1177/2053951715622512
anniversary
conference
participatory
design
2008
pdc
08
41
50
13
kathleen
chaykowski
2016
facebook
ban
ethnic
affinity
targeting
housing
employment
credit
25
carl
disalvo
phoebe
sengers
hrönn
related
ads
forbes
brynjarsdóttir
2010
mapping
landscape
sustainable
hci
proceedings
sigchi
14
danielle
keats
citron
frank
pasquale
2014
conference
human
factors
computing
systems
scored
society
due
process
automated
chi
10
1975
1984
predictions
washington
law
review
89
https://doi.org/10.1145/1753326.1753625
15
ashley
colley
jacob
thebault-spieker
allen
yilun
26
paul
dourish
2006
implications
design
lin
donald
degraen
benjamin
fischman
jonna
proceedings
sigchi
conference
human
paper
656
page
11
chi
2018
paper
chi
2018
april
21
26
2018
montréal
qc
canada
factors
computing
systems
chi
06
541
550
39
bryce
goodman
seth
flaxman
2016
european
https://doi.org/10.1145/1124772.1124855
union
regulations
algorithmic
decision-making
27
benjamin
edelman
michael
luca
2014
digital
right
explanation
icml
workshop
human
discrimination
case
airbnb
com
harvard
interpretability
machine
learning
whi
2016
business
school
working
paper
14
054
40
david
graff
2016
update
adwords
policy
28
benjamin
edelman
michael
luca
daniel
svirsky
lending
products
google
public
policy
blog
2017
racial
discrimination
sharing
economy
retrieved
september
15
2017
evidence
field
experiment
american
https://www.blog.google/topics/public-policy/an-
economic
journal
applied
economics
22
update-to-our-adwords-policy-on
29
erin
egan
2016
improving
enforcement
41
anthony
greenwald
mahzarin
banaji
brian
promoting
diversity
updates
ethnic
affinity
nosek
2015
statistically
small
effects
marketing
facebook
newsroom
blog
retrieved
implicit
association
test
can
societally
large
september
14
2017
effects
journal
personality
social
psychology
https://newsroom.fb.com/news/2016/11/updates-to-
108
553
561
https://doi.org/10.1037/pspa0000016
ethnic-affinity-marketing
42
maya
gupta
andrew
cotter
jan
pfeifer
konstantin
30
pelle
ehn
1990
work-oriented
design
computer
voevodski
kevin
canini
alexander
mangylov
artifacts
erlbaum
associates
inc
hillsdale
nj
wojciech
moczydlowski
alexander
van
esbroeck
usa
2016
monotonic
calibrated
interpolated
look-up
tables
journal
machine
learning
research
17
31
motahhare
eslami
aimee
rickman
kristen
vaccaro
109
47
amirhossein
aleyasen
andy
vuong
karrie
karahalios
kevin
hamilton
christian
sandvig
43
bernard
harcourt
2007
prediction
2015
always
assumed
wasn
really
profiling
policing
punishing
actuarial
age
close
reasoning
invisible
algorithms
university
chicago
press
news
feeds
proceedings
33rd
annual
44
moritz
hardt
eric
price
nathan
srebro
2016
acm
conference
human
factors
computing
equality
opportunity
supervised
learning
systems
chi
15
153
162
advances
neural
information
processing
systems
https://doi.org/10.1145/2702123.2702556
nips
2016
3315
3323
32
daniel
esty
andrew
winston
2006
green
45
shin
inouye
2016
advocates
applaud
google
ban
gold
smart
companies
use
environmental
payday
loan
advertisements
leadership
strategy
innovate
create
value
build
conference
civil
human
rights
retrieved
competitive
advantage
yale
university
press
september
15
2017
33
executive
office
president
2016
big
data
http://civilrights.org/advocates-applaud-googles-ban-
report
algorithmic
systems
opportunity
civil
on-payday-loan-advertisements
rights
46
lucas
introna
helen
nissenbaum
2000
34
federal
trade
commission
2016
big
data
tool
shaping
web
politics
search
engines
inclusion
exclusion
understanding
issues
matters
information
society
16
169
185
https://doi.org/10.1080/01972240050133634
35
batya
friedman
helen
nissenbaum
1996
bias
computer
systems
acm
transactions
information
47
isaac
johnson
connor
mcmahon
johannes
schöning
systems
14
330
347
brent
hecht
2017
effect
population
https://doi.org/10.1145/230538.230561
structural
biases
social
media-based
algorithms
case
study
geolocation
inference
across
36
shaun
gabbidon
2003
racial
profiling
store
urban-rural
spectrum
proceedings
2017
clerks
security
personnel
retail
chi
conference
human
factors
computing
establishments
exploration
shopping
systems
chi
17
1167
1178
black
journal
contemporary
criminal
justice
19
https://doi.org/10.1145/3025453.3026015
345
364
https://doi.org/10.1177/1043986203254531
48
robert
jungk
norbert
müllert
institute
social
inventions
1987
future
workshops
create
37
marilyn
geewax
2015
tipping
point
desirable
futures
institute
social
inventions
americans
longer
middle
class
npr
london
38
tarleton
gillespie
2014
relevance
algorithms
49
matthew
kay
cynthia
matuszek
sean
media
technologies
essays
communication
munson
2015
unequal
representation
gender
materiality
society
university
press
stereotypes
image
search
results
occupations
scholarship
tarleton
gillespie
pablo
boczkowski
proceedings
33rd
annual
acm
conference
kirsten
foot
eds
mit
press
paper
656
page
12
chi
2018
paper
chi
2018
april
21
26
2018
montréal
qc
canada
human
factors
computing
systems
chi
15
human
factors
computing
systems
chi
15
207
3819
3828
https://doi.org/10.1145/2702123.2702520
210
https://doi.org/10.1145/2702123.2702514
50
jonathan
lazar
julio
abascal
simone
barbosa
58
claire
cain
miller
2015
algorithms
jeremy
barksdale
batya
friedman
jens
grossklags
discriminate
new
york
times
jan
gulliksen
jeff
johnson
tom
mcewan
loïc
59
robert
morgan
shelby
hunt
1994
martínez-normand
wibke
michalk
janice
tsai
commitment-trust
theory
relationship
marketing
gerrit
van
der
veer
hans
von
axelson
ake
walldius
journal
marketing
58
20
38
gill
whitney
marco
winckler
volker
wulf
elizabeth
https://doi.org/10.2307/1252308
churchill
lorrie
cranor
janet
davis
alan
hedge
harry
hochheiser
juan
pablo
hourcade
clayton
60
laura
murphy
2016
airbnb
work
fight
lewis
lisa
nathan
fabio
paterno
blake
reid
discrimination
build
inclusion
report
whitney
quesenbery
ted
selker
brian
wentz
submitted
airbnb
retrieved
september
15
2017
2016
human
computer
interaction
international
http://blog.atairbnb.com/wp-
public
policymaking
framework
understanding
content
uploads
2016
09
report_airbnbs-work-to
taking
future
actions
foundations
trends
fight-discrimination-and-build-inclusion
pdf
3c10be
human-computer
interaction
69
149
61
carey
nadeau
amy
glasmeier
2016
minimum
https://doi.org/10.1561/1100000062
wage
can
individual
family
live
51
min
kyung
lee
su
baykal
2017
algorithmic
retrieved
september
15
2017
mediation
group
decisions
fairness
perceptions
http://livingwage.mit.edu/articles/15-minimum-wage-
algorithmically
mediated
vs
discussion-based
social
can-an-individual-or-a-family-live-on-it
division
proceedings
20th
acm
conference
62
safiya
umoja
noble
2014
teaching
trayvon
race
computer-supported
cooperative
work
social
media
politics
spectacle
black
scholar
computing
cscw
17
1035
1048
44
12
29
52
min
kyung
lee
ji
tae
kim
leah
lizarondo
https://doi.org/10.5816/blackscholar.44.1.0012
2017
human-centered
approach
algorithmic
63
cathy
neil
2016
weapons
math
destruction
services
considerations
fair
motivating
smart
big
data
increases
inequality
threatens
community
service
management
allocates
democracy
crown
new
york
donations
non-profit
organizations
proceedings
64
jahna
otterbacher
jo
bates
paul
clough
2017
2017
chi
conference
human
factors
competent
men
warm
women
gender
computing
systems
chi
17
3365
3376
stereotypes
backlash
image
search
results
53
richard
lundman
robert
kaufman
2003
proceedings
2017
chi
conference
human
driving
black
effects
race
ethnicity
factors
computing
systems
chi
17
6620
6631
gender
citizen
self-reports
traffic
stops
https://doi.org/10.1145/3025453.3025727
police
actions
criminology
41
195
220
65
sarah
perez
2016
microsoft
silences
new
bot
https://doi.org/10.1111/j.1745-9125.2003.tb00986.x
tay
twitter
users
teach
racism
techcrunch
54
caitlin
lustig
bonnie
nardi
2015
algorithmic
66
sarah
pink
2014
visual
ethnography
sage
authority
case
bitcoin
48th
hawaii
publications
international
conference
system
sciences
hicss
2015
743
752
67
angelisa
plane
elissa
redmiles
michelle
mazurek
https://doi.org/10.1109/hicss.2015.95
michael
tschantz
2017
exploring
user
perceptions
discrimination
online
targeted
55
caitlin
lustig
katie
pine
bonnie
nardi
lilly
irani
advertising
proceedings
2017
usenix
min
kyung
lee
dawn
nafus
christian
sandvig
security
symposium
2016
algorithmic
authority
ethics
politics
economics
algorithms
interpret
decide
68
bernadette
proctor
jessica
semega
melissa
manage
proceedings
2016
chi
conference
kollar
2016
income
poverty
united
extended
abstracts
human
factors
computing
states
2015
united
states
census
bureau
systems
chi
ea
16
1057
1062
retrieved
september
15
2017
https://doi.org/10.1145/2851581.2886426
https://www.census.gov/library/publications/2016/dem
p60-256
html
56
peggy
mcintosh
1990
white
privilege
unpacking
invisible
knapsack
independent
school
49
31
69
emilee
rader
rebecca
gray
2015
understanding
user
beliefs
algorithmic
curation
57
amanda
menking
ingrid
erickson
2015
facebook
news
feed
proceedings
33rd
heart
work
wikipedia
gendered
emotional
labor
annual
acm
conference
human
factors
world
largest
online
encyclopedia
computing
systems
chi
15
173
182
proceedings
33rd
annual
acm
conference
https://doi.org/10.1145/2702123.2702174
paper
656
page
13
chi
2018
paper
chi
2018
april
21
26
2018
montréal
qc
canada
70
matt
ratto
2011
critical
making
conceptual
79
clay
shirky
2011
speculative
post
idea
material
studies
technology
social
life
algorithmic
authority
retrieved
september
15
2017
information
society
27
252
260
http://www.shirky.com/weblog/2009/11/a-
https://doi.org/10.1080/01972243.2011.583819
speculative-post-on-the-idea-of-algorithmic-authority
71
noopur
raval
paul
dourish
2016
standing
80
kiley
sobel
katie
leary
julie
kientz
2015
crowd
emotional
labor
body
labor
maximizing
children
opportunities
inclusive
temporal
labor
ridesharing
proceedings
play
considerations
interactive
technology
19th
acm
conference
computer-supported
design
proceedings
14th
international
cooperative
work
social
computing
cscw
16
conference
interaction
design
children
idc
97
107
https://doi.org/10.1145/2818048.2820026
15
39
48
https://doi.org/10.1145/2771839.2771844
72
horst
rittel
melvin
webber
1973
81
derald
wing
sue
2010
microaggressions
everyday
dilemmas
general
theory
planning
policy
life
race
gender
sexual
orientation
wiley
sciences
155
169
82
astra
taylor
jathan
sadowski
2015
https://doi.org/10.1007/bf01405730
companies
turn
facebook
activity
credit
73
rosemary
rodriguez
2015
discovery
good
score
nation
wife
83
david
thomas
2006
general
inductive
74
daniela
rosner
saba
kawas
wenqi
li
nicole
approach
analyzing
qualitative
evaluation
data
tilly
yi-chen
sung
2016
time
american
journal
evaluation
27
237
246
place
reflections
design
workshops
research
https://doi.org/10.1177/1098214005283748
method
proceedings
19th
acm
conference
84
vanessa
thomas
christian
remy
mike
hazas
computer-supported
cooperative
work
social
oliver
bates
2017
hci
environmental
public
computing
cscw
16
1131
1141
policy
opportunities
engagement
proceedings
https://doi.org/10.1145/2818048.2820021
2017
chi
conference
human
factors
75
elizabeth
sanders
pieter
jan
stappers
2008
computing
systems
chi
17
6986
6992
co-creation
new
landscapes
design
https://doi.org/10.1145/3025453.3025579
codesign
18
85
blase
ur
pedro
giovanni
leon
lorrie
faith
cranor
https://doi.org/10.1080/15710880701875068
richard
shay
yang
wang
2012
smart
useful
76
christian
sandvig
kevin
hamilton
karrie
karahalios
scary
creepy
perceptions
online
behavioral
cedric
langbort
2015
can
algorithm
advertising
proceedings
eighth
symposium
unethical
65th
annual
meeting
international
usable
privacy
security
soups
12
communication
association
15
https://doi.org/10.1145/2335356.2335362
77
christian
sandvig
kevin
hamilton
karrie
karahalios
86
jeff
warshaw
nina
taft
allison
woodruff
2016
cedric
langbort
auditing
algorithms
research
intuitions
analytics
killing
ants
inference
literacy
methods
detecting
discrimination
internet
high
school-educated
adults
us
platforms
data
discrimination
converting
proceedings
twelfth
symposium
usable
critical
concerns
productive
inquiry
may
2014
privacy
security
soups
16
78
sassafras
tech
collective
2016
icebreaker
87
brian
wynne
1991
knowledges
context
science
exploring
social
justice
design
hci
workshop
technology
human
values
16
111
121
chi
2016
paper
656
page
14