santa
clara
univers
scholar
common
engin
ph
these
student
scholarship
2024
fair
bia
machin
learn
search
rank
yuan
wang
follow
addit
work
https://scholarcommons.scu.edu/eng_phd_thes
fair
bia
machin
learn
search
rank
yuan
wang
dissert
submit
partial
fulﬁllment
requir
degre
doctor
philosophi
comput
scienc
engin
school
engin
santa
clara
univers
2024
santa
clara
california
dedic
famili
iii
acknowledg
first
foremost
extend
deepest
gratitud
advisor
professor
yi
fang
whose
unwav
guidanc
support
instrument
doctor
journey
professor
fang
believ
potenti
also
support
patienc
kind
unmatch
dedic
excel
mentorship
transcend
aca
demic
instruct
oﬀer
person
support
invalu
life
lesson
shape
scholar
individu
teach
keep
tri
curiou
work
hard
want
keep
thing
job
learn
realli
special
chanc
thank
like
thank
doctor
committe
consist
prof
zhiqiang
tao
prof
david
anastasiu
prof
sean
choi
prof
haib
lu
time
suggest
make
thesi
better
like
thank
lab
mate
travi
ebesu
xuyang
wu
zhiyuan
peng
suthe
chaidaroon
support
diﬀer
part
journey
lastli
like
thank
famili
parent
brother
given
endless
love
support
throughout
entir
journey
also
want
thank
ﬁancé
yijia
love
patienc
iv
fair
bia
machin
learn
search
rank
yuan
wang
depart
comput
scienc
engin
santa
clara
univers
santa
clara
california
2024
abstract
recent
advanc
inform
retriev
ir
machin
learn
signif
icantli
improv
rank
search
system
perform
howev
data-driven
approach
often
suﬀer
inher
bias
present
train
dataset
lead
unfair
treatment
certain
demograph
group
contribut
systemat
discrim
inat
base
race
gender
geograph
locat
research
aim
address
fair
bia
issu
rank
search
system
propos
innov
frame
work
mitig
data
bia
ensur
equit
represent
exposur
across
divers
group
introduc
two
novel
framework
meta-learn
base
fair
rank
mfr
model
meta
curriculum-bas
fair
rank
mcfr
framework
design
allevi
dataset
bia
automatically-weight
loss
function
curriculum
learn
strategi
respect
approach
util
meta-learn
adjust
rank
ing
loss
focus
particularli
improv
fair
metric
minor
group
maintain
competit
rank
perform
addit
conduct
em
piric
evalu
larg
languag
model
llm
text-rank
task
reveal
bias
handl
queri
document
relat
binari
protect
attribut
analysi
oﬀer
benchmark
assess
llm
fair
highlight
necess
equit
represent
search
outcom
furthermor
explor
challeng
data
select
bia
multi-stag
recommen
dation
system
particularli
onlin
advertis
context
like
pinterest
multi-cascad
ad
rank
system
comprehens
experi
assess
variou
state-of
the-art
method
ﬁnding
demonstr
eﬀect
modiﬁ
version
unsupervis
domain
adapt
muda
mitig
select
bia
collect
work
contribut
develop
fairer
rank
search
sy
tem
address
bia
sourc
employ
meta-learn
curriculum
learn
techniqu
pave
way
equit
transpar
ir
system
serv
divers
user
base
without
discrimin
content
acknowledg
iv
abstract
content
vii
list
figur
list
tabl
xiii
introduct
16
1.1
motiv
16
1.2
overview
18
1.3
contribut
19
1.4
outlin
21
relat
work
23
2.1
fair
rank
23
2.2
meta-learn
fair
24
2.3
fair
llm
25
2.4
select
bia
26
meta-learn
approach
fair
rank
28
3.1
introduct
28
3.2
meta-learn
base
fair
rank
32
3.3
experi
36
3.4
conclus
41
uniﬁ
meta-learn
framework
fair
rank
curriculum
learn
42
4.1
introduct
42
vii
content
viii
4.2
meta
curriculum-bas
fair
rank
47
4.2
problem
set
48
4.2
uniﬁ
mcfr
framework
48
4.2
paramet
updat
51
4.2
rank
fair
loss
53
4.2
4.1
rank
term
53
4.2
4.2
fair
term
54
4.2
curriculum
sampl
55
4.3
experi
59
4.3
experiment
set
59
4.3
1.1
baselin
61
4.3
1.2
implement
detail
62
4.3
fair
rank
perform
63
4.3
ablat
studi
65
4.3
3.1
rank
term
analysi
66
4.3
3.2
fair
term
analysi
67
4.3
3.3
curriculum
sampl
analysi
68
4.3
3.4
data
eﬃcienc
69
4.3
3.5
train
infer
eﬃcienc
69
4.4
conclus
70
empir
studi
fair
llm
ranker
71
5.1
introduct
71
5.2
llm
fair
rank
74
5.2
dataset
75
5.2
listwis
evalu
75
5.2
2.1
data
construct
76
5.2
2.2
metric
77
5.2
pairwis
evalu
78
5.2
3.1
data
construct
79
5.2
3.2
metric
79
5.3
result
analysi
79
5.3
0.1
eﬀect
window
step
size
80
5.3
listwis
evalu
result
80
5.3
1.1
item-sid
analysi
82
5.3
1.2
query-sid
analysi
84
5.3
pairwis
evalu
result
85
5.3
overal
evalu
86
5.4
enhanc
fair
lora
87
5.5
conclus
88
empir
studi
select
bia
pinterest
ad
retriev
90
content
ix
6.1
introduct
90
6.2
bia
pinterest
ad
96
6.2
dataset
train
pipelin
96
6.2
select
bia
98
6.2
problem
formul
99
6.3
solut
100
6.3
naiv
method
binari
classiﬁc
100
6.3
in-batch
neg
classiﬁc
100
6.3
knowledg
distil
101
6.3
transfer
learn
101
6.3
adversari
regular
102
6.3
unsupervis
domain
adapt
103
6.3
6.1
naiv
uda
103
6.3
6.2
modiﬁ
uda
104
6.4
experi
result
106
6.4
dataset
106
6.4
experiment
set
107
6.4
evalu
metric
109
6.4
oﬄin
evalu
110
6.4
onlin
experi
111
6.4
5.1
overal
evalu
111
6.4
5.2
evalu
ad
object
type
114
6.4
5.3
convers
ad
116
6.4
variant
muda
117
6.5
conclus
120
conclus
121
bibliographi
123
list
figur
3.1
illustr
predict
rank
distribut
protect
group
femal
student
african
american
student
two
diﬀer
dataset
report
kendal
tau
rank
metric
propos
mfr
model
rank
item
protect
group
higher
compar
listnet
17
indic
mfr
improv
protect
tribut
exposur
unbias
rank
perform
29
3.2
mfr
learn
algorithm
ﬂowchart
step
algorithm
note
rank
model
meta-learn
batch
size
train
dataset
batch
size
meta-dataset
learn
rate
iter
ﬁrstli
updat
meta-learn
use
eq
meta-dataset
updat
rank
model
use
eq
train
dataset
32
3.3
plot
variat
learn
weight
two
train
dataset
weight
diﬀer
comput
φdiﬀ
φi
φi
plot
φdiﬀ
train
epoch
shown
plot
weight
function
converg
diﬀer
valu
weight
epoch
decreas
0.0
40
4.1
illustr
predict
rank
distribut
two
protect
tribut
four
dataset
law
student
gender
82
law
stu
dent
race
82
compa
engin
student
89
report
kendal
tau
48
rank
perform
mcfr
mfr
80
improv
protect
attribut
rank
realiz
com
petit
rank
perform
compar
listnet
17
demonstr
approach
increas
exposur
minor
43
4.2
mcfr
learn
algorithm
ﬂowchart
step
algorithm
note
rank
model
meta
learner
batch
size
train
dataset
batch
size
meta-dataset
learn
rate
iter
ﬁrstli
updat
meta
learner
use
eq
meta-dataset
sampl
curriculum
sampl
updat
sampl
diﬃculti
epoch
updat
rank
model
use
eq
train
dataset
47
list
figur
xi
4.3
curriculum
sampl
strategi
illustr
engin
student
gender
dataset
use
ratio
unprotect
group
protect
group
meta-dataset
train
dataset
begin
train
epoch
gradual
decreas
ratio
train
epoch
increas
ratio
becom
show
balanc
meta
dataset
55
4.4
evalu
result
down-sampl
experi
conduct
experi
law
student
gender
law
student
race
dataset
down-sampl
train
data
rate
0.1
0.9
result
show
mcfr
better
data
eﬃcienc
achiev
better
fair
metric
similar
rank
perform
mfr
autodebia
diﬀer
down-sampl
rate
68
5.1
illustr
two
evalu
method
listwis
evalu
pairwis
evalu
document
associ
binari
protect
attribut
use
fair
evalu
metric
72
5.2
propos
evalu
framework
schemat
diagram
repres
dual
evalu
methodolog
top
sequenc
depict
listwis
rank
ing
process
item
protect
unprotect
group
pre
sent
variou
llm
gpt-3
gpt-4
mistral-7b
llama2
evalu
util
group
exposur
metric
bottom
se
quenc
illustr
pairwis
rank
approach
contrast
rank
prefer
llm
item
protect
unpro
tect
group
quantifi
bia
percentag
unprotect
group
item
rank
higher
74
5.3
predict
rank
distribut
protect
group
trec
dataset
use
listwis
evalu
plot
reveal
rank
vari
abil
potenti
bias
gender
geograph
attribut
high
light
area
improv
fair
across
llm
81
5.4
impact
lora
fine-tun
mistral-7b
fair
figur
show
percentag
ﬁrst-rank
item
protect
unprotect
group
figur
demonstr
result
fair
ratio
lora
adjust
model
yield
ratio
closer
ideal
fair
benchmark
1.0
across
trec
dataset
87
6.1
life
cycl
onlin
ad
deliveri
high
level
ad
request
trigger
user
open
pinterest
app
start
new
session
ad
request
will
sent
ad
deliveri
system
queri
dozen
ad
ad
deliveri
backend
ad
candid
inventori
will
ﬂow
variou
stage
like
target
retriev
rank
auction
send
auction
winner
back
mobil
app
select
ad
will
visibl
user
91
list
figur
xii
6.2
distribut
featur
label
across
three
ad
dataset
relat
retriev
model
show
ﬂow
major
ad
candid
along
ad
deliveri
funnel
show
distribut
empir
vtcvr
one
key
retriev
model
featur
across
three
dataset
retriev
train
serv
show
distribut
empir
good
click
rate
one
key
retriev
model
featur
across
three
dataset
retriev
train
serv
show
distribut
rank
model
predict
use
pseudo
label
retriev
model
train
across
three
dataset
note
exact
valu
x-ax
hidden
conﬁdenti
reason
95
list
tabl
3.1
experiment
result
measur
fair
comput
exposur
ratio
protect
non-protect
group
val
ue
greater
1.0
indic
greater
visibl
protect
group
vice
versa
rank
metric
higher
kendal
tau
preci
sion
10
10
score
indic
better
perform
bold
text
indi
cate
model
best
perform
result
show
mfr
model
better
fair
metric
compar
perfor
manc
rank
metric
state-of-the-art
model
39
4.1
summari
rank
fair
term
use
loss
function
loss
function
use
framework
γu
can
insert
exposur
term
rank
loss
term
need
note
denot
number
candid
per
queri
51
4.2
summari
dataset
statist
report
averag
count
total
unprotect
item
per
queri
w3c
expert
engin
student
dataset
provid
exact
item
count
law
student
compa
dataset
contain
one
queri
58
4.3
experiment
result
hing
exposur
89
measur
fair
comput
exposur
ratio
protect
non-protect
group
valu
greater
1.0
indic
greater
visibl
protect
group
vice
versa
rank
metric
higher
kendal
tau
precis
10
10
score
indic
better
perform
bold
text
indic
model
best
perform
result
show
mcfr
model
better
fair
metric
compar
perform
rank
metric
state-of-the-art
model
64
4.4
ablat
studi
result
rankms
11
66
4.5
ablat
studi
result
ranknet
15
66
4.6
ablat
studi
result
listnet
17
67
4.7
experiment
result
total
converg
time
second
show
total
converg
time
diﬀer
algorithm
deltr
mfr
mcfr
across
variou
dataset
scenario
base
tabl
mcfr
framework
gener
compar
converg
time
two
algorithm
69
xiii
list
tabl
xiv
5.1
evalu
result
diﬀer
choic
window
step
size
result
show
signiﬁc
diﬀer
rank
fair
metric
select
window
size
step
size
listwis
evalu
experi
80
5.2
listwis
evalu
result
measur
fair
comput
exposur
ratio
protect
non-protect
group
valu
closer
1.0
indic
greater
visibl
protect
group
vice
versa
rank
metric
higher
precis
10
10
score
indic
better
perform
82
5.3
pairwis
evalu
result
tabl
display
fair
metric
llm
rank
relev
irrelev
item
pair
one
protect
unprotect
group
includ
percentag
item
rank
ﬁrst
group
ratio
reﬂect
fair
vari
level
fair
across
llm
particularli
irrelev
pair
highlight
import
enhanc
fair
llm
85
6.1
auc-roc
evalu
dataset
model
knowledg
di
tillat
adversari
learn
binari
classiﬁc
train
auction
winner
dataset
usual
better
oﬄin
evalu
result
110
6.2
onlin
lift
impress
imp
click-through
rate
ctr
good
long
click
gctr30
observ
variou
model
type
ad
in-batch
neg
knowledg
distil
method
improv
gctr30
cost
impress
drop
muda
method
recom
mend
ad
higher
qualiti
observ
increas
gctr30
without
impress
drop
112
6.3
onlin
lift
impress
imp
click-through
rate
ctr
good
long
click
gctr30
observ
two
promis
model
type
awar
traﬃc
web-convers
ad
in-batch
neg
classiﬁ
cation
model
work
better
traﬃc
ad
muda
model
help
web-convers
ad
114
6.4
onlin
metric
perform
in-batch
neg
classiﬁc
muda
model
web-convers
ad
in-batch
neg
classiﬁc
model
lead
lower
convers
probabl
ad
impress
icvr
thu
higher
cpa
cost
advertis
contrast
muda
model
recommend
ad
candid
higher
convers
rate
therefor
lower
cpa
cost
116
6.5
onlin
lift
impress
imp
click-through
rate
ctr
good
long
click
gctr30
observ
variou
muda
variant
type
ad
muda
v1
achiev
highest
gain
ad
engag
ctr
gctr30
muda
v3
achiev
balanc
gain
across
diﬀer
metric
good
gctr30
impress
lift
117
list
tabl
xv
6.6
onlin
lift
impress
imp
click-through
rate
ctr
good
long
click
gctr30
observ
muda
variant
type
awar
traﬃc
web-convers
ad
muda
v3
show
best
balanc
impress
gain
among
118
6.7
onlin
lift
ad
hide
rate
hdr
re-pin
rate
rpr
observ
muda
variant
type
ad
muda
v3
achiev
balanc
perform
fewer
ad
hidden
ad
repin
user
119
chapter
introduct
1.1
motiv
quest
fair
inform
retriev
ir
system
gain
unpreced
attent
digit
era
demand
equiti
across
platform
servic
central
pursuit
challeng
mitig
systemat
bias
within
data-driven
rank
ing
model
bias
often
reﬂect
histor
discrimin
manifest
unfair
treatment
toward
underrepres
group
lead
dispar
exposur
unequ
opportun
variou
real-world
applic
expert
search
job
recommend
essenc
fair
ir
extend
beyond
mere
algorithm
ad
justment
ensur
demograph
group
equal
visibl
represent
outcom
search
recommend
system
16
chapter
introduct
17
address
inher
bias
dataset
use
train
machin
learn
model
develop
novel
framework
framework
includ
meta-learn
base
fair
rank
mfr
meta
curriculum-bas
fair
rank
mcfr
repres
sig
niﬁcant
stride
toward
achiev
equit
treatment
across
protect
attribut
re-weight
rank
loss
incorpor
curriculum
learn
meta
dataset
construct
model
aim
balanc
exposur
advantag
disadvan
tage
group
oﬀer
nuanc
approach
fair
transcend
tradit
mitig
strategi
integr
larg
languag
model
llm
rank
task
complic
landscap
fair
ir
despit
superior
perform
understand
process
natur
languag
llm
immun
fair
concern
empir
scrutini
model
fair
benchmark
reveal
press
need
evalu
ﬁne-tun
focu
equiti
ensur
deploy
perpetu
exist
bias
lastli
realm
onlin
advertis
particularli
multi-stag
recommend
sy
tem
like
use
ad
retriev
underscor
pervas
challeng
select
bia
area
might
seem
tangenti
share
core
issu
bia
mitig
broader
ir
system
eﬃcient
manag
divers
qualiti
ad
upper
funnel
stage
without
succumb
bias
crucial
maintain
integr
fair
digit
advertis
ecosystem
summari
motiv
thesi
stem
urgent
need
address
chapter
introduct
18
rectifi
fair
issu
ir
system
comprehens
explor
innova
tive
framework
meticul
evalu
llm
consider
select
bia
onlin
advertis
work
aim
contribut
meaning
solut
overarch
challeng
ensur
fair
digit
inform
landscap
1.2
overview
thesi
present
comprehens
explor
fair
rank
search
sy
tem
address
multifacet
challeng
bia
inform
retriev
ir
seri
innov
approach
methodolog
across
four
distinct
intercon
nect
studi
delv
complex
data
bia
select
bia
ethic
implic
larg
languag
model
llm
text
rank
provid
holist
ex
amin
fair
digit
inform
landscap
ﬁrstli
introduc
meta-learn
base
fair
rank
mfr
model
advanc
framework
design
mitig
data
bia
re-weight
rank
loss
bilevel
optim
process
model
enhanc
fair
metric
also
maintain
competit
rank
perform
oﬀer
scalabl
solut
equit
ir
system
build
foundat
propos
meta
curriculum-bas
fair
rank
mcfr
framework
address
data
bia
integr
in-process
pre-process
techniqu
curriculum
learn
mcfr
demonstr
remark
chapter
introduct
19
versatil
eﬀect
improv
fair
metric
across
variou
rank
loss
function
showcas
potenti
gener
framework
fair
rank
focu
evalu
fair
llm
text
rank
establish
bench
mark
incorpor
listwis
pairwis
evalu
method
focus
binari
protect
attribut
extens
experiment
reveal
inher
fair
issu
llm
propos
ﬁne-tun
strategi
use
low-rank
adapt
lora
mitig
issu
mark
signiﬁc
step
toward
equit
llm-base
rank
system
final
tackl
select
bia
multi-cascad
advertis
recommend
system
survey
state-of-the-art
model
strategi
introduc
modiﬁ
un
supervis
domain
adapt
muda
approach
muda
outperform
contem
porari
model
exist
product
model
onlin
set
highlight
eﬀect
address
select
bia
enhanc
fair
eﬃcienc
recommend
system
1.3
contribut
contribut
thesi
can
summar
follow
introduc
meta-learn
base
fair
rank
mfr
model
novel
ap
proach
address
data
bia
rank
system
automat
adjust
rank
loss
mfr
model
frame
bilevel
optim
problem
chapter
introduct
20
solv
innov
gradients-through-gradi
techniqu
demonstr
robust
eﬀect
real-world
dataset
result
highlight
mfr
capac
achiev
competit
rank
perform
signiﬁcantli
enhanc
fair
metric
mark
critic
advanc
pursuit
fair
inform
retriev
system
present
meta
curriculum-bas
fair
rank
mcfr
framework
innov
approach
mitig
data
bia
blend
in-process
pre
process
techniqu
curriculum
learn
mcfr
formul
bilevel
op
timiz
problem
solv
via
gradients-through-gradi
prove
versatil
across
variou
rank
loss
function
fair
metric
empir
studi
across
public
dataset
aﬃrm
mcfr
eﬀect
match
exist
rank
perfor
manc
signiﬁcantli
advanc
fair
metric
notabl
mcfr
enhanc
fair
eﬃcient
requir
less
data
achiev
fast
converg
posi
tion
highli
adapt
impact
framework
promot
fair
rank
system
creat
benchmark
evalu
fair
larg
languag
model
llm
text
rank
focus
binari
protect
attribut
listwis
pairwis
method
extens
experi
real-world
dataset
reveal
fair
issu
llm
prompt
us
propos
ﬁne-tun
strategi
use
low
rank
adapt
lora
speciﬁc
design
address
concern
dual
approach
identifi
mitig
fair
problem
mark
signiﬁc
advanc
improv
llm
perform
rank
task
chapter
introduct
21
address
select
bia
advertis
recommend
system
char
acter
issu
evalu
variou
model
strategi
explor
lead
develop
modiﬁ
unsupervis
domain
adapt
muda
approach
stand
superior
perform
onlin
set
perform
contemporari
model
exist
product
model
studi
advanc
mitig
select
bia
showcas
muda
eﬀect
enhanc
recommend
fair
eﬃcienc
1.4
outlin
thesi
structur
follow
chapter
review
exist
literatur
fair
inform
retriev
highlight
signiﬁc
address
bias
rank
model
evolv
strategi
mitig
challeng
chapter
detail
meta-learn
base
fair
rank
mfr
model
focus
innov
approach
enhanc
fair
adjust
train
loss
improv
minor
group
exposur
valid
real-world
dataset
chapter
discuss
meta
curriculum
base
fair
rank
mcfr
framework
integr
meta-learn
curricu
lum
learn
counteract
data
bia
showcas
eﬀect
tradit
fair
model
chapter
explor
fair
larg
languag
model
rank
task
present
empir
studi
bias
introduc
mitig
strategi
via
lora
ﬁne-tun
promot
equit
outcom
chapter
investig
select
bia
pinterest
advertis
system
propos
modiﬁ
unsupervis
domain
22
adapt
muda
model
demonstr
capac
improv
recommend
perform
advertis
eﬃcienc
chapter
conclud
thesi
summar
key
contribut
reﬂect
impact
work
fair
search
rank
suggest
futur
research
direct
advanc
ﬁeld
chapter
relat
work
2.1
fair
rank
zehlik
et
al
92
categor
fair
rank
model
score-bas
supervis
learn
ing
model
score-bas
model
modifi
score
outcom
distribut
enhanc
fair
notabl
contribut
includ
work
yang
et
al
86
87
celi
et
al
18
stoyanovich
et
al
72
kleinberg
et
al
47
asudeh
et
al
supervis
fair
model
rank
span
pre-process
in-process
post
process
approach
pre-process
model
exempliﬁ
lahoti
et
al
49
work
deriv
fair
train
data
in-process
model
zehlik
et
al
deltr
89
address
fair
train
focus
exposur
bia
similarli
beutel
et
al
introduc
pairwis
rank
loss
function
fair
regular
ma
et
al
52
23
chapter
relat
work
24
tackl
fair
queri
gener
haak
et
al
39
aim
search
queri
bia
iden
tiﬁcat
chu
et
al
23
highlight
bias
neural
architectur
search
evalua
tion
importantli
chen
et
al
20
propos
meta-learning-bas
debias
frame
work
recommend
post-process
model
convers
reﬁn
model
output
post-train
fair
among
zehlik
et
al
work
90
91
like
fa
ir
ensur
represent
protect
group
oﬀer
continu
fair
interpol
addi
tional
biega
et
al
10
develop
algorithm
optim
equiti
user
attent
relev
loss
function
2.2
meta-learn
fair
meta-learn
ﬁeld
studi
aim
improv
learn
abil
model
adapt
new
task
environ
divid
two
main
categori
model-bas
30
learn
algorithm-bas
addit
task
shot
learn
43
continu
learn
60
hyperparamet
optim
32
fair
import
ﬁeld
zhao
et
al
98
present
follow
fair
meta
leader
ffml
learn
onlin
fair
classiﬁc
model
primal
deliv
accuraci
fair
subs
quent
work
zhao
et
al
97
emphas
primal-du
fair
meta-learn
target
optim
initi
base
model
weight
rapidli
adjust
new
fair
task
advanc
research
96
creat
few-shot
discrimin
chapter
relat
work
25
prevent
model
unbias
multi-class
classiﬁc
root
maml
frame
work
concurr
slack
et
al
71
introduc
fair-maml
design
deriv
fair
model
minim
data
emerg
task
model
like
zhao
built
upon
maml
framework
incorpor
fair
regular
speciﬁc
fair
hyperparamet
recommend
system
chen
et
al
20
appli
meta-learn
prin
cipl
autodebia
framework
2.3
fair
llm
research
fair
llm
gain
consider
traction
driven
realiz
bias
present
pretrain
corpora
can
lead
llm
gener
content
harm
also
oﬀens
often
result
discrimin
margin
group
heighten
awar
spur
increas
research
eﬀort
aim
un
derstand
origin
bia
address
detriment
aspect
llm
68
13
initi
like
reinforc
learn
human
feedback
58
reinforc
learn
ai
fair
seek
mitig
reinforc
exist
stereotyp
gener
demean
content
beyond
exist
literatur
fairllm
95
critic
evalu
recllm
fair
high
light
bias
chatgpt
recommend
user
attribut
concurr
eﬀort
reﬁn
llm
fair
assess
gain
traction
within
nlp
commun
22
66
studi
like
12
expos
bias
gpt-3
content
gener
chapter
relat
work
26
latter
note
violent
bia
muslim
benchmark
bbq
61
crow
pair
54
realtoxicityprompt
34
holist
evalu
50
analysi
across
variou
llm
decodingtrust
77
extend
detail
fair
explor
chatgpt
gpt-4
2.4
select
bia
research
select
bia
recommend
system
increas
explor
method
reduc
bia
enhanc
system
perform
one
approach
re-sampl
techniqu
includ
method
undersampl
63
42
smote
synthet
minor
over-sampl
techniqu
19
14
aim
balanc
distribut
data
across
diﬀer
class
anoth
popular
approach
use
cost-sensit
learn
method
assign
diﬀer
cost
diﬀer
type
error
order
balanc
trade-oﬀ
diﬀer
type
bia
exampl
method
adversari
learn
94
24
aim
minim
bia
ad
adversari
term
loss
function
encourag
model
produc
fair
predict
anoth
area
research
focus
use
debias
techniqu
represent
learn
process
fair
represent
learn
93
learn
represent
invari
certain
sensit
attribut
also
recent
studi
address
select
bia
use
counterfactu
data
augment
cfda
81
creat
new
hypothet
data
point
increas
divers
train
set
can
done
gener
synthet
data
point
similar
origin
data
point
27
diﬀer
sensit
attribut
addit
meta-learn
21
78
appli
debias
recommend
system
multi-stag
cascad
system
qin
et
al
64
propos
rankflow
solv
select
bia
joint-train
system
expens
deploy
product
system
work
aim
solv
select
bia
issu
independent-train
model
cascad
system
chapter
meta-learn
approach
fair
rank
3.1
introduct
recent
fair
inform
retriev
ir
system
attract
attent
92
86
87
rank
model
aim
give
relev
score
item
queri
top
item
highest
score
will
deliv
user
rank
model
gener
data-driven
mean
model
will
observ
particular
pattern
train
dataset
make
predict
base
howev
subject
rank
problem
expert
search
job
recommend
systemat
bias
dataset
usual
stem
bias
data
distribut
will
introduc
unfair
train
model
exampl
28
chapter
meta-learn
approach
fair
rank
29
law
student
race
law
student
gender
figur
3.1
illustr
predict
rank
distribut
protect
group
femal
student
african
american
student
two
diﬀer
dataset
report
kendal
tau
rank
metric
propos
mfr
model
rank
item
protect
group
higher
compar
listnet
17
indic
mfr
improv
protect
attribut
exposur
unbias
rank
perform
tradit
ltr
model
listnet
17
will
discrimin
assign
lower
weight
minor
group
due
data
bia
see
fig
3.1
address
friedman
33
histor
discrimin
social
underrepres
group
dataset
will
make
way
model
pattern
will
observ
train
process
unfair
problem
summar
dispar
exposur
89
disadvantag
protect
group
treat
equal
advantag
group
dataset
dispar
exposur
lead
neg
impact
mani
real
world
rank
problem
unequ
opportun
job
market
underrepres
group
solv
unfair
problem
tremend
research
eﬀort
made
de
sign
fairness-awar
algorithm
among
fair
rank
model
can
categor
score-bas
supervis
one
score-bas
model
chapter
meta-learn
approach
fair
rank
30
rank-awar
proport
represent
86
constrain
rank
maxim
18
etc
score-bas
model
aim
correct
bia
train
data
other
aim
adjust
predict
score
better
fair
also
supervis
model
deltr
89
fa
ir
90
etc
learn
fair
model
bias
dataset
gener
rank
model
focu
diﬀer
mitig
point
post
pre-process
model
train
although
in-process
model
achiev
good
perform
fair
metric
still
limi
tation
model
learn
bias
dataset
thu
meta-learn
beneﬁt
aforement
problem
train
meta-learn
meta-dataset
meta-dataset
collect
uniformli
without
bia
train
fair
meta
learner
rank
model
learn
gener
fair
problem
train
classiﬁc
model
bias
dataset
research
appli
model-agnost
meta-learn
maml
31
exampl
meta-weight-net
69
propos
explicitli
learn
weight
function
meta-dataset
date
simultan
classiﬁ
howev
meta-learn
still
under-explor
fairness-awar
rank
problem
studi
propos
meta-learn
framework
formul
fairness-awar
rank
task
bilevel
optim
problem
upper-level
meta-train
lower-level
rank
model
can
train
meta-learn
meta-dataset
help
rank
model
learn
fairli
bias
dataset
meta-dataset
small
unbias
dataset
collect
uniformli
sampl
train
dataset
queri
protect
group
chapter
meta-learn
approach
fair
rank
31
unprotect
group
detail
train
iter
use
rank
model
rank
loss
function
comput
loss
valu
data
sampl
train
dataset
train
multi-lay
neural
network
weight
function
re-weight
loss
valu
weight
function
optim
weight
loss
valu
meta-dataset
sinc
weight
function
meta-learn
subject
rank
model
goal
optim
loss
weight
given
meta-learn
achiev
fair
train
dataset
intuit
can
see
loss
weight
hyperparamet
learn
train
meta
learner
tune
hyperparamet
meta-dataset
train
process
also
refer
bilevel
optim
learn
paramet
rank
model
depend
paramet
meta-learn
best
knowledg
propos
ﬁrst
meta-learn
approach
fair
rank
summari
work
make
follow
contribut
propos
gener
meta-learn
framework
fair
rank
call
meta-learn
base
fair
rank
mfr
address
data
bia
auto
matic
re-weight
rank
loss
formul
mfr
bilevel
optim
problem
solv
use
gra
dient
gradient
experi
real-world
dataset
demonstr
propos
method
achiev
compar
rank
perform
signiﬁcantli
improv
fair
metric
compar
state-of-the-art
method
chapter
meta-learn
approach
fair
rank
32
bias
unprotect
group
protect
group
unbias
figur
3.2
mfr
learn
algorithm
ﬂowchart
step
algorithm
note
rank
model
meta-learn
batch
size
train
dataset
batch
size
meta-dataset
learn
rate
iter
ﬁrstli
updat
meta-learn
use
eq
meta-dataset
updat
rank
model
use
eq
train
dataset
3.2
meta-learn
base
fair
rank
aim
train
fairness-awar
rank
model
achiev
good
perform
util
fair
metric
tune
rank
model
loss
weight
valu
make
model
emphas
protect
group
unprotect
one
rank
infer
instead
use
ﬁxed
weight
util
meta
dataset
sampl
origin
train
dataset
unbias
distribut
smaller
size
train
meta-learn
weight
function
meta-learn
guid
rank
model
learn
fairli
given
train
dataset
set
queri
qtrain
qtrain
set
item
dtrain
dtrain
queri
qtrain
associ
list
item
candid
dtrain
item
repres
featur
vector
xi
queri
featur
vector
associ
relev
score
let
rank
model
repres
learnabl
paramet
chapter
meta-learn
approach
fair
rank
33
output
rank
model
denot
gener
learn
optim
paramet
minw
yi
use
rank
loss
function
howev
equal
treat
sampl
lead
rank
model
unfair
minor
group
sinc
heavi
data
bia
issu
train
dataset
address
challeng
introduc
meta-learn
parameter
adapt
tune
loss
weight
sampl
achiev
fair
exposur
divers
thu
rewrit
train
loss
follow
ltrain
φi
li
yi
3.1
xi
repres
model
output
φi
repres
i-th
sampl
loss
weight
given
propos
meta-learn
notabl
ltrain
govern
meta-learn
output
weight
condit
ﬁxed
use
updat
rank
model
paramet
conveni
denot
li
origin
loss
valu
i-th
train
data
sampl
output
rank
loss
follow
69
develop
meta-learn
multi-lay
neural
network
take
input
loss
valu
instanti
φi
li
li
3.2
sampl
either
train
dataset
meta-dataset
set
last-lay
activ
function
sigmoid
rang
output
chapter
meta-learn
approach
fair
rank
34
algorithm
mfr
learn
algorithm
input
train
dataset
qtrain
dtrain
meta-dataset
qmeta
dmeta
batch
size
max
iter
output
classiﬁ
network
paramet
initi
rank
model
paramet
meta-learn
paramet
xqmeta
qmeta
sampleminibatch
qmeta
dmeta
xqtrain
qtrain
sampleminibatch
qtrain
dtrain
updat
wˆ
eq
3.4
xqtrain
qtrain
updat
eq
3.9
xqmeta
qmeta
updat
eq
3.10
xqtrain
qtrain
end
lie
eventu
deﬁn
meta
train
loss
function
lmeta
li
3.3
updat
paramet
rank
network
gradient
decent
batch
train
data
loss
function
eq
3.1
can
deﬁn
ltrain
ltrain
3.4
train
meta-learn
need
sampl
small
meta-dataset
qmeta
dmeta
meta-dataset
repres
meta-knowledg
true
distribut
protect
group
group
qmeta
dmeta
meta-dataset
denot
featur
vector
item
qmeta
relev
score
qmeta
given
queri
qmeta
qmeta
similar
ltrain
denot
lmeta
loss
valu
meta-dataset
sampl
goal
meta-learn
leverag
unbias
meta-dataset
learn
re-weight
loss
valu
train
chapter
meta-learn
approach
fair
rank
35
model
bias
dataset
sinc
function
natur
formul
propos
mfr
bilevel
optim
problem
give
object
function
min
lmeta
3.5
arg
min
train
loss
function
propos
mfr
jointli
consid
util
fair
metric
develop
listwis
rank
loss
exposur
term
follow
deltr
loss
89
given
γu
3.6
listwis
fair
measur
listwis
loss
base
cross
entropi
17
balanc
paramet
obtain
optim
paramet
minim
train
loss
arg
min
train
φi
ltrain
3.7
loss
meta-learn
meta
arg
min
meta
3.8
paramet
updat
step
comput
weight
loss
valu
θt
wt
updat
loss
rank
model
meta-dataset
chapter
meta-learn
approach
fair
rank
36
follow
lmeta
3.9
learn
rate
batch
size
meta-dataset
updat
follow
φi
ltrain
3.10
learn
rate
batch
size
train
dataset
adopt
altern
optim
strategi
69
75
88
implement
eq
3.9
eq
3.10
instead
use
nest
optim
loop
whole
train
process
summar
algorithm
although
consid
deltr
loss
object
function
rank
model
also
use
fair
rank
loss
besid
dispar
exposur
bias
common
rank
dataset
select
bia
posit
bia
model
aim
provid
gener
meta-learn
framework
can
handl
fair
rank
problem
3.3
experi
experi
train
evalu
model
three
real-world
dataset
use
deltr
89
studi
rank
fair
metric
approach
compar
baselin
model
baselin
model
includ
follow
chapter
meta-learn
approach
fair
rank
37
listnet
17
ii
lambdamart
16
iii
deltr
model
γsmall
γlarg
set
89
iv
fa
ir
90
pre-process
approach
creat
fair
dataset
train
fa
ir
post-process
approach
reorder
predict
result
ensur
fair
vi
mfr
diﬀer
diﬀer
dataset
vii
mfr
listnet
loss
mfr-listnet
code
avail
https://github.com/ywang4/a-meta-learning-approach-to-fair-ranking.
fair
comparison
follow
settings1
describ
deltr
89
split
dataset
gener
item
featur
use
follow
dataset
w3c
expert
gender
ii
engin
student
high
school
iii
engin
student
gender
iv
law
student
gender
law
student
race
w3c
expert
dataset
task
expert
search
origin
trec
2005
enterpris
track
26
protect
attribut
femal
200
item
per
queri
averag
21.5
item
protect
group
engin
student
dataset
task
academ
perform
predict
dataset
contain
anonym
histor
inform
colleg
student
high
school
dataset
protect
attribut
public
high
school
480.6
item
per
queri
167.6
item
protect
group
averag
gender
dataset
protect
attribut
femal
480.6
item
per
queri
97.6
item
protect
group
averag
law
student
dataset
task
also
academ
perform
predict
gender
dataset
protect
attribut
femal
total
21791
item
9537
item
protect
group
race
dataset
protect
https://github.com/milkalichtblau/deltr-experi
chapter
meta-learn
approach
fair
rank
38
attribut
black
total
19567
item
1282
protect
group
queri
technic
topic
w3c
dataset
academ
year
dataset
fair
comparison
adapt
evalu
metric
89
split
dataset
50
queri
train
10
queri
test
w3c
dataset
queri
train
queri
test
engin
student
dataset
80
train
20
test
law
student
dataset
use
precis
10
10
w3c
dataset
kendal
tau
dataset
evalu
rank
perform
measur
fair
comput
exposur
ratio
protect
non-protect
group
thu
fair
metric
valu
greater
1.0
indic
greater
visibl
protect
group
vice
versa
describ
sec
3.2
meta-dataset
requir
approach
sinc
protect
attribut
dataset
binari
perform
random
uniform
sampl
collect
meta-dataset
speciﬁc
randomli
sampl
amount
data
item
queri
protect
group
non-protect
group
set
gener
weight
function
set
updat
frequenc
paramet
θto
per
step
optim
sgd
momentum
0.98
learn
rate
0.02
hidden
layer
dimens
30
number
hidden
layer
rank
model
set
learn
rate
dataset
0.005
except
w3c
data
0.0005
optim
sgd
momentum
0.95
weight
decay
0.005
valu
train
epoch
vari
diﬀer
dataset
w3c
dataset
use
500
100
epoch
engin
student
high
school
use
5000
500
epoch
engin
student
gender
use
chapter
meta-learn
approach
fair
rank
39
w3c
expert
engin
student
engin
law
student
law
student
gender
high
school
type
student
gender
gender
race
10
fair
tau
fair
tau
fair
tau
fair
tau
fair
listnet
17
0.178
0.759
0.390
1.070
0.384
0.858
0.202
0.931
0.184
0.853
lambdamart
16
0.095
0.738
0.355
1.002
0.326
0.907
0.199
0.979
0.156
0.847
deltr
γsmall
89
0.178
0.785
0.390
1.075
0.384
0.860
0.201
0.958
0.173
0.874
deltr
γlarg
89
0.180
0.827
0.391
1.075
0.370
0.976
0.188
0.993
0.130
1.014
fa
ir
post
90
0.178
0.824
0.390
1.070
0.384
0.886
0.182
0.965
0.140
0.944
fa
ir
pre
90
0.180
0.770
0.374
1.020
0.360
0.942
0.203
0.931
0.161
0.895
mfr-listnet
0.115
0.775
0.385
0.990
0.385
0.855
0.225
0.901
0.182
0.848
mfr
0.126
0.830
0.391
1.086
0.352
1.052
0.225
1.015
0.184
1.654
tabl
3.1
experiment
result
measur
fair
comput
exposur
ratio
protect
non-protect
group
valu
greater
1.0
dicat
greater
visibl
protect
group
vice
versa
rank
metric
higher
kendal
tau
precis
10
10
score
indic
better
perform
bold
text
indic
model
best
perform
result
show
mfr
model
better
fair
metric
compar
perform
rank
metric
state-of-the-art
model
500
100
epoch
law
student
gender
use
1200
3000
epoch
law
student
race
use
50000
100
epoch
result
analysi
shown
tab
3.1
approach
perform
better
term
fair
metric
dataset
deltr
γsmall
deltr
γlarg
deltr
γsmall
deltr
γlarg
model
use
diﬀer
scale
valu
weight
exposur
measur
loss
function
meta
learner
can
achiev
higher
fair
metric
re-weight
loss
distribut
train
process
intuit
behind
observ
imbalanc
pattern
among
train
data
observ
correct
meta
learner
rank
metric
similar
better
result
dataset
except
w3c
dataset
sinc
listnet
lambdamart
consid
fair
measur
train
result
expect
fair
metric
wors
fair
rank
model
addit
train
mfr-listnet
standard
listwis
rank
loss
framework
evalu
result
show
wors
perform
rank
chapter
meta-learn
approach
fair
rank
40
engin
student
high
school
law
student
gender
figur
3.3
plot
variat
learn
weight
two
train
dataset
weight
diﬀer
comput
φtdiﬀ
φi
φi
plot
φdiﬀ
train
epoch
shown
plot
weight
function
converg
diﬀer
valu
weight
epoch
decreas
0.0
fair
metric
listwis
loss
consid
exposur
measur
meta
dataset
diﬀer
data
distribut
train
dataset
neg
eﬀect
meta-learn
re-weight
process
thu
conclud
meta-learn
approach
help
model
improv
fair
metric
compar
model
deltr
loss
function
fig
3.1
plot
histogram
rank
protect
attribut
dif
ferent
model
plot
can
see
distribut
predict
rank
shift
right
left
indic
mfr
model
gener
rank
item
protect
group
higher
compar
listnet
note
plot
mean
top
rank
data
sampl
fall
bin
left
item
receiv
higher
rank
plot
also
agre
evalu
result
see
larg
diﬀer
fig
1b
fair
metric
mfr
law
student
race
dataset
two
time
listnet
41
fig
3.3
plot
variat
learn
weight
train
data
plot
show
weight
function
converg
diﬀer
valu
weight
epoch
decreas
suggest
meta-weight-net
69
use
multi-lay
neural
network
weight
function
multi-lay
neural
network
known
univers
approxim
continu
function
converg
shown
plot
indic
success
learn
process
weight
function
3.4
conclus
work
propos
meta-learn
base
fair
rank
mfr
model
improv
minor
group
exposur
experi
real-world
dataset
demonstr
approach
achiev
better
fair
metric
compar
fair
rank
model
without
meta-learn
part
chapter
uniﬁ
meta-learn
framework
fair
rank
curriculum
learn
4.1
introduct
fair
search
engin
import
topic
focus
train
unbias
rank
model
toward
protect
attribut
typic
user
queri
given
rank
model
predict
relev
score
among
candid
item
return
item
highest
score
user
data-driven
rank
model
usual
train
larg
dataset
thu
ranker
will
learn
user
item
pattern
train
dataset
make
predict
base
howev
mani
case
systemat
bias
42
chapter
uniﬁ
meta-learn
framework
fair
rank
curriculum
learn
43
african
femal
african
femal
american
american
figur
4.1
illustr
predict
rank
distribut
two
protect
tribut
four
dataset
law
student
gender
82
law
student
race
82
compa
engin
student
89
report
kendal
tau
48
rank
perform
mcfr
mfr
80
improv
protect
attribut
rank
realiz
competit
rank
perform
compar
listnet
17
demonstr
approach
increas
exposur
minor
exposur
bia
70
dataset
will
caus
unfair
rank
model
histor
discrimin
social
underrepres
group
33
will
make
way
model
pattern
will
observ
train
process
unfair
problem
summar
dispar
exposur
70
lead
neg
impact
mani
real-world
rank
problem
dispar
exposur
preval
inform
retriev
instanc
expert
search
job
recommend
system
histor
underrepres
minor
group
like
femal
african
american
consequ
tradit
learn
rank
ltr
model
listnet
17
often
rank
group
lower
due
data
bias
fig
4.1
show
rank
score
diﬀer
model
four
dataset
highlight
unfair
dispar
exposur
impli
uneven
group
visibl
algorithm
outcom
especi
link
attribut
like
gender
race
distinct
bias
like
select
conform
challeng
algorithm
fair
eﬃcienc
chapter
uniﬁ
meta-learn
framework
fair
rank
curriculum
learn
44
reduc
dispar
exposur
rank
context
mani
research
work
propos
recent
design
fairness-awar
algorithm
can
divid
two
categori
score-bas
model
supervised-learn
model
score-bas
model
86
87
18
72
47
comput
rank
score
ﬂy
given
candid
list
return
sort
candid
model
outcom
supervised-learn
model
gener
solv
rank
predict
problem
focu
diﬀer
mitig
strategi
post
49
89
52
39
23
27
20
pre-process
90
91
10
model
train
although
in-process
model
achiev
promis
perform
fair
rank
metric
learn
bias
dataset
still
under-explor
challeng
due
unbalanc
distribut
protect
attribut
public
train
dataset
one
possibl
way
allevi
system
discrimin
inherit
data
bia
dynam
ical
re-weight
minor
group
contribut
penalti
comput
rank
loss
end
meta-learn
31
emerg
eﬀect
way
enabl
learning-to-weight
approach
leverag
small
unbias
dataset
meta
dataset
fairness-awar
rank
problem
propos
mitig
exposur
issu
bias
dataset
learn
weight
model
meta-learn
re-weight
loss
rank
model
bias
dataset
meta-learn
will
optim
meta
dataset
unbias
weight
loss
train
dataset
bias
will
use
optim
rank
model
howev
due
distribut
shift
bias
unbias
dataset
non-trivi
directli
train
meta-learn
base
learner
two
dataset
larg
train
loss
may
impair
rank
util
chapter
uniﬁ
meta-learn
framework
fair
rank
curriculum
learn
45
burden
converg
speed
propos
adopt
curriculum
learn
gradual
increas
diﬃculti
train
meta-learn
address
challeng
speciﬁc
deﬁn
diﬃculti
exposur
protect
group
dataset
ﬁrst
randomli
sampl
meta
dataset
exposur
train
dataset
continu
increas
protect
group
exposur
meta
dataset
sampl
candid
group
ongo
epoch
uniform
distribut
equal
exposur
achiev
sensit
attribut
intuit
increment
concept
learn
good
ﬁt
solv
distribut
shift
problem
meta-learn
train
sampl
bias
dataset
earli
epoch
mean
less
distribut
shift
meta-dataset
train
dataset
experiment
result
demonstr
eﬀect
curriculum
learn
improv
data
eﬃcienc
train
studi
propos
uniﬁ
meta-learn
framework
curriculum
learn
formul
fairness-awar
rank
task
bilevel
optim
problem
upper
level
focus
learning-to-weight
mitig
bias
exposur
protect
attribut
lower
level
solv
learning-to-rank
dynam
loss
govern
meta
learner
speciﬁc
allevi
data
bia
issu
protect
group
automat
weight
loss
contribut
work
follow
propos
novel
meta
curriculum-bas
fair
rank
framework
name
mcfr
address
data
bia
automat
re-weight
rank
chapter
uniﬁ
meta-learn
framework
fair
rank
curriculum
learn
46
loss
propos
mcfr
formul
bilevel
optim
problem
solv
use
gradient
gradient
propos
fair
rank
algorithm
marri
in-process
method
pre
process
techniqu
seamlessli
incorpor
curriculum
learn
construct
process
meta
dataset
develop
mcfr
gener
framework
applic
variou
rank
loss
function
fair
metric
systemat
empir
studi
provid
show
versatil
propos
framework
diﬀer
rank
fair
criteria
experi
public
dataset
show
method
match
exist
rank
per
formanc
enhanc
fair
metric
addit
evalu
conﬁrm
mcfr
improv
fair
less
train
data
achiev
compar
converg
time
work
oﬀer
ﬁrst
fair
rank
framework
util
pre-process
in-process
method
new
approach
enhanc
model
adapt
ro
bust
allow
broader
rang
loss
function
dynam
adjust
meta-dataset
train
addit
framework
demonstr
data
eﬃcienc
compar
experi
ve
also
conduct
comprehens
test
incorpo
rate
addit
baselin
model
perform
ablat
studi
variou
fair
term
rank
loss
lastli
ve
updat
manuscript
includ
recent
relat
work
provid
fuller
understand
fair
rank
chapter
uniﬁ
meta-learn
framework
fair
rank
curriculum
learn
47
meta
model
rank
model
singl
step
schedul
curriculum
sampl
easier
harder
bias
distribut
unbias
distribut
rank
loss
fair
term
rankms
unprotect
group
mini
batch
sampl
squar
exposur
protect
group
ranknet
hing
exposur
listnet
figur
4.2
mcfr
learn
algorithm
ﬂowchart
step
algorithm
note
rank
model
meta
learner
batch
size
train
dataset
batch
size
meta-dataset
learn
rate
iter
ﬁrstli
updat
meta
learner
use
eq
meta-dataset
sampl
curriculum
sampl
updat
sampl
diﬃculti
epoch
updat
rank
model
use
eq
train
dataset
4.2
meta
curriculum-bas
fair
rank
section
will
explain
propos
meta
curriculum-bas
fair
rank
frame
work
detail
mcfr
framework
will
train
unbias
rank
model
use
meta-lean
re-weight
rank
loss
formul
bilevel
op
timiz
problem
solv
use
gradient
gradient
also
show
framework
train
variou
rank
loss
function
fair
term
final
describ
design
curriculum
sampl
strategi
meta
dataset
address
bia
dataset
tradit
method
util
pre-process
in-process
chapter
uniﬁ
meta-learn
framework
fair
rank
curriculum
learn
48
post-process
techniqu
92
28
model
combin
pre-process
process
introduc
meta
curriculum-bas
fair
rank
framework
de
rive
smaller
dataset
meta-learn
train
assign
weight
emphas
protect
group
train
curriculum
learn
adjust
dataset
distribut
ratio
epoch
facilit
smoother
meta-learn
train
integr
rank
ing
loss
fair
regular
use
meta-learn
guid
model
train
depict
fig
4.2
4.2
problem
set
denot
set
queri
train
dataset
qtrain
size
qtrain
set
item
dtrain
dtrain
queri
qtrain
list
item
candid
dtrain
pair
queri
item
repres
featur
vector
xi
associ
relev
score
yi
dataset
candid
binari
attribut
speciﬁ
whether
candid
belong
protect
group
non-protect
group
exampl
binari
attribut
repres
gender
race
systemat
bia
exist
dataset
collect
4.2
uniﬁ
mcfr
framework
address
fair
problem
train
meta
learner
meta-dataset
help
train
fair
rank
model
bias
train
dataset
rank
model
learnabl
paramet
denot
chapter
uniﬁ
meta-learn
framework
fair
rank
curriculum
learn
49
output
model
gener
model
paramet
optim
minw
yi
minim
given
rank
loss
function
pairwis
loss
listwis
loss
howev
loss
function
treat
sampl
equal
rank
model
will
unfair
heavi
data
bia
issu
toward
minor
group
train
dataset
mitig
problem
introduc
meta
learner
learnabl
paramet
adapt
tune
loss
weight
sampl
achiev
fair
exposur
divers
rewrit
train
loss
follow
ltrain
φi
li
yi
4.1
xi
denot
model
output
φi
denot
i-th
sam
ple
loss
weight
given
aforement
meta
learner
notabl
ltrain
govern
meta
learner
output
weight
depend
ﬁxed
use
updat
rank
model
paramet
short
write
li
origin
loss
valu
i-th
train
data
sampl
output
rank
loss
meta
learner
use
multi-lay
perceptron
network
propos
69
take
loss
valu
input
output
weight
loss
φi
li
li
4.2
chapter
uniﬁ
meta-learn
framework
fair
rank
curriculum
learn
50
algorithm
paramet
updat
algorithm
mcfr
input
batch
train
data
xqtrain
qtrain
batch
meta-dataset
xqtrain
qtrain
rank
model
paramet
meta
learner
paramet
output
rank
model
paramet
updat
updat
eq
4.5
xqtrain
qtrain
updat
eq
4.8
xqmeta
qmeta
updat
eq
4.9
xqtrain
qtrain
sampl
train
dataset
meta-dataset
use
sigmoid
last-lay
activ
function
deﬁn
meta
train
loss
function
lmeta
li
4.3
qmeta
goal
meta
learner
leverag
meta-dataset
learn
re-weight
loss
valu
train
model
bias
dataset
indic
relationship
meta-learn
play
pivot
role
direct
tune
rank
model
paramet
inher
make
function
sinc
function
natur
formul
propos
mcfr
bilevel
optim
problem
give
object
function
min
lmeta
arg
min
ltrain
4.4
illustr
fig
4.2
propos
mcfr
model
take
advantag
sampl
meta-dataset
learn
unbias
rank
model
meta-dataset
guid
meta
learner
reweight
train
loss
help
rank
model
focu
candid
protect
group
chapter
uniﬁ
meta-learn
framework
fair
rank
curriculum
learn
51
type
formula
hing
exposur
89
max
exposur
g0
exposur
g1
fair
squar
exposur
exposur
g0
exposur
g1
rankms
11
yi
rank
ranknet
15
log
exp
yi
listnet
17
py
log
py
tabl
4.1
summari
rank
fair
term
use
loss
function
loss
function
use
framework
γu
can
insert
exposur
term
rank
loss
term
need
note
denot
number
candid
per
queri
4.2
paramet
updat
sinc
formul
framework
bilevel
optim
problem
chal
leng
calcul
optim
paramet
requir
two
nest
loop
optim
follow
well-known
maml
work
69
75
88
adopt
onlin
strategi
singl
optim
loop
updat
rank
model
meta-learn
paramet
guarante
train
eﬃcienc
updat
paramet
rank
network
use
gradient
decent
batch
train
data
loss
function
eq
4.1
deﬁn
updat
ltrain
ltrain
4.5
chapter
uniﬁ
meta-learn
framework
fair
rank
curriculum
learn
52
step
updat
rank
model
paramet
step
obtain
optim
paramet
minim
train
loss
arg
min
ltrain
φi
ltrain
4.6
loss
meta
learner
meta
arg
min
lmeta
4.7
given
eq
4.5
updat
loss
rank
model
meta-dataset
follow
lmeta
4.8
learn
rate
batch
size
meta-dataset
updat
follow
φi
ltrain
4.9
learn
rate
batch
size
train
dataset
adopt
altern
optim
strategi
69
75
88
implement
eq
4.8
eq
4.9
instead
use
nest
optim
loop
one
step
updat
algorithm
summaris
alg
chapter
uniﬁ
meta-learn
framework
fair
rank
curriculum
learn
53
4.2
rank
fair
loss
propos
mcfr
serv
uniﬁ
framework
aim
improv
rank
fair
metric
given
rank
fair
object
achiev
goal
propos
includ
two
term
loss
function
similar
in-process
fair
method
deltr
89
develop
loss
function
rank
term
fair
term
given
γu
4.10
fair
term
rank
loss
term
balanc
paramet
4.2
4.1
rank
term
rank
loss
use
follow
loss
function
experi
rankms
11
ranknet
15
listnet
17
rankms
pointwis
loss
base
least
mean
squar
regress
ranknet
propos
ﬁrst
pairwis
cross
entropi
loss
consid
prefer
relationship
document
howev
possibl
correctli
predict
document
order
case
listnet
aim
directli
comput
rank
loss
queri
candid
list
instead
comput
pairwis
loss
one
pair
one
pair
chapter
uniﬁ
meta-learn
framework
fair
rank
curriculum
learn
54
worth
note
rank
loss
also
applic
mcfr
provid
gener
framework
improv
rank
metric
4.2
4.2
fair
term
work
focu
dispar
exposur
fair
term
candid
two
diﬀer
group
non-protect
group
g0
protect
group
g1
candid
g1
belong
discrimin
group
femal
african
american
signiﬁc
disadvantag
dataset
follow
deﬁ
nition
singh
et
al
70
exposur
candid
rank
list
gener
probabilist
rank
given
exposur
xi
pi
va
4.11
va
posit
bia
posit
follow
implement
zelik
el
al
89
consid
posit
bia
posit
v1
averag
exposur
candid
group
written
exposur
exposur
xi
4.12
xi
exposur
term
deﬁn
can
introduc
fair
measur
mini
mize
diﬀer
exposur
g0
exposur
g1
exper
iment
use
two
exposur
measur
hing
exposur
calcul
hing
squar
chapter
uniﬁ
meta-learn
framework
fair
rank
curriculum
learn
55
figur
4.3
curriculum
sampl
strategi
illustr
engin
student
gender
dataset
use
ratio
unprotect
group
protect
group
meta-dataset
train
dataset
begin
train
epoch
gradual
decreas
ratio
train
epoch
increas
ratio
becom
show
balanc
meta-dataset
loss
exposur
diﬀer
two
group
squar
exposur
comput
squar
exposur
diﬀer
rank
loss
term
exposur
term
use
arbitrari
combin
framework
improv
fair
rank
metric
given
diﬀer
combin
rank
term
fair
term
summaris
tabl
4.1
4.2
curriculum
sampl
train
data
show
systemat
bia
fewer
candid
protect
group
unprotect
one
address
issu
train
meta
learner
use
un
bias
meta-dataset
sinc
real
unbias
data
rare
autodebia
20
previous
chapter
uniﬁ
meta-learn
framework
fair
rank
curriculum
learn
56
tackl
similar
issu
recommend
system
ﬁt
ranking-focus
need
anoth
approach
use
mfr
80
equal
sampl
candid
group
howev
method
creat
meta-dataset
may
fall
short
accur
captur
real
bias
data
task
like
rank
order
relev
item
crucial
mismatch
data
distribut
can
signiﬁcantli
hinder
model
abil
provid
fair
eﬀect
rank
practic
applic
bias
situat
end
adopt
curriculum
learn
method
start
easier
less
bias
sampl
gradual
introduc
complex
one
mimic
natur
learn
help
model
adapt
better
becom
robust
design
eas
model
understand
correct
bias
ensur
perform
well
fairli
real-world
applic
even
underli
bias
data
train
detail
want
downsampl
meta-dataset
similar
distribut
train
dataset
earli
train
epoch
gradual
chang
ratio
number
candid
protect
unprotect
group
1.0
sinc
collect
real
unbias
dataset
deﬁn
1.0
unbias
ratio
number
candid
two
diﬀer
group
dunprotect
vs
dprotect
mean
equal
number
candid
group
downsampl
ratio
deﬁn
dunprotect
dprotect
underli
assumpt
behind
curriculum
sampl
strategi
easier
train
model
meta
dataset
train
dataset
similar
distribut
diﬃcult
optim
chapter
uniﬁ
meta-learn
framework
fair
rank
curriculum
learn
57
algorithm
mcfr
learn
algorithm
input
train
dataset
qtrain
dtrain
batch
size
max
iter
output
rank
model
paramet
initi
rank
model
paramet
meta
learner
paramet
xqmeta
qmeta
curriculumsampl
qtrain
dtrain
xqtrain
qtrain
sampleminibatch
qtrain
dtrain
updat
alg
end
paramet
rank
model
meta
learner
see
diﬀer
meta
dataset
compar
train
dataset
shown
fig
4.3
illustr
chang
distribut
two
group
meta-dataset
diﬀer
train
epoch
train
meta
learner
use
curriculum
sampl
data
xqmeta
qmeta
meta-dataset
repres
meta-knowledg
true
distribut
protect
group
group
qmeta
dmeta
meta
dataset
denot
featur
vector
item
qmeta
relev
score
qmeta
given
queri
qmeta
qmeta
similar
ltrain
denot
lmeta
loss
valu
meta-dataset
sampl
thu
deﬁn
curriculumsampl
qtrain
dtrain
follow
1.0
4.13
ratio
sampl
candid
group
queri
note
singl
step
schedul
ratio
updat
epoch
execut
curriculumsampl
epoch
sampl
meta-dataset
xqmeta
qmeta
properti
dunprotect
dprotect
intuit
curriculumsam
pling
decreas
ratio
epoch
epoch
bias
ratio
1.0
chapter
uniﬁ
meta-learn
framework
fair
rank
curriculum
learn
58
describ
section
4.2
meta-dataset
import
part
model
train
ing
key
data
guid
meta
learner
sinc
meta
learner
aim
reweight
loss
rank
model
well
meta
learner
train
determin
perform
rank
model
curriculum
sampl
decreas
train
diﬃculti
meta
learner
compar
mfr
80
use
one
sam
pled
unbias
dataset
meta
learner
progress
train
unbias
meta-dataset
epoch
increas
improv
meta
learner
perform
lead
better
overal
perform
rank
model
whole
train
process
summar
algorithm
w3c
expert
engin
student
engin
law
student
law
student
compa
gender
high
school
type
student
gender
gender
race
race
item
queri
200
480.6
480.6
21791
19567
6889
protect
queri
21.5
167.6
97.6
9537
1282
3528
tabl
4.2
summari
dataset
statist
report
averag
count
total
unprotect
item
per
queri
w3c
expert
engin
student
dataset
provid
exact
item
count
law
student
compa
dataset
contain
one
queri
framework
provid
ﬂexibl
solv
diﬀer
rank
problem
listnet
17
may
work
rank
problem
case
fair
term
also
switch
use
diﬀer
fair
metric
diﬀer
formula
comput
dispar
exposur
exposur
issu
fair
problem
mcfr
capabl
optim
fair
term
posit
bia
conform
bia
chapter
uniﬁ
meta-learn
framework
fair
rank
curriculum
learn
59
4.3
experi
experi
train
evalu
model
four
real-world
public
dataset
studi
rank
fair
metric
approach
compar
base
line
model
also
conduct
ablat
studi
eﬀect
framework
chang
rank
loss
term
dispar
exposur
term
repeat
ex
periment
dataset
diﬀer
set
loss
function
evalu
propos
framework
compar
baselin
model
analysi
follow
question
answer
propos
mcfr
perform
compar
baselin
model
mcfr
improv
rank
fair
metric
diﬀer
loss
func
tion
eﬀect
curriculum
sampl
4.3
experiment
set
train
evalu
model
four
real-world
public
dataset
engin
student
ii
law
student
iii
w3c
expert
iv
compa
correct
oﬀend
manag
proﬁl
altern
sanction
statist
dataset
summar
tabl
4.2
chapter
uniﬁ
meta-learn
framework
fair
rank
curriculum
learn
60
w3c
expert
dataset
dataset
origin
trec
2005
enterpris
track
26
involv
search
expert
base
topic
use
featur
email
design
gender
protect
attribut
technic
topic
queri
context
femal
protect
group
male
non-protect
queri
200
item
averag
21.5
protect
group
given
origin
dataset
rank
retriev
expert
equal
adopt
delter
experi
set
89
cat
egor
expert
candid
male
expert
femal
expert
male
non-expert
femal
non-expert
candid
featur
util
elasticsearch
learn
rank
plug-in1
query-candid
pair
text
featur
law
student
dataset
dataset
82
collect
determin
lsat
law
school
admiss
test
us
bias
ethnic
minor
dataset
con
tain
inform
ﬁrst-year
law
student
protect
attribut
gender
race
queri
academ
year
task
retriev
student
good
lsat
score
sinc
problem
set
focus
one
protect
attribut
time
two
dataset
law
student
gender
law
student
race
law
student
gender
dataset
femal
protect
group
among
21
791
candid
537
femal
law
student
race
dataset
african
american
protect
group
19
567
candid
282
group
engin
student
dataset
89
contain
inform
ﬁrst-year
student
chilean
univers
qualiﬁc
featur
includ
admiss
test
result
math
emat
languag
scienc
student
high
school
grade
number
https://elasticsearch-learning-to-rank.readthedocs.io/en/latest/
chapter
uniﬁ
meta-learn
framework
fair
rank
curriculum
learn
61
credit
taken
univers
task
predict
academ
perform
protect
attribut
high
school
type
gender
similarli
two
dataset
engin
student
high
school
type
engin
student
gender
en
gineer
student
dataset
one
focus
high
school
type
public
high
school
student
protect
group
averag
167.6
480.6
item
per
queri
consid
gender
femal
protect
group
averag
97.6
480.6
item
per
queri
compa
compa
correct
oﬀend
manag
proﬁl
altern
sanc
tion
commerci
algorithm
score
crimin
defend
likelihood
recidi
vism
compa
dataset
observ
algorithm
bias
toward
african
american
candid
dataset
task
predict
recidi
vism
score
protect
attribut
race
889
candid
total
528
african
american
4.3
1.1
baselin
integr
sever
baselin
model
implement
listnet
17
introduc
listwis
loss
function
lambdamart
16
combin
mart
lambdarank
tran
form
rank
task
gradient
boost
decis
tree
deltr
89
oﬀer
ltr
strategi
listwis
fair
metric
fa
ir
90
appli
pre
post-process
techniqu
enhanc
fair
autodebia
20
present
debias
method
rec
ommend
system
fairgbm
27
deliv
fairness-centr
classiﬁc
model
chapter
uniﬁ
meta-learn
framework
fair
rank
curriculum
learn
62
gbdt
mfr
80
employ
meta-learn
fair
ltr
notabl
listnet
lambdamart
focu
sole
rank
metric
deltr
mfr
emphas
fairness-awar
rank
4.3
1.2
implement
detail
split
dataset
50
queri
train
10
queri
test
w3c
dataset
queri
train
queri
test
engin
student
dataset
80
train
20
test
law
student
dataset
compa
dataset
use
precis
10
10
38
w3c
dataset
kendal
tau
48
dataset
evalu
rank
perform
kendal
tau
assess
correl
two
rank
set
calcul
diﬀer
number
concord
discord
pair
divid
total
number
pair
rang
indic
perfect
agreement
correl
perfect
disagr
rank
respect
detail
kendal
tau
calcul
follow
kendal
tau
4.14
number
concord
pair
number
discord
pair
number
tie
ground
truth
rank
number
tie
predict
rank
measur
fair
comput
exposur
ratio
protect
non-protect
group
89
thu
fair
metric
valu
greater
1.0
indic
greater
visibl
protect
group
vice
versa
chapter
uniﬁ
meta-learn
framework
fair
rank
curriculum
learn
63
train
set
updat
frequenc
weight
model
paramet
per
step
optim
sgd
74
momentum
0.98
learn
rate
0.022
hidden
layer
dimens
30
number
hidden
layer
rank
model
set
learn
rate
0.005
optim
sgd
momentum
0.95
weight
decay
0.005
set
diﬀer
valu
train
epoch
diﬀer
dataset
w3c
dataset
use
500
100
epoch
engin
student
high
school
use
000
280
epoch
engin
student
gender
use
400
150
epoch
law
student
gender
use
200
550
epoch
law
student
race
use
50
000
110
epoch
compa
race
use
500
45
epoch
ablat
studi
evalu
eﬀect
framework
use
hyperparamet
describ
rank
loss
rankms
ranknet
experi
collect
result
combin
rank
loss
fair
term
4.3
fair
rank
perform
tabl
4.3
detail
perform
baselin
fair
rank
model
train
hing
exposur
propos
mcfr
outperform
baselin
model
fair
ness
metric
across
dataset
compar
listnet
lambdamart
model
like
deltr
mfr
fa
ir
autodebia
fairgbm
mcfr
show
enhanc
result
chapter
uniﬁ
meta-learn
framework
fair
rank
curriculum
learn
64
w3c
expert
engin
student
engin
gender
high
school
type
student
gender
precis
10
fair
kendal
tau
fair
kendal
tau
fair
listnet
17
0.178
0.759
0.390
1.070
0.384
0.858
lambdamart
16
0.095
0.738
0.355
1.002
0.326
0.907
deltr
89
0.180
0.827
0.391
1.075
0.370
0.976
fa
ir
pre
90
0.180
0.770
0.374
1.020
0.360
0.942
fa
ir
post
90
0.180
0.827
0.391
1.075
0.370
0.976
autodebia
20
0.033
0.829
0.372
0.955
0.372
0.955
fairgbm
27
0.087
0.941
0.338
0.909
0.336
0.892
mfr
0.126
0.830
0.391
1.086
0.352
1.052
mcfr
0.118
0.843
0.390
1.088
0.350
1.055
law
student
law
student
compa
gender
race
race
kendal
tau
fair
kendal
tau
fair
kendal
tau
fair
listnet
17
0.202
0.931
0.184
0.853
0.639
0.836
lambdamart
16
0.199
0.979
0.156
0.847
0.542
0.956
deltr
89
0.188
0.993
0.130
1.014
0.576
0.970
fa
ir
pre
90
0.203
0.931
0.161
0.895
0.557
1.039
fa
ir
post
90
0.182
0.965
0.140
0.944
0.557
1.040
autodebia
20
0.222
0.894
0.135
1.009
0.644
1.136
fairgbm
27
0.141
0.998
0.210
1.116
0.550
0.917
mfr
0.225
1.015
0.184
1.654
0.644
1.138
mcfr
0.225
1.023
0.182
1.671
0.644
1.144
tabl
4.3
experiment
result
hing
exposur
89
measur
fair
comput
exposur
ratio
protect
non-protect
group
valu
greater
1.0
indic
greater
visibl
protect
group
vice
versa
rank
metric
higher
kendal
tau
precis
10
10
score
indic
better
perform
bold
text
indic
model
best
perform
result
show
mcfr
model
better
fair
metric
compar
perform
rank
metric
state-of-the-art
model
due
inclus
fair
measur
train
notabl
mcfr
use
cur
riculum
sampl
meta-dataset
allow
surpass
mfr
fair
metric
meta-learn
adeptli
adjust
loss
distribut
mcfr
train
curricu
lum
sampl
creat
meta-dataset
meta
model
w3c
dataset
limit
item
protect
group
hinder
signiﬁc
distribut
shift
meta-dataset
sampl
aﬀect
rank
perform
constraint
primarili
contribut
chapter
uniﬁ
meta-learn
framework
fair
rank
curriculum
learn
65
decreas
rank
perform
observ
model
train
w3c
data
except
w3c
dataset
mcfr
competit
result
rank
metric
compar
baselin
model
indic
train
mcfr
focu
sole
fair
metric
listnet
result
also
expect
optim
rank
metric
better
perform
rank
metric
engin
stu
dent
gender
law
student
race
sinc
autodebia
fairgbm
tailor
recommend
classiﬁc
task
respect
limit
perform
rank
problem
expect
fig
4.1
also
plot
histogram
rank
protect
attribut
diﬀer
model
plot
can
see
distribut
predict
rank
shift
right
left
indic
mcfr
model
gener
rank
item
protect
group
higher
compar
listnet
mfr
plot
x-axi
indic
top
rank
candid
fall
bin
left
mean
candid
receiv
higher
rank
rank
algorithm
mcfr
en
hanc
visibl
underrepres
protect
group
howev
fair
doesn
mean
maxim
exposur
expens
non-protect
group
visibl
4.3
ablat
studi
present
ablat
studi
result
mcfr
oﬀer
ﬂexibl
choos
loss
function
fair
term
gener
framework
mcfr
consist
enhanc
rank
fair
metric
across
variou
loss
function
exposur
formu
la
employ
rankms
ranknet
listnet
repres
pointwis
pairwis
listwis
loss
serv
baselin
model
tabl
4.4
4.5
4.6
chapter
uniﬁ
meta-learn
framework
fair
rank
curriculum
learn
66
w3c
expert
engin
student
engin
exposur
gender
high
school
type
student
gender
type
precis
10
fair
kendal
tau
fair
kendal
tau
fair
rankms
0.121
0.770
0.187
0.800
0.376
0.836
mfr
hing
0.115
0.781
0.384
1.049
0.357
1.010
mcfr
hing
0.115
0.782
0.384
1.052
0.353
1.020
mfr
squar
0.115
0.780
0.384
1.045
0.360
0.982
mcfr
squar
0.115
0.782
0.384
1.045
0.360
0.990
law
student
law
student
compa
exposur
gender
race
race
type
kendal
tau
fair
kendal
tau
fair
kendal
tau
fair
rankms
0.213
0.874
0.190
0.847
0.493
0.768
mfr
hing
0.225
0.910
0.191
0.847
0.634
0.911
mcfr
hing
0.226
0.920
0.190
0.851
0.634
0.911
mfr
squar
0.223
1.010
0.139
0.992
0.633
0.911
mcfr
squar
0.225
1.023
0.138
0.996
0.630
0.928
tabl
4.4
ablat
studi
result
rankms
11
w3c
expert
engin
student
engin
exposur
gender
high
school
type
student
gender
type
precis
10
fair
kendal
tau
fair
kendal
tau
fair
ranknet
0.121
0.770
0.131
0.806
0.190
0.800
mfr
hing
0.121
0.774
0.126
0.925
0.188
0.810
mcfr
hing
0.123
0.775
0.131
0.867
0.186
0.820
mfr
squar
0.121
0.774
0.126
0.925
0.188
0.810
mcfr
squar
0.121
0.774
0.131
0.867
0.186
0.812
law
student
law
student
compa
exposur
gender
race
race
type
kendal
tau
fair
kendal
tau
fair
kendal
tau
fair
ranknet
0.093
0.942
0.105
0.866
0.128
0.768
mfr
hing
0.131
1.033
0.140
1.284
0.373
0.839
mcfr
hing
0.132
1.036
0.152
1.370
0.375
0.840
mfr
squar
0.173
1.033
0.105
0.866
0.352
0.832
mcfr
squar
0.220
1.050
0.105
0.866
0.352
0.832
tabl
4.5
ablat
studi
result
ranknet
15
4.3
3.1
rank
term
analysi
first
analyz
perform
mcfr
use
diﬀer
rank
term
loss
func
tion
use
listnet
mcfr
wors
rank
perform
w3c
expert
gender
engin
student
gender
dataset
listnet
model
dataset
mcfr
listnet
model
similar
rank
perform
note
law
student
gender
dataset
mcfr
also
improv
rank
metric
chapter
uniﬁ
meta-learn
framework
fair
rank
curriculum
learn
67
w3c
expert
engin
student
engin
exposur
gender
high
school
type
student
gender
type
precis
10
fair
kendal
tau
fair
kendal
tau
fair
listnet
0.178
0.759
0.390
1.070
0.384
0.858
mfr
hing
0.126
0.830
0.391
1.086
0.352
1.052
mcfr
hing
0.118
0.843
0.390
1.088
0.350
1.055
mfr
squar
0.118
0.803
0.330
1.005
0.358
1.006
mcfr
squar
0.118
0.803
0.341
1.005
0.342
1.018
law
student
law
student
compa
exposur
gender
race
race
type
kendal
tau
fair
kendal
tau
fair
kendal
tau
fair
listnet
0.202
0.931
0.184
0.853
0.639
0.836
mfr
hing
0.225
1.015
0.184
1.654
0.644
1.138
mcfr
hing
0.225
1.023
0.182
1.671
0.644
1.144
mfr
squar
0.223
1.010
0.113
1.166
0.340
0.828
mcfr
squar
0.225
1.014
0.079
1.115
0.632
1.068
tabl
4.6
ablat
studi
result
listnet
17
use
rankms
similar
pattern
observ
ranknet
mcfr
achiev
similar
rank
perform
w3c
expert
gender
dataset
improv
rank
metric
law
student
gender
law
student
race
dataset
addit
fair
metric
consist
improv
rank
metric
show
propos
mcfr
gener
framework
can
adapt
mani
rank
loss
function
4.3
3.2
fair
term
analysi
second
evalu
diﬀer
fair
term
loss
function
use
listnet
rank
loss
term
mcfr
greatli
improv
fair
metric
w3c
expert
gender
engin
student
gender
dataset
dataset
mcfr
perform
listnet
model
fair
metric
similar
rank
perform
use
rankms
mcfr
also
improv
fair
metric
law
student
chapter
uniﬁ
meta-learn
framework
fair
rank
curriculum
learn
68
gender
law
student
race
dataset
see
mcfr
can
improv
fair
metric
variou
rank
loss
term
4.3
3.3
curriculum
sampl
analysi
moreov
compar
perform
mcfr
mfr
show
eﬀect
curriculum
learn
use
diﬀer
loss
note
mfr
use
set
loss
function
mcfr
fair
comparison
use
hing
exposur
mcfr
usual
better
fair
perform
minor
trade-oﬀ
rank
metric
except
w3c
expert
gender
dataset
use
listnet
use
squar
exposur
except
law
student
race
dataset
mcfr
improv
rank
fair
metric
compar
mfr
result
demonstr
eﬀect
curriculum
learn
fair
rank
fair
rank
metric
gen
metric
gen
metric
race
metric
race
der
der
figur
4.4
evalu
result
down-sampl
experi
conduct
experi
law
student
gender
law
student
race
dataset
sampl
train
data
rate
0.1
0.9
result
show
mcfr
better
data
eﬃcienc
achiev
better
fair
metric
similar
rank
perform
mfr
autodebia
diﬀer
down-sampl
rate
chapter
uniﬁ
meta-learn
framework
fair
rank
curriculum
learn
69
4.3
3.4
data
eﬃcienc
assess
curriculum
learn
eﬀect
data
eﬃcienc
compar
mcfr
mfr
autodebia
use
down-sampl
train
data
vari
10
90
orig
inal
data
figur
4.4
illustr
mcfr
outperform
mfr
autodebia
across
sampl
rate
fair
gender-rel
data
achiev
fair
metric
close
1.0
maintain
high
rank
perform
mcfr
demonstr
superior
fair
ness
reduc
train
data
race-rel
data
mcfr
achiev
better
rank
perform
higher
fair
metric
indic
curriculum
strategi
eﬀect
enhanc
fair
protect
group
even
less
data
w3c
expert
engin
student
engin
law
student
law
student
compa
gender
high
school
type
student
gender
gender
race
race
deltr
43.69
14.09
40.92
14.35
17.70
19.67
mfr
21.16
15.24
17.24
51.29
49.72
76.88
mcfr
171.37
92.57
91.64
294.42
293.92
352.96
tabl
4.7
experiment
result
total
converg
time
second
show
total
converg
time
diﬀer
algorithm
deltr
mfr
mcfr
across
variou
dataset
scenario
base
tabl
mcfr
framework
gener
compar
converg
time
two
algorithm
4.3
3.5
train
infer
eﬃcienc
enhanc
rank
fair
mcfr
sought
balanc
fair
eﬃcienc
shown
tabl
4.7
mcfr
train
complex
compar
method
like
deltr
curriculum
sampl
extend
train
time
linearli
sampl
round
notabl
infer
mcfr
mfr
deltr
will
show
consist
eﬃcienc
sinc
algorithm
share
base
rank
model
number
paramet
layer
one
forward
pass
70
predict
tabl
4.7
show
mcfr
extend
converg
time
due
curriculum
sampl
ad
epoch
mcfr
fair
beneﬁt
clear
yet
valu
eﬃcienc
time-sensit
applic
overal
result
demonstr
curriculum
learn
mcfr
enhanc
fair
without
compromis
rank
perform
also
make
train
eﬃcient
4.4
conclus
studi
introduc
meta
curriculum-bas
fair
rank
mcfr
frame
work
address
data
bia
search
problem
employ
meta-learn
train
curriculum-learning-sampl
meta-dataset
approach
re-weight
train
loss
target
ranker
bias
data
re-weight
loss
aid
develop
unbias
rank
model
enhanc
exposur
minor
group
compar
ex
periment
real-world
dataset
conﬁrm
mcfr
superior
fair
rank
model
lack
meta-learn
curriculum
learn
compon
chapter
empir
studi
fair
llm
ranker
5.1
introduct
emerg
larg
languag
model
llm
like
gpt
model
12
57
llama2
76
mark
signiﬁc
trend
multipl
ﬁeld
rang
natur
languag
process
inform
retriev
rank
challeng
llm
shown
demonstr
perform
research
exempliﬁ
project
like
rankgpt
73
65
highlight
proﬁcienc
gpt
model
deliv
competit
rank
result
surpass
tradi
tional
neural
rank
model
precis
relev
grow
popular
llm
assess
fair
becom
crucial
evalu
eﬀect
71
chapter
empir
studi
fair
llm
ranker
72
search
queri
agricultur
rank
passag
base
relev
search
queri
hana
meisel
femal
agronomist
thoma
gile
male
pastoralist
theodor
bergmann
male
agronomist
thoma
gile
male
pastoralist
theodor
bergmann
male
agronomist
hana
meisel
femal
agronomist
listwis
evalu
search
queri
agricultur
rank
two
passag
base
relev
search
queri
hana
meisel
femal
agronomist
thoma
gile
male
pastoralist
thoma
gile
male
pastoralist
hana
meisel
femal
agronomist
pairwis
evalu
figur
5.1
illustr
two
evalu
method
listwis
evalu
pairwis
evalu
document
associ
binari
protect
attribut
use
fair
evalu
metric
recent
research
primarili
concentr
eﬃcienc
accuraci
llm
rank
task
increas
concern
fair
concern
particularli
highlight
given
signiﬁc
impact
easi
accessi
biliti
model
prior
studi
natur
languag
process
41
62
rec
ommend
system
95
shown
unfair
treatment
toward
underrepres
group
llm
although
fair
issu
tradit
search
engin
ex
tensiv
explor
notabl
gap
examin
llm
ranker
search
system
studi
seek
address
gap
conduct
in-depth
audit
variou
llm
includ
gpt
model
open-sourc
altern
work
conduct
empir
studi
assess
llm
text
ranker
user
item
perspect
evalu
fair
investig
chapter
empir
studi
fair
llm
ranker
73
model
despit
train
vast
vari
dataset
might
unintent
alli
mirror
social
bias
rank
outcom
concentr
variou
binari
protect
attribut
frequent
underrepres
search
result
examin
llm
rank
document
associ
attribut
respons
divers
user
queri
speciﬁc
examin
llm
use
listwis
pairwis
evalua
tion
method
aim
provid
comprehens
studi
fair
model
furthermor
mitig
pairwis
fair
issu
ﬁne-tun
llm
unbias
dataset
experiment
result
show
improv
evalu
best
knowledg
work
present
ﬁrst
benchmark
result
investig
fair
issu
llm
ranker
summari
work
make
contribut
follow
build
ﬁrst
llm
fair
rank
benchmark
llm
text
ranker
incorpor
listwis
pairwis
evalu
method
consider
binari
protect
attribut
conduct
extens
comprehens
experi
reveal
fair
prob
lem
llm
real-word
dataset
propos
mitig
strategi
involv
ﬁne-tun
open-sourc
llm
use
lora
40
address
fair
issu
observ
pairwis
evalu
chapter
empir
studi
fair
llm
ranker
74
listwis
rank
gpt-3
gpt-4
mistral
rank
rank
rank
rank
rank
rank
protect
group
unprotect
group
llama2
util
group
exposur
pairwis
rank
gpt-3
gpt-4
item
rank
higher
llm
mistral
llama2
percentag
unprotect
group
figur
5.2
propos
evalu
framework
schemat
diagram
repres
dual
evalu
methodolog
top
sequenc
depict
listwis
rank
process
item
protect
unprotect
group
present
variou
llm
gpt-3
gpt-4
mistral-7b
llama2
evalu
util
group
exposur
metric
bottom
sequenc
illustr
pairwis
rank
approach
contrast
rank
prefer
llm
item
protect
unprotect
group
quantifi
bia
percentag
unprotect
group
item
rank
higher
5.2
llm
fair
rank
deﬁn
set
queri
dataset
consist
queri
set
item
compris
item
queri
exist
list
item
candid
repres
i-th
query-item
pair
text
token
vector
xi
associ
relev
score
yi
importantli
item
candid
annot
binari
attribut
indic
classiﬁc
either
belong
protect
group
non-protect
group
attribut
repres
aspect
like
gender
race
crucial
highlight
potenti
exposur
bia
present
rank
predict
process
next
present
evalu
benchmark
dataset
introduc
two
fair
evalu
method
listwis
pairwis
evalu
chapter
empir
studi
fair
llm
ranker
75
5.2
dataset
benchmark
leverag
dataset
trec
fair
rank
track
29
year
2021
2022
primarili
focu
task
wikiproject
coordin
search
relev
articl
2022
dataset
contain
44
queri
2021
dataset
57
queri
select
200
item
english
wikipedia
ap
pli
deltr
89
experi
methodolog
introduc
discriminatori
pattern
sort
candid
categor
four
group
expert
non-protect
group
expert
protect
group
non-expert
non-protect
group
non-expert
protect
group
speciﬁc
expert
deﬁn
relev
candid
given
queri
non-expert
irrelev
candid
randomli
select
relev
candid
queri
bench
mark
includ
three
dataset
diﬀerenti
protect
group
trec
2022
gender
femal
consid
protect
group
male
non-protect
trec
2022
locat
trec
2021
locat
non-european
design
protect
group
european
serv
non-protect
group
5.2
listwis
evalu
listwis
evalu
assess
fair
two
perspect
query-sid
item
side
focus
attribut
like
gender
measur
well
llm
integr
repres
group
rank
use
group
fair
visibl
precis
chapter
empir
studi
fair
llm
ranker
76
util
query-sid
analysi
check
bias
protect
attribut
contrast
ing
gender-neutr
gender-sensit
queri
verifi
consist
rank
across
group
method
togeth
ensur
thorough
fair
evalu
llm
rank
5.2
2.1
data
construct
fair
evalu
dataset
leverag
rankgpt
73
approach
standard
prompt
templat
captur
user
instruct
detail
prefer
task
detail
dataset
incorpor
item-sid
protect
group
introduc
neutral
sensit
queri
templat
former
without
demograph
marker
latter
includ
speciﬁc
refer
attribut
like
gender
geographi
queri
side
fair
assess
speciﬁc
templat
neutral
sensit
instruct
follow
neutral
search
system
wikiproject
coordin
user
goal
search
relev
articl
produc
rank
list
articl
need
work
editor
can
consult
look
work
search
queri
queri
rank
passag
base
relev
search
queri
item
d1
dn
sensit
search
system
query-sid
sensit
attribut
wikipro
ject
coordin
user
goal
search
relev
articl
produc
rank
list
articl
need
work
editor
can
consult
look
chapter
empir
studi
fair
llm
ranker
77
work
search
queri
queri
rank
passag
base
relev
search
queri
item
d1
dn
5.2
2.2
metric
group
exposur
ratio
listwis
fair
evalu
deﬁn
two
group
candid
within
non-protect
group
g0
protect
group
g1
latter
repres
histor
discrimin
group
femal
non-european
often
underrepres
dataset
follow
methodolog
introduc
singh
joachim
70
measur
exposur
candid
repres
text
token
xi
rank
list
gener
probabilist
rank
model
express
exposur
xi
pi
va
5.1
pi
probabl
place
document
rank
va
repres
posit
bia
posit
va
log
follow
zehlik
castillo
89
focu
posit
bia
top
posit
v1
averag
exposur
candid
group
exposur
exposur
xi
5.2
xi
exposur
final
deﬁn
group
exposur
ratio
exposur
g1
ratio
closer
1.0
indic
fairer
rank
list
chapter
empir
studi
fair
llm
ranker
78
5.2
pairwis
evalu
pairwis
evalu
method
delv
item-sid
fair
present
pair
item
llm
one
protect
group
one
non-protect
group
method
includ
two
distinct
task
relev
item
comparison
provid
llm
pair
randomli
select
relev
item
prompt
determin
item
relev
fair
assess
hing
balanc
number
item
recogn
relev
group
nearli
equal
count
signiﬁ
fair
indic
unbias
relev
assess
fair
quantiﬁ
ratio
recogn
relev
group
ratio
close
1.0
signal
greater
fair
irrelev
item
comparison
similarli
present
pair
irrelev
item
follow
procedur
scenario
fair
llm
exhibit
similar
indiﬀ
enc
irrelev
item
group
reﬂect
ratio
approach
1.0
pairwis
evalu
employ
detect
bias
llm
rank
toward
protect
unprotect
group
directli
contrast
item
vari
group
method
uncov
potenti
group
prefer
within
llm
oﬀer
clear
view
fair
diﬀer
rank
scenario
chapter
empir
studi
fair
llm
ranker
79
5.2
3.1
data
construct
pairwis
evalu
use
ﬁxed
prompt
templat
pair
relev
irrel
evant
item
contain
one
protect
group
one
unprotect
group
mitig
posit
bia
two
item
pair
queri
twice
order
protect
unprotect
item
altern
speciﬁc
templat
follow
search
system
wikiproject
coordin
user
goal
search
relev
articl
produc
rank
list
articl
need
work
editor
can
consult
look
work
rank
two
passag
base
relev
queri
queri
item
d1
d2
5.2
3.2
metric
pairwis
evalu
metric
calcul
proport
time
item
protect
unprotect
group
rank
ﬁrst
addit
comput
ratio
number
time
protect
group
item
rank
ﬁrst
number
time
unprotect
group
item
rank
ﬁrst
ratio
near
1.0
indic
higher
fair
5.3
result
analysi
benchmark
care
evalu
popular
llm
includ
gpt-3
gpt-4
llama2-13b
mistral-7b
44
section
detail
analysi
perform
chapter
empir
studi
fair
llm
ranker
80
across
listwis
pairwis
evalu
5.3
0.1
eﬀect
window
step
size
window
step
20
fair
0.1261
0.9881
10
0.1295
0.9634
10
0.1227
0.9777
20
10
0.1205
0.9628
tabl
5.1
evalu
result
diﬀer
choic
window
step
size
re
sult
show
signiﬁc
diﬀer
rank
fair
metric
select
window
size
step
size
listwis
evalu
experi
shown
tabl
5.1
conduct
addit
experi
evalu
diﬀer
set
window
size
step
size
experi
conduct
listwis
evalu
2022
gender
dataset
neutral
queri
use
mistral-7b
model
set
window
size
rang
20
step
size
10
follow
slide
window
strategi
provid
rankgpt
73
empir
observ
signiﬁc
diﬀer
rank
fair
metric
thu
adopt
small
win
dow
step
size
window
size
step
size
account
less
gpu
memori
save
comput
resourc
5.3
listwis
evalu
result
listwis
evalu
adopt
rankgpt
methodolog
use
slide
window
strategi
extract
rank
list
llm
use
window
size
step
size
across
test
llm
given
model
train
chapter
empir
studi
fair
llm
ranker
81
trec
2022
gender
trec
2022
locat
trec
2021
locat
figur
5.3
predict
rank
distribut
protect
group
trec
dataset
use
listwis
evalu
plot
reveal
rank
variabl
po
tential
bias
gender
geograph
attribut
highlight
area
improv
fair
across
llm
extens
internet
corpora
trec
dataset
deriv
wikipedia
input
wikipedia
page
titl
approach
leverag
llm
inher
knowledg
base
topic
addit
includ
two
neural
ranker
monot5
56
monobert
55
baselin
model
unlik
llm
use
full
text
wikipedia
webpag
input
neural
ranker
chapter
empir
studi
fair
llm
ranker
82
queri
attribut
neutral
male
femal
metric
20
fair
20
fair
20
fair
monot5
0.1852
0.9964
0.0830
0.7809
0.5239
1.9402
monobert
0.1761
0.9559
0.1000
0.8101
0.5102
1.7475
gpt-3
0.1227
0.9919
0.0841
0.9463
0.1705
1.2186
gpt-4
0.1239
0.9955
0.1080
0.9504
0.1761
1.2576
mistral-7b
0.1261
0.9881
0.0966
0.9382
0.2102
1.4879
llama2-13b
0.1216
1.0304
0.0920
0.9661
0.1614
1.2550
trec
2022
gender
queri
attribut
neutral
european
non-european
metric
20
fair
20
fair
20
fair
monot5
0.2110
0.9739
0.2800
0.8543
0.0180
1.4682
monobert
0.1980
1.0031
0.2860
0.8890
0.0370
1.3201
gpt-3
0.1440
0.9308
0.1500
0.8846
0.1480
0.9368
gpt-4
0.1240
0.9268
0.1510
0.8889
0.1420
0.9432
mistral-7b
0.1230
0.9426
0.1490
0.8895
0.0930
1.1073
llama2-13b
0.1280
0.9607
0.1340
0.9130
0.1030
1.0227
trec
2022
locat
queri
attribut
neutral
european
non-european
metric
20
fair
20
fair
20
fair
monot5
0.2018
1.0406
0.3035
0.8483
0.0158
1.5039
monobert
0.1974
1.0340
0.2658
0.9254
0.0728
1.3143
gpt-3
0.1184
0.9820
0.1421
0.9173
0.1228
0.9841
gpt-4
0.1167
0.9850
0.1544
0.9071
0.1325
0.9877
mistral-7b
0.1430
0.9856
0.1614
0.9142
0.0684
1.1448
llama2-13b
0.1211
0.9634
0.1105
0.9247
0.1105
1.0325
trec
2021
locat
tabl
5.2
listwis
evalu
result
measur
fair
comput
exposur
ratio
protect
non-protect
group
valu
closer
1.0
indic
greater
visibl
protect
group
vice
versa
rank
metric
higher
precis
10
10
score
indic
better
perform
5.3
1.1
item-sid
analysi
tabl
5.2
monot5
monobert
exhibit
robust
precis
20
score
reﬂect
eﬀect
rank
howev
fair
metric
reveal
gap
equit
gender
represent
monot5
slightli
outperform
monobert
front
chapter
empir
studi
fair
llm
ranker
83
perform
discrep
like
model
util
complet
text
wikipedia
page
provid
wealth
featur
repres
item
com
prehens
hand
llm
face
constraint
due
maximum
token
limit
input
limit
capac
fulli
exploit
extens
textual
inform
avail
trec
dataset
therebi
impact
rank
capabl
among
llm
includ
gpt-3
gpt-4
mistral-7b
llama2-13b
preci
sion
20
score
compar
lower
neural
rank
model
may
reﬂect
gener
model
broader
focu
beyond
just
rank
task
fair
metric
llm
vari
gpt-3
gpt-4
manag
stay
closer
ideal
fair
ratio
indic
balanc
treatment
gender
group
mistral-7b
maintain
similar
precis
fall
behind
fair
indic
potenti
gen
der
bia
rank
llama2-13b
although
consist
approach
fair
reveal
room
improv
precis
contrast
neural
ranker
llm
becom
appar
although
neu
ral
ranker
demonstr
higher
precis
necessarili
outperform
llm
term
fair
observ
underscor
import
consid
fair
particularli
user
priorit
precis
speciﬁc
applic
within
llm
group
uniform
achiev
fair
suggest
model
train
design
inher
bias
may
inﬂuenc
abil
rank
fairli
chapter
empir
studi
fair
llm
ranker
84
5.3
1.2
query-sid
analysi
analyz
query-sid
fair
tabl
5.2
focu
whether
llm
provid
similar
rank
perform
diﬀer
queri
attribut
male
vs
femal
european
vs
non-european
reveal
consist
trend
across
neural
rank
model
llm
tend
favor
femal
european
queri
male
non-european
one
fair
metric
llm
like
gpt-3
gpt-4
mistral-7b
llama2-13b
rel
close
indic
attempt
balanc
treatment
precis
20
score
suggest
diﬀer
stori
clear
skew
toward
femal
european
queri
observ
pattern
evid
monot5
monobert
point
underli
bia
persist
despit
eﬀort
achiev
equit
treatment
across
queri
attribut
underscor
need
enhanc
model
train
fair
optim
figur
5.3
plot
predict
rank
protect
group
highlight
di
tinct
pattern
fair
rank
perform
neural
ranker
llm
llm
demonstr
tighter
rank
distribut
exhibit
bias
toward
certain
queri
attribut
exampl
dispar
observ
treatment
gender
geo
graphic
attribut
monot5
monobert
often
rank
femal
euro
pean
queri
favor
trend
also
note
vari
degre
within
llm
suggest
neural
ranker
may
excel
precis
llm
oﬀer
consist
rank
though
neither
group
devoid
fair
issu
ﬁnding
emphas
necess
tune
bia
mitig
neural
ranker
llm
chapter
empir
studi
fair
llm
ranker
85
ensur
equit
treatment
across
queri
attribut
5.3
pairwis
evalu
result
relev
item
irrelev
item
unprotect
protect
ratio
unprotect
protect
ratio
gpt-3
0.2407
0.2453
1.0190
0.1797
0.2979
1.6580
gpt-4
0.2275
0.2496
1.0971
0.2033
0.2939
1.4430
mistral-7b
0.2366
0.0995
0.4206
0.1335
0.1160
0.8689
llama2-13b
0.1227
0.2293
1.8694
0.0920
0.2913
3.1643
trec
2022
gender
femal
protect
group
male
non-protect
relev
item
irrelev
item
unprotect
protect
ratio
unprotect
protect
ratio
gpt-3
0.2638
0.2537
0.9615
0.3199
0.2245
0.7500
gpt-4
0.2347
0.2878
1.2262
0.2759
0.2401
0.8701
mistral-7b
0.2484
0.4168
1.6779
0.1876
0.1928
1.0277
llama2-13b
0.1521
0.2290
1.5052
0.2444
0.1643
0.6725
trec
2022
locat
non-european
protect
european
non-protect
relev
item
irrelev
item
unprotect
protect
ratio
unprotect
protect
ratio
gpt-3
0.2117
0.3150
1.4877
0.2385
0.2616
1.0968
gpt-4
0.2148
0.3125
1.4545
0.2428
0.2598
1.0701
mistral-7b
0.2582
0.4137
1.6019
0.2516
0.1628
0.6471
llama2-13b
0.1490
0.2688
1.8035
0.2540
0.1752
0.6898
trec
2021
locat
non-european
protect
european
non-protect
tabl
5.3
pairwis
evalu
result
tabl
display
fair
metric
llm
rank
relev
irrelev
item
pair
one
protect
unprotect
group
includ
percentag
item
rank
ﬁrst
group
ratio
reﬂect
fair
vari
level
fair
across
llm
particularli
irrelev
pair
highlight
import
enhanc
fair
llm
pairwis
evalu
detail
tabl
5.3
focu
assess
fair
variou
llm
studi
rank
pair
item
consid
relev
irrelev
analysi
aim
reveal
whether
model
display
bias
toward
item
speciﬁc
group
gpt-3
consist
show
prefer
femal
item
scenario
inclin
pronounc
irrelev
item
chapter
empir
studi
fair
llm
ranker
86
suggest
bia
favor
femal
item
similarli
gpt-4
display
moder
bia
toward
femal
item
ratio
indic
stronger
bia
irrelev
context
observ
trend
across
model
dataset
signal
area
improv
point
need
balanc
algorithm
favor
one
group
anoth
particularli
situat
item
relev
neutral
contrastingli
mistral-7b
show
distinct
bia
toward
male
item
relev
pair
notabl
trec
2022
gender
dataset
rais
question
model
decis
make
process
suggest
algorithm
may
weigh
male
item
heavili
relev
howev
bia
diminish
irrelev
pair
indic
diﬀer
algorithm
behavior
context
llama2-13b
hand
present
signiﬁc
bia
toward
femal
item
across
dataset
relev
irrelev
pair
concern
overal
fair
overal
llm
show
nuanc
bias
other
like
llama2-13b
requir
intervent
ensur
fair
equit
treatment
across
group
attribut
5.3
overal
evalu
overal
analyz
listwis
pairwis
evalu
result
tabl
5.2
tabl
5.3
observ
complex
pictur
fair
listwis
evalu
base
group
exposur
ratio
suggest
fair
represent
diﬀer
group
pairwis
evalu
reveal
unfair
llm
inconsist
particularli
evid
chapter
empir
studi
fair
llm
ranker
87
llm
rank
pair
relev
irrelev
item
protect
unprotect
group
5.4
enhanc
fair
lora
percentag
protect
vs
unprotect
group
item
rank
ﬁrst
across
diﬀer
trec
dataset
ratio
protect
unprotect
group
across
diﬀer
trec
dataset
figur
5.4
impact
lora
fine-tun
mistral-7b
fair
figur
show
percentag
ﬁrst-rank
item
protect
unprotect
group
figur
demonstr
result
fair
ratio
lora-adjust
model
yield
ratio
closer
ideal
fair
benchmark
1.0
across
trec
dataset
employ
lora
40
ﬁne-tun
mistral-7b
model
approach
involv
creat
balanc
train
dataset
equal
represent
respons
protect
unprotect
group
balanc
dataset
aim
steer
model
toward
fairer
rank
evalu
pair
relev
irrelev
item
divers
group
implement
lora
modul
facilit
use
peft
53
packag
align
parameter-eﬃci
methodolog
outlin
origin
lora
studi
speciﬁc
focus
adapt
attent
weight
simplifi
enhanc
parameter-eﬃci
opt
freez
paramet
case
set
optim
rank
deem
low-rank
adapt
matrix
adequ
chosen
88
learn
rate
0.003
batch
size
set
conﬁgur
select
base
consider
speciﬁc
studi
dataset
compris
approxim
140
000
item
pair
randomli
sampl
trec
dataset
facilit
comprehens
train
process
conduct
nvidia
a100
80gb
need
approxim
30
hour
split
queri
train
test
use
80
train
remain
20
test
result
ﬁne-tun
mistral-7b
lora
illustr
figur
5.4
post
tune
notic
reduct
consist
respons
model
queri
twice
revers
item
order
indic
increas
respons
variabil
iti
posit
indic
fair
less
predict
respons
can
miti
gate
systemat
bia
improv
fair
support
figur
4b
outcom
post-lora
ﬁne-tun
show
ratio
approach
1.0
indic
equit
treatment
protect
unprotect
group
model
5.5
conclus
conclus
in-depth
analysi
reveal
intric
bias
present
larg
lan
guag
model
evalu
fair
listwis
pairwis
method
listwis
evalu
paint
pictur
rel
fair
deeper
investig
via
pair
wise
evalu
uncov
subtler
profound
bias
often
favor
certain
protect
group
implement
lora
ﬁne-tun
mistral-7b
model
89
yield
encourag
stride
toward
rectifi
bias
demonstr
enhanc
fair
model
output
chapter
empir
studi
select
bia
pinterest
ad
retriev
6.1
introduct
pinterest
visual
discoveri
platform
allow
user
discov
save
idea
variou
interest
fashion
home
decor
travel
becom
popular
destin
user
search
discov
new
product
idea
inspir
result
also
becom
attract
advertis
platform
busi
look
reach
engag
target
audienc
support
grow
demand
onlin
advertis
pinterest
develop
large-scal
advertis
serv
platform
use
multi-cascad
rank
system
51
deliv
relev
ad
user
90
chapter
empir
studi
select
bia
pinterest
ad
retriev
91
ad
ad
request
inventori
ad
target
ad
retriev
ad
rank
auction
auction
winner
pinterest
app
ad
deliveri
stack
figur
6.1
life
cycl
onlin
ad
deliveri
high
level
ad
request
trigger
user
open
pinterest
app
start
new
session
ad
request
will
sent
ad
deliveri
system
queri
dozen
ad
ad
deliveri
backend
ad
candid
inventori
will
ﬂow
variou
stage
like
target
retriev
rank
auction
send
auction
winner
back
mobil
app
select
ad
will
visibl
user
like
mani
onlin
advertis
platform
multi-cascad
recommend
sy
tem
contain
sever
stage
ﬁlter
rank
ad
base
variou
busi
logic
model
signal
shown
figur
6.1
typic
ad
serv
system
four
main
stage
ad
target
ad
retriev
ad
rank
ad
auction
ad
target
ﬁrst
stage
stage
select
ad
meet
target
criterion
preset
advertis
ad
retriev
second
stage
right
ad
target
stage
variou
mechan
includ
retriev
model
model
use
retriev
stage
use
select
smaller
subset
ad
candid
million
candid
receiv
target
stage
select
ad
candid
pass
ad
rank
stage
comprehens
score
rank
chapter
empir
studi
select
bia
pinterest
ad
retriev
92
ad
rank
stage
set
sophist
model
develop
accur
score
speciﬁc
object
ctr
cvr
relev
etc
ad
candid
select
retriev
stage
model
predict
stage
will
directli
impact
mani
key
aspect
qualiti
deliv
ad
result
stage
abl
score
limit
number
ad
candid
spend
much
allot
time
budget
score
ad
candid
use
complex
perform
model
ensur
predict
accuraci
ad
auction
last
stage
serv
stack
main
object
make
ﬁnal
decis
auction
candid
whether
candid
deliv
user
posit
target
surfac
candid
insert
afterward
win
candid
will
deliv
user
devic
insert
correspond
posit
user
will
see
ad
respond
ad
variou
user
action
discuss
ad
retriev
second
stage
deliveri
system
respons
retriev
valuabl
ad
larg
set
ad
candid
queri
goal
stage
retriev
relev
ad
also
minim
number
irrelev
low-qual
one
requir
use
machin
learn
model
can
eﬃcient
predict
relev
qualiti
ad
candid
base
varieti
featur
signal
diﬃcult
problem
retriev
stage
eﬃcient
fulﬁll
mission
due
sever
key
challeng
chapter
empir
studi
select
bia
pinterest
ad
retriev
93
select
subset
candid
high
qualiti
avoid
wast
capac
expens
full
ad
rank
low
qualiti
ad
size
select
candid
small
enough
subsequ
com
prehens
rank
ad
rank
stage
can
handl
ad
candid
retriev
model
requir
score
rank
post
target
ad
candid
order
million
retriev
model
will
access
lot
ml
signal
especi
ex
pensiv
real-tim
one
will
also
abl
leverag
sophist
model
architectur
due
scalabl
consider
discuss
previou
point
result
build
perform
retriev
model
constraint
challeng
ing
problem
machin
learn
domain
current
retriev
model
ad
platform
use
two-tow
model
architectur
propos
covington
et
al
25
among
challeng
associ
retriev
model
develop
optimiza
tion
select
bia
train
data
long-last
problem
impair
perform
model
work
focu
issu
data
select
bia
ad
retriev
stage
pinterest
multi-cascad
ad
rank
system
train
data
use
train
model
reﬂect
real
user
prefer
also
includ
product
model
person
recommend
mean
train
data
repres
overal
popul
advertis
can
lead
inaccur
result
chapter
empir
studi
select
bia
pinterest
ad
retriev
94
addit
distribut
discrep
train
data
observ
user
action
true
label
infer
data
compos
ad
candid
target
stage
can
impact
model
perform
address
data
select
bia
ad
retriev
funnel
ﬁrst
investig
data
distribut
across
variou
type
ad
candid
dataset
assess
var
iou
ml
techniqu
includ
unsupervis
domain
adapt
uda
83
improv
perform
retriev
model
number
ad
candid
real
user
action
small
will
beneﬁci
model
train
leverag
unlabel
ad
candid
data
particularli
one
similar
distribut
infer
data
one
diﬃculti
model
train
strategi
determin
eﬀect
use
unlabel
data
point
consist
distribut
compar
model
infer
data
work
leverag
variou
state-of-the-art
sota
method
incorpor
unlabel
data
train
retriev
model
addit
develop
modiﬁ
version
uda
muda
improv
perform
naiv
im
plement
uda
retriev
model
train
onlin
experiment
result
show
coupl
method
potenti
improv
perform
ad
rank
system
compar
knowledg
distil
model
current
product
environ
method
thu
contribut
summar
follow
identiﬁ
character
select
bia
issu
upper
funnel
multi-cascad
advertis
recommend
system
chapter
empir
studi
select
bia
pinterest
ad
retriev
95
survey
seri
sota
model
strategi
evalu
perform
oﬄin
onlin
set
propos
modiﬁ
version
unsupervis
domain
adapt
muda
provid
best
onlin
perform
among
model
strate
gie
examin
onlin
experi
show
muda
also
outper
form
current
product
model
post-target
retriev
post-retriev
auction
auction
ad
inventori
candid
model
candid
candid
winner
target
rank
auction
filter
train
pipelin
train
data
figur
6.2
distribut
featur
label
across
three
ad
dataset
relat
retriev
model
show
ﬂow
major
ad
candid
along
ad
deliveri
funnel
show
distribut
empir
vtcvr
one
key
retriev
model
featur
across
three
dataset
retriev
train
serv
show
distribu
tion
empir
good
click
rate
one
key
retriev
model
featur
across
three
dataset
retriev
train
serv
show
distribut
rank
model
predict
use
pseudo
label
retriev
model
train
across
three
dataset
note
exact
valu
x-ax
hidden
conﬁdenti
reason
chapter
empir
studi
select
bia
pinterest
ad
retriev
96
6.2
bia
pinterest
ad
illustr
figur
6.1
pinterest
ad
serv
system
consist
four
stage
ad
target
ad
retriev
ad
rank
ad
auction
stage
score
ﬁlter
ad
candid
base
request
ad
content
featur
given
ad
request
ad
retriev
narrow
million
ad
candid
coupl
thousand
candid
sent
ad
rank
accur
predict
user
action
well
ﬁltere
final
run
ad
auction
survivor
determin
auction
winner
base
predeﬁn
util
function
advertis
bid
retriev
stage
latenc
limit
crucial
larg
number
ad
candid
databas
adopt
two-tow
dnn
structur
25
candid
embed
comput
oﬄin
serv
model
will
produc
score
ad
candid
calcul
dot-product
precomput
candid
embed
queri
embed
comput
on-the-ﬂi
request
6.2
dataset
train
pipelin
mention
earlier
ad
serv
system
consist
target
retriev
rank
auction
shown
ﬁgure
2a
million
candid
ad
inventori
will
ﬂow
variou
stage
across
ad
deliveri
funnel
small
set
valuabl
ad
will
surviv
deliv
user
speciﬁc
initi
ad
inventori
candid
will
select
ad
target
reﬁn
set
ad
candid
chapter
empir
studi
select
bia
pinterest
ad
retriev
97
post-target
candid
will
score
rank
retriev
model
select
retriev
model
survivor
post-retriev
candid
will
ﬁltere
select
variou
busi
logic
model
rank
stage
lead
new
set
ad
candid
auction
candid
will
evalu
auction
stage
auction
stage
will
pick
dozen
winner
auction
candid
deliv
ﬁnal
survivor
auction
winner
pinterest
user
exist
retriev
model
two
type
train
data
collect
auction
candid
auction
winner
latter
dataset
includ
observ
user
action
true
label
former
one
includ
rank
model
predict
pseudo
label
rank
model
predict
use
auction
stage
determin
win
ad
auction
candid
pool
current
use
rank
model
predict
pseudo
label
train
retriev
model
aim
maxim
funnel
eﬃcienc
deliv
valuabl
ad
candid
pinterest
user
ensur
model
fresh
retriev
model
continu
train
evalu
daili
basi
speciﬁc
model
snapshot
train
day
data
load
train
day
data
newli
train
model
evalu
day
data
daili
train
setup
enabl
model
captur
recent
pattern
keep
respons
new
trend
second-day
evalu
allow
detect
possibl
overﬁt
abnorm
behavior
serv
product
traﬃc
chapter
empir
studi
select
bia
pinterest
ad
retriev
98
6.2
select
bia
mention
retriev
model
current
train
auction
candid
auction
winner
rank
model
predict
use
pseudo
label
setup
inevit
introduc
data
select
bia
particularli
inconsi
tenci
dataset
train
serv
79
serv
time
howev
model
need
make
predict
post-target
ad
candid
auction
can
didat
winner
small
subset
post-target
candid
gener
variou
busi
logic
rank
model
distribut
dataset
will
inconsist
model
train
serv
figur
2a
illustr
concept
inconsist
ad
dataset
use
train
inferenc
cycl
retriev
model
demonstr
bia
analyz
distribut
pseudo
label
two
import
retriev
model
featur
across
three
diﬀer
dataset
post-target
candid
auction
candid
auction
winner
figur
2b
2c
2d
demonstr
distribut
diﬀer
across
three
dataset
distribut
diﬀer
much
signiﬁc
tween
two
dataset
use
current
retriev
model
train
one
use
retriev
model
serv
simplic
rest
work
will
interchang
use
follow
term
post-target
candid
serv
dataset
retriev
model
unbias
dataset
chapter
empir
studi
select
bia
pinterest
ad
retriev
99
6.2
problem
formul
simplic
repres
data
record
tupl
three
element
featur
request
contain
user
proﬁl
featur
context
featur
search
term
search
surfac
advertis
candid
featur
groundtruth
label
observ
user
action
addit
let
repres
distribut
request
featur
advertis
fea
ture
inventori
repres
full
distribut
request
ad
candid
pair
final
let
fθ
repres
model
trainabl
paramet
loss
function
want
minim
model
map
request
candid
featur
numer
valu
function
map
two
numer
valu
scalar
loss
valu
ideal
want
minim
train
loss
unbias
data
min
lideal
fθ
fθ
6.1
realiti
imposs
calcul
loss
function
unbias
dataset
true
label
avail
result
leverag
bias
dataset
chapter
empir
studi
select
bia
pinterest
ad
retriev
100
whose
true
label
avail
us
next
section
will
describ
seri
method
use
bias
unbias
dataset
build
model
score
post-target
ad
candid
system
6.3
solut
6.3
naiv
method
binari
classiﬁc
naiv
method
train
simpl
classiﬁc
model
common
way
train
click
classiﬁc
model
base
dataset
observ
user
action
one
user
click
treat
posit
exampl
one
click
treat
neg
naiv
method
will
optim
follow
loss
function
min
lnaiv
fθ
fθ
6.2
dataset
denot
set
request
auction
winner
pair
observ
user
action
6.3
in-batch
neg
classiﬁc
similar
naiv
classiﬁc
method
will
build
classiﬁc
model
base
bias
dataset
observ
user
action
true
label
real-world
chapter
empir
studi
select
bia
pinterest
ad
retriev
101
advertis
system
view
ad
without
user
click
necessarili
reliabl
neg
ativ
exampl
user
still
ﬁnd
ad
valuabl
even
take
action
moment
diﬀer
naiv
classiﬁc
method
gener
neg
exampl
introduc
ad
candid
request
train
batch
current
request
follow
common
setup
35
45
84
85
speciﬁc
deliv
ad
user
click
includ
train
data
click
ad
diﬀer
request
batch
treat
neg
exampl
6.3
knowledg
distil
rank
model
train
complex
architectur
numer
input
featur
contrast
retriev
model
limit
architectur
two-tow
dnn
well
avail
featur
due
demand
requir
scalabl
low
serv
latenc
minim
perform
loss
knowledg
distil
kd
37
adopt
mean
retriev
model
train
rank
model
predict
pseudo
label
formal
denot
rank
model
optim
follow
loss
function
min
lkd
fθ
fθ
6.3
6.3
transfer
learn
core
idea
transfer
learn
train
model
sourc
domain
data
ﬁne
tune
part
paramet
target
domain
particularli
dnn
model
chapter
empir
studi
select
bia
pinterest
ad
retriev
102
earli
layer
usual
ﬁxed
ﬁne
tune
shown
repres
primit
gener
featur
59
case
retriev
model
two-tow
dnn
data
distribut
discrep
across
diﬀer
dataset
ad
candid
result
use
unbias
data
ﬁne
tune
ad
embed
tower
keep
queri
tower
unchang
6.3
adversari
regular
anoth
view
bia
issu
represent
learn
bias
data
gener
enough
appli
unbias
dataset
lead
perform
degra
dation
can
therefor
add
regular
learn
intermedi
output
model
inform
indic
data
sourc
techniqu
known
adversari
adv
learn
36
dnn
model
can
split
two
part
former
one
take
raw
input
give
intermedi
output
latter
one
take
intermedi
output
give
ﬁnal
predict
adversari
regular
train
data
sourc
classiﬁ
intermedi
output
neg
whose
loss
function
ad
origin
one
regular
formal
let
f1
f2
denot
two
part
dnn
denot
classiﬁ
loss
function
data
sourc
classiﬁ
deﬁn
equat
6.4
lcl
log
f1
log
f1
6.4
chapter
empir
studi
select
bia
pinterest
ad
retriev
103
ﬁnal
loss
function
adversari
regular
shown
equat
6.5
ladv
ltarget
f2
f1
λlcl
6.5
ltarget
origin
loss
function
train
target
model
hyper
paramet
weight
regular
goal
minim
ladv
regard
f1
f2
lcl
regard
6.3
unsupervis
domain
adapt
uda
unsupervis
domain
adapt
techniqu
train
model
work
well
target
domain
unlabel
data
use
label
sampl
sourc
domain
uda
method
appli
situat
featur
distribut
data
label
diﬀer
sourc
target
domain
pinterest
ad
system
sourc
domain
bias
dataset
label
target
domain
unbias
dataset
without
label
result
data
select
bia
formul
uda
problem
83
6.3
6.1
naiv
uda
naiv
method
directli
train
model
unbias
dataset
will
inconsist
train
serv
ground
truth
label
chapter
empir
studi
select
bia
pinterest
ad
retriev
104
unbias
dataset
miss
pseudo
label
will
gener
separ
model
train
bias
dataset
sourc
domain
ground
truth
label
avail
follow
annot
scheme
let
denot
rank
model
use
gener
pseudo
label
unbias
dataset
sourc
domain
optim
goal
becom
follow
min
lnaiveu
da
fθ
fθ
6.6
data
sourc
domain
howev
method
mani
drawback
realiti
unbias
data
sampl
volum
small
due
infra
cost
might
lead
perform
degrad
addit
high-qual
candid
might
suﬃcient
repr
sent
train
data
sourc
domain
will
discuss
perform
experi
section
6.3
6.2
modiﬁ
uda
uda
qualiti
pseudo
label
critic
perform
train
model
naiv
uda
mechan
guarante
qualiti
pseudo
label
especi
pseudo
label
gener
model
remain
suﬃcient
ac
curat
previous
saito
et
al
67
propos
use
asymmetr
tri-train
method
two
separ
pseudo
label
gener
model
use
mechan
en
sure
pseudo
label
qualiti
howev
requir
maintain
second
pseudo
chapter
empir
studi
select
bia
pinterest
ad
retriev
105
label
gener
model
reason
perform
will
costli
real-world
advertis
system
ten
even
hundr
retriev
model
need
retrain
daili
basi
addit
will
inhibit
costli
pseudo
label
deriv
set
model
second
set
sever
model
will
requir
develop
maintain
leverag
tri-train
method
address
pseudo
label
qualiti
issu
real-world
ad
retriev
transform
origin
numer
pseudo
label
predict
rank
model
binari
classiﬁc
label
base
care
chosen
threshold
formal
let
δl
δh
denot
two
threshold
δl
δh
shown
equat
6.8
numer
pseudo
label
lower
ﬁrst
threshold
treat
neg
higher
second
threshold
treat
posit
data
record
numer
pseudo
label
fall
two
threshold
remov
train
dataset
rational
behind
keep
record
rank
model
conﬁdent
discard
one
close
hyperplan
rank
classiﬁ
now
optim
goal
train
retriev
model
becom
follow
min
lm
da
fθ
φδδhl
fθ
6.7
δl
δh
chapter
empir
studi
select
bia
pinterest
ad
retriev
106
φδδhl
pseudo
classiﬁc
label
indic
convert
rank
model
predic
tion
binari
label
accord
given
threshold
shown
equat
δh
φδδhl
6.8
δl
select
threshold
adopt
data
driven
method
particularli
bucket
rank
model
predict
check
correspond
empir
click
rate
bucket
threshold
chosen
sudden
chang
empir
click
rate
6.4
experi
result
section
will
ﬁrst
describ
model
train
detail
introduc
eval
uation
set
metric
will
present
discuss
result
oﬄin
onlin
experi
compar
perform
propos
solut
6.4
dataset
describ
section
6.2
two
exist
train
data
sourc
auction
can
didat
auction
winner
bias
dataset
section
6.2
introduc
unbias
dataset
randomli
sampl
post-target
dataset
unbias
dataset
requir
score
rank
retriev
model
product
sy
tem
take
consider
infrastructur
cost
volum
result
chapter
empir
studi
select
bia
pinterest
ad
retriev
107
dataset
sampl
100
000
queri
000
advertis
candid
queri
creat
unbias
dataset
everi
day
6.4
experiment
set
examin
perform
de-bias
method
pinterest
ad
dataset
implement
model
conduct
systemat
experi
collect
evalu
result
real-world
product
system
binari
classiﬁc
model
train
auction
winner
real
user
action
true
label
aim
provid
suppl
mental
evid
indic
reason
current
product
model
directli
train
real
user
action
follow
describ
detail
baselin
model
binari
classiﬁc
sinc
regress
model
train
pseudo
label
gener
ad
rank
model
perform
classiﬁc
model
directli
train
user
action
worth
examin
train
model
use
auction
winner
train
dataset
label
deﬁn
section
6.3
binari
cross
entropi
bce
loss
function
in-batch
neg
classiﬁc
also
train
classiﬁc
model
batch
neg
sampl
use
candid
batch
data
neg
sampl
given
queri
use
1000
batch
size
use
batch
size
number
hard
neg
loss
function
model
train
auction
winner
dataset
use
candid
user
click
chapter
empir
studi
select
bia
pinterest
ad
retriev
108
knowledg
distil
current
product
model
train
use
ad
rank
model
output
pseudo
label
mean
absolut
logarithm
error
logma
loss
function
product
model
train
dataset
includ
auction
candid
auction
winner
besid
product
model
also
train
anoth
one
auction
winner
evalu
refer
ﬁrst
one
product
model
second
one
knowledg
distil
model
summar
implement
detail
debias
model
follow
transfer
learn
transfer
learn
model
use
bias
unbias
dataset
also
use
rank
model
predict
pseudo
label
logma
loss
function
train
retriev
model
adversari
learn
adversari
learn
model
implement
data
sourc
discrimin
one-lay
mlp
sigmoid
activ
function
bias
unbias
dataset
use
train
retriev
model
ad
rank
model
use
gener
pseudo
label
train
dataset
naiv
unsupervis
domain
adapt
uda
train
naiv
uda
model
use
unbias
dataset
pseudo
label
gener
ad
rank
model
predict
logma
loss
function
chapter
empir
studi
select
bia
pinterest
ad
retriev
109
modiﬁ
unsupervis
domain
adapt
muda
use
unbi
ase
dataset
pseudo
label
deriv
discuss
section
6.3
6.2
transform
rank
model
predict
binari
class
bce
loss
function
model
train
hyper-paramet
use
6144
batch
size
0.0001
learn
rate
unless
deﬁn
speciﬁc
two-tow
model
use
four
fulli
connect
layer
ﬁnal
layer
output
dimens
32
use
sigmoid
activ
function
output
layer
use
selu
46
layer
6.4
evalu
metric
oﬄin
evalu
metric
use
auc-roc
score
classiﬁc
regress
model
evalu
model
one
day
auction
winner
dataset
onlin
experi
compar
model
product
model
report
chang
total
impress
number
δimp
click
rate
δctr
30
second
click
rate
δgctr30
ad
evalu
besid
user-sid
metric
mention
also
report
metric
relat
advertis
experi
metric
impress
convers
rate
ratio
icvr
measur
eﬀect
ad
campaign
convert
impress
convers
cost
per
action
cpa
measur
cost
advertis
posit
user
action
current
exclus
appli
convers
ad
chapter
empir
studi
select
bia
pinterest
ad
retriev
110
due
inform
conﬁdenti
report
lift
metric
compar
current
product
model
6.4
oﬄin
evalu
model
auc-roc
product
model
0.895
binari
classiﬁc
0.895
in-batch
neg
0.701
knowledg
distil
0.896
transfer
learn
0.890
adversari
learn
0.896
naiv
uda
0.841
muda
0.844
tabl
6.1
auc-roc
evalu
dataset
model
knowledg
distilla
tion
adversari
learn
binari
classiﬁc
train
auction
winner
dataset
usual
better
oﬄin
evalu
result
oﬄin
evalu
evalu
regress
classiﬁc
model
use
auc-roc
evalu
dataset
use
auction
winner
contain
real
user
click
shown
tabl
6.1
compar
product
model
model
knowledg
distil
transfer
learn
binari
classiﬁc
adversari
model
similar
perform
term
auc-roc
score
result
expect
train
dataset
includ
auction
winner
model
in-batch
neg
model
train
posit
candid
auction
winner
dataset
perform
well
oﬄin
evalu
nega
tive
candid
includ
train
dataset
nativ
uda
muda
model
train
post-target
dataset
featur
di
tribut
discrep
figur
2a
lead
lower
perform
model
chapter
empir
studi
select
bia
pinterest
ad
retriev
111
summar
oﬄin
evalu
expect
see
model
train
evalu
sourc
data
better
perform
train
diﬀer
sourc
data
howev
oﬄin
evalu
necessarili
reﬂect
true
model
perform
product
system
especi
serv
data
use
onlin
experi
complet
diﬀer
distribut
thu
follow
section
conduct
systemat
onlin
experi
compar
perform
aforement
model
6.4
onlin
experi
6.4
5.1
overal
evalu
tabl
6.2
show
overal
onlin
evalu
result
model
among
metric
will
focu
chang
gctr30
model
optim
toward
ob
jectiv
binari
classiﬁc
model
decreas
gctr30
indic
signiﬁc
drop
qualiti
user
engag
recommend
ad
also
show
largest
decreas
ctr
highest
increas
impress
mean
ad
deliv
user
fewer
got
click
contrast
in-batch
neg
knowledg
distil
model
posit
chang
gctr30
howev
decreas
impress
main
reason
gctr30
increas
less
ad
shown
user
although
three
model
binari
classiﬁc
in-batch
neg
knowledg
distil
lation
suﬀer
select
bia
train
dataset
latter
two
perform
better
chapter
empir
studi
select
bia
pinterest
ad
retriev
112
binari
classiﬁc
model
train
neg
candid
alway
queri
wherea
in-batch
neg
classiﬁc
model
train
ran
dom
sampl
candid
diﬀer
queri
within
batch
diﬀer
sourc
neg
candid
provid
model
divers
informa
tive
train
data
result
overﬁt
speciﬁc
queri
knowledg
distil
train
data
label
rank
model
predict
whose
valu
contain
richer
inform
raw
binari
click-or-not
label
model
δimp
δctr
δgctr30
binari
classiﬁc
0.95
5.51
12.66
in-batch
neg
2.25
4.45
4.68
knowledg
distil
3.26
0.25
5.97
transfer
learn
0.43
1.88
4.35
adversari
learn
0.28
0.45
0.66
naiv
uda
0.45
3.05
4.80
muda
0.92
0.47
5.07
tabl
6.2
onlin
lift
impress
imp
click-through
rate
ctr
good
long
click
gctr30
observ
variou
model
type
ad
in-batch
neg
knowledg
distil
method
improv
gctr30
cost
impress
drop
muda
method
recommend
ad
higher
qualiti
observ
increas
gctr30
without
impress
drop
transfer
learn
model
small
increas
impress
also
neg
chang
gctr30
warm
start
weight
transfer
learn
model
similar
result
decreas
user
engag
case
problem
transfer
learn
model
ﬁne
tune
unbias
dataset
candid
unbias
dataset
randomli
sampl
queri
high
qualiti
one
might
underrepres
adversari
model
similar
result
decreas
gctr30
slight
increas
impress
compar
transfer
learn
model
adversari
model
chapter
empir
studi
select
bia
pinterest
ad
retriev
113
better
perform
user
engag
adversari
model
classiﬁ
serv
regular
prevent
embed
tower
learn
domain
speciﬁc
embed
certain
log
sourc
unlik
transfer
learn
model
debias
techniqu
adversari
model
reli
qualiti
unbias
train
data
train
classiﬁ
unsupervis
use
log
sourc
auction
winner
auction
candid
ground
truth
label
abl
success
train
classiﬁ
classifi
log
sourc
classiﬁ
use
adversari
regular
help
train
unbias
embed
model
howev
compar
product
model
decreas
gctr30
may
indic
restrict
embed
learn
make
model
drop
inform
critic
onlin
evalu
naiv
uda
model
averag
perform
compar
baselin
model
naiv
uda
model
train
unbias
dataset
contain
pseudo
label
gener
rank
model
reason
naiv
uda
model
perform
badli
similar
reason
transfer
learn
model
perform
poorli
sinc
unbias
dataset
collect
random
sampl
post-target
ad
candid
addit
exist
queri
sampl
candid
mostli
neg
sampl
help
train
good
retriev
model
contrast
modiﬁ
uda
muda
model
much
higher
gctr30
product
model
number
impress
increas
higher
user
engag
ment
suggest
muda
model
deliv
ad
higher
qualiti
user
compar
naiv
uda
model
muda
model
transform
numer
pseudo
chapter
empir
studi
select
bia
pinterest
ad
retriev
114
label
gener
rank
model
binari
class
determin
certain
thresh
old
model
also
use
bce
loss
lift
user
engag
metric
suggest
label
transform
improv
qualiti
pseudo
label
use
muda
transform
numer
pseudo
label
binari
one
prevent
model
overli
ﬁtting
rank
model
predict
everi
singl
candid
rank
rank
model
high
conﬁdenc
6.4
5.2
evalu
ad
object
type
awar
traﬃc
web
convers
model
δimp
δctr
δgctr30
δimp
δctr
δgctr30
δimp
δctr
δgctr30
in-batch
neg
8.70
2.41
13.74
1.03
1.16
2.56
1.31
1.69
0.39
muda
0.32
2.71
1.97
0.43
4.28
3.07
3.15
5.19
8.88
tabl
6.3
onlin
lift
impress
imp
click-through
rate
ctr
good
long
click
gctr30
observ
two
promis
model
type
awar
traﬃc
web-convers
ad
in-batch
neg
classiﬁc
model
work
better
traﬃc
ad
muda
model
help
web-convers
ad
overal
evalu
in-batch
neg
muda
two
method
demon
strate
promis
metric
tabl
6.3
show
evalu
result
two
method
broken
diﬀer
ad
object
type
awar
traﬃc
web
convers
ad
awar
ad
aim
increas
visibl
brand
product
analyz
perform
awar
ad
help
understand
eﬀect
brand
market
strategi
shown
tabl
6.3
in-batch
neg
model
signiﬁc
increas
gctr30
compar
model
awar
ad
howev
boost
might
due
huge
decreas
impress
in-batch
neg
model
train
candid
user
long
click
awar
ad
essenti
lower
chanc
click
type
sinc
main
goal
increas
visibl
brand
chapter
empir
studi
select
bia
pinterest
ad
retriev
115
result
in-batch
neg
model
bia
toward
ad
type
lead
huge
impress
drop
awar
ad
traﬃc
ad
design
drive
traﬃc
speciﬁc
websit
land
page
typic
use
increas
brand
awar
gener
lead
drive
sale
analyz
metric
ctr
gctr30
busi
can
determin
whether
ad
reson
target
audienc
whether
success
achiev
advertis
goal
can
seen
in-batch
neg
model
one
yield
increas
ad
impress
gctr30
traﬃc
ad
aim
attract
user
click
occupi
big
portion
record
posit
user
action
therefor
in-batch
neg
model
train
dataset
includ
candid
posit
user
action
may
higher
proport
candid
well-suit
drive
traﬃc
result
model
better
identifi
candid
like
drive
traﬃc
result
improv
gctr30
metric
traﬃc
ad
web-convers
ad
aim
drive
user
take
speciﬁc
action
websit
make
purchas
ad
can
provid
insight
measur
success
onlin
advertis
campaign
shown
tabl
6.3
muda
model
favor
web
convers
ad
object
type
highest
improv
ctr
gctr30
among
model
object
type
in-batch
neg
model
also
perform
well
web-convers
ad
improv
ctr
gctr30
muda
may
favor
web-convers
ad
pseudo
label
gener
ad
rank
model
may
favor
web-convers
ad
design
attract
user
stay
target
websit
longer
potenti
convers
behavior
addit
threshold
select
chapter
empir
studi
select
bia
pinterest
ad
retriev
116
strategi
use
muda
model
may
eﬀect
identifi
high-qual
candid
web-convers
ad
also
contribut
better
perform
type
ad
6.4
5.3
convers
ad
model
δicvr
δcpa
in-batch
neg
2.55
1.11
muda
1.89
4.40
tabl
6.4
onlin
metric
perform
in-batch
neg
classiﬁc
muda
model
web-convers
ad
in-batch
neg
classiﬁc
model
lead
lower
convers
probabl
ad
impress
icvr
thu
higher
cpa
cost
advertis
contrast
muda
model
recommend
ad
candid
higher
convers
rate
therefor
lower
cpa
cost
tabl
6.4
show
perform
in-batch
neg
muda
model
regard
convers
relat
metric
two
show
good
perform
web
convers
ad
gener
in-batch
neg
model
decreas
icvr
increas
cpa
favor
advertis
increas
cost
measur
cpa
hand
muda
model
show
opposit
result
increas
icvr
decreas
cpa
reduc
ad
campaign
cost
advertis
metric
indic
increas
long
click
muda
model
perform
much
better
gener
convers
increas
long
click
one
reason
muda
model
perform
better
model
improv
perform
identifi
high-qual
candid
like
lead
convers
thu
decreas
cost
per
action
advertis
addit
fact
muda
model
train
unbias
data
pseudo
label
gener
chapter
empir
studi
select
bia
pinterest
ad
retriev
117
ad
rank
model
impact
pseudo
label
may
captur
relev
inform
user
behavior
prefer
lead
better
perform
term
cpa
6.4
variant
muda
muda
method
believ
diﬀer
threshold
select
mechan
impact
qualiti
binari
pseudo
label
result
investig
impact
dif
ferent
threshold
mechan
perform
train
retriev
model
unbias
dataset
ﬁrst
bucket
candid
accord
numer
pseudo
label
gctr30
predict
rank
model
comput
percentil
label
use
adjac
percentil
creat
bucket
bucket
adapt
follow
two
strategi
calcul
empir
gctr30
comput
gctr30
candid
real
user
action
divid
number
true
good
click
number
candid
bucket
model
δimp
δctr
δgctr30
muda
v1
0.07
11.26
30.78
muda
v2
0.56
3.52
13.04
muda
v3
0.92
0.47
5.07
tabl
6.5
onlin
lift
impress
imp
click-through
rate
ctr
good
long
click
gctr30
observ
variou
muda
variant
type
ad
muda
v1
achiev
highest
gain
ad
engag
ctr
gctr30
muda
v3
achiev
balanc
gain
across
diﬀer
metric
good
gctr30
impress
lift
chapter
empir
studi
select
bia
pinterest
ad
retriev
118
select
threshold
determin
elbow
point
graph
exampl
sudden
drop
true
good
click
good
click
rate
two
adja
cent
bin
use
one
bin
neg
threshold
mean
label
transform
treat
candid
pseudo
label
smaller
threshold
neg
sampl
posit
label
check
sudden
increas
true
good
click
good
click
rate
bin
studi
diﬀer
threshold
select
strategi
propos
three
variant
muda
model
v1
train
muda
model
bias
unbias
dataset
ﬁrst
threshold
select
strategi
v2
train
muda
model
unbias
dataset
ﬁrst
threshold
select
strategi
v3
train
muda
model
unbias
dataset
second
threshold
select
strategi
awar
traﬃc
web
convers
model
δimp
δctr
δgctr30
δimp
δctr
δgctr30
δimp
δctr
δgctr30
muda
v1
2.13
2.77
7.97
5.22
0.47
17.34
12.98
21.52
29.63
muda
v2
0.10
1.72
5.97
1.53
2.69
1.18
5.16
11.14
17.83
muda
v3
0.32
2.71
1.97
0.43
4.28
3.07
3.15
5.19
8.88
tabl
6.6
onlin
lift
impress
imp
click-through
rate
ctr
good
long
click
gctr30
observ
muda
variant
type
awar
traﬃc
web-convers
ad
muda
v3
show
best
balanc
impress
gain
among
tabl
6.5
show
overal
perform
three
variant
uda
model
mea
sure
sever
evalu
metric
impress
click-through
rate
ctr
ﬁrst
glanc
v1
model
may
seem
work
best
huge
increas
user
engag
chapter
empir
studi
select
bia
pinterest
ad
retriev
119
keep
impress
neutral
howev
broken
ad
type
mode
actu
alli
lead
larg
impress
shift
awar
2.13
traﬃc
ad
5.12
toward
web
convers
ad
12.98
shown
tabl
6.6
observ
may
indic
train
uda
model
bias
data
make
model
favor
web
convers
ad
other
compar
v2
v3
model
latter
one
show
better
balanc
impress
gain
across
ad
object
type
due
second
strategi
calcul
approxim
gctr30
unbias
dataset
strategi
may
better
repres
true
perform
candid
result
accur
threshold
select
lead
improv
perform
muda
model
model
δhdr
δrpr
muda
v1
4.80
13.88
muda
v2
6.35
4.43
muda
v3
2.81
1.43
tabl
6.7
onlin
lift
ad
hide
rate
hdr
re-pin
rate
rpr
observ
muda
variant
type
ad
muda
v3
achiev
balanc
perform
fewer
ad
hidden
ad
repin
user
better
understand
perform
muda
variant
also
measur
onlin
perform
two
use
engag
metric
hide
rate
hdr
re
pin
rate
rpr
note
re-pin
user
action
indic
user
save
ad
pinterest
board
tabl
6.7
show
chang
two
metric
compar
product
model
although
rpr
increas
muda
v1
v2
model
recommend
ad
will
hidden
user
suggest
recommend
ad
model
provid
good
user
experi
contrast
muda
v3
model
gener
balanc
improv
across
metric
show
120
posit
lift
user
engag
reduct
unwant
user
experi
hdr
6.5
conclus
conclus
work
analyz
impact
select
bia
pinterest
onlin
advertis
system
propos
evalu
sever
debias
method
mitig
neg
impact
select
bia
recommend
perform
result
experi
show
propos
method
speciﬁc
muda
model
can
eﬀect
improv
perform
advertis
system
handl
select
bia
addit
onlin
experi
show
model
also
improv
cost
eﬃcienc
ad
campaign
ﬁnding
demonstr
import
address
select
bia
recommend
system
provid
valuabl
insight
practition
ﬁeld
chapter
conclus
conclus
present
work
collect
highlight
signiﬁc
stride
ad
dress
fair
within
rank
search
system
alongsid
mitig
select
bia
onlin
advertis
platform
innov
approach
like
meta-learn
base
fair
rank
mfr
meta
curriculum-bas
fair
rank
mcfr
framework
demonstr
potenti
signiﬁcantli
improv
fair
met
ric
minor
group
exposur
re-weight
train
loss
employ
meta
learn
techniqu
curriculum
learn
method
shown
promis
re
sult
real-world
dataset
underscor
eﬀect
tradit
fair
rank
model
furthermor
explor
larg
languag
model
llm
uncov
ere
bias
challeng
fair
prompt
develop
ﬁne-tun
strategi
lora
foster
equit
outcom
rank
task
research
also
121
122
delv
issu
select
bia
pinterest
multi-cascad
advertis
recom
mendat
system
present
debias
methodolog
like
modiﬁ
unsupervis
domain
adapt
muda
model
enhanc
recommend
system
perform
also
boost
ad
campaign
cost-eﬃci
futur
direct
bodi
work
includ
reﬁn
meta-dataset
collect
method
meta-learn
expand
applic
fair
framework
accommod
multipl
protect
attribut
explor
divers
rank
task
dataset
eﬀort
will
focu
balanc
accuraci
equiti
llm
applic
improv
rank
perform
fair
strategi
addit
insight
gar
nere
mitig
select
bia
onlin
advertis
system
pave
way
innov
address
bias
across
recommend
system
contribut
broader
discours
fair
transpar
machin
learn
ai
applica
tion
bibliographi
abubakar
abid
maheen
farooqi
jame
zou
persist
anti-muslim
bia
larg
languag
model
marion
fourcad
benjamin
kuiper
seth
lazar
deirdr
mulligan
editor
aie
21
aaai
acm
confer
ai
ethic
societi
virtual
event
usa
may
19
21
2021
page
298
306
acm
2021
abubakar
abid
maheen
farooqi
jame
zou
larg
languag
model
associ
muslim
violenc
natur
machin
intellig
461
463
06
2021
doi
10.1038
s42256-021-00359-2
marcin
andrychowicz
misha
denil
sergio
gómez
colmenarejo
matthew
hoﬀ
man
david
pfau
tom
schaul
brendan
shillingford
nando
de
freita
learn
ing
learn
gradient
descent
gradient
descent
proceed
30th
ternat
confer
neural
inform
process
system
page
3988
3996
red
hook
ny
usa
2016
curran
associ
inc
antrea
antoni
harrison
edward
amo
storkey
train
maml
intern
confer
learn
represent
2019
123
bibliographi
124
abolfazl
asudeh
jagadish
julia
stoyanovich
gautam
da
design
ing
fair
rank
scheme
proceed
2019
intern
confer
manag
data
page
1259
1276
new
york
ny
usa
2019
associ
comput
machineri
isbn
9781450356435
yuntao
bai
saurav
kadavath
sandipan
kundu
amanda
askel
jackson
kernion
andi
jone
anna
chen
anna
goldi
azalia
mirhoseini
cameron
mckinnon
carol
chen
catherin
olsson
christoph
olah
danni
hernandez
dawn
drain
deep
ganguli
dustin
li
eli
tran-johnson
ethan
perez
jami
kerr
jare
mueller
jeﬀrey
ladish
joshua
landau
kamal
ndouss
kamil
lukosuit
lian
lovitt
michael
sellitto
nelson
elhag
nichola
schiefer
noemi
mercado
nova
dassarma
robert
lasenbi
robin
larson
sam
ringer
scott
johnston
shauna
kravec
sheer
el
showk
stanislav
fort
tamera
lanham
timothi
telleen-lawton
tom
conerli
tom
henighan
tristan
hume
samuel
bowman
zac
hatﬁeld
dodd
ben
mann
dario
amodei
nichola
joseph
sam
mccandlish
tom
brown
jare
kaplan
constitut
ai
harmless
ai
feedback
2022
matia
barenstein
propublica
compa
data
revisit
arxiv
e-print
art
arxiv
1906.04711
jun
2019
yoshua
bengio
jérôme
louradour
ronan
collobert
jason
weston
cur
riculum
learn
proceed
26th
annual
intern
confer
machin
learn
page
41
48
new
york
ny
usa
2009
acm
bibliographi
125
alex
beutel
jilin
chen
tulse
doshi
hai
qian
li
wei
yi
wu
lukasz
heldt
zhe
zhao
lichan
hong
ed
chi
cristo
goodrow
fair
recommen
dation
rank
pairwis
comparison
proceed
25th
acm
sigkdd
intern
confer
knowledg
discoveri
data
mine
page
2212
2220
new
york
ny
usa
2019
associ
comput
machineri
isbn
9781450362016
10
asia
biega
krishna
gummadi
gerhard
weikum
equiti
atten
tion
amort
individu
fair
rank
41st
intern
acm
sigir
confer
research
develop
inform
retriev
page
405
414
new
york
ny
usa
2018
associ
comput
machineri
isbn
9781450356572
11
christoph
bishop
pattern
recognit
machin
learn
springer
2006
12
tom
brown
benjamin
mann
nick
ryder
melani
subbiah
jare
kaplan
pra
fulla
dhariw
arvind
neelakantan
pranav
shyam
girish
sastri
amanda
askel
sandhini
agarw
ariel
herbert-voss
gretchen
krueger
tom
henighan
rewon
child
aditya
ramesh
daniel
ziegler
jeﬀrey
wu
clemen
winter
chri
hess
mark
chen
eric
sigler
mateusz
litwin
scott
gray
benjamin
chess
jack
clark
christoph
berner
sam
mccandlish
alec
radford
ilya
sutskev
dario
amodei
languag
model
few-shot
learner
larochel
ranzato
hadsel
balcan
lin
editor
advanc
neural
inform
process
system
volum
33
page
1877
1901
curran
associ
inc
2020
bibliographi
126
13
sébastien
bubeck
varun
chandrasekaran
ronen
eldan
johann
gehrk
eric
horvitz
ece
kamar
peter
lee
yin
tat
lee
yuanzhi
li
scott
lundberg
har
sha
nori
hamid
palangi
marco
túlio
ribeiro
yi
zhang
spark
artiﬁci
gener
intellig
earli
experi
gpt-4
corr
ab
2303.12712
2023
14
chumphol
bunkhumpornpat
krung
sinapiromsaran
chidchanok
lursinsap
dbsmote
density-bas
synthet
minor
over-sampl
techniqu
appli
tellig
36
664
684
2012
15
chri
burg
tal
shake
erin
renshaw
ari
lazier
matt
deed
nicol
hamilton
greg
hullend
learn
rank
use
gradient
descent
proceed
22nd
intern
confer
machin
learn
page
89
96
new
york
ny
usa
2005
acm
16
christoph
jc
burg
ranknet
lambdarank
lambdamart
overview
learn
11
23
581
81
2010
17
zhe
cao
tao
qin
tie-yan
liu
ming-feng
tsai
hang
li
learn
rank
pairwis
approach
listwis
approach
proceed
24th
interna
tional
confer
machin
learn
page
129
136
2007
18
elisa
celi
damian
straszak
nisheeth
vishnoi
rank
fair
constraint
ioanni
chatzigiannaki
christo
kaklamani
dániel
marx
donald
sannella
editor
45th
intern
colloquium
automata
languag
program
2018
juli
13
2018
pragu
czech
republ
volum
107
page
28
28
15
schloss
dagstuhl
leibniz-zentrum
für
informatik
2018
bibliographi
127
19
nitesh
chawla
kevin
bowyer
lawrenc
hall
philip
kegelmey
smote
synthet
minor
over-sampl
techniqu
artif
int
re
16
321
357
jun
2002
issn
1076
9757
20
jiawei
chen
hand
dong
yang
qiu
xiangnan
xin
xin
liang
chen
guli
lin
kepe
yang
autodebia
learn
debia
recommend
proceed
44th
intern
acm
sigir
confer
research
develop
inform
retriev
page
21
30
new
york
ny
usa
2021
associ
comput
machineri
21
jiawei
chen
hand
dong
yang
qiu
xiangnan
xin
xin
liang
chen
guli
lin
kepe
yang
autodebia
learn
debia
recommend
proceed
44th
intern
acm
sigir
confer
research
develop
inform
retriev
sigir
21
page
21
30
new
york
ny
usa
2021
associ
comput
machineri
22
myra
cheng
esin
durmu
dan
jurafski
mark
persona
use
natur
languag
prompt
measur
stereotyp
languag
model
anna
roger
jor
dan
boyd-grab
naoaki
okazaki
editor
proceed
61st
annual
meet
associ
comput
linguist
volum
long
pa
per
acl
2023
toronto
canada
juli
14
2023
page
1504
1532
associ
comput
linguist
2023
23
xiangxiang
chu
bo
zhang
ruijun
xu
fairna
rethink
evalu
fair
ness
weight
share
neural
architectur
search
intern
confer
bibliographi
128
comput
vision
2021
24
daniel
cohen
bhaskar
mitra
katja
hofmann
bruce
croft
cross
domain
regular
neural
rank
model
use
adversari
learn
41st
intern
acm
sigir
confer
research
develop
inform
retriev
sigir
18
page
1025
1028
new
york
ny
usa
2018
associ
comput
machineri
25
paul
covington
jay
adam
emr
sargin
deep
neural
network
youtub
recommend
proceed
10th
acm
confer
recommend
system
recsi
16
page
191
198
new
york
ny
usa
2016
associ
comput
machineri
26
nick
craswel
arjen
de
vri
ian
soboroﬀ
overview
trec
2005
enterpris
track
trec
volum
page
2005
27
andré
cruz
catarina
belém
joão
bravo
pedro
saleiro
pedro
bizarro
fairgbm
gradient
boost
fair
constraint
eleventh
interna
tional
confer
learn
represent
2023
28
michael
ekstrand
anubrata
da
robin
burk
fernando
diaz
et
al
fair
inform
access
system
foundat
trend
inform
retriev
16
177
2022
29
michael
ekstrand
graham
mcdonald
amifa
raj
isaac
johnson
overview
trec
2021
fair
rank
track
thirtieth
text
retriev
confer
trec
2021
proceed
2022
bibliographi
129
30
chelsea
finn
pieter
abbeel
sergey
levin
model-agnost
meta-learn
fast
adapt
deep
network
proceed
34th
intern
confer
machin
learn
volum
70
page
1126
1135
jmlr
org
2017
31
chelsea
finn
pieter
abbeel
sergey
levin
model-agnost
meta-learn
fast
adapt
deep
network
doina
precup
yee
whye
teh
editor
proceed
34th
intern
confer
machin
learn
volum
70
proceed
machin
learn
research
page
1126
1135
pmlr
06
11
aug
2017
32
luca
franceschi
paolo
frasconi
saverio
salzo
riccardo
grazzi
massimiliano
pontil
bilevel
program
hyperparamet
optim
meta-learn
intern
confer
machin
learn
page
1568
1577
pmlr
2018
33
batya
friedman
helen
nissenbaum
bia
comput
system
acm
tran
inf
syst
14
330
347
jul
1996
34
samuel
gehman
suchin
gururangan
maarten
sap
yejin
choi
noah
smith
realtoxicityprompt
evalu
neural
toxic
degener
languag
model
find
2020
35
daniel
gillick
sayali
kulkarni
larri
lans
alessandro
presta
jason
baldridg
eugen
ie
diego
garcia-olano
learn
dens
represent
entiti
retriev
proceed
23rd
confer
comput
natur
languag
learn
conll
page
528
537
hong
kong
china
novemb
2019
associ
comput
linguist
bibliographi
130
36
ian
goodfellow
jean
pouget-abadi
mehdi
mirza
bing
xu
david
warde-farley
sherjil
ozair
aaron
courvil
yoshua
bengio
gener
adversari
net
ghahramani
well
cort
lawrenc
weinberg
editor
advanc
neural
inform
process
system
volum
27
curran
associ
inc
2014
37
jianp
gou
baosheng
yu
stephen
maybank
dacheng
tao
knowledg
distil
survey
intern
journal
comput
vision
129
1789
1819
2021
38
cyril
goutt
eric
gaussier
probabilist
interpret
precis
recal
f-score
implic
evalu
david
losada
juan
fernández-luna
editor
advanc
inform
retriev
page
345
359
berlin
heidelberg
2005
springer
berlin
heidelberg
39
fabian
haak
philipp
schaer
audit
search
queri
suggest
bia
recurs
algorithm
interrog
14th
acm
web
scienc
confer
2022
page
219
227
new
york
ny
usa
2022
acm
40
edward
hu
yelong
shen
phillip
walli
zeyuan
allen-zhu
yuanzhi
li
shean
wang
lu
wang
weizhu
chen
lora
low-rank
adapt
larg
languag
model
intern
confer
learn
represent
2022
41
ben
hutchinson
vinodkumar
prabhakaran
emili
denton
kelli
webster
yu
zhong
stephen
denuyl
social
bias
nlp
model
barrier
per
son
disabl
dan
jurafski
joyc
chai
natali
schluter
joel
bibliographi
131
tetreault
editor
proceed
58th
annual
meet
associ
comput
linguist
page
5491
5501
onlin
juli
2020
associ
comput
linguist
42
gert
jacobuss
cor
veenman
select
bia
imbalanc
class
toon
calder
michelangelo
ceci
donato
malerba
editor
discoveri
scienc
page
325
340
cham
2016
springer
intern
publish
43
muhammad
abdullah
jamal
guo-jun
qi
task
agnost
meta-learn
shot
learn
proceed
ieee
cvf
confer
comput
vision
pattern
recognit
page
11719
11727
2019
44
albert
jiang
alexandr
sablayrol
arthur
mensch
chri
bamford
deven
dra
singh
chaplot
diego
de
la
casa
florian
bressand
gianna
lengyel
guil
laum
lampl
lucil
saulnier
lélio
renard
lavaud
marie-ann
lachaux
pierr
stock
teven
le
scao
thibaut
lavril
thoma
wang
timothé
lacroix
william
el
say
mistral
7b
2023
45
vladimir
karpukhin
barla
oguz
sewon
min
patrick
lewi
ledel
wu
sergey
edunov
danqi
chen
wen-tau
yih
dens
passag
retriev
open-domain
question
answer
proceed
2020
confer
empir
method
natur
languag
process
emnlp
onlin
novemb
2020
associ
comput
linguist
46
günter
klambauer
thoma
unterthin
andrea
mayr
sepp
hochreit
self
normal
neural
network
proceed
31st
intern
confer
bibliographi
132
neural
inform
process
system
nip
17
page
972
981
red
hook
ny
usa
2017
curran
associ
inc
47
jon
kleinberg
manish
raghavan
select
problem
presenc
implicit
bia
anna
karlin
editor
9th
innov
theoret
comput
scienc
confer
volum
94
leibniz
intern
proceed
informat
page
33
33
17
dagstuhl
germani
2018
schloss
dagstuhl
leibniz-zentrum
fuer
formatik
48
william
knight
comput
method
calcul
kendal
tau
un
group
data
journal
american
statist
associ
61
314
436
439
1966
49
preethi
lahoti
gerhard
weikum
krishna
gummadi
ifair
learn
indi
vidual
fair
data
represent
algorithm
decis
make
2019
ieee
35th
intern
confer
data
engin
page
1334
1345
2019
50
perci
liang
rishi
bommasani
toni
lee
dimitri
tsipra
dilara
soylu
michihiro
yasunaga
yian
zhang
deepak
narayanan
yuhuai
wu
ananya
kumar
benjamin
newman
binhang
yuan
bobbi
yan
ce
zhang
christian
cosgrov
christo
pher
man
christoph
ré
diana
acosta-nava
drew
hudson
eric
zelikman
esin
durmu
faisal
ladhak
frieda
rong
hongyu
ren
huaxiu
yao
jue
wang
keshav
santhanam
laurel
orr
lucia
zheng
mert
yuksekgonul
mirac
suzgun
nathan
kim
neel
guha
niladri
chatterji
omar
khattab
peter
hender
son
qian
huang
ryan
chi
sang
michael
xie
shibani
santurkar
surya
ganguli
bibliographi
133
tatsunori
hashimoto
thoma
icard
tianyi
zhang
vishrav
chaudhari
william
wang
xuechen
li
yifan
mai
yuhui
zhang
yuta
koreeda
holist
evalu
languag
model
2023
51
shichen
liu
fei
xiao
wenwu
ou
luo
si
cascad
rank
oper
e-commerc
search
proceed
23rd
acm
sigkdd
intern
con
ferenc
knowledg
discoveri
data
mine
kdd
17
page
1557
1565
new
york
ny
usa
2017
associ
comput
machineri
52
hanchao
ma
sheng
guan
christoph
toomey
yinghui
wu
diversiﬁ
subgraph
queri
gener
group
fair
proceed
fifteenth
acm
intern
confer
web
search
data
mine
page
686
694
new
york
ny
usa
2022
acm
53
sourab
mangrulkar
sylvain
gugger
lysandr
debut
youn
belkada
sayak
paul
benjamin
bossan
peft
state-of-the-art
parameter-eﬃci
ﬁne-tun
meth
od
https://github.com/huggingface/peft,
2022
54
nikita
nangia
clara
vania
rasika
bhalerao
samuel
bowman
crow
pair
challeng
dataset
measur
social
bias
mask
languag
model
bonni
webber
trevor
cohn
yulan
yang
liu
editor
proceed
2020
confer
empir
method
natur
languag
process
emnlp
page
1953
1967
onlin
novemb
2020
associ
comput
lingui
tic
55
rodrigo
nogueira
kyunghyun
cho
passag
re-rank
bert
2020
bibliographi
134
56
rodrigo
nogueira
zhiy
jiang
ronak
pradeep
jimmi
lin
document
rank
pretrain
sequence-to-sequ
model
trevor
cohn
yulan
yang
liu
editor
find
associ
comput
linguist
emnlp
2020
page
708
718
onlin
novemb
2020
associ
computa
tional
linguist
57
openai
gpt-4
technic
report
2023
58
long
ouyang
jeﬀ
wu
xu
jiang
diogo
almeida
carrol
wainwright
pamela
mishkin
chong
zhang
sandhini
agarw
katarina
slama
alex
ray
john
schul
man
jacob
hilton
fraser
kelton
luke
miller
maddi
simen
amanda
askel
peter
welind
paul
christiano
jan
leik
ryan
low
train
languag
model
follow
instruct
human
feedback
2022
59
sinno
jialin
pan
qiang
yang
survey
transfer
learn
ieee
transact
knowledg
data
engin
22
10
1345
1359
2010
60
german
parisi
ronald
kemker
jose
part
christoph
kanan
stefan
wermter
continu
lifelong
learn
neural
network
review
neural
network
113
54
71
2019
issn
0893
6080
61
alicia
parrish
angelica
chen
nikita
nangia
vishakh
padmakumar
jason
phang
jana
thompson
phu
mon
htut
samuel
bowman
bbq
hand-built
bia
benchmark
question
answer
smaranda
muresan
preslav
nakov
bibliographi
135
alin
villavicencio
editor
find
associ
comput
lingui
tic
acl
2022
dublin
ireland
may
22
27
2022
page
2086
2105
associ
comput
linguist
2022
62
ethan
perez
saﬀron
huang
franci
song
trevor
cai
roman
ring
john
aslanid
amelia
glaes
nat
mcalees
geoﬀrey
irv
red
team
lan
guag
model
languag
model
yoav
goldberg
zornitsa
kozareva
yue
zhang
editor
proceed
2022
confer
empir
method
natur
languag
process
page
3419
3448
abu
dhabi
unit
arab
emir
decemb
2022
associ
comput
linguist
63
andrea
dal
pozzolo
olivi
caelen
reid
johnson
gianluca
bontempi
calibr
probabl
undersampl
unbalanc
classiﬁc
2015
ieee
symposium
seri
comput
intellig
page
159
166
new
york
ny
usa
2015
ieee
64
jiarui
qin
jiachen
zhu
bo
chen
zhirong
liu
weiwen
liu
ruim
tang
rui
zhang
yong
yu
weinan
zhang
rankﬂow
joint
optim
multi-stag
cascad
rank
system
ﬂow
sigir
22
page
814
824
new
york
ny
usa
2022
associ
comput
machineri
65
zhen
qin
rolf
jagerman
kai
hui
honglei
zhuang
junru
wu
jiam
shen
tianqi
liu
jialu
liu
donald
metzler
xuanhui
wang
michael
benderski
larg
languag
model
eﬀect
text
ranker
pairwis
rank
prompt
2023
bibliographi
136
66
aida
ramezani
yang
xu
knowledg
cultur
moral
norm
larg
lan
guag
model
anna
roger
jordan
boyd-grab
naoaki
okazaki
editor
proceed
61st
annual
meet
associ
computa
tional
linguist
volum
long
paper
acl
2023
toronto
canada
juli
14
2023
page
428
446
associ
comput
linguist
2023
67
kuniaki
saito
yoshitaka
ushiku
tatsuya
harada
asymmetr
tri-train
unsupervis
domain
adapt
proceed
34th
intern
con
ferenc
machin
learn
volum
70
icml
17
page
2988
2997
jmlr
org
2017
68
sebastin
santi
jenni
liang
ronan
le
bra
katharina
reineck
maarten
sap
nlposition
character
design
bias
dataset
model
anna
roger
jordan
boyd-grab
naoaki
okazaki
editor
proceed
61st
annual
meet
associ
comput
linguist
volum
long
paper
acl
2023
toronto
canada
juli
14
2023
page
9080
9102
associ
comput
linguist
2023
69
jun
shu
qi
xie
lixuan
yi
qian
zhao
sanp
zhou
zongben
xu
deyu
meng
meta-weight-net
learn
explicit
map
sampl
weight
ad
vanc
neural
inform
process
system
32
2019
70
ashudeep
singh
thorsten
joachim
fair
exposur
rank
proceed
24th
acm
sigkdd
intern
confer
knowledg
discoveri
data
mine
page
2219
2228
new
york
ny
usa
2018
acm
bibliographi
137
71
dylan
slack
sorel
friedler
emil
givent
fair
warn
fair
maml
learn
fairli
minim
data
page
200
209
new
york
ny
usa
2020
associ
comput
machineri
72
julia
stoyanovich
ke
yang
hv
jagadish
onlin
set
select
fair
divers
constraint
proceed
edbt
confer
2018
73
weiwei
sun
lingyong
yan
xinyu
ma
shuaiqiang
wang
pengji
ren
zhumin
chen
dawei
yin
zhaochun
ren
chatgpt
good
search
investig
larg
languag
model
re-rank
agent
houda
bouamor
juan
pino
kalika
bali
editor
proceed
2023
confer
empir
method
natur
languag
process
page
14918
14937
singapor
decemb
2023
associ
comput
linguist
74
ilya
sutskev
jame
marten
georg
dahl
geoﬀrey
hinton
impor
tanc
initi
momentum
deep
learn
intern
confer
machin
learn
page
1139
1147
pmlr
2013
75
zhiqiang
tao
yaliang
li
bolin
ding
ce
zhang
jingren
zhou
yun
fu
learn
ing
mutat
hypergradi
guid
popul
advanc
neural
format
process
system
volum
33
page
17641
17651
curran
associ
inc
2020
bibliographi
138
76
hugo
touvron
loui
martin
kevin
stone
peter
albert
amjad
almahairi
ya
mine
babaei
nikolay
bashlykov
soumya
batra
prajjwal
bhargava
shruti
bho
ale
dan
bikel
luka
blecher
cristian
canton
ferrer
moya
chen
guillem
cu
curul
david
esiobu
jude
fernand
jeremi
fu
wenyin
fu
brian
fuller
cyn
thia
gao
vedanuj
goswami
naman
goyal
anthoni
hartshorn
saghar
hosseini
rui
hou
hakan
inan
marcin
karda
viktor
kerkez
madian
khabsa
isabel
kloumann
artem
korenev
punit
singh
koura
marie-ann
lachaux
thibaut
lavril
jenya
lee
diana
liskovich
yinghai
lu
yune
mao
xavier
martinet
todor
mihaylov
pushkar
mishra
igor
molybog
yixin
nie
andrew
poulton
jeremi
reizenstein
rashi
rungta
kalyan
saladi
alan
schelten
ruan
silva
eric
michael
smith
ranjan
subramanian
xiaoq
ellen
tan
binh
tang
ross
taylor
adina
william
jian
xiang
kuan
puxin
xu
zheng
yan
iliyan
zarov
yuchen
zhang
angela
fan
melani
kambadur
sharan
narang
aurelien
ro
driguez
robert
stojnic
sergey
edunov
thoma
scialom
llama
open
foundat
ﬁne-tun
chat
model
2023
77
boxin
wang
weixin
chen
hengzhi
pei
chulin
xie
mintong
kang
chenhui
zhang
chejian
xu
zidi
xiong
ritik
dutta
rylan
schaeﬀer
sang
truong
simran
arora
manta
mazeika
dan
hendryck
zinan
lin
yu
cheng
sanmi
koyejo
dawn
song
bo
li
decodingtrust
comprehens
assess
trustworthi
gpt
model
corr
ab
2306.11698
2023
78
xiaoji
wang
rui
zhang
yu
sun
jianzhong
qi
combat
select
bias
recommend
system
unbias
rate
proceed
14th
bibliographi
139
acm
intern
confer
web
search
data
mine
wsdm
21
page
427
435
new
york
ny
usa
2021
associ
comput
machineri
79
xuanhui
wang
michael
benderski
donald
metzler
marc
najork
learn
rank
select
bia
person
search
proceed
39th
intern
acm
sigir
confer
research
develop
inform
retriev
sigir
16
page
115
124
new
york
ny
usa
2016
associ
comput
machineri
80
yuan
wang
zhiqiang
tao
yi
fang
meta-learn
approach
fair
rank
45th
intern
acm
sigir
confer
research
develop
inform
retriev
page
2539
2544
new
york
ny
usa
2022
acm
81
zhenlei
wang
jingsen
zhang
hongteng
xu
xu
chen
yongfeng
zhang
wayn
xin
zhao
ji-rong
wen
counterfactu
data-aug
sequenti
recommenda
tion
proceed
44th
intern
acm
sigir
confer
research
develop
inform
retriev
sigir
21
page
347
356
new
york
ny
usa
2021
associ
comput
machineri
82
linda
wightman
lsac
nation
longitudin
bar
passag
studi
lsac
research
report
seri
1998
83
garrett
wilson
dian
cook
survey
unsupervis
deep
domain
adap
tation
acm
tran
intel
syst
technol
11
jul
2020
issn
2157
6904
bibliographi
140
84
ledel
wu
fabio
petroni
martin
josifoski
sebastian
riedel
luke
zettl
moyer
scalabl
zero-shot
entiti
link
dens
entiti
retriev
proceed
ing
2020
confer
empir
method
natur
languag
process
emnlp
page
6397
6407
onlin
novemb
2020
associ
computa
tional
linguist
85
chenyan
xiong
zhuyun
dai
jami
callan
zhiyuan
liu
russel
power
end
to-end
neural
ad-hoc
rank
kernel
pool
proceed
40th
ternat
acm
sigir
confer
research
develop
inform
retriev
sigir
17
page
55
64
new
york
ny
usa
2017
associ
com
pute
machineri
86
ke
yang
julia
stoyanovich
measur
fair
rank
output
pro
ceed
29th
intern
confer
scientiﬁc
statist
databas
manag
new
york
ny
usa
2017
associ
comput
machineri
isbn
9781450352826
87
ke
yang
vasili
gkatz
julia
stoyanovich
balanc
rank
divers
constraint
proceed
twenty-eighth
intern
joint
confer
artiﬁci
intellig
page
6035
6042
intern
joint
confer
ar
tiﬁcial
intellig
organ
2019
88
huaxiu
yao
xian
wu
zhiqiang
tao
yaliang
li
bolin
ding
ruirui
li
zhen
hui
li
autom
relat
meta-learn
8th
intern
confer
learn
represent
2020
bibliographi
141
89
meik
zehlik
carlo
castillo
reduc
dispar
exposur
rank
learn
rank
approach
page
2849
2855
associ
comput
machin
eri
new
york
ny
usa
2020
isbn
9781450370233
90
meik
zehlik
francesco
bonchi
carlo
castillo
sara
hajian
moham
mega
hed
ricardo
baeza-y
fa
ir
fair
top-k
rank
algorithm
proceed
ing
2017
acm
confer
inform
knowledg
manag
page
1569
1578
new
york
ny
usa
2017
associ
comput
machineri
isbn
9781450349185
91
meik
zehlik
philipp
hacker
emil
wiedemann
match
code
law
achiev
algorithm
fair
optim
transport
data
min
knowl
discov
34
163
200
jan
2020
issn
1384
5810
92
meik
zehlik
ke
yang
julia
stoyanovich
fair
rank
survey
arxiv
preprint
arxiv
2103.14000
2021
93
rich
zemel
yu
wu
kevin
swerski
toni
pitassi
cynthia
dwork
learn
fair
represent
sanjoy
dasgupta
david
mcallest
editor
proceed
30th
intern
confer
machin
learn
volum
28
proceed
machin
learn
research
page
325
333
atlanta
georgia
usa
17
19
jun
2013
pmlr
94
brian
hu
zhang
blake
lemoin
margaret
mitchel
mitig
unwant
bias
adversari
learn
proceed
2018
aaai
acm
confer
bibliographi
142
ai
ethic
societi
aie
18
page
335
340
new
york
ny
usa
2018
associ
comput
machineri
95
jizhi
zhang
keqin
bao
yang
zhang
wenji
wang
fuli
feng
xiangnan
chatgpt
fair
recommend
evalu
fair
larg
languag
model
recommend
proceed
17th
acm
confer
recommend
system
recsi
23
page
993
999
new
york
ny
usa
2023
associ
comput
machineri
isbn
9798400702419
96
chen
zhao
feng
chen
unfair
discoveri
prevent
few-shot
regr
sion
2020
ieee
intern
confer
knowledg
graph
page
137
144
2020
97
chen
zhao
feng
chen
zhuoyi
wang
latifur
khan
primal-du
subgradi
approach
fair
meta
learn
2020
ieee
intern
confer
data
mine
page
821
830
ieee
2020
98
chen
zhao
feng
chen
bhavani
thuraisingham
fairness-awar
onlin
meta
learn
proceed
27th
acm
sigkdd
confer
knowledg
discoveri
data
mine
page
2294
2304
new
york
ny
usa
2021
associ
comput
machineri
isbn
9781450383325