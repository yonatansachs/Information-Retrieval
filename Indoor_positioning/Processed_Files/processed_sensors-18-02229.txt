sensors
article
indoor
positioning
system
based
static
objects
large
indoor
scenes
using
smartphone
cameras
aoranxiao1
id
ruizhichen1
id
derenli1
yujinchen3
id
anddewenwu1
statekeylaboratoryofinformationengineeringinsurveying
mappingandremotesensing
wuhanuniversity
wuhan430079
china
xiaoaoran@whu.edu.cn
wudewen@whu.edu.cn
collaborativeinnovationcenterofgeospatialtechnology
wuhanuniversity
wuhan430079
china
schoolofgeodesyandgeomatics
wuhanuniversity
wuhan430079
china
yujin.chen@whu.edu.cn
correspondence
ruizhi.chen@whu.edu.cn
drli@whu.edu.cn
cid
cid
cid
cid
cid
cid
cid
cid
cid
cid
cid
cid
cid
cid
cid
cid
cid
received
4june2018
accepted
9july2018
published
11july2018
abstract
demand
location-based
services
lbs
large
indoor
spaces
airports
shoppingmalls
museumsandlibraries
hasbeenincreasinginrecentyears
however
thereisstill
nofullyapplicablesolutionforindoorpositioningandnavigationlikeglobalnavigationsatellite
system
gnss
solutionsinoutdoorenvironments
positioninginindoorscenesbyusingsmartphone
camerashasitsownadvantages
noadditionalneededinfrastructure
lowcostandalargepotential
market
due
popularity
smartphones
etc
however
existing
methods
systems
based
smartphone
cameras
visual
algorithms
limitations
implemented
relativelylargeindoorspaces
todealwiththisproblem
wedesignedanindoorpositioningsystem
tolocateusersinlargeindoorscenes
thesystemusescommonstaticobjectsasreferences
doors
andwindows
tolocateusers
byusingsmartphonecameras
ourproposedsystemisabletodetect
static
objects
large
indoor
spaces
calculate
smartphones
position
locate
users
thesystemintegratesalgorithmsofdeeplearningandcomputervision
itscostislowbecauseit
doesnotrequireadditionalinfrastructure
experimentsinanartmuseumwithacomplicatedvisual
environmentsuggestthatthismethodisabletoachievepositioningaccuracywithin1m
keywords
indoorpositioning
smartphone
largeindoorscene
computervision
deeplearning
introduction
itseemsobviousforustoconcludethathumanbeingsaswellasmostofanimalslocatethemselves
byvisualperception
accordingtoourownexperiences
peopleobservetheenvironmentsurrounding
themintentionallyorunintentionally
draw
aroughmapintheirmind
thewinnersofthe
nobelprizeinphysiologyormedicine2014provedthisidea
keefeetal
discoveredthatsome
place
cells
type
nerve
cells
particular
area
brain
always
activated
rat
located
particular
place
room
place
cells
also
activated
rat
moved
different
places
keefe
concluded
room
map
mind
formed
placecells
in2005
may-brittandedvardmoser
madeafurtherdiscovery
theyfoundanother
important
component
location
system
brain
another
type
nerve
cell
named
gridcells
thatcancreateacoordinatesystemtorealizeprecisepositioningandfindaccuratepaths
theirsubsequentresearch
indicatedhowplacecellsandgridcellsareabletodetermineposition
andallowonetonavigate
inspired
interesting
discovery
propose
indoor
positioning
system
used
smartphonecamerasasdataacquisitiondevicestocapturevisualinformationforlocation
considering
sensors2018
18
2229
doi
10.3390
s18072229
www.mdpi.com/journal/sensorssensors2018,18,2229
2of17
specific
indoor
surroundings
including
objects
layouts
activate
place
cells
rat
brain
wedecidedtouseparticularobjectsintheroomsforpositioning
inanapplication
objects
used
positioning
references
common
immovable
doors
windows
theseobjectsarewidelydistributed
manyofwhicharenecessaryforindoorscenes
andremainstill
andwell-preservedforalongtime
astheirlocationsareknowninplanmaps
theybecomeideal
referencesourcesforpositioning
inthispaper
wecalledthem
staticobjects
besides
largeindoor
scenessuchaslibraries
airportsandmuseums
provideawideandstablevisionconditionforvisual
algorithmsofthesystem
traditionalvision-basedindoorpositioningmethodshavetheirownlimits
whenimplementinginthiskindofrelativelylargeindoorenvironments
seesection5
evaluation
thus
wedecidedtousethesystemtolocatepeopleinlargeindoorscenes
inourpreviousresearch
wu
etal
comparedthepositioningaccuracybetweenhumanbrains
andavisualalgorithmwasproposed
whichprovedthattheindoorvisualpositioningmethodvia
smartphoneoutperformshumanbrains
theyexperimentedwiththepositioningalgorithminseveral
placesincludinglibrariesandanofficetoprovetherobustness
inthispaper
weimprovedthemethod
toawholesystem
realizingpositioninginlargeindoorspacesinourapplication
system
proposed
paper
aims
locate
smartphones
users
via
static
objects
staticobjectsinimagearedetectedandidentifiedfirstly
thenthepositionsofusersarecalculatedas
output
themaincontributionofourworkcanbesummarizedasfollows
weproposeanindoorpositioningsystembyusingsmartphonecameras
whichisdesignedfor
largeindoorscenes
previousstudiesofindoorpositioningbasedonsmartphonecamerashave
theirownshortcomingsinsuchlargeindoorscenes
thesystemintegratescomputervision
cv
anddeeplearning
dl
algorithms
commonstaticobjects
suchasdoorsandwindows
inthe
indoorsceneareusedasreferencesforlocatingpurposes
makingourmethodgeneral
andeasy
toreplicate
wetestedoursysteminalargeindoorspacewithacomplicatedfieldofvision
anartmuseum
experimentsindicatedthatourmethodisabletoachieveapositioningaccuracywithin1min
suchcircumstances
method
low-cost
developers
need
take
several
photos
static
objects
sample
collection
without
additional
infrastructure
also
easily
operated
using
monocular
photography
means
users
don
photograph
scenes
multiple
anglesortakeavideo
therestofthepaperisorganizedasfollows
section2reviewsrelatedworks
detailsaboutthe
methodaredemonstratedinsection3
experimentswithperformanceevaluationarepresentedin
section4
section5isthediscussionandsection6istheconclusions
relatedworks
despiteoftheincreasingdemandforindoorlocation-basedservices
thereisstillnopersuasive
solutionforindoorlocationandnavigationlikeglobalnavigationsatellitesystem
gnss
foroutdoor
environments
asgnsssignalsaretooweaktopenetrateintowalls
also
thecomplexspatialtopology
andrftransmissionmakelocalizationinindoorenvironmentsverycomplicated
recent
years
witnessed
many
studies
indoor
positioning
especially
means
smartphones
widespread
use
development
equipped
various
sensors
supporting
rich
rf
signals
smartphones
hence
can
located
various
means
can
divided
three
categories
gnss
signal
receiver
including
gps
bds
glonass
galileo
built-in
sensors
smartphones
accelerometers
gyroscopes
magnetometers
barometers
lightersensors
microphones
loudspeakersandcameras
etc
rfsignalslikewi-fi
bluetoothandcellularwirelesscommunicationsignal
etc
exceptforthegnsssignalreceiver
allof
sensors
rf
signals
designed
positioning
purposes
can
used
calculateindoorlocationsviadifferentprinciplesandalgorithms
amongthem
theestablishmentofsensors2018
18
2229
3of17
fingerprintingofwi-fi
11
geomagnetism
12
orbluetooth
13
16
arepopularapproachesdue
totheireffectivenessandindependencefrominfrastructure
thesemethodscanreachpositioning
accuraciesof2
5mbutareeasilyinterferedbychangingenvironmentsandnearbyhumanbodies
besides
fingerprinting
database
updated
every
months
inconvenient
fordevelopers
heetal
17
combinedthestrengthsoftrilaterationandfingerprintingtoforman
accurateandeffectiveindoorlocalizationframework
thebluetoothantennaarray
18
canachievea
higherlocationaccuracybuthaslimitationssuchashighcostandshortworkingdistance
cellular
technology
19
20
hasgreatpotentialinindoorpositioningbecausecellularsignalsarewidespread
butthepositioningerrorofthesekindofmethodsisrelativelylarge
infraredtechnology
21
ultrasonicwaves
22
23
canachievehigherindoorpositioningaccuracy
withthelimitationofneeding
additionalinfrastructure
sinceallofthesemethodshavetheirownadvantagesanddisadvantages
multi-sensorfusionapproacheshavebeenresearchedbymanypeopletotakeadvantageofdifferent
methods
kim
et
al
24
combined
magnetic
signals
wi-fi
signals
cellular
signals
realize
indoorlocation
jeonetal
25
proposedamethodintegratingbluetoothrssiwithanaccelerometer
andabarometeronsmartphonestoreachhigherpositioningaccuracycomparedwiththeapproach
withoutbluetoothrssi
chenetal
26
integratedatypicalwi-fiindoorpositioningsystemwitha
pdrsystemandachievedabetterpositioningperformancethanthepdrsystemorwi-fipositioning
systemalone
lietal
27
proposedadead-reckoning
dr
wi-fifingerprinting
magneticmatching
mm
integrationstructure
thestructureusesconsumers
portabledeviceswithoff-the-shelfsensors
andexistingwi-fiinfrastructurestoraisepositioningaccuracy
liuetal
28
fusedmultiplesensors
including
cameras
wi-fi
inertial
sensors
used
deep
learning
method
realize
indoor
localization
beckeretal
29
usedvisionimagesforclassificationtorecognizecorridors
withexisting
wirelesslanaccesspointsincorrespondingcorridortorealizepositioning
gaoetal
30
31
designed
amethodwhichcombinedcameraandgyroscopeinsmartphonetorealizeindoorpositioningwith
accuracyof2m
8m
intheirmethod
atleastthreesmartphonephotosarephotographedineach
test
place
capture
references
points
store
logos
provide
positioning
information
andgyroscoperecordsangleinformationatthesametime
afterthat
thepositioncanbecalculated
viatrilateration
addition
vision-based
indoor
positioning
problem
always
hotspot
issue
researchinthelastdecades
in1998
thevisiontechnologygroupofmicrosoftdiscussedaneasy-living
life
future
32
one
core
technologies
locate
people
house
using
several
video
surveillance
techniques
methods
indoor
positioning
based
vision
keptdeveloping
andtheycanberoughlydividedintothreecategories
33
thefirstcategoryuses
referencesfrombuildingmodels
thesekindsofmethodsdetectobjectsinimagesandmatchthemwith
thoseinthebuildingdatabase
hileandborriello
34
comparedtheimageswiththefloorplanofthe
buildingtolocatesmartphones
kohouteketal
35
detectedspecificobjectsincloudpointsobtainedby
arangeimagingcamera
andcomparedthemwiththedigitalspatial-semanticinteriorbuildingmodel
citygmltodeterminelocationandorientation
thesecondcategoryofvisualpositioningmethodsare
basedonimages
theseapproachesmainlycomparesimilaritiesamongtestingimagesandreference
imagescapturedinofflinephaseandoutputthelocationofthereferenceimagewiththehighestscore
kimandjun
36
matchedthecurrentviewofacamerawithimagesequencesstoredinadatabase
theirmethodisdesignedforaugmentedrealityapplicationsforextrainformation
werneretal
37
estimatedpositionandorientationbyusingreferenceimagesandlocationinformationacquiredfrom
thepre-builtdatabase
theydesignedanalgorithmtoestimatedistancethroughtheratioofmatched
pixeldistancetomeasureviewpoint-to-imagedistance
mölleretal
38
designedanmobileindoor
navigationsystemcombinedinterfacesofvirtualreality
vr
andaugmentedreality
ar
elements
thelastcategoryisutilizingdeployedcodedtargets
includingconcentricrings
barcodesorpatterns
consistingofcoloreddots
etc
mullonietal
39
pastedthebarcodeindifferentplaces
socameras
cancapturethesemarkstogetlocationaswellasotherinformation
bytelightcompanycreateda
special
led
light
specific
frequency
represent
different
position
information
can
besensors2018
18
2229
4of17
capturedbycamerasinsteadofhumaneyes
40
inadditiontothesesystemsandmethods
visual
gsyernosor
s4
210
1a8
1d8
vx
isualodometertechnology
42
arealsousedasvisualpositioning
thealgorithm4
oof
1f7
visionpositioningismorecomplex
largercomputationandhigherpowerconsumptionthanother
maentdh
ohdisg
hhero
wpeovweer
wciotnhsfuumrtphteiroinm
tphraonv
eomtheenrt
omfsemthaordtsp
ohnoewpeevrefor
mwainthc
ef
uthrtihsekri
nidmopfromveetmhoednst
iosf
esxmpeacrttepdhotonefu
prethrfeorrpmoapnuclea
tihzeisi
nkitnhde
ofuf
tmureeth
ods
expected
popularize
future
33
syysstetemma
annddm
meeththooddoolologgyy
inint
hthisiss
esectcitoionn
ysystsetemmo
ovveervrvieiewwi
sisp
prerseesenntetedda
attfi
frisrts
thheennk
keeyym
moodduulelessa
arerei
lillulustsrtarateteddw
witihth
pprorocecesssso
offt
hthees
ysystsetmem
33.1
syysstetemmo
ovveerrvvieieww
tthheem
maainini
dideeaao
offo
ouurrs
syysstetemmi
sist
otou
ussees
smmaarrtptphhoonneei
mimaaggeesst
otol
oloccaateteu
usseersrsv
viaias
statatitcico
obbjejecctstsi
ninl
alargrgee
ininddoooorrs
scceenneess
annddt
hthees
ysystsetemmfl
folowwd
diaiaggrarammi
siss
hshoowwnna
assf
figiguurere1
thheep
proroppooseseddi
ninddoooorrp
poosistiitoionniningg
ssyysstetemmc
coonnssisiststso
offt
wtwoop
paratrst
tsatatitcico
obbjejectcstsr
erceocoggnnitiitoionna
nanddp
posoistiitoionnc
aclacluculaltaitoionn
thhees
tsatatitcico
obbjejecctsts
rereccooggnnitiitoionn
aaimimss
ttoo
ddeetteecctt
aanndd
iiddeennttiiffyy
ssttaattiicc
oobbjjeeccttss
iinn
imimaaggeess
aanndd
ththenen
ddeteetremrminien
ecocoorodridniantaetse
osf
ocfocnotrnotrl
oplopinotisn
ftosrf
coarlccuallactuinlagt
iunsgeruss
elorsc
atlioocna
isoenct
isoenc
3ti
o1n
t3h
1e
potshiteiopno
csailtciounlatciaolnc
uinlactliuodnesin
pcolusidtieosn
peosstiitmioantieosnti
diasttiaonnc
ed
eissttaimncaetieosnti
amnadt
iao
nfilatnerd
sacrfieletnerinsgc
rgereonsisn
gpogirnotsss
apnodi
notustapnudt
uosuetrpsu
tpuosseitriso
np
osseictitoionn
s3e
2c
on3
figure
system
flow
diagram
figure1
systemflowdiagram
current
version
system
web-based
smartphone
photographs
test
images
thecurrentversionofoursystemisweb-based
afterthesmartphonephotographstestimages
desktop
server
will
implement
rest
algorithms
return
results
adesktopasserverwillimplementtherestofalgorithmsandreturntheresults
sensors2018
18
2229
5of17
sensors
2018
18
17
3.2
staticobjectsrecognition
3.2
static
objects
recognition
3.2
staticobjectdetection
identification
3.2
static
object
detection
identification
whenuserstakeaphotoasinput
thefirsttaskofthesystemistodetectstaticobjectsinimages
rwechoegnn
iuzseertsh
etairkeu
na
ipqhuoetiod
aesn
itnitpieust
tthhei
sfirissta
takseky
omf
tohdeu
slyestoefmth
ies
tsoy
sdteetmec
osutattpicu
totbinjegctbso
iunn
imdaargieess
aanndd
rideceongtintiizese
tohfesirta
utinciqoubeje
icdtesnitnitiiems
tghesis
ha
ekebyo
umnoddaurliee
sofo
tfhset
astyicsteombj
octustpinutitminagg
beoiunnflduaerniecse
atnhde
pideerfnotritmieasn
coef
osftafetiact
uorbejeecxttsr
aicnti
oinmaangdesm
tathceh
inbgouinndthaeriefos
lloofw
sintagtipc
roocbejdecutrse
si
na
nimdaidgee
nitnitfileuseonfcset
atthice
opbejrefcotrsmaraentchee
okfe
fyeatotufirned
excotrrarcetsipoonn
adnindg
matattrcihbuintegs
iinn
tdhaet
afoblalsoew
sinugch
parsocroedomurnesu
manbder
idpeixnetlitcioeso
rodfi
nstaatteisc
aonbdjecotbsj
eacrtse
ctohoer
dkienya
tetos
offincodn
tcroorlrpesopinotnsd
ientcg
attributes
database
room
number
pixel
coordinintahtiessp
aanpde
ro
bwjeectism
cpoloermdeinnattfesa
sotfe
rc-ornctrnoln
paolignotsr
tehtcm
43
forthistask
faster-rcnnintegrates
regioinnp
throisp
posaaple
rf
wateu
rimeepxltermacetniot
nf
acsltaesrs-rificcnatnio
nalagnodritrhecmta
n4g3l
f-orer
fithnies
itnatsok
fnaesetenrd-r-tco-nennd
innteetgwroatreks
wrehgiicohn
gprreoaptloysarle
fueacteutrhe
eexatmraocutinotno
fclcaaslsciufilcaattiioonn
aanndd
srpeceteadngulpe-rthefeindee
tinectoti
oonnep
eroncde-stos
esnmd
anretptwhoornke
iwmhaigcehs
garreeafitrlyst
lryedzouocme
ethdei
natmooaufinxte
dofs
iczael
ctuhleantiothno
saenfidx
sepde-seidz
euipm
athgee
sdaerteescetinodn
toprtohceenses
wsmorakr
tjpuhsotnase
fimigaugrees2
airlelu
fisrtsrtaltye
sz
oaotmtheed
binetgoi
nan
fiinxgedo
fsitzhee
tnheetnw
tohroksteh
feixreeda-rseiz1e3
icmoangvelsa
ayreer
ss
e1n3dr
teol
uthlea
yneertswaonrdk
jouusrt
paos
ofliignugrlea
y2e
irlsl
utsthriastecso
abt
itnhaet
iboengoinfndiinffge
roefn
tthlaey
neerstwisoarckt
uthalelryea
aprea
r1t3o
fcovngvg
l1a6yenrest
1o3
rrkel
u44
ywehrsic
ahnids
afofuarm
poouoslninegtw
laoyrekrisn
timhiasg
ceocmlabsisnifiactiaotnio
nof
rdeiaflfiezrienngt
fleaayteurrse
iesx
atrcatuctailolny
fao
rpasmrt
aorft
pvhgogne16im
naegtweso
rtkh
e4n4a
rwehgiicohn
pisr
oap
ofasamlonuest
wnoertkw
orrpkn
ng
iemneargaet
ecslfaosrseigfircoautinodn
nrcehaloirzsinags
wfeealltuasreb
oeuxntrdaicntgiobno
xforre
gsrmesasriotpnhboinase
images
region
proposal
network
rpn
generates
foreground
anchors
well
bounding
tocalculateproposalsfromthesefeatures
roipoolinglayersuseproposalstoextractproposalfeature
box
regression
bias
calculate
proposals
features
roi
pooling
layers
use
proposals
forsubsequentfullyconvolutionalnetworkandsoftmaxnetworktoclassifyproposals
thewhole
extract
proposal
feature
subsequent
fully
convolutional
network
softmax
network
classify
networkistrainedonthebasisoftheconvergenceoflossfunctionasbelow
proposals
whole
network
trained
basis
convergence
loss
function
loss
11
loss
cid
3404
cid
1840
cls
cid
3533
cid
1838
cid
3030
cid
3039
cid
3046
cid
4666
cid
1868
cid
3036
cid
1868
cid
3036
cid
1499
cid
4667
cid
3397
cid
1840
reg
cid
3533
cid
1868
cid
3036
cid
1499
cid
1838
cid
3045
cid
3032
cid
3034
cid
4666
cid
1872
cid
3036
cid
1872
cid
3036
cid
1499
cid
4667
cid
3030
cid
3039
cid
3046
cid
3036
cid
3045
cid
3032
cid
3034
cid
3036
er
re
ii
cid
1861
ih
ti
hn
ed
ix
ndo
ef
xa
och
ar
cp
hr
oe
rp
re
cid
1868
se
rets
pp
rer
se
ed
nic
tsti
pn
rep
dro
icb
ta
iob
nil
py
rf
oo
br
ac
bl
ia
ls
yifi
foat
ri
cn
lao
sf
sif
fo
ir
ce
ag
tir
oo
nu
od
fon
rc
eh
go
rr
ou
nta
ct
hic
oro
ij
ec
sa
tan
td
ic
oi
bs
jet
ch
te
au
nt
de
cid
1872
isc
ta
hn
eg
oe
uo
tef
rp
rr
ee
cd
ti
ac
nte
gd
le
oar
pe
rt
edp
ic
tea
dn
tat
gr
ee
cid
1868
cid
1499
nt
dt
cid
1872
cid
1499
ro
eprr
re
es
sp
eo
nn
thin
eg
cg
ro
reu
sn
pd
ontr
du
nh
go
gf
rp
ouan
nd
trr
ue
ts
hp
oc
ft
cid
1868
aly
dn
cid
1872
cl
sra
en
spd
en
ctrievgea
lyre
cid
1840
um
aner
ds
cid
1840
fan
ah
ro
ns
ua
mnd
beo
ru
st
cid
3030
cid
3039
cid
3046
cid
3045
cid
3032
cid
3034
ae
nc
ct
han
og
rsle
dl
colsu
ra
rn
ed
ctl
anregg
le
cid
1838
ns
cid
4666
cid
4667
ar
nac
dt
io
cid
1838
cid
4666
cid
4667
run
subtraction
cid
3030
cid
3039
cid
3046
cid
3045
cid
3032
cid
3034
figure
faster-rcnn
network
static
objects
detection
identification
figure2
faster-rcnnnetworkforstaticobjectsdetectionandidentification
order
improve
performance
robustness
system
whole
network
shall
order
improve
performance
robustness
system
whole
network
shall
retrained
offline
phase
photos
static
objects
photographed
various
angles
different
retrained
offline
phase
photos
static
objects
photographed
various
angles
different
distances
used
training
images
training
customized
network
system
outputs
outer
distancesareusedfortrainingimages
aftertrainingcustomizednetwork
thesystemoutputsouter
rectangles
identities
static
objects
appeared
images
figure
rectanglesandidentitiesofstaticobjectsappearedinimages
asfigure3
sensors2018
18
2229
6of17
sensors
2018
18
17
figure
example
output
right
process
static
object
detection
identification
figure3
anexampleofoutput
right
inprocessofstaticobjectdetection
identification
3.2
obtaining
control
points
coordinates
3.2
obtainingcontrolpointscoordinates
define
control
points
physical
feature
points
static
objects
accurately
define
control
points
physical
feature
points
static
objects
accurately
surveyed
coordinate
location
can
identified
relatively
easy
building
relationship
surveyedcoordinatelocationandcanbeidentifiedrelativelyeasy
bybuildingrelationshipbetween
pixel
coordinates
image
corresponding
space
coordinates
control
points
collinear
equation
pixelcoordinatesinimageandcorrespondingspacecoordinatesofcontrolpoints
collinearequation
model
45
position
smartphone
can
obtained
thus
key
problem
find
model
45
thepositionofthesmartphonecanthenbeobtained
thus
thekeyproblemistofind
corresponding
pixel
coordinate
control
points
test
images
strategy
offline
corresponding
pixel
coordinate
control
points
test
images
strategy
phase
images
static
objects
photographed
stored
dataset
called
reference
images
offlinephase
imagesofstaticobjectsarephotographedandstoredindataset
calledthe
reference
pixel
coordinates
control
points
images
measured
recorded
online
phase
images
pixelcoordinatesofcontrolpointsintheseimagesaremeasuredandrecorded
intheonline
detecting
identifying
static
objects
test
images
feature
points
testing
image
phase
afterdetectingandidentifyingstaticobjectsintestimages
featurepointsintestingimageand
corresponding
reference
images
extracted
feature
matching
algorithm
implemented
correspondingreferenceimagesareextracted
thenthefeaturematchingalgorithmisimplementedto
get
enough
homonymy
feature
points
used
calculate
homographic
matrix
next
step
getenoughhomonymyfeaturepoints
whichisusedtocalculatehomographicmatrixinnextstep
homographic
matrix
represents
mapping
relationship
pixels
testing
image
thehomographicmatrixrepresentsthemappingrelationshipbetweenpixelsoftestingimageand
reference
image
finally
pixel
coordinates
control
points
testing
image
can
calculated
referenceimage
finally
thepixelcoordinatesofcontrolpointsintestingimagecanbecalculated
homographic
matrix
reference
images
coordinates
control
points
details
fromthehomographicmatrixandreferenceimagescoordinatesofcontrolpoints
thedetailsofthe
algorithm
showed
algorithm
algorithmareshowedinalgorithm1
aallggoorriitthhmm
11
ob
bt
ta
ai
ni
ng
pi
ix
xe
el
co
oo
rd
di
na
te
es
co
nt
tr
ro
ol
poo
ii
nn
tt
ss
ii
nn
tt
ee
ss
tt
ii
mm
aa
gg
ee
ss
input
image
block
static
objects
test
image
input
imageblockofstaticobjectsfromtestimage
procedure
procedure
get
reference
image
identity
static
object
database
getreferenceimagethroughidentityofstaticobjectfromdatabase
extract
feature
points
test
image
block
reference
image
sift
operator
46
extractfeaturepointsforbothtestimageblockandreferenceimagebysiftoperator
46
perform
feature
matching
get
homonymy
feature
point
pairs
performfeaturematchingtogethomonymyfeaturepointpairs
employed
ransac
47
remove
false
matching
points
remaining
matching
points
marked
employedransac
47
toremovefalsematchingpoints
theremainingmatchingpointsmarkedas
cid
1842
test
image
cid
1842
reference
image
ptestf
cid
3047
cid
3032
cid
3046
cid
3047
testimageandp
ref
cid
3045
cid
3032
cid
3033
eferenceimage
calculate
homographic
matrix
cid
1834
solving
formula
calculatehomographicmatrixh
cid
3035
cid
3042
cid
3040
cid
3042
ysolvingformulabelow
homo
cid
1842
cid
3404
cid
1834
cid
3400
cid
1842
cid
3021
cid
3032
cid
3046
cid
3047
cid
3035
cid
3042
cid
3040
cid
3042
cid
3045
cid
3032
cid
3033
estimate
pixel
coordinates
control
tpeostints
inh
otmeost
imraegfes
cpt
following
formula
cid
1829
cid
1842
cid
1846
cid
3045
cid
3032
cid
3033
s6e
te
osft
ipmixaetel
cpoioxerdlcinoaotredsi
noaf
tceosnotfroclo
pnotrionltsp
oinin
rtesfeinretnecste
iimmaaggeess
ptasfollowingformula
cpt
ref
istheset
ofpixelcoordinatesofcontrolpointsin
cid
1829
cid
1842
cid
1846
fe
cid
3404
ren
cid
1834
ceima
cid
3400
cid
1829
es
cid
1842
cid
1846
cid
3035
cid
3042
cid
3040
cid
3042
cid
3045
cid
3032
cid
3033
output
cid
1829
cid
1842
cid
1846
cpt
cpt
homo
ref
output
cpt
figure
shows
example
output
algorithm
pixel
coordinates
control
points
reference
images
measured
offline
phase
reason
directly
choose
feature
points
test
image
output
specific
control
points
may
belong
set
feature
points
sift
texture
images
complicated
also
hard
design
robust
effective
filter
screen
specific
point
plenty
feature
points
algorithm
fast
effective
approach
instead
sensors2018
18
2229
7of17
figure4showsanexampleofoutputbyalgorithm1
thepixelcoordinatesofcontrolpointsin
referenceimagesaremeasuredintheofflinephase
thereasonwhywedonotdirectlychoosefeature
pointsfromtestimageasoutputisthatthespecificcontrolpointsmaynotbelongtothesetoffeature
pointsbysiftwhenthetextureofimagesaretoocomplicated
also
itishardtodesignarobust
andeffectivefiltertoscreenthespecificpointfromplentyoffeaturepoints
algorithm1isafastand
seefnfesocrtsi
v20e18a
1p8
xo
achinstead
17
ffiigguurree
44
aann
eexxaammppllee
ooff
oouuttppuutt
bbyy
aallggoorriitthhmm
11
tthhee
ppiixxeell
ccoooorrddiinnaatteess
ooff
ccoonnttrrooll
ppooiinnttss
iinn
tteesstt
iimmaaggee
aarree
oobbttaaiinneedd
ffrroomm
rreeffeerreennccee
iimmaaggee
3.3
position
calculation
3.3
positioncalculation
33
33
11
ppoossiittiioonn
eessttiimmaattiioonn
tthhee
ggeeoommeettrriicc
rreellaattiioonn
bbeettwweeeenn
ccoonnttrrooll
ppooiinnttss
iinn
iimmaaggee
aanndd
oobbjjeecctt
ssppaaccee
ccaann
bbee
iilllluussttrraatteedd
vviiaa
ccoolllliinneeaarr
eeqquuaattiioonn
mmooddeell
aasse
eqquuaatitoionn
oforrp
pixiexlecl
ocoorodridniantaete
cid
4666
cid
1876
cid
1877
cid
4667
dansdp
ascpeaccoe
ocrodoirndaitnea
txe
cid
4666
cid
1850
cid
1851
cid
1852
cid
4667
othf
ethsea
msaemceo
nctornotlrpool
ipnoti
ntht
thgee
ogmeoemtriectrriecl
aretiloantiocnan
cabne
bilelu
isllturastteradteads
baes
lboewlo
cid
1749
cid
1750
cid
1748
cid
1750
cid
1747
cid
1877
cid
1876
cid
3398
cid
3398
yx
00
cid
1876
cid
1877
cid
2868
cid
2868
cid
3404
cid
3404
cid
3398
cid
3398
ff
cid
1858
cid
1858
tttt
3231
cid
1872
cid
1872
cid
1872
cid
1872
1111
cid
2871
cid
2869
cid
2870
cid
2871
cid
2869
cid
2869
cid
2869
cid
2869
xxxx
cid
4666
cid
4666
cid
4666
cid
4666
cid
1850
cid
1850
cid
1850
cid
1850
cid
3398
cid
3398
cid
3398
cid
3398
xxxx
cid
1850
cid
1850
cid
1850
cid
1850
oooo
cid
3016
cid
3016
cid
3016
cid
3016
cid
4667
cid
4667
cid
4667
cid
4667
cid
3397
cid
3397
cid
3397
cid
3397
ttt
cid
1872
cid
1872
cid
1872
cid
1872
321
cid
2869
cid
2871
cid
2870
cid
2871
222
cid
2870
cid
2870
cid
2870
cid
2870
cid
4666
cid
4666
cid
4666
cid
4666
yyy
cid
1851
cid
1851
cid
1851
cid
1851
cid
3398
cid
3398
cid
3398
cid
3398
yyy
cid
1851
cid
1851
cid
1851
cid
1851
ooo
cid
3016
cid
3016
cid
3016
cid
3016
cid
4667
cid
4667
cid
4667
cid
4667
cid
3397
cid
3397
cid
3397
cid
3397
cid
1872
cid
1872
cid
1872
cid
1872
ttt
cid
2869
cid
2871
cid
2870
cid
2871
321
cid
2871
cid
2871
cid
2871
cid
2871
333
cid
4666
cid
4666
cid
4666
cid
4666
cid
1852
cid
1852
cid
1852
cid
1852
zzz
cid
3398
cid
3398
cid
3398
cid
3398
cid
1852
cid
1852
cid
1852
cid
1852
zzz
cid
3016
cid
3016
cid
3016
cid
3016
ooo
cid
4667
cid
4667
cid
4667
cid
4667
formula
cid
4666
cid
1876
cid
1877
cid
1858
cid
4667
intrinsic
parameters
camera
can
measured
formula
cid
2868
cid
2868
intrinsic
parameters
camera
can
measured
camera
calibration
offline
48
cid
4666
cid
1850
cid
1851
cid
1852
cid
4667
space
coordinates
smartphone
camera
bycameracalibrationoffline
48
cid
3016
cid
3016
cid
3016
arethespacecoordinatesofthesmartphonecamera
position
user
cid
1872
cid
4666
cid
1861
cid
1862
cid
3404
cid
4667
nine
directional
cosines
related
exterior
orientation
thepositionofuser
cid
3036
cid
3037
areninedirectionalcosinesrelatedtotheexteriororientationof
ij
smartphone
hence
long
three
control
points
offered
including
pixel
coordinates
smartphone
hence
aslongasmorethanthreecontrolpointsareoffered
includingpixelcoordinates
space
coordinates
result
cid
1829
cid
1842
cid
1846
last
step
section
3.2
cid
4666
cid
1827
cid
1853
cid
4667
cid
4666
cid
1828
cid
1854
cid
4667
andspacecoordinates
whicharetheresultofcptfromlaststep
section3
2.2
suchas
cid
4666
cid
1829
cid
1855
cid
4667
figure
position
can
calculated
model
system
outputs
infigure5
thepositioncanbecalculatedthroughthismodel
thesystemoutputsestimated
pes
ot
sim
itia
ot
ned
cid
xp
yiti
cid
4666
cid
1850
cid
cid
3016
cid
1499
cid
1851
cid
3016
cid
1499
cid
1852
cid
3016
cid
1499
cid
4667
rab
ty
iv
en
rte
ca
et
si
sv
process
osensors2018
18
2229
8of17
sensors
2018
18
17
sensors
2018
18
17
ffigiguurere5
prirninccipipaallo
offp
poossitiitoionne
esstitmimaatitoionn
oo
cid
4666
cid
1876
cid
2868
cid
1877
cid
2868
cid
4667
sist
htheep
prirnincicpipaallp
pooinintto
offc
acmamerearai
mimaag
gee
annddt
hthee
lel
fenn
ig
ggt
uhth
ro
5fo
cid
1841
cid
1867
rs
nits
ch
ite
phf
aeo
cf
ooa
fcl
plel
nl
seg
tt
ihg
ot
nhf
eb
cid
1858
sy
ib
mcya
lcc
tau
iollc
naut
lnaotg
cid
4666
cid
1876
ncgo
cid
1877
clion
cid
4667
lel
ia
sre
tea
hqr
ue
paqt
rui
ioa
nnt
ci
iom
pn
ao
lmd
peo
olds
ineol
tfs
coo
ff
cc
ator
monlt
erp
ro
aol
ipn
mot
aipn
gat
ei
rp
aa
niar
ds
ta
cb
la
ncd
ta
hn
db
fa
cid
1841
bt
cid
1867
stp
hes
eipt
foo
osn
cit
aiin
lo
ln
eio
nnf
ggs
hmo
fa
cid
1858
sr
mt
bpah
yr
ot
cpn
ahe
lcoo
un
ax
ti
cid
1841
cid
2868
cid
4666
cid
1850
cid
2868
cid
3016
lz
cid
1851
cid
3016
cid
1852
ac
cid
3016
cid
4667
qcb
uae
ibb
oet
na
oi
mnbe
otad
di
en
le
sd
control
point
pairs
positioning
smartphone
cid
1841
cid
4666
cid
1850
cid
1851
cid
1852
cid
4667
can
obtained
cid
3016
cid
3016
cid
3016
33.3
3.2
disistatanncceee
esstitmimaatitoionn
3.3
i2ni
orisdrtdeaernrtc
oteo
ae
avsvotioimdidag
tgriooronsss
se
rerrororrf
oforrt
htheefi
fninalalp
poosistiitoionn
disitsatanncecee
setsitmimaatitoionni
sist
htheenni
mimpplelemmeennteteddt
oto
cchheecckkt
htheeo
ouutptpuutto
offc
ocolllilnineeaarre
eqquuaatitoionnm
mooddele
order
avoid
gross
error
final
position
distance
estimation
implemented
tthheep
prirnicnicpilpeleo
fodf
isdtiasntacnecees
teimstaimtioantiocann
cbaen
ilbleu
sitlrluatsetdraatesdf
iagsu
rfeig6ua
rea
6aan
cid
1827
aanrde
cid
1828
oacroe
nttwrool
pcoonintrtso
check
output
collinear
equation
model
tphoeipnats
tr
lt
ele
pleo
ip
nraa
cmr
ipal
lil
ene
obo
flg
drea
ismr
te
ap
nirn
ce
esb
enlu
st
tse
im
irme
apa
tigr
oee
nsp
cln
aat
nns
im
ea
aa
ilgn
lued
tp
rla
aar
tne
ee
dc
ara
sr
fasn
ip
gdo
rbd
6a
agre
cid
1827
cixo
arlr
nse
dos
pf
cid
1828
oc
rti
erno
tgl
pp
ooi
ix
cne
otls
ns
ti
rno
imc
poa
ong
ner
slg
tao
hni
end
psg
aia
rnr
li
lm
em
loaidg
gpe
ra
mi
cid
1833
isa
nno
bf
ll
ui
cid
1859
rra
ee
pb
rm
ea
sind
ed
np
toa
sbi
ir
mtess
apo
gfe
lti
pinv
le
ae
nl
cid
1827
cid
1828
aa
asd
nth
ae
bf
acea
rs
elp
pe
coc
oti
rin
rv
ete
slw
py
ni
cid
1841
dh
niis
gs
ta
phls
ie
xo
eft
lo
shc
ea
ol
ppo
cos
oii
ntni
tot
lo
pfi
otch
ih
ne
tss
sm
il
nasr
ot
mthh
aeo
np
eeo
cid
1833
itthi
aen
nd
dois
cid
1859
tah
ne
ac
rse
emb
maetrw
dpe
phe
oon
nteh
et
oshm
fe
lad
ir
nits
ept
ah
cid
1827
cid
1828
cne
aba
nent
ddw
aebesn
ta
ethi
sce
os
ebm
cj
tea
ivcrt
etpc
lyah
nb
cid
1841
ee
isnim
thp
el
fit
fa
oetd
ci
ac
aosbthjeectl
ecnagnt
hbeo
sfilminpeliofiged
wash
tihche
lceanngbthe
eosf
tliimnea
te
cid
1841
cid
1833
wyfhoilclho
wcainn
gbefo
ersmtiumlaa
ted
following
formula
point
also
position
smartphone
distance
smartphone
static
object
can
simplified
length
line
cid
1841
cid
1841
cid
1833
cid
1859
can
estimated
following
formula
og
cid
1841
cid
1833
cid
3404
cid
1853
cid
1841
cid
1854
cid
1859
cid
3400
cid
1827
cid
1828
cid
3404
cid
1856
cid
3045
cid
1841
cid
1833
cid
3404
cid
3400
cid
1827
cid
1828
cid
3404
cid
1856
length
cid
1841
cid
1859
can
calculated
figu
cid
1853
cid
1854
6b
cid
3045
rincipal
point
camera
image
line
cid
1841
cid
1867
thelengthofogcanbecalculatedasfigure6b
oisprincipalpointofcameraimage
lineoois
tfo
hc
ea
ll
ne
gn
tg
ht
cid
1858
cid
1841
cid
1859
cu
calculated
figure
6b
principal
point
camera
image
line
cid
1841
cid
1867
thefocallength
thus
focal
length
cid
1858
thus
cid
1841
cid
1859
cid
3404
cid
113
cid
3493
cid
4666
cid
1841
cid
1867
cid
4667
cid
2870
cid
3397
cid
4666
cid
1867
cid
1859
cid
4667
cid
2870
cid
1841
cid
1859
cid
3404
cid
3493
cid
4666
cid
1841
cid
1867
cid
4667
cid
2870
cid
3397
cid
4666
cid
1867
cid
1859
cid
4667
cid
2870
figure
principal
distance
estimation
geometric
relation
smartphone
camera
control
points
static
object
interior
geometric
relation
smartphone
camera
figure
principal
distance
estimation
geometric
relation
smartphone
camera
figure6
principalofdistanceestimation
isgeometricrelationbetweensmartphonecameraand
control
points
static
object
interior
geometric
relation
smartphone
camera
co
inn
aro
dl
dp
io
tii
nts
sn
ins
cta
et
tc
ho
eb
pje
oct
tb
io
nis
oin
se
mrio
ar
rg
tpeo
hm
onet
er
ic
cid
1841
re
cid
3404
la
cid
4666
ti
cid
1850
cid
1499
cid
1851
cid
1499
cid
1852
cid
1499
cid
4667
rt
hh
ao
sn
ec
ea
nm
er
sa
imated
previous
cid
3016
cid
3016
cid
3016
ca
ac
dal
dc
iu
til
oa
nte
st
ih
ne
ed
tis
ht
ea
pc
oe
cid
1841
io
cid
1833
oi
fr
smctl
ay
ta
pn
hd
nm
cid
1841
rk
cid
3404
ed
cid
4666
cid
1850
cid
1499
cid
1851
cid
1499
cid
1856
cid
1852
cid
3032
cid
1499
cid
4667
hh
ae
sn
eth
ene
ec
tn
imtro
atll
ee
dd
ine
pro
rer
vγ
io
ua
ss
cid
3016
cid
3016
cid
3016
can
calculate
distance
cid
1841
cid
1833
directly
marked
cid
1856
controlled
error
cid
3032
sensors2018
18
2229
9of17
sensors
2018
18
17
sensors
2018
18
17
fo
ol
ll
lo
ow
wini
nag
gd
da
ari
rte
ei
ou
uns
esd
di
toc
oe
stc
chr
re
eee
epn
osiu
utit
gnr
ro
oos
sfs
ss
emr
rr
rao
ortr
rp
ih
fo
γn
ei
le
ss
cid
txh
ha
oa
toh
th
ho
cid
ehs
sh
hao
osl
lbd
de
et
tnh
ee
se
ets
sit
tmi
im
mata
aet
tde
ed
di
ppo
os
srei
tvi
io
oion
nu
iss
wacececpantacbalelc
ausla
ftienathl
esydsitsetamn
coeuotpgutd
irectlyandmarkeditasd
thenthecontrollederrorγasfollowing
acceptable
final
system
output
areusedtoscreenoutgrosserror
ifγislessthanthethreshold
theestimatedpositionisacceptableas
finalsystemoutput
cid
2011
cid
2011
cid
3404
cid
3404
cid
1313
cid
1313
cid
1856
cid
1856
cid
3045
cid
3398
cid
3398
cid
1856
cid
1856
cid
3032
cid
1313
cid
1313
cid
3045
cid
3032
cid
107
cid
107
experiments
experiments
experiments
section
details
experiments
represented
tested
system
large
indoor
section
details
experiments
represented
tested
system
large
indoor
spacei
nwthitihs
sae
crteiolant
ivdeeltyai
lcsoomfepxlipceartiemde
enntsvairroenrempernest
eanntedd
cowmepteasrteedd
othuer
spyossteitmionininagl
arregseuilntsd
owoirthsp
tahcee
space
relatively
complicated
environment
compared
positioning
results
wgriothunadre
tlrautitvhe
lycomplicatedenvironmentandcomparedthepositioningresultswiththegroundtruth
ground
truth
44
11
eexxppeerriimmeenntt
sseettuupp
4.1
experiment
setup
tthhee
eexxppeerriimmeenntt
wwaass
ccoonndduucctteedd
oonn
tthhee
ffiirrsstt
fflloooorr
ooff
wwaannlliinn
aarrtt
mmuusseeuumm
iinn
wwuuhhaann
uunniivveerrssiittyy
experiment
conducted
first
floor
wanlin
art
museum
wuhan
university
tthhee
mmuusseeuumm
hhaass
aabboouutt
88440000
mm2
bbuuiillddiinngg
aarreeaa
aanndd
iittss
ffiirrsstt
flfloooorr
hhaass
mmoorree
tthhaann
11000000
mm2
wwiitthh
aann
ooppeenn
museum
8400
m2
building
area
first
floor
1000
m2
open
ffiieelldd
aanndd
ssttaabbllee
iilllluummiinnaattiioonn
wwhhiicchh
iiss
aa
ttyyppiiccaall
llaarrggee
iinnddoooorr
sscceennee
ffiigguurree
77
iinn
oorrddeerr
ttoo
vveerriiffyy
tthhee
field
stable
illumination
typical
large
indoor
scene
figure
order
verify
eeffffeeccttiivveenneessss
ssttaattiicc
oobbjjeeccttsss
shhaallllb
beec
coommmmoonna
anndde
aesays-yt-ot-oc-actacthchin
inim
imagaeg
et
htehreeraer
aerteh
trheeregel
agslsasdso
doorsoirns
effectiveness
static
objects
shall
common
easy-to-catch
image
three
glass
doors
itnh
ethexep
eexrpimereinmtaelnstiatel
saitlel
falwl
hoifc
hwchainchb
ecasnee
bnea
tseaenny
patla
acneyo
fptlhaecero
oofm
th
fei
grouorem8
ftiwguored
o8o
st
widoe
ndtiofioerds
experimental
site
can
seen
place
room
figure
two
doors
aisd
ednotiofire1d
aasn
dd
odoor1o
r2
da
edoonort2h
saorue
tohno
tfhteh
seomutuhs
oeuf
tmhe
amnuds
eduomo
a3n
dlo
cdaoteosri3n
tlhoecanteosr
tihn
twhee
ncohrotshe
identified
door1
door2
south
museum
door3
locates
north
wthees
cehtohsree
ethgelsaes
sthdroeoer
gslaassss
tdaotiocros
bajse
csttsatainc
dobujseecdts
tahnedm
ufsoerdl
othcaetmin
gfo
locating
chose
three
glass
doors
static
objects
used
locating
ffiigguurree
77
tteesstt
eennvviirroonnmmeenntto
offt
htheep
prorpoopsoesdeds
yssytsetmem
ei
ew
wanalinnlianr
atmrt
umseuusmeu
ias
ius
tosiudtesildoeo
klooofkt
hoef
figure
test
environment
proposed
system
wanlin
art
museum
outside
look
tahret
marut
smeuumse
mb
ba
rce
aprheo
ptohsootofsi
nosfi
dinesliodoek
looonkt
ohne
fithres
tfflirosto
fr
loor
art
museum
photos
inside
look
first
floor
ffiiiggguuurrreee
88
th
htr
rhe
ere
ee
gegl
la
ags
slas
sd
dso
odo
ros
arss
sat
tsa
tsi
ic
cta
otb
bicj
je
eoc
ct
tbs
sj
ei
nct
tsh
hie
en
ex
xthp
pee
er
rei
im
mxpe
een
nrt
ti
ae
nc
ct
ar
ea
cd
oao
orr
re1
od
doo
oro
o1r
adn
nod
r2d
oo
oar
rn3
3d
rde
es
sop
poe
erc
c3t
iv
vre
eel
lsy
yp
ctively
sseennssoorrss
22001188
1188
2x2
29
1100
ooff
1177
used
iphone
6s
smartphone
take
images
offline
online
phases
including
trainiwnge
iumseadgeasn
foipr
hnoentweo6rsks
mreafertrpenhcoen
iemtoagtaesk
eanimd
ategsets
iminabgoetsh
ooftflheinr
eparoncdedonulriense
opf
hthaese
ssy
sitnecmlu
wdienrge
tcroanindiuncgteimd
aing
eas
cfoomrnpeuttwero
wrki
thre
tfeirteannc
xepim
garagpeshiacnsd
caterdst
ifmora
ag
epsu
roetlyh
ewrepbro-bcaesdeudr
essoloufttiohne
iyns
ttehmis
wcaesree
cthoen
dbautctteerdieisn
oaf
scmomarptpuhteornwesi
tdhot
nitoatn
coxnpsugmraep
hmicuschca
prdow
feorr
athpeu
grerloyuwnde
btr-buathse
odf
sspolauctei
ocno
orinditnhaitsecsa
fsoer
tahlle
bcoanttterroiel
spoofisnmtsa
ratrpeh
omneeassduorendo
tbcyo
nas
uhmie-tmaurgceht
pzotwse-r4
2t0hre
gtrootuanl
dsttarutitohno
hspi-atcaercgoeot
rdsiunravteeysifnogr
ainllsctrounmtroelnpt
ocinot
slatrde
mgeuaasnugrezdhobuy
achhiin-taa
feitgzutres
94
writtho
t2a
lmstmat
iponos
ihtioi-ntianrgge
etrsruorrv
feoyri
negveirnys
t1ru0m00e
nmt
cdios
talntdce
uangzhou
china
figure9
with2mmpositioningerrorforevery1000mdistance
figure
hi-target
zts-420r
total
station
used
measuring
space
coordinates
control
points
figure9
hi-targetzts-420rtotalstationisusedformeasuringspacecoordinatesofcontrolpoints
ground
truth
test
points
andgroundtruthoftestpoints
randomly
selected
twelve
places
test
points
photographed
plenty
static
objects
randomly
selected
twelve
places
test
points
photographed
plenty
static
objects
images
test
points
distributed
throughout
room
evenly
figure
12
images
allthetestpointsaredistributedthroughouttheroomevenly
figure12
4.2
performance
static
object
recognition
4.2
performanceofstaticobjectrecognition
phase
static
object
detection
identification
data
augmentation
training
inthephaseofstaticobjectdetectionandidentification
wediddataaugmentationfortraining
images
order
prevent
network
overfitting
improve
success
rate
static
object
imagesinordertopreventthenetworkfromoverfittingandimprovethesuccessrateofstaticobject
detection
randomly
blocked
30
area
static
target
area
training
image
simulate
detection
werandomlyblocked30
areaofthestatictargetareainthetrainingimagetosimulate
actual
situation
static
objects
may
blocked
pedestrians
things
theactualsituationthatthestaticobjectsmaybeblockedbypedestriansorotherthings
therewere
302
training
images
total
adopted
strategy
transfer
learning
retrained
302trainingimagesintotal
weadoptedthestrategyoftransferlearning
andretrainedthenetworked
networked
using
training
images
basis
model
trained
imagenet
49
using
byusingtrainingimagesonthebasisofamodeltrainedbyimagenet
49
usingthecross-validation
cross-validation
method
randomly
selected
50
images
training
25
testing
method
werandomlyselected50
oftheimagesfortraining
25
fortesting
and25
forvalidation
25
validation
accurate
precision
ap
detection
identification
shown
table
theaccurateprecision
ap
ofthedetectionandidentificationisshownintable1
table
performance
faster-rcnn
network
detect
identify
static
objects
ground
truth
table1
performanceoffaster-rcnnnetworktodetectandidentifystaticobjects
thegroundtruth
test
images
offered
human
eye
judgement
oftestimagesisofferedbyhumaneyejudgement
phase
static
object
accurate
precision
ap
phase
dosotra1ti
cobject
acc1u00ra
te
precision
ap
door2d
oor1
100
100
training
door3d
oor2
90.9
100
training
meand
oor3
97.0
90.9
testing
door1
door2m
deoaonr3
100
97.0
testing
door1
door2
door3
100
accuracy
coordinates
control
points
test
image
determined
homographic
matrix
cid
1834
determines
final
positioning
accuracy
large
extend
manually
thea
cid
3035
cid
3042
cid
3040
cu
cid
3042
racyofcoordinatesofcontrolpointsintestimageisdeterminedbythehomographic
measured
recorded
ground
truth
control
points
pixels
test
images
pixels
error
matrix
determines
final
positioning
accuracy
large
extend
manually
homo
compared
calculation
results
cid
1829
cid
1842
cid
1846
errors
pixel
coordinates
matching
measuredandrecordedthegroundtruthofcontrolpoints
pixelsintestimages
with2
3pixelserror
showed
figure
10
mostly
fall
within
ten
pixels
considered
acceptable
sensors2018
18
2229
11of17
andcomparedthemwiththecalculationresultscpt
theerrorsofpixelcoordinatesformatching
sensors
2018
18
11
17
asshowedinfigure10
mostlyfallwithintenpixels
whichweconsideredasacceptable
25
20
15
10
10
11
12
13
14
15
16
17
18
19
20
21
figure
10
accuracy
control
points
coordinates
test
images
horizontal
axis
index
test
images
vertical
axis
pixel
error
obtained
pixel
coordinates
control
points
ground
truth
size
images
photographed
iphone
6s
3024
4032
pixels
test
images
size
time
cost
static
object
recognition
phase
0.3
4.3
positioning
results
analysis
part
demonstrates
positioning
results
evaluated
accuracy
euclidean
distance
calculated
position
ground
truth
position
figure
11
illustrates
relationship
distance
user-static
object
positioning
error
within
range
40
significant
correlation
distance
positioning
precision
test
points
achieved
accuracy
1.5
within
figure
11
relation
position
error
distance
figure
12
plan
map
experimental
site
green
circles
map
error
boundaries
centers
circles
represent
test
points
words
near
circles
0.14
means
positioning
accuracy
error
test
point
0.14
just
figure
shows
nearly
test
points
achieve
accuracy
within
except
two
test
points
caused
unreasonable
distribution
control
points
see
section
discussion
plan
map
can
see
system
ability
locate
smartphone
within
accuracy
large
indoor
scene
rorre
lexip
index
images
1.6
1.4
1.2
0.8
0.6
0.4
0.2
14
19
24
29
34
39
rorre
gninoitisop
sensors
2018
18
11
17
25
20
15
10
10
11
12
13
14
15
16
17
18
19
20
21
fifgiugurer
e101
aacccucruarcayc
yofo
fcocnotnrtorlo
plpoionitnst
scocoorodrdiniantaetse
sini
ntetsets
timimagaegse
hteh
ehohroirzioznotnatla
alxaixsi
sisi
sthteh
einidndexe
xofo
tetsets
itmimagaegse
theh
evevretrictiacla
alxaixsi
sisi
sppixiexle
elrerrorro
rbbetewtweeene
nobotbatianiende
dppixiexle
clocoorodrdiniantaetse
sofo
fcocnotnrtorlo
plpoionitnst
sanadnd
grgoruoundnd
trturuthth
size
images
photographed
iphone
6s
3024
4032
pixels
test
images
thesizeofimagesphotographedbyiphone6sis3024
4032pixels
foralloftestimageswith
size
time
cost
static
object
recognition
phase
0.3
suchsize
timecostinstaticobjectrecognitionphaseareabout0
3s
4.3
positioning
results
analysis
4.3
positioningresultsandanalysis
part
demonstrates
positioning
results
evaluated
accuracy
euclidean
thispartdemonstratespositioningresults
weevaluatedtheaccuracythrougheuclideandistance
distance
calculated
position
ground
truth
position
figure
11
illustrates
relationship
calculated
position
ground
truth
position
figure
11
illustrates
relationship
distance
distance
user-static
object
positioning
error
within
range
40
significant
user-staticobject
andpositioningerror
withintherangeof40m
thereisnosignificantcorrelation
correlation
distance
positioning
precision
test
points
achieved
accuracy
distance
positioning
precision
test
points
achieved
accuracy
1.5
1.5
within
andmostofthemarewithin1m
distance
figure
11
relation
position
error
distance
figure
12
plan
map
experimental
site
green
circles
map
error
boundaries
centers
circles
represent
test
points
words
near
circles
0.14
means
positioning
accuracy
error
test
point
0.14
just
figure
shows
nearly
test
points
achieve
accuracy
within
except
two
test
points
caused
unreasonable
distribution
control
points
see
section
discussion
plan
map
can
see
system
ability
locate
smartphone
within
accuracy
large
indoor
scene
rorre
lexip
index
images
1.6
1.4
1.2
0.8
0.6
0.4
0.2
14
19
24
29
34
39
rorre
gninoitisop
distance
figure11
relationbetweenpositionerroranddistance
figure12istheplanmapoftheexperimentalsite
greencirclesonthemapareerrorboundaries
andcentersofthesecirclesrepresenttestpoints
thewordsnearcirclessuchas
14m
meansthat
thepositioningaccuracyerrorofthistestpointis0
14m
justasthefigureshows
nearlyalltestpoints
achieveaccuracywithin1m
exceptfortwotestpoints
whichiscausedbyunreasonabledistribution
ofcontrolpoints
seesection5
discussion
fromtheplanmapwecanseethatoursystemhasability
tolocatesmartphonewithinaccuracyof1minsuchalargeindoorscene
sensors2018
18
2229
12of17
sensors
2018
18
12
17
ffiigguurree1
122
pllaannm
maappo
offe
exxppeerrimimeennttaalls
sitietea
annddp
poossitiitoionnininggr
reessuultlsts
55
diissccuussssiioonn
llaarrggeei
ninddoooorrs
psapcaecsews
withithw
iwdiedfiee
flidelodf
voifs
vioisnioann
danstda
bslteabillleu
milliunmatiinonat
isounc
hsuaschm
auss
emuumsse
ummasl
smaanldls
aairnpdo
artisr
pporrotsv
dperoavpipdleic
aapbpleliecnavbilreo
ennmveirnotnsmfoernvtiss
ufoarl
pvoissuitaiol
npionsgit
ihoneinncge
hweenucsee
wcoem
umseo
ncosmtamticoonb
sjetacttisc
inobtjheecstes
sipna
ctehsesaes
rsepfearceensc
eass
torelofecraetnecsems
atrotp
lhoocnaetec
asmmearratpvhiaovnies
ucaalmalegroar
ivthiam
sv
isouuarl
eaxlpgeorriimthemnts
noaunr
aerxtpmeurismeuemnt
sinu
gagne
asrtst
mthuasteouumrs
syusgtegmesitss
athbalet
otoura
cshyisetvemep
ios
saibtiloen
tion
gacahciceuvrea
pcyoswitiitohninin1g
macceuvreancyth
watitthhien
e1x
pme
reivmeenn
tthaalte
nthvei
reoxnpmereinmteisntcaolm
enpvliicraotnemdeinntv
iiss
icoonm
plicated
vision
55.1
exxppeerriimmeennttaalld
difififfcicuultltieiessa
annddc
crritieterriaiaf
oforrc
chhoooossininggs
statatitcico
obbjejecctsts
tthhee
ssttaattiicc
oobbjjeeccttss
ddoooorrss
wwee
chchooses
eini
nexepxepreimrimenetnalt
aslitesi
aterea
arectuacatlulya
clloymcpolmicpatleicda
tteod
prtoocpesrso
cfoesrs
fvoirsuaavl
iaslugaolraitlhgmor
bthemca
ubsee
ctahuesye
atrhee
myaadree
omf
agdlaessoefsg
slainsscees
lassins
cdeoogrlas
sasred
otroarnssparaeretnrat
tshpeairr
etnext
tuthree
iirn
tiemxtaugree
iisn
dimepaegnediss
odne
pthene
dosuotsnidthe
eenouvitrsoidnemeennvti
wonhmicehn
cta
nw
chhicahngcaen
dcuhea
tnog
medanuye
tfoacmtoarns
lifkaect
woresa
tlhikeer
wtiemateh
esre
atsiomne
islleuamsoinna
nilclue
maninda
snhcoeoatnindg
sahnogolteisn
getacn
gtlheiss
echtca
rtachtiesricshtiacr
alicmteirtsis
ptiecrlfiomrmitsanpceer
foofr
mfeaantucree
oefxfteraatcutiroene
xatnrda
ctfieoantuarne
dmfeaatcthuirnegm
aintc
hthinisg
cainset
htihsec
asstera
ttehgeys
ttrhaatte
gdyesthigantidnges
iag
nfeinagtuaref
efailttuerre
tfio
ltgeert
thoogmetohnoymmoyn
pyominytsp
oofi
nfetsatoufrfee
aptouirnetsp
forionmts
rferfoemrenrecfee
rimenacgeeism
dairgeecstldyi
aesc
ttlhy
ea
fsintahle
cfionnatrloclo
pnotrinotlsp
ioni
ntetsst
inimtaesgte
misa
ngoet
irsobnuosttr
oabtu
fsitr
sta
tpfiixreslts
pofi
xceolnstoroflc
opnotirnotls
pino
itnetsst
iinmtaegsetsi
mmaagye
nsomt
abye
nexottrbaceteedxt
raasc
fteeadtuarse
fpeaotiunrtes
ioni
nsutsc
hi
ncosnudchiticoonn
cihtiooons
icnhgo
tohsein
ngetahreesnt
enaeriegshtbnoerig
fhebatourrfee
aptouirnetsp
oinin
ttessitn
imteasgteim
inacgreeainscerse
pasixeesl
pcioxoerldcionoartde
inerartoere
rsreocro
nsdelcyo
idt
liys
hitarisd
htoar
ddetsoigdne
sai
gronbausrto
bfeuasttufreea
ftiultreer
fitlot
esrelteocts
etlheec
tctohrereccot
rornecet
foronme
fhroumgeh
aumgoeuanmt
oouf
fnetaotufrfee
aptouirnetsp
woihnetsn
wfahcienngf
cahcainnggecahbalneg
iemaabglee
itmexatugeret
txhtuurse
wteh
duess
iwgneedde
tshige
nsterdattehgey
sttora
gteegty
ctoongtreotlc
opnotirnotlsp
ioni
nttessitn
imtesatgiems
afgreosmf
robmothb
ohthomhoomgroagprhaipch
micamtraixtr
ix
cid
1834
aanndd
ccoonnttrrooll
ppooiinnttss
inin
cid
3035
cid
3042
cid
3040
ho
cid
3042
mo
rreeffeerreenncceei
mimaaggeessi
ninssteteaadd
byyt
thhiisss
sttrraatteeggyy
htheep
prraacctitcicaaliltiytyo
offt
thhees
syysstteemmi
innccrreeaasseess
hhoowweevveerr
inno
orrddeerr
ttoog
geenneerraatteem
moorreef
feeaattuurreep
pooiinnttsst
iinnccrreeaassee
aaccccuurraaccyy
ooff
hhoommooggrraapphhiicc
mmaattrriixx
cid
1834
statatitcico
obbjejecctstsw
witithh
cid
3035
cid
3042
cid
3040
cid
3042
nnoonn
ttrraannssppaarreennttm
maateterriaiallw
wililllb
beeb
beetttteerr
altlthhoouugghhw
weeu
usseeddd
doooorrssa
ass
ssttaattiicc
oobbjjeeccttss
iinn
oouurr
eexxppeerriimmeennttss
aannyyththininggc
caannb
bees
seetta
asss
sttaattiicc
oobbjjeeccttss
iinn
iinnddoooorr
sscceenneess
wwhhiicchh
iinnccrreeaasseess
tthhee
pprraaccttiiccaabbiilliittyy
ooff
tthhee
mmeetthhoodd
bbeessiiddeess
ccoonnttrrooll
ppooiinnttss
oonn
ssttaattiicc
oobbjejeccttss
sshhaallll
bbee
cchhoosseenn
pprrooppeerrllyy
ttwwoo
tteesstt
ppooininttss
wwitithh
hhigighheerr
ppoossititioionniinngg
aaccccuurraaccyy
eerrrroorr
11.4
455m
ma
anndd1
1.2
255m
mr
eressppeecctitviveelyly
reessuultleteddf
rfroommi
mimpprrooppeerrd
disistrtribibuuttioionno
ccoonnttrroollp
pooinintsts
onnllyy
ddoooorr11
caannb
bees
seeeenno
onnt
thheesseet
twwoop
plalacceess
annddt
thheec
coonnttrroollp
pooininttssi
nini
mimaaggeessw
weerree
rroouugghhllyy
ddisisttrriibbuutteedd
oonn
aa
sstrtraaigighhtt
lilninee
ootthheerr
tteesstt
ppooiinnttss
tthhaatt
hhaavvee
pprrooppeerr
oobbsseerrvvaattiioonn
ccoonnddiittiioonn
rreeaacchheeddi
dideeaalla
accccuurraaccyy
geenneerraallllyy
coonntrtroollp
pooinintstss
shhaallllb
beee
eaassyy-t-oto-c-caapptuturreei
nini
mimaaggee
witihthc
chhaarraaccteterrss
ddififffeerreenntt
ffrroommn
neeigighhbboorriinngg
rreeggiioonnss
ssuucchh
aass
tthhoossee
wwiitthh
uunniiqquuee
ccoolloorr
oorr
eeddggee
ppooininttss
eettcc
aanndd
tthheeyy
shall
distributed
evenly
throughout
static
objects
static
objects
chosen
referencessensors2018
18
2229
13of17
shallbedistributedevenlythroughoutthestaticobjects
staticobjectschosenasreferences
small
otherwise
control
points
will
distributed
close
output
accurate
positioningresults
5.2
evaluation
vision-basedindoorpositioningproblemhasalwaysbeenahotresearchissueinrecentyears
however
methodsthatarecompletelybasedonvisionalgorithmsandconductedonsmartphones
aremuchlessfrequent
andeachmethodhasitsownscopeofapplication
duetothelowcostor
evenwithouttheneedforanyinfrastructuresaswellasthepopularityofsmartphones
webelieve
kind
method
promising
future
however
methods
systems
designed
farmayhavetheirownshortcomingswhenimplementedinlargeindoorscenes
inthefollowing
wewilldiscussandevaluatethesestate-of-artofpurelyvisualindoorpositioningmethodsorsystems
performing
large
indoor
spaces
based
smartphone
cameras
system
weexcludedmethodsthatintegratedsmartphonecamerawithrfsignals
suchaswi-fi
bluetooth
wirelesslanandsoon
becauseoursystemusesvisionalgorithmonly
andthuswithout
anyinfrastructures
thesignpostsystemdesignedbymullonietal
39
detectsunobtrusivefiduciarymarkersthat
contain
position
information
different
places
location
users
strategy
easy
transplant
due
low
cost
low
computation
power
cellphones
users
find
nearest
marker
tiny
markers
made
large
size
inconvenient
peopleinlargeindoorspacessincetheymayhavetomovealongdistancetofindandscanamarker
hileetal
34
builtanovelsystemtofindpreciselocationsandorientusersbymatchingfeatures
extracted
smartphone
images
relevant
sections
floorplan
map
however
creativesystemisdesignedforenvironmentslikehallways
itmayperformpoorlyinlargeindoor
scenes
becausetheavailablefeaturessuchasedgeorcornersaremuchlessabundantinlargespaces
thedistanceestimationalgorithmbywerneretal
37
isadoptedbyoursystemasdistanceestimation
module
section3
3.2
thisalgorithmisabletocalculateaccuratedistancesbetweencamerasand
reference
targets
however
since
trilateral
location
method
requires
least
three
reference
targetpositionsaswellasthecorrespondingdistancestothecamera
onedistanceforeachimage
algorithm
performs
better
environments
corridors
narrow
width
requiring
onetarget
distanceonly
thanwideopenindoordistricts
requireatleastthreetargets
distances
van
opdenbosch
et
al
50
realized
indoor
positioning
image
recognition
order
achieve
meter-accuratelocalization
theyphotographedimagesinevery1m
1mgridcell
using16viewing
anglesforeachspot
however
thisstrategyhaslowefficiencyinlargerroomsbecausethevastnumber
ofimagesinthedatasetwillresultinahugecomputationcostandincreasetheburdenofsmartphones
web
servers
kawaji
et
al
51
realized
indoor
positioning
large
indoor
space
railway
museum
theyusedomnidirectionalpanoramicimagescapturedbyanomnidirectionalcameraand
supplementalimagescapturedbydigitalcamerastobuildadatasetandmatchedthetestdigitalcamera
imageswithreferenceimagesinthedatasettolocateusers
sinceomnidirectionalpanoramicimages
aresuitableforlargescenes
thismethodiseffectiveforlocalizationinlargeindoorspaces
however
theoutputlocationoftestimagesisthesameasthatoftheomnidirectionalpanoramicimages
achieve
relatively
accurate
position
deretey
et
al
52
proposed
method
matching
cameraimageswith3dmodelsofindoorscenesbyasimultaneouslocalizationandmapping
slam
systemtorealizepositioning
althoughitrequiresa3dmodelbuildingprocessinanofflinephase
thinkitisapromisingmethodduetothedevelopmentofslamtechnology
xuelal
53
proposed
anovelmonocularvisualmethodtolocatepositionsinofficesbasedonceilings
thisstrategymay
notfunctioninlargeindoorsceneslikemuseumsorairportsbecausetheseplacesusuallydonothave
aplanarceilingfloorwithaseriesofchessboard-likeblockslikeoffices
oursolutiontolocateusers
ismoreworkableinlargeindoorenvironments
staticobjectssuchasdoorsandwindowsarenotsensors2018
18
2229
14of17
onlycommoninindoorscenes
butalsorelativelylargeenoughtobecapturedfromalongdistance
thelongestdistanceinourexperimentisnearly40m
withapositioningaccuracyof0
7m
therearesomefactorsthatmayinfluencetheperformanceofoursystem
illuminationofthe
indoorscenesaswellasshootinganglesmaychangeimagesandhaveanimpactonfeaturematching
inaddition
theperformanceofthesmartphonesmayalsoaffectthefinalresult
thesystemdoes
notconsumemuchbatterypowerofsmartphonesasoursystemisweb-basedandthesmartphone
onlytakeimagesasinput
theclarityofimagestakenbysmartphonecamerasishighenoughforour
task
thedistortionofimagesbydifferentsmartphonesmaychangethefinalpositionoutput
acameracalibrationprocesscanfixthisproblem
detailscanbefoundinourpreviousresearch
inthefuture
wewilltrytoimprovetherobustnessofoursystemandexperimentinotherlargeindoor
spaceswithmoreroomsandmorecomplextopologies
conclusions
inthispaper
apositioningsysteminlargeindoorspacesbyusingsmartphonecamerasbasedon
staticobjectsisproposed
oursystemusessmartphoneimagestodetectspecificstaticobjectsindoors
andcalculateusers
position
thesystemimitatesthehumanbrain
scognitivemodeandintegrates
algorithmsofdeeplearningandcomputervision
weexperimentedinanartmuseumwithalarge
indoorareaandacomplexvisualenvironment
experimentalresultsshowthatthismethodhasthe
abilitytoachievethepositioningaccuracywithin1minadistancerangeof40mindoors
webelieve
thatithaspotentialforwideapplicationinlargeindoorscenes
authorcontributions
thispaperisacollaborativeworkbyallauthors
proposedtheidea
implemented
thesystem
performedtheexperiments
analyzedthedataandwrotethemanuscript
andd
helpedto
proposetheidea
givesuggestionsandrevisetheroughdraft
helpedwithallofexperiments
especiallydata
acquisition
helpedrevisedcodeandhelpedtodosomeoftheexperiments
funding
study
supported
national
key
research
development
program
china
2016yfb0502201
2016yfb0502202
nsfc
91638203
state
key
laboratory
research
expenses
ofliesmars
conflictsofinterest
theauthorsdeclarenoconflictofinterest
references
keefe
placeunitsinthehippocampusofthefreelymovingrat
exp
neurol
1976
51
78
109
crossref
keefe
dostrovsky
thehippocampusasaspatialmap
preliminaryevidencefromunitactivityinthe
freely-movingrat
brainres
1971
34
171
175
crossref
fyhn
molden
witter
moser
moser
spatialrepresentationintheentorhinalcortex
science2004
305
1258
1264
crossref
pubmed
sargolini
fyhn
hafting
mcnaughton
witter
moser
moser
conjunctive
representationofposition
direction
andvelocityinentorhinalcortex
science2006
312
758
762
crossref
pubmed
wu
chen
chen
visualpositioningindoors
humaneyesvs
smartphonecameras
sensors2017
17
2645
crossref
pubmed
ruizhi
liang
indoorpositioningwithsmartphones
thestate-of-the-artandthechallenges
actageod
cartogr
sin
2017
46
1316
1326
crossref
youssef
agrawala
thehoruswlanlocationdeterminationsystem
inproceedingsofthe3rd
internationalconferenceonmobilesystems
applications
andservices
seattle
wa
usa
8june2005
acm
newyork
ny
usa
2005
pp
205
218
bahl
padmanabhan
radar
in-building
rf-based
user
location
tracking
system
inproceedingsoftheieeeinfocom2000conferenceoncomputercommunications
nineteenthannual
jointconferenceoftheieeecomputerandcommunicationssocieties
cat
00ch37064
telaviv
israel
26
30march2000
volume2
pp
775
784
sensors2018
18
2229
15of17
vaupel
seitz
kiefer
haimerl
thielecke
wi-fi
positioning
system
considerations
devicecalibration
inproceedingsofthe2010internationalconferenceonindoorpositioningandindoor
navigation
ipin
zurich
switzerland
15
17september2010
pp
10
hansen
wind
jensen
thomsen
algorithmicstrategiesforadaptingtoenvironmentalchanges
in802
11locationfingerprinting
inproceedingsofthe2010internationalconferenceonindoorpositioning
andindoornavigation
ipin
zurich
switzerland
15
17september2010
pp
10
11
teuber
eissfeller
wlan
indoor
positioning
based
euclidean
distances
fuzzy
logic
proceedings
3rd
workshop
positioning
navigation
communication
lower
saxony
germany
16march2006
pp
159
168
12
haverinen
kemppainen
global
indoor
self-localization
based
ambient
magnetic
field
rob
auton
syst
2009
57
1028
1035
crossref
13
chen
kuusniemi
chen
pei
kröger
chen
informationfilterwithspeeddetectionfor
indoorbluetoothpositioning
inproceedingsofthe2011internationalconferenceonlocalizationandgnss
icl-gnss
tampere
finland
29
30june2011
pp
47
52
14
chen
kuusniemi
chen
liu
pei
ruotsalainen
chen
constraintkalmanfilterfor
indoorbluetoothlocalization
inproceedingsofthe201523rdeuropeansignalprocessingconference
eusipco
nice
france
31august
4september2015
pp
1915
1919
15
chen
pei
kuusniemi
chen
kröger
chen
bayesianfusionforindoorpositioningusing
bluetoothfingerprints
wirel
pers
commun
2013
70
1735
1745
crossref
16
bargh
degroote
indoorlocalizationbasedonresponserateofbluetoothinquiries
inproceedings
first
acm
international
workshop
mobile
entity
localization
tracking
gps-less
environments
sanfrancisco
ca
usa
19september2008
acm
newyork
ny
usa
2008
pp
49
54
17
chan
intri
contour-based
trilateration
indoor
fingerprint-based
localization
ieeetrans
mob
comput
2017
16
1676
1690
crossref
18
quuppacompany
availableonline
http://quuppa.com/company/(accessedon10july2018).
19
lakmali
databasecorrelationforgsmlocationinoutdoor
indoorenvironments
inproceedings
ofthe4thinternationalconferenceoninformationandautomationforsustainability
iciafs
colombo
srilanka
12
14december2008
20
zhao
standardizationofmobilephonepositioningfor3gsystems
ieeecommun
mag
2002
40
108
116
crossref
21
want
hopper
falcao
gibbons
theactivebadgelocationsystem
acmtrans
inf
syst
1992
10
91
102
crossref
22
ward
jones
hopper
anewlocationtechniquefortheactiveoffice
ieeepers
commun
1997
42
47
crossref
23
priyantha
chakraborty
balakrishnan
thecricketlocation-supportsystem
inproceedingsofthe
6thnnualinternationalconferenceonmobilecomputingandnetworking
boston
ma
usa
11august
2011
acm
newyork
ny
usa
2000
pp
32
43
24
kim
kwak
lee
kwon
amulti-prongedapproachforindoorpositioningwithwifi
magnetic
andcellularsignals
inproceedingsofthe2014internationalconferenceonindoorpositioningandindoor
navigation
ipin
busan
korea
27
30october2014
pp
723
726
25
jeon
kong
nam
yim
indoor
positioning
system
using
bluetooth
rssi
accelerometerandabarometeronasmartphone
inproceedingsofthe201510thinternationalconference
onbroadbandandwirelesscomputing
communicationandapplications
bwcca
krakow
poland
6november2015
pp
528
531
26
chen
wu
jin
chen
intelligentfusionofwi-fiandinertialsensor-basedpositioning
systemsforindoorpedestriannavigation
ieeesens
2014
14
4034
4042
crossref
27
li
zhuang
zhang
lan
niu
el-sheimy
animprovedinertial
wifi
magneticfusion
structureforindoornavigation
inf
fusion2017
34
101
119
crossref
28
liu
chen
li
chen
guo
cao
pan
scenerecognitionforindoorlocalizationusing
amulti-sensorfusionapproach
sensors2017
17
2847
crossref
pubmed
29
becker
ahuja
implementingreal-lifeindoorpositioningsystemsusingmachinelearningapproaches
inproceedingsofthe20178thinternationalconferenceoninformation
intelligence
systems
applications
iisa
larnaca
cyprus
27
30august2017
pp
sensors2018
18
2229
16of17
30
gao
ye
wang
smartphoneindoorlocalizationbyphoto-takingoftheenvironment
inproceedings
ofthe2014ieeeinternationalconferenceoncommunications
icc
sydney
australia
10
14june2014
pp
2599
2604
31
tian
gao
bian
ye
wang
wang
li
towardsubiquitousindoorlocalizationservice
leveragingenvironmentalphysicalfeatures
inproceedingsoftheieeeinfocom2014
ieeeconference
oncomputercommunications
toronto
canada
27april
2may2014
pp
55
63
32
shafer
krumm
brumitt
meyers
czerwinski
robbins
theneweasylivingprojectat
microsoftresearch
inproceedingsofthe1998jointdarpa
nistsmartspacesworkshop
gaithersburg
md
usa
30
31july1998
pp
30
31
33
mautz
indoorpositioningtechnologies
habilitationthesis
instituteofgeodesyandphotogrammetry
departmentofcivil
environmentalandgeomaticengineering
ethzurich
zurich
switzerland
2012
34
hile
borriello
positioningandorientationinindoorenvironmentsusingcameraphones
ieeecomput
graph
appl
2008
28
32
39
crossref
35
kohoutek
mautz
donaubauer
real-time
indoor
positioning
using
range
imaging
sensors
proceedings
real-time
image
video
processing
2010
brussels
belgium
may
2010
volume7724
pp
36
kim
jun
vision-basedlocationpositioningusingaugmentedrealityforindoornavigation
ieeetrans
consum
electron
2008
54
954
962
crossref
37
werner
kessel
marouane
indoorpositioningusingsmartphonecamera
inproceedingsof
2011
international
conference
indoor
positioning
indoor
navigation
guimaraes
portugal
21
23september2011
crossref
38
möller
kranz
huitl
diewald
roalter
amobileindoornavigationsysteminterfaceadapted
tovision-basedlocalization
inproceedingsofthe11thinternationalconferenceonmobileandubiquitous
multimedia
mum2012
ulm
germany
6december2012
pp
10
39
mulloni
wagner
barakonyi
schmalstieg
indoorpositioningandnavigationwithcamera
phones
ieeepervasivecomput
2009
22
31
crossref
40
ganick
ryan
lightpositioningsystemusingdigitalpulserecognition
patent824
846
7b1
26july2011
41
ruotsalainen
kuusniemi
bhuiyan
chen
chen
two-dimensional
pedestrian
navigationsolutionaidedwithavisualgyroscopeandavisualodometer
gpssolut
2013
17
575
586
crossref
42
ruotsalainen
visualgyroscopeandodometerforpedestrianindoornavigationwithasmartphone
proceedings
25th
international
technical
meeting
satellite
division
institute
navigation
iongnss2012
nashville
tn
usa
17
21september2012
pp
2422
2431
43
ren
girshick
sun
fasterr-cnn
towardsreal-timeobjectdetectionwithregionproposal
networks
ieeetrans
patternanal
mach
intell
2017
39
1137
1149
crossref
pubmed
44
simonyan
zisserman
verydeepconvolutionalnetworksforlarge-scaleimagerecognition
arxiv
2014
arxiv
1409.1556
45
zuxun
jianqing
digitalphotogrametry
2nded
wuhanunivertypress
wuhan
china
2002
46
keypoints
lowe
distinctiveimagefeaturesfrom
int
comput
vis
2004
60
91
110
crossref
47
fischler
bolles
randomsampleconsensus
aparadigmformodelfittingwith
commun
acm
1981
24
381
395
crossref
48
zhang
aflexiblenewtechniqueforcameracalibration
ieeetrans
patternanal
mach
intell
2000
22
1330
1334
crossref
49
deng
dong
socher
li
li
li
imagenet
alarge-scalehierarchicalimagedatabase
inproceedingsofthe2009ieeeconferenceoncomputervisionandpatternrecognition
miami
fl
usa
20
25june2009
pp
248
255
50
vanopdenbosch
schroth
huitl
hilsenbeck
garcea
steinbach
camera-basedindoor
positioningusingscalablestreamingofcompressedbinaryimagesignatures
inproceedingsofthe2014
ieeeinternationalconferenceonimageprocessing
icip
paris
france
27
30october2014
pp
2804
2808
51
kawaji
hatada
yamasaki
aizawa
image-based
indoor
positioning
system
fast
image
matchingusingomnidirectionalpanoramicimages
inproceedingsofthe1stacminternationalworkshop
onmultimodalpervasivevideoanalysis
firenze
italy
29october2010
acm
firenze
italy
2010
pp
sensors2018
18
2229
17of17
52
deretey
ahmed
marshall
greenspan
visualindoorpositioningwithasinglecamera
usingpnp
inproceedingsofthe2015internationalconferenceonindoorpositioningandindoornavigation
ipin
banff
ab
canada
13
16october2015
pp
53
xu
han
tan
li
ceiling-basedvisualpositioningforanindoormobilerobotwithmonocular
vision
ieeetrans
ind
electron
2009
56
1617
1628
2018bytheauthors
licenseemdpi
basel
switzerland
thisarticleisanopenaccess
articledistributedunderthetermsandconditionsofthecreativecommonsattribution
ccby
license
http://creativecommons.org/licenses/by/4.0/).