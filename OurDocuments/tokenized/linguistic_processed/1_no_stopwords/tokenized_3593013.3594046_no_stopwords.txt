unfair
search
engine
manipulation
undetectable
amortized
inequity
abstract
tim
de
jonge
tim.dejonge@ru.nl
radboud
university
nijmegen
nijmegen
netherlands
djoerd
hiemstra
hiemstra@cs.ru.nl
radboud
university
nijmegen
nijmegen
netherlands
retrieval
systems
fairness
concerns
broad
modern
society
increasingly
relies
information
retrieval
systems
answer
various
information
needs
since
impacts
society
many
ways
great
deal
work
ensure
fairness
systems
prevent
societal
harms
prevalent
risk
failing
model
entire
system
nefarious
actors
can
produce
harm
outside
scope
fairness
metrics
demonstrate
practical
possibility
risk
unfair
ranking
system
achieves
performance
measured
fairness
competitive
current
state-of-the-art
simultaneously
ing
manipulative
setup
unfair
demonstrates
adhering
fairness
metric
amortized
equity
can
insufficient
prevent
search
engine
manipulation
possibility
manipulation
passing
fairness
metric
discourages
imposing
fairness
metric
ahead
time
motivates
instead
holistic
approach
fairness
assessments
ccs
concepts
information
systems
learning
rank
keywords
fairness
information
retrieval
search
engine
manipulation
effect
exposure
unfair
acm
reference
format
tim
de
jonge
djoerd
hiemstra
2023
unfair
search
engine
manip
ulation
undetectable
amortized
inequity
2023
acm
conference
fairness
accountability
transparency
facct
23
june
12
15
2023
chicago
il
usa
acm
new
york
ny
usa
10
pages
https://doi.org/10.
1145
3593013.3594046
introduction
modern
society
increasingly
relies
information
retrieval
systems
answer
various
information
needs
ranging
high
impact
applications
like
healthcare
16
automated
fact
checking
39
everyday
problems
fashion
matching
46
music
recommendation
25
since
information
retrieval
systems
impact
society
many
ways
great
deal
work
ensure
fairness
systems
easy
see
automated
fact
checking
requires
care
nearly
information
spectrum
efforts
increase
fairness
systems
22
efforts
greater
good
many
authors
cite
harms
aim
address
15
risk
fairness
interventions
deployed
situations
mitigate
harm
address
fairness
metric
kept
use
although
adequately
measure
harm
situation
selbst
et
al
provide
excellent
overview
difficulties
ab
stracting
complicated
notion
fairness
indicating
five
traps
fair-ml
work
falls
first
foremost
fram
ing
trap
failure
model
entire
system
social
criterion
fairness
will
enforced
means
algorithm
can
appear
fair
model
algorithm
causes
societal
harm
outside
scope
assessment
44
theo
retical
possibility
framing
trap
well-established
little
practical
research
demonstrating
harms
enter
system
demonstrate
dangers
framing
trap
un
fair
novel
ranking
system
achieves
performance
mea
sured
fairness
competitive
current
state-of-the-art
clearly
manipulative
setup
unfair
demonstrates
failing
model
entire
system
can
result
search
engine
manipulation
adhering
specific
fairness
metric
amortized
equity
manipulating
amortized
inequity
possible
imposing
fairness
metric
ahead
time
might
insufficient
prevent
societal
harm
motivates
holistic
approach
fairness
assessments
26
section
will
introduce
search
engine
manipulation
harm
information
retrieval
section
provide
technical
specification
model
built
information
retrieval
system
section
look
amortized
equity
common
fairness
metric
introduce
metric
assess
search
engine
manipulation
section
introduce
ranking
system
unfair
illustrate
ranking
systems
bypass
carelessly
applied
fairness
metrics
section
show
experimental
setup
results
thereof
section
discuss
findings
provide
outlook
research
fair
ranking
work
licensed
creative
commons
attribution
international
4.0
license
facct
23
june
12
15
2023
chicago
il
usa
2023
copyright
held
owner
author
acm
isbn
979
4007
0192
23
06
https://doi.org/10.1145/3593013.3594046
facct
23
june
12
15
2023
chicago
il
usa
tim
de
jonge
djoerd
hiemstra
search
engine
manipulation
illustration
societal
harms
can
result
infor
mation
retrieval
systems
use
search
engine
manipulation
effect
epstein
robertson
13
held
experiment
showed
participants
results
mock
search
engine
manipu
lated
heavily
politically
skewed
experimental
design
can
found
figure
first
polled
participants
prospective
election
asked
participants
interact
search
engine
results
page
biased
towards
one
candidates
polled
participants
see
whether
shift
taken
place
results
varied
strongly
participants
features
prior
knowledge
election
net
probability
influencing
vote
direction
manipulation
high
25
susceptible
sub
group
population
poorly
informed
moderate
voters
13
contrast
least
susceptible
subgroup
showed
slight
negative
response
making
less
likely
participant
vote
candidate
favoured
search
results
figure
experimental
design
search
engine
manipu
lation
effect
taken
13
condition
neutral
con
dition
conditions
skew
towards
left
right
respectively
conditions
altered
versions
con
narrowly
cooperated
cambridge
analytica
facebook
micro-target
advertisements
specifically
susceptible
cambridge
analytica
claims
done
several
elections
around
globe
38
ex
amples
necessarily
search
engine
manipulation
effectiveness
unclear
11
17
20
36
show
tech
giants
moving
political
spheres
intent
granting
electoral
advantage
model
specification
3.1
learning-to-rank
must
first
formalize
abstraction
information
retrieval
system
investigate
societal
harm
may
result
informa
tion
retrieval
systems
table
contains
overview
notation
used
paper
core
task
information
retrieval
system
rank
set
documents
optimally
given
query
primarily
want
show
users
documents
want
see
section
will
show
conditions
diversity
results
non-discrimination
fairness
can
imposed
well
use
online
learning-to-rank
model
entails
start
session
model
information
much
population
interested
document
will
learn
23
learning-to
rank
common
information
retrieval
frequently
corpora
large
rely
expert
judgements
instead
learning-to
rank
algorithms
used
dynamically
ensure
users
model
shown
good
results
even
relatively
sparse
feedback
build
information
retrieval
system
model
used
morik
et
al
27
following
morik
et
al
27
observe
political
news
site
assume
editors
site
selected
30
documents
displayed
users
learning-to-rank
algorithm
must
rank
documents
estimated
relevance
using
data
users
provide
case
clicks
sequentially
users
come
site
presented
ranking
documents
looking
dition
mask
bias
results
documents
user
will
give
attention
docu
manipulation
search
results
can
difficult
detect
end-users
since
user
interacts
search
engine
limited
amount
times
can
hard
find
patterns
results
provided
search
engine
additionally
expect
users
expertise
required
detect
bias
search
results
use
search
engine
acquire
knowledge
first
place
powerful
position
large
tech
companies
find
combined
inability
individuals
realize
something
afoot
makes
nasty
problem
manipulation
search
engines
take
place
although
direct
examples
search
engine
ma
nipulation
used
malicious
intent
adjacent
cases
2012
us
election
obama
administration
coop
erated
narrowly
google
ensure
electoral
advantage
47
google
leverage
swathes
personal
data
estimate
persuasion
scores
target
advertisements
towards
individuals
easiest
persuade
ensure
maximal
ments
alternatively
phrased
documents
get
exposure
user
exposed
documents
will
click
whichever
documents
interested
clicks
registered
model
ranking
system
target
interpret
clicks
produce
best
ranking
according
quality
standard
relevance
fairness
definition
morik
et
al
27
introduces
two
rankers
d-ultr
glob
standing
dynamic-unbiased
learning-to-rank
global
fairco
will
now
take
look
d-ultr
glob
take
closer
look
fairco
section
5.1
fairco
unfair
extensions
d-ultr
glob
system
d-ultr
glob
mitigates
bias
users
inter
act
documents
top
ranking
documents
especially
relevant
19
means
use
click
data
direct
proxy
rele
vance
users
clicked
documents
near
top
ranking
documents
deserved
assume
attention
distribution
can
use
inverse
propensity
scoring
impact
similarly
2016
us
election
trump
administration
calculate
estimated
relevance
users
clicks
30
43
d-ultr
glob
ranks
documents
27
use
finding
document
relevant
ultr
glob
baseline
concerned
fairness
issues
illustrate
d-ultr
glob
simple
example
user
enters
site
clicks
articles
position
18
leaves
site
site
registers
clicks
passes
processing
since
user
clicked
articles
position
18
assume
user
interested
articles
put
article
18
top
results
page
next
actual
relevance
document
user
probability
otherwise
user
since
users
likely
scroll
results
first
last
user
much
likely
interact
article
bernoulli
article
18
next
user
inverse
propensity
score
makes
article
18
new
article
article
new
article
article
new
article
information
documents
remain
order
enough
iterations
additive
feedback
model
will
converge
ranking
high
probability
producing
relevant
documents
given
user
joining
site
3.2
technical
specification
section
lay
details
model
ranking
system
will
operate
unfortunately
outside
laboratorium
setting
di
rectly
observe
relevance
rather
restricted
observing
user
interactions
documents
user
interact
docu
ment
must
find
document
relevant
seen
first
place
assume
attention
user
gives
article
dependent
position
document
gets
ranking
higher
document
ranks
likely
user
see
19
denote
rank
document
gets
user
system
conceptualize
probability
user
sees
document
attention
exposure
user
gives
document
time
user
visits
page
requires
ranking
calculated
documents
user-base
made
two
smaller
sub-populations
left-wing
sub-population
drawn
normal
distribution
centered
around
0.5
analogously
log2
right-wing
sub-population
drawn
normal
distribution
centered
around
0.5
truncate
distributions
users
ease
graphing
result
substantial
changes
results
experiments
portion
left-wing
users
represented
left
model
assume
everyone
either
left-wing
right-wing
portion
right-wing
users
given
left
combining
concepts
political
lean
users
given
note
indeed
attention
range
meaning
interpret
ing
probability
consistent
attention
function
indicates
top-rated
document
likely
seen
rapid
initial
drop
drop
levels
first
results
meaning
less
difference
documents
rank
20
rank
21
documents
rank
rank
require
binary
value
user
seeing
document
leading
following
variable
user
seeing
document
leftn
0.5
0.2
left
0.5
0.2
bernoulli
finally
user
clicks
document
restricted
political
lean
seen
document
deem
relevant
means
user
maximally
left
wing
political
lean
model
can
observe
click
feedback
means
user
maximally
right-wing
documents
political
lean
normally
distributed
around
0.5
similarly
restricted
phrasing
implies
two-party
system
need
case
pluralistic
political
system
one
can
run
analysis
substituting
left-wing
party
one
choice
right-wing
fitting
comparison
group
section
4.2
motivates
choice
two
groups
gives
indication
groups
chosen
describe
users
openness
willingness
interact
documents
align
political
preferences
access
aforementioned
underlying
variables
exception
assume
unfair
access
susceptibility
users
using
ensure
manipulation
described
section
5.2
let
us
illustrate
model
example
user
robin
comes
page
left-wing
portion
pop
ulation
robin
political
lean
robin
0.4
openness
robin
0.3
come
across
document
propublica
pp
political
lean
pp
0.2
probability
robin
0.4
0.2
users
openness
uniformly
distributed
0.05
0.55
finds
document
pp
relevant
robin
pp
80
0.32
0.05
0.55
also
interpret
users
openness
susceptibility
likelihood
change
vote
based
robin
found
document
position
pp
robin
odds
robin
seeing
propublica
article
robin
results
page
pp
factors
interact
natural
way
user
likely
find
document
relevant
political
lean
document
close
political
lean
user
open
user
receptive
documents
align
political
preference
operationalizing
probability
user
log2
50
now
robin
person
rather
concept
can
actually
sure
whether
see
article
whether
find
relevant
turns
find
article
relevant
see
click
system
registers
robin
click
propublica
article
evaluation
4.1
relevance
multi-lateral
inequity
tem
primarily
information
retrieval
system
provide
users
documents
deem
relevant
assess
relevance
use
ndcg
10
18
technical
specification
ndcg
can
found
appendix
although
delivering
users
articles
want
see
important
interpretation
performance
sole
possible
interpretation
also
give
documents
fair
treatment
assess
ranking
systems
fairness
amortized
inequity
details
amortized
inequity
can
found
subsequent
section
4.2
finally
assess
electoral
impact
introduce
metric
measure
specifically
search
engine
manipulation
introduced
section
section
4.3
provides
details
metric
multi-lateral
inequity
compare
groups
average
deviations
27
31
mentioned
biega
et
al
multi-lateral
inequity
primarily
useful
optimiza
tion
target
unfairness
zero
groups
treated
equitably
according
chosen
definition
merit
however
multi-lateral
inequity
less
convenient
metric
level
skew
system
impossible
see
deviations
average
taking
place
since
pairwise
differences
summed
case
groups
scattered
closely
around
mean
differ
ent
analysis
case
one
group
discriminated
one
group
favoured
ease
analysis
suggest
using
bi-lateral
fairness
definition
measuring
inequity
41
one
take
care
appropriately
choose
groups
tested
one
group
one
suspects
unfair
inequality
appropriate
comparison
group
case
two
groups
denoted
inequity
follows
bi-lateral
inequity
table
notations
used
paper
short
representa
tion
meanings
4.2
fairness
assessing
whether
system
fair
trivial
undertaking
users
click
document
slightly
click
document
seems
sensible
system
shows
document
slightly
users
minimal
preference
document
system
always
ranks
document
higher
document
seems
violate
proportionality
main
thing
determine
assessing
system
appropriate
level
can
attach
different
meanings
merit
dependent
cir
cumstance
restrictive
equity
attention
equality
attention
special
case
give
group
equal
merit
equality
attention
can
good
choice
cases
can
accurately
measure
estimate
document
value
restrictive
use
much
otherwise
frequently
merit
attached
relevance
show
document
users
proportional
extent
users
want
see
relevance
conceptually
attractive
noisy
point
practically
intractable
means
assessment
real-world
information
retrieval
systems
relevance
will
either
estimate
relevance
user
behaviour
recruit
judges
investigate
documents
mark
relevance
document
query
trec
largest
applied
text
retrieval
conference
historically
used
binary
relevance
lacks
nuance
compares
different
ways
users
might
experience
documents
real
world
work
comprehensively
define
relevance
best
way
assess
information
retrieval
systems
ongoing
proven
challenging
24
35
40
combat
noise
relevance
can
assess
fairness
across
multiple
queries
accumulate
relevance
attention
across
queries
system
seen
compare
totals
amortized
inequity
can
differentiation
documents
difference
attention
becomes
harmful
amortized
inequity
partition
set
documents
additionally
conceptu
biega
et
al
introduced
term
amortized
inequity
alize
merit
extent
differentiation
appropriate
accumulation
inequity
across
queries
commonplace
either
treat
group
according
merit
fair
stray
treatment
according
merit
unfair
becomes
notion
treating
group
according
merit
called
equity
attention
two
groups
can
calculate
multi-lateral
inequity
follows
direct
summation
visited
queries
10
27
31
33
42
45
expected
value
query
space
29
34
amortized
inequity
can
used
target
long
amortized
inequity
close
zero
groups
received
attention
proportion
merit
4.3
electoral
impact
suggested
section
might
possible
build
system
adheres
restrictions
posed
fairness
metrics
resulting
societal
harm
assess
whether
search
engine
manipulation
takes
place
devise
following
measure
unfair
set
demonstrate
ranking
system
can
result
societal
harm
adhering
restrictions
imposed
fair
ness
metric
end
create
undetectably
nefarious
fair
ranker
unfair
important
understand
intention
contribute
state-of-the-art
electoral
manipulation
rather
possibility
unfair
algorithm
existing
motivates
amortized
impact
careful
use
fairness
metrics
careless
application
fairness
metrics
might
stop
harm
intends
stop
code
run
unfair
can
found
https://github.com/unfairpaper/unfair.
unfair
system
conditions
baseline
positive
assume
every
document
impact
reader
equal
attention
document
received
reader
impacted
proportional
susceptibility
mentioned
section
google
facebook
attempted
estimate
users
susceptibility
previous
political
contexts
explicit
intention
influencing
elections
amortized
impact
continuous
extension
theory
es
tablished
epstein
robertson
13
systems
can
manipulate
people
electoral
preference
25
heavily
skewed
search
results
pages
matches
range
amortized
impact
negative
unfair
assigns
one
conditions
user
ranks
documents
based
condition
user
baseline
condition
unfair
uses
appropriate
high-performing
ranker
case
use
d-ultr
glob
introduced
section
3.1
27
baseline
ranker
need
fair
unfair
solves
fairness
metric
use
positive
negative
conditions
positive
condition
direct
modification
baseline
condition
unfair
first
ranks
documents
according
baseline
ranker
positive
ranker
finds
first
documents
positive
political
lean
places
account
queries
less
heavily
skewed
amortized
impact
scales
impact
difference
attention
groups
first
positions
results
page
pushing
receive
acknowledge
amortized
impact
makes
simplifying
sumptions
embedded
disputed
claims
one
can
assess
ahead
time
much
user
vote
will
swayed
search
engine
28
every
results
page
non-zero
effect
user
vote
11
fundamental
complaint
likelihood
someone
vote
might
desirable
possible
capture
data
even
limitations
value
examining
metric
proxy
real-world
impact
model
analysis
stops
model
borders
whereas
value
can
found
observing
layer
beyond
model
output
44
choices
can
made
exact
specification
amortized
impact
following
discus
sion
still
holds
fair
rankers
5.1
fairco
fairco
27
learning-to-rank
system
targets
amortized
inequity
fairness
metric
since
paper
received
best
paper
award
sigir
2020
general-purpose
ranker
will
use
state-of-the-art
baseline
understand
fairco
first
recall
section
3.1
d-ultr
glob
operates
d-ultr
glob
estimates
relevance
document
corrected
position
bias
denote
d-ultr
glob
creates
results
page
ranking
documents
estimated
rel
evance
ensure
fairco
allow
inequity
attention
morik
et
al
modify
base
ranker
use
amortized
inequity
equation
amortized
inequity
transformed
error
term
err
err
whenever
privileged
group
err
equal
amortized
inequity
otherwise
rank
results
necessary
results
page
presented
user
positive
condition
corresponds
case
figure
negative
condition
defined
similarly
replacing
instances
positive
negative
corresponding
case
figure
unfair
assigns
conditions
users
susceptibility
score
unfair
offers
positive
condition
users
highest
susceptibility
scores
negative
ranker
lowest
susceptibility
scores
herein
lies
manipulation
since
attention
equal
algorithm
aims
high-impact
attention
go
towards
privileged
group
low
impact
attention
goes
towards
maltreated
group
means
voters
can
influenced
will
influenced
towards
positive
group
formal
equity
attention
system
can
produce
electoral
impact
formalize
keep
thresholds
unfair
uses
positive
condition
likewise
unfair
uses
negative
condition
unfair
uses
baseline
condition
recall
working
inside
learning-to-rank
model
means
start
experiment
know
anything
user
distribution
means
update
throughout
run
maintain
balance
different
conditions
unfairsmooth
first
mechanism
choosing
thresholds
thresholds
move
smoothly
within
domain
every
timestep
unfairsmooth
sets
err
similarly
err
ensures
unfairsmooth
chooses
negative
condition
frequently
discrepancy
exposure
positive
vice
versa
investigate
results
choosing
parameter
section
ing
err
produces
ranking
system
converges
limit
zero
amortized
inequity
unfaircoarse
mechanism
choosing
thresholds
unfaircoarse
uses
limited
set
possible
threshold
val
ues
consequence
can
execute
explicit
control
model
ensure
convergence
cost
flexibility
convenience
use
notation
amortized
inequity
amount
users
can
ensure
guarantee
amortized
inequity
remains
tends
parameter
can
interpreted
spring
constant
explore
effects
varying
section
6.4
6.3
performance
vary
different
levels
evaluation
completeness
investigated
relevance
assessment
changes
vary
amount
documents
evaluated
figure
ensure
divide
population
evenly
can
see
differences
different
evaluations
unfairsmooth
performs
well
ndcg
unfairsmooth
sized
chunks
along
susceptibility
axis
system
balance
system
uses
left
right
ranker
outermost
uses
baseline
condition
otherwise
10
inequity
10
towards
positive
negative
ranker
takes
lowest
susceptibility
chunk
performance
declines
results
evaluated
fairco
unfaircoarse
perform
equally
well
throughout
always
worse
d-ultr
glob
notable
ndcg
30
much
higher
ndcg
population
rises
unfaircoarse
will
assign
chunks
rankers
reflective
rankers
proficient
ranking
documents
instead
quirk
model
chosen
population
negative
condition
thus
stopping
rise
will
result
amortized
inequity
tending
previously
explained
results
6.1
experimental
setup
following
section
will
demonstrate
unfair
can
attain
similar
performance
fairness
fairco
reaching
substantial
electoral
impact
code
reproduce
results
can
found
https://github.com/unfairpaper/unfair.
unless
otherwise
listed
set
fairco
parameter
0.01
suggested
morik
et
al
27
unfair
parameter
0.005
left
0.5
experiment
uses
30
random
seeds
previously
used
developing
unfair
previous
experiments
within
experiment
evaluate
systems
random
seeds
resulting
experimental
conditions
6.2
can
unfair
achieve
electoral
impact
maintaining
competitive
performance
fairness
figure
shows
long
run
systems
evaluated
rele
vance
fairness
electoral
impact
experimental
setup
learn-to-rank
30
documents
10000
simulated
users
figure
classical
trade-off
fairness
performance
clearly
visible
12
d-ultr
glob
performs
best
terms
relevance
unfair
according
exposure
inequity
unfair
coarse
fairco
similar
performance
relevance
fairness
achieving
inequity
performance
loss
furthermore
can
see
fairco
reduces
electoral
impact
well
d-ultr
glob
stray
far
neutral
electoral
impact
implementations
unfair
deviate
unfairsmooth
can
see
oscillating
behaviour
users
interact
system
oscillating
behaviour
due
delay
imbalance
amortized
equity
un
fairsmooth
response
unfairsmooth
thresholds
move
opposite
direction
error
term
err
err
positive
already
decreasing
unfairsmooth
will
still
change
thresholds
skewed
towards
negative
side
thus
overshooting
target
results
spring-like
behavior
amortized
equity
will
turn
negative
rather
finding
equilibrium
unfair
performance
purely
random
ranker
also
significantly
higher
evaluated
ndcg
30
comparisons
tween
systems
metric
valid
comparisons
metrics
mostly
6.4
effects
unfair
lambda
parameter
following
experiment
vary
unfairsmooth
without
comparison
baseline
figure
shows
similar
per
formance
rankers
0.05
performs
poorly
0.003
performs
best
higher
results
heavier
oscillation
electoral
impact
exposure
inequity
initially
driven
continue
steady
decline
conversely
low
results
steady
slow
behaviour
observations
consistent
interpretation
spring
constant
system
middle
ground
two
extremes
retain
0.005
experiments
6.5
unfair
effective
different
user
distributions
finally
worth
observing
happens
populations
shift
figure
vary
left-wing
proportion
population
left
35
65
intervals
four
systems
used
evaluated
30
previously
unseen
seeds
plotted
values
system
produces
3000
users
used
system
figure
terms
ndcg
unfairsmooth
un
faircoarse
closely
mimic
fairco
performance
terms
rele
vance
although
lower
baseline
see
fairco
slightly
outperforms
unfair
minimizing
inequity
un
fair
still
achieve
serious
reduction
inequity
compared
d-ultr
glob
terms
electoral
impact
d-ultr
glob
polarized
scores
fairco
mitigates
impact
population
skew
unfair
cases
system
already
skewed
towards
positive
side
unfair
reduce
impact
much
cases
system
balanced
skewed
towards
negative
side
unfair
moves
impact
even
towards
positive
side
fairco
figure
ndcg
10
left
amortized
inequity
middle
amortized
impact
right
averaged
30
trials
10000
simulated
users
figure
left
right
ndcg
ndcg
ndcg
30
averaged
30
trials
3000
simulated
users
figure
ndcg
10
left
amortized
inequity
middle
amortized
impact
right
unfairsmooth
0.001
0.003
0.005
0.01
0.02
0.05
averaged
30
trials
3000
users
figure
ndcg
10
left
amortized
inequity
middle
amortized
impact
right
averaged
30
trials
3000
simulated
users
value
left
35
65
discussion
moving
forward
throughout
results
unfair
reaches
performance
close
fairco
similarly
fair
according
amortized
inequity
achieving
unfair
mitigate
electoral
impact
d-ultr
glob
baseline
reasonable
unfair
adds
positive
electoral
impact
said
unfair
certainly
imperfections
practical
use
one
create
refined
unfair
ranker
however
point
paper
provide
new
state-of-the-art
manipulating
elections
point
illustrate
current
fairness
metrics
need
careful
application
although
amortized
inequity
plausible
metric
search
engine
manipulation
see
nefarious
actor
create
system
appears
fair
amortized
inequity
reducing
search
engine
manipulation
way
unfair
algorithm
start
towards
investigating
limita
tions
fairness
metrics
information
retrieval
leaves
questions
yet
unanswered
paper
demonstrates
unfair
one
simulated
dataset
one
metric
algorithm
agnostic
metric
used
dataset
future
research
will
point
whether
unfair
functions
equally
well
circumstances
models
classify
rather
rank
theorems
proving
impossibility
satisfying
multiple
fairness
metrics
time
21
similar
theorems
ranking
powerful
tool
understand
trade-offs
inherent
fair
ranking
scholars
pondering
justice
fairness
centuries
given
definitive
answers
justice
far
distilling
fairness
single
number
seems
overzealous
32
rather
practical
application
fairness
algorithms
needs
grounded
relevant
literature
outside
just
information
retrieval
14
supported
normative
assumptions
clarify
substantive
fairness
benefiting
appears
fairness
metrics
fitting
role
canary
coal
mine
canary
falls
bottom
cage
time
evacuate
mine
however
live
canary
mean
mine
way
safe
building
policy
keep
canary
safe
fool
errand
just
limitations
usage
fairness
metrics
mean
practice
abolished
37
energy
invested
towards
greater
good
laudable
problem
remains
complex
suggestion
different
people
working
towards
greater
good
different
goals
making
goals
explicit
allows
us
judge
systems
adequately
15
naively
optimizing
towards
chosen
metric
one
miss
target
reducing
societal
harm
left
system
looks
better
metric
holistic
algorithmic
design
assessment
might
necessary
ensure
fair
algorithms
mökander
et
al
26
suggest
ethics
based
auditing
method
ensure
morally
sustainable
algorithms
ethics
based
auditing
expands
auditing
pro
cess
trying
assess
system
within
system
first
one
identifies
moral
values
potential
harms
can
continuous
evaluation
whether
system
upholds
moral
values
enables
us
evaluate
whether
performance
indicators
used
still
measure
underlying
norm
rather
evaluating
whether
system
still
adheres
performance
indicators
conclusion
investigated
amortized
equity
attention
definition
fair
ness
showed
system
manipulate
electoral
results
fair
amortized
equity
proposed
algorithm
un
fair
achieves
competitive
performance
fair
learning-to-rank
information
retrieval
system
simultaneously
clearly
manipulative
setup
acknowledgments
work
funded
part
eu
project
openwebsearch
eu
ga
101070014
like
thank
frederik
zuiderveen
borgesius
marvin
van
bekkum
richard
felius
adm
club
valuable
input
throughout
research
ethical
concerns
paper
establishes
algorithm
circumvent
fairness
measures
still
achieve
electoral
manipulation
method
becomes
relevant
adhering
amortized
equity
become
manda
tory
without
qualititative
measures
deem
unlikely
work
will
used
nefarious
purposes
relevance
assessment
start
can
see
whether
users
shown
documents
relevant
interests
performance
model
classical
sense
assess
performance
according
relevance
use
normalized
discounted
cumulative
gain
ndcg
18
ndcg
derived
metric
dcg
defined
su
lin
blodgett
solon
barocas
hal
daumé
iii
hanna
wallach
2020
lan
guage
technology
power
critical
survey
bias
nlp
proceed
ings
58th
annual
meeting
association
computational
linguis
tics
association
computational
linguistics
online
5454
5476
https
doi
org
10.18653
v1
2020
acl-main
485
alexandra
chouldechova
2017
fair
prediction
disparate
impact
study
bias
recidivism
prediction
instruments
big
data
2017
153
163
feder
cooper
ellen
abrams
2021
emergent
unfairness
algorithmic
fairness-accuracy
trade-off
research
proceedings
2021
aaai
acm
con
ference
ai
ethics
society
46
54
yashar
deldjoo
dietmar
jannach
alejandro
bellogin
alessandro
difonzo
dario
zanzonelli
2022
survey
research
fair
recommender
systems
arxiv
preprint
arxiv
2205.11127
2022
fernando
diaz
bhaskar
mitra
michael
ekstrand
asia
biega
ben
carterette
2020
evaluating
stochastic
rankings
expected
exposure
proceedings
29th
acm
international
conference
information
knowledge
management
275
284
10
virginie
sam
corbett-davies
jamal
atif
nicolas
usunier
2022
online
certification
preference-based
fairness
personalized
recommender
systems
proceedings
aaai
conference
artificial
intelligence
vol
36
6532
6540
dcg
log
11
tim
draws
nava
tintarev
ujwal
gadiraju
alessandro
bozzon
benjamin
timmermans
2021
ordered
exploring
biased
search
result
rankings
affect
user
attitudes
debated
topics
proceedings
44th
international
acm
sigir
conference
research
development
information
retrieval
295
305
position
document
user
ranked
policy
dcg
captures
intuition
relevant
documents
need
placed
near
top
ranking
since
range
dcg
can
vary
queries
comparing
systems
across
queries
cumbersome
ease
comparison
across
queries
dcg
normalized
di
viding
ideal
dcg
obtainable
query
evaluate
ideal
ranking
policy
orders
documents
relevance
ideal
ranker
practically
obtainable
provides
useful
12
sanghamitra
dutta
dennis
wei
hazar
yueksel
pin-yu
chen
sijia
liu
kush
varshney
2020
trade-off
fairness
accuracy
perspective
using
mismatched
hypothesis
testing
international
conference
machine
learning
pmlr
2803
2813
13
robert
epstein
ronald
robertson
2015
search
engine
manipulation
effect
seme
possible
impact
outcomes
elections
proceedings
national
academy
sciences
112
33
2015
e4512-e4521
14
sina
fazelpour
zachary
lipton
2020
algorithmic
fairness
non-ideal
perspective
proceedings
aaai
acm
conference
ai
ethics
society
57
63
15
ben
green
2019
good
isn
good
enough
proceedings
ai
social
good
workshop
neurips
vol
17
benchmark
denote
ideal
dcg
idcg
dcg
normalized
dcg
ndcg
ndcg
dcg
result
ndcg
always
allowing
comparison
across
queries
one
nuance
might
appropriate
assume
user
observes
documents
pre
sented
dcg
formula
can
adapted
meet
need
index
documents
based
position
results
page
dcg
evaluated
th
position
calculated
dcg
16
anat
hashavit
hongning
wang
raz
lin
tamar
stern
sarit
kraus
2021
un
derstanding
mitigating
bias
online
health
search
proceedings
44th
international
acm
sigir
conference
research
development
information
retrieval
virtual
event
canada
sigir
21
association
computing
machin
ery
new
york
ny
usa
265
274
https://doi.org/10.1145/3404835.3462930
17
alex
hern
2018
cambridge
analytica
turn
clicks
votes
guardian
2018
18
kalervo
järvelin
jaana
kekäläinen
2002
cumulated
gain-based
evaluation
ir
techniques
acm
transactions
information
systems
tois
20
2002
422
446
19
thorsten
joachims
laura
granka
bing
pan
helene
hembrooke
filip
radlinski
geri
gay
2007
evaluating
accuracy
implicit
feedback
clicks
ndcg
can
similarly
adapted
query
reformulations
web
search
acm
transactions
information
systems
log
ndcg
dcg
result
can
tune
performance
measure
observa
tions
made
users
typically
investigate
10
docu
ments
ndcg
10
suitable
assess
whether
given
system
delivering
relevant
results
users
vary
order
preference
ranking
systems
can
also
vary
references
agathe
balayn
seda
gürses
2021
beyond
debiasing
regulating
ai
equalities
edri
report
https://edri.
org
wp-content
uploads
2021
09
edri_beyond
debiasing-report_online
pdf
2021
solon
barocas
moritz
hardt
arvind
narayanan
2019
fairness
machine
learning
limitations
opportunities
fairmlbook
org
http://www.fairmlbook.
org
hal
berghel
2018
malice
domestic
cambridge
analytica
dystopia
computer
51
2018
84
89
asia
biega
krishna
gummadi
gerhard
weikum
2018
equity
attention
amortizing
individual
fairness
rankings
41st
international
acm
sigir
conference
research
development
information
retrieval
405
414
20
joshua
kalla
david
broockman
2018
minimal
persuasive
effects
campaign
contact
general
elections
evidence
49
field
experiments
american
political
science
review
112
2018
148
166
21
jon
kleinberg
sendhil
mullainathan
manish
raghavan
2016
inherent
trade-offs
fair
determination
risk
scores
corr
abs
1609.05807
2016
arxiv
1609.05807
http://arxiv.org/abs/1609.05807
22
yunqi
li
hanxiong
chen
shuyuan
xu
yingqiang
ge
juntao
tan
shuchang
liu
yongfeng
zhang
2022
fairness
recommendation
survey
arxiv
preprint
arxiv
2205.13619
2022
23
tie-yan
liu
et
al
2009
learning
rank
information
retrieval
foundations
trends
information
retrieval
2009
225
331
24
david
losada
javier
parapar
alvaro
barreiro
2019
stop
making
relevance
judgments
study
stopping
methods
building
information
retrieval
test
collections
journal
association
information
science
technology
70
2019
49
60
25
alessandro
melchiorre
navid
rekabsaz
emilia
parada-cabaleiro
stefan
brandl
oleg
lesota
markus
schedl
2021
investigating
gender
fairness
recommen
dation
algorithms
music
domain
information
processing
management
58
2021
102666
26
jakob
mökander
jessica
morley
mariarosaria
taddeo
luciano
floridi
2021
ethics-based
auditing
automated
decision-making
systems
nature
scope
limitations
science
engineering
ethics
27
2021
30
27
marco
morik
ashudeep
singh
jessica
hong
thorsten
joachims
2020
con
trolling
fairness
bias
dynamic
learning-to-rank
proceedings
43rd
international
acm
sigir
conference
research
development
information
retrieval
429
438
28
arvind
narayanan
2019
recognize
ai
snake
oil
arthur
miller
lecture
science
ethics
2019
29
harrie
oosterhuis
2021
computationally
efficient
optimization
plackett-luce
ranking
models
relevance
fairness
proceedings
44th
international
acm
sigir
conference
research
development
information
retrieval
1023
1032
30
zohreh
ovaisi
kathryn
vasilaky
elena
zheleva
2021
propensity
independent
bias
recovery
offline
learning-to-rank
systems
proceedings
44th
international
acm
sigir
conference
research
development
information
retrieval
1763
1767
31
amifa
raj
connor
wood
ananda
montoly
michael
ekstrand
2020
com
paring
fair
ranking
metrics
arxiv
preprint
arxiv
2009.01311
2020
32
andrew
selbst
danah
boyd
sorelle
friedler
suresh
venkatasubramanian
janet
vertesi
2019
fairness
abstraction
sociotechnical
systems
proceedings
conference
fairness
accountability
transparency
59
68
33
ashudeep
singh
thorsten
joachims
2018
fairness
exposure
rankings
proceedings
24th
acm
sigkdd
international
conference
knowledge
discovery
data
mining
2219
2228
34
ashudeep
singh
thorsten
joachims
2019
policy
learning
fairness
ranking
advances
neural
information
processing
systems
32
2019
35
eero
sormunen
2002
liberal
relevance
criteria
trec
counting
negligible
documents
proceedings
25th
annual
international
acm
sigir
conference
research
development
information
retrieval
324
330
36
david
sumpter
2018
facebook
data
available
cambridge
analytica
used
target
personalities
us
presidential
election
2018
https://soccermatics.medium.com/why-the-facebook-data-
available-to-cambridge-analytica-could-not-be-used-to-target-personalities
in-2904fa0571bd
37
jared
sylvester
edward
raff
2018
applied
fairness
arxiv
preprint
arxiv
1806.05250
2018
38
channel
news
investigations
team
2018
exposed
undercover
secrets
trump
data
firm
2018
https://www.channel4.com/news/exposed-
undercover-secrets-of-donald-trump-data-firm-cambridge-analytica
39
nguyen
vo
kyumin
lee
2019
learning
fact-checkers
analysis
generation
fact-checking
language
proceedings
42nd
international
acm
sigir
conference
research
development
information
retrieval
paris
france
sigir
19
association
computing
machinery
new
york
ny
usa
335
344
https://doi.org/10.1145/3331184.3331248
40
ellen
voorhees
ian
soboroff
jimmy
lin
2022
can
old
trec
col
lections
reliably
evaluate
modern
neural
retrieval
models
arxiv
preprint
arxiv
2201.11086
2022
41
sandra
wachter
brent
mittelstadt
chris
russell
2021
fairness
automated
bridging
gap
eu
non-discrimination
law
ai
computer
law
security
review
41
2021
105567
42
lequn
wang
yiwei
bai
wen
sun
thorsten
joachims
2021
fairness
exposure
stochastic
bandits
international
conference
machine
learning
pmlr
10686
10696
43
xuanhui
wang
michael
bendersky
donald
metzler
marc
najork
2016
learning
rank
selection
bias
personal
search
proceedings
39th
international
acm
sigir
conference
research
development
information
retrieval
115
124
44
hilde
weerts
lambèr
royakkers
mykola
pechenizkiy
2022
end
justify
means
moral
justification
fairness-aware
machine
learning
arxiv
preprint
arxiv
2202.08536
2022
45
tao
yang
qingyao
ai
2021
maximizing
marginal
fairness
dynamic
learning
rank
proceedings
web
conference
2021
137
145
46
xun
yang
xiangnan
xiang
wang
yunshan
ma
fuli
feng
meng
wang
tat-seng
chua
2019
interpretable
fashion
matching
rich
attributes
proceedings
42nd
international
acm
sigir
conference
research
development
information
retrieval
paris
france
sigir
19
association
computing
machinery
new
york
ny
usa
775
784
https://doi.org/10.1145/
3331184.3331242
47
shoshana
zuboff
2019
age
surveillance
capitalism
fight
human
future
new
frontier
power
barack
obama
books
2019
profile
books
121
125
pages
received
may
10
2023