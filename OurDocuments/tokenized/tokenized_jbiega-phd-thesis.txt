enhancing
privacy
and
fairness
in
search
systems
dissertation
submitted
towards
the
degree
doctor
of
engineering
dr
ing
of
the
faculty
of
mathematics
and
computer
science
of
saarland
university
by
joanna
biega
saarbrücken
december
2018
ii
defense
colloquium
date
april
2019
dean
of
the
faculty
prof
dr
sebastian
hack
examination
committee
chair
prof
dr
bernt
schiele
reviewer
advisor
prof
dr
gerhard
weikum
reviewer
co-advisor
prof
dr
krishna
gummadi
reviewer
prof
dr
carlos
castillo
reviewer
prof
dr
wolfgang
nejdl
academic
assistant
dr
erisa
terolli
iii
acknowledgments
am
greatly
indebted
to
my
phd
advisors
gerhard
weikum
and
krishna
gummadi
for
their
mentorship
thank
you
gerhard
for
your
excellent
technical
guidance
for
pushing
me
to
work
to
the
best
of
my
ability
and
for
allowing
me
so
much
freedom
to
pursue
my
research
interests
thank
you
krishna
for
teaching
me
to
think
deeply
about
the
problems
work
on
for
showing
how
to
be
playful
in
coming
up
with
new
ideas
and
for
the
many
hours
of
non-technical
discussions
that
helped
me
to
grow
as
researcher
tremendous
thanks
to
prof
carlos
castillo
and
prof
wolfgang
nejdl
for
reviewing
this
thesis
and
for
all
the
helpful
feedback
thanks
also
to
prof
bernt
schiele
and
dr
erisa
terolli
for
agreeing
to
devote
their
time
to
serve
on
my
examination
committee
special
thanks
to
fabian
suchanek
for
being
fantastic
mentor
for
introducing
me
to
the
research
world
and
later
convincing
me
to
do
phd
and
for
being
an
inspiring
example
of
how
to
reconcile
professional
excellence
with
various
hobbies
thanks
to
the
privacy
infrastructure
team
at
google
zurich
for
hosting
me
during
my
internship
and
teaching
me
so
many
valuable
lessons
about
engineering
excellence
want
to
thank
all
the
friends
and
colleagues
from
d5
mpi-inf
socsys
mpi-sws
and
the
institute
administration
for
creating
such
an
amazing
working
environment
thanks
to
my
old
friends
from
the
sanok
group
for
being
constant
in
my
life
despite
the
fact
that
we
are
so
geographically
distributed
now
and
for
reminding
me
that
am
not
my
work
thanks
to
dominika
as
well
as
all
the
friends
from
our
polish
geek
group
in
sb
for
all
the
good
times
and
great
discussions
thanks
to
all
the
balnica
friends
for
all
the
artistically
creative
times
that
powered
me
through
the
work
times
heartfelt
thanks
to
the
family
roth
for
making
germany
and
switzerland
feel
bit
more
like
home
thanks
to
my
sister
ela
for
all
the
emotional
support
during
the
good
times
and
the
bad
times
want
to
thank
my
parents
lilianna
and
marek
for
making
our
education
priority
particular
thanks
go
to
my
mom
who
in
small
polish
town
in
the
80s
and
90s
had
visionary
dream
that
her
daughters
become
engineers
and
grow
up
to
be
independent
women
it
is
only
years
later
that
realize
how
privileged
was
to
have
been
raised
this
way
as
girl
last
but
not
least
thank
you
ben
for
having
supported
me
in
countless
ways
through
all
these
years
for
all
the
amazing
experiences
we
ve
had
together
and
for
all
the
value
you
bring
to
my
life
asia
abstract
ollowing
period
of
expedited
progress
in
the
capabilities
of
digital
systems
the
society
begins
to
realize
that
systems
designed
to
assist
people
in
various
tasks
can
also
harm
individuals
and
society
mediating
access
to
information
and
explicitly
or
implicitly
ranking
people
in
increasingly
many
applications
search
systems
have
substantial
potential
to
contribute
to
such
unwanted
outcomes
since
they
collect
vast
amounts
of
data
about
both
searchers
and
search
subjects
they
have
the
potential
to
violate
the
privacy
of
both
of
these
groups
of
users
moreover
in
applications
where
rankings
influence
people
economic
livelihood
outside
of
the
platform
such
as
sharing
economy
or
hiring
support
websites
search
engines
have
an
immense
economic
power
over
their
users
in
that
they
control
user
exposure
in
ranked
results
this
thesis
develops
new
models
and
methods
broadly
covering
different
aspects
of
privacy
and
fairness
in
search
systems
for
both
searchers
and
search
subjects
specifically
it
makes
the
following
contributions
we
propose
model
for
computing
individually
fair
rankings
where
search
subjects
get
exposure
proportional
to
their
relevance
the
exposure
is
amortized
over
time
using
constrained
optimization
to
overcome
searcher
attention
biases
while
preserving
ranking
utility
we
propose
model
for
computing
sensitive
search
exposure
where
each
subject
gets
to
know
the
sensitive
queries
that
lead
to
her
profile
in
the
top-k
search
results
the
problem
of
finding
exposing
queries
is
technically
modeled
as
reverse
nearest
neighbor
search
followed
by
weekly-supervised
learning
to
rank
model
ordering
the
queries
by
privacy-sensitivity
we
propose
model
for
quantifying
privacy
risks
from
textual
data
in
online
communities
the
method
builds
on
topic
model
where
each
topic
is
annotated
by
crowdsourced
sensitivity
score
and
privacy
risks
are
associated
with
user
relevance
to
sensitive
topics
we
propose
relevance
measures
capturing
different
dimensions
of
user
interest
in
topic
and
show
how
they
correlate
with
human
risk
perceptions
we
propose
model
for
privacy-preserving
personalized
search
where
search
queries
of
different
users
are
split
and
merged
into
synthetic
profiles
the
model
mediates
the
privacy-utility
trade-off
by
keeping
semantically
coherent
fragments
of
search
histories
within
individual
profiles
while
trying
to
minimize
the
similarity
of
any
of
the
synthetic
profiles
to
the
original
user
profiles
the
models
are
evaluated
using
information
retrieval
techniques
and
user
studies
over
variety
of
datasets
ranging
from
query
logs
through
social
media
and
community
question
answering
postings
to
item
listings
from
sharing
economy
platforms
vii
kurzfassung
ach
einer
zeit
schneller
fortschritte
in
den
fähigkeiten
digitaler
systeme
beginnt
die
gesellschaft
zu
erkennen
dass
systeme
die
menschen
bei
verschiedenen
aufgaben
unterstützen
sollen
den
einzelnen
und
die
gesellschaft
auch
schädigen
können
suchsysteme
haben
ein
erhebliches
potenzial
um
zu
solchen
unerwünschten
ergebnissen
beizutragen
weil
sie
den
zugang
zu
informationen
vermitteln
und
explizit
oder
implizit
menschen
in
immer
mehr
anwendungen
in
ranglisten
anordnen
da
sie
riesige
datenmengen
sowohl
über
suchende
als
auch
über
gesuchte
sammeln
können
sie
die
privatsphäre
dieser
beiden
benutzergruppen
verletzen
in
anwendungen
in
denen
ranglisten
einen
einfluss
auf
den
finanziellen
lebensunterhalt
der
menschen
außerhalb
der
plattform
haben
auf
sharing-economy-plattformen
oder
jobbörsen
haben
suchmaschinen
eine
immense
wirtschaftliche
macht
über
ihre
nutzer
indem
sie
die
sichtbarkeit
von
personen
in
suchergebnissen
kontrollieren
in
dieser
dissertation
werden
neue
modelle
und
methoden
entwickelt
die
verschiedene
aspekte
der
privatsphäre
und
der
fairness
in
suchsystemen
sowohl
für
suchende
als
auch
für
gesuchte
abdecken
insbesondere
leistet
die
arbeit
folgende
beiträge
wir
schlagen
ein
modell
für
die
berechnung
von
fairen
rankings
vor
bei
denen
suchsubjekte
entsprechend
ihrer
relevanz
angezeigt
werden
die
sichtbarkeit
wird
im
laufe
der
zeit
durch
ein
optimierungsmodell
adjustiert
um
die
verzerrungen
der
sichtbarkeit
für
sucher
zu
kompensieren
während
die
nützlichkeit
des
rankings
beibehalten
bleibt
wir
schlagen
ein
modell
für
die
bestimmung
kritischer
suchanfragen
vor
in
dem
für
jeden
nutzer
aanfragen
die
zu
seinem
nutzerprofil
in
den
top-k-suchergebnissen
führen
herausgefunden
werden
das
problem
der
berechnung
von
exponierenden
suchanfragen
wird
als
reverse-nearest-neighbor-suche
modelliert
solche
kritischen
suchanfragen
werden
dann
von
einem
learning-to-rank-modell
geordnet
um
die
sensitiven
suchanfragen
herauszufinden
wir
schlagen
ein
modell
zur
quantifizierung
von
risiken
für
die
privatsphäre
aus
textdaten
in
online-communities
vor
die
methode
baut
auf
einem
themenmodell
auf
bei
dem
jedes
thema
durch
einen
crowdsourcing-sensitivitätswert
annotiert
wird
die
risiko-scores
sind
mit
der
relevanz
eines
benutzers
mit
kritischen
themen
verbunden
wir
schlagen
relevanzmaße
vor
die
unterschiedliche
dimensionen
des
benutzerinteresses
an
einem
thema
erfassen
und
wir
zeigen
wie
diese
maße
mit
der
risikowahrnehmung
von
menschen
korrelieren
wir
schlagen
ein
modell
für
personalisierte
suche
vor
in
dem
die
privatsphäre
geschützt
wird
in
dem
modell
werden
suchanfragen
von
nutzer
partitioniert
und
in
synthetische
profile
eingefügt
das
modell
erreicht
einen
guten
kompromiss
zwischen
der
suchsystemnützlichkeit
und
der
privatsphäre
indem
semantisch
kohärente
fragmente
der
suchhistorie
innerhalb
einzelner
profile
beibehalten
werden
wobei
gleichzeitig
angestrebt
wird
die
ähnlichkeit
der
synthetischen
profile
mit
den
ursprünglichen
nutzerprofilen
zu
minimieren
viii
die
modelle
werden
mithilfe
von
informationssuchtechniken
und
nutzerstudien
ausgewertet
wir
benutzen
eine
vielzahl
von
datensätzen
die
von
abfrageprotokollen
über
soziale
medien
postings
und
die
fragen
vom
forums
bis
hin
zu
artikellistungen
von
sharing-economyplattformen
reichen
contents
introduction
1.1
motivation
1.1
search
systems
1.1
privacy
in
search
1.1
fairness
in
search
1.2
challenges
1.3
thesis
contributions
1.4
other
contributions
of
the
author
1.5
prior
publications
1.6
organization
background
user
privacy
11
2.1
preliminaries
11
2.2
privacy
risks
and
notions
12
2.2
information
leakage
12
2.2
profiling
13
2.2
exposure
13
achieving
privacy
14
2.3
limiting
information
leakage
14
2.3
limiting
profiling
15
2.3
limiting
exposure
16
2.4
cost
of
privacy
17
2.5
privacy
in
search
systems
18
2.6
selected
other
dimensions
in
privacy
research
19
2.3
background
algorithmic
fairness
21
3.1
preliminaries
21
3.2
algorithmic
fairness
notions
23
3.2
group
fairness
23
3.2
individual
fairness
24
3.3
achieving
algorithmic
fairness
24
3.4
accountability
25
3.5
cost
of
fairness
25
3.6
sources
of
algorithmic
unfairness
25
3.7
fairness
in
search
systems
27
3.8
selected
other
dimensions
in
algorithmic
fairness
research
28
contents
equity
of
attention
31
4.1
introduction
32
4.2
equity-of-attention
fairness
34
4.2
notation
34
4.2
defining
equity
of
attention
35
4.2
equality
of
attention
36
4.2
relation
to
group
fairness
in
rankings
36
rankings
with
equity
of
attention
36
4.3
measuring
un
fairness
36
4.3
measuring
ranking
quality
37
4.3
optimizing
fairness-quality
tradeoffs
37
4.3
an
ilp-based
fair
ranking
mechanism
38
experiments
40
4.4
data
40
4.4
position
bias
42
4.4
implementation
and
parameters
42
4.4
mechanisms
under
comparison
43
4.4
data
characteristics
relevance
vs
attention
43
4.4
performance
on
synthetic
data
43
4.4
performance
on
airbnb
data
48
4.4
performance
on
stackexchange
data
54
4.5
related
work
54
4.6
conclusion
55
4.3
4.4
sensitive
search
exposure
57
5.1
introduction
5.2
problem
statement
59
5.3
generating
exposure
sets
60
5.4
ranking
of
queries
in
exposure
sets
61
5.4
learning
to
rank
the
exposing
queries
61
5.4
features
62
5.4
5.5
5.6
58
relevance
64
experiments
65
5.5
dataset
65
5.5
rknn
generation
65
5.5
query
ranking
in
exposure
sets
65
5.5
user-study
evaluation
67
insights
into
search
exposure
relevance
70
5.6
tweet
context
70
5.6
search
exposure
relevance
vs
topical
sensitivity
70
5.7
related
work
71
5.8
conclusion
73
contents
xi
rank-susceptibility
6.1
introduction
6.2
r-susceptibility
model
6.2
sensitive
states
and
adversaries
6.2
sensitive
topics
6.2
background
knowledge
6.2
r-susceptibility
6.3
risk
assessment
measures
6.3
entropy
baseline
measure
6.3
differential-privacy
baseline
measure
6.3
topical
risk
measure
6.4
identifying
sensitive
topics
6.4
experiments
on
topic
sensitivity
6.5
experiments
6.5
setup
6.5
traditional
vs
ir
risk
scoring
6.5
risk
scoring
with
dimensions
of
interest
6.5
robustness
to
configuration
changes
6.5
discussion
6.6
related
work
6.7
conclusion
75
76
78
78
78
79
79
79
80
80
81
85
85
87
87
90
90
91
92
94
96
privacy
through
solidarity
7.1
introduction
7.2
framework
overview
7.2
architecture
7.2
incentives
of
participating
parties
7.2
trusted
and
adversarial
parties
7.3
assignment
model
7.3
concepts
and
notation
7.3
objective
7.3
measuring
privacy
gain
7.3
measuring
user
utility
loss
7.3
assignment
algorithms
7.4
mediator
accounts
in
search
systems
7.4
framework
elements
7.4
service
provider
model
7.5
experiments
7.5
experimental
setup
7.5
results
and
insights
7.6
related
work
7.7
conclusion
97
98
99
99
100
101
101
102
102
102
103
104
105
105
106
106
106
108
111
113
conclusions
and
outlook
115
xii
contents
amt
user
study
topical
sensitivity
117
amt
user
study
search
exposure
119
bibliography
121
list
of
figures
141
list
of
tables
143
chapter
introduction
contents
1.1
1.1
1.1
motivation
search
systems
1.1
privacy
in
search
1.1
fairness
in
search
1.2
challenges
1.3
thesis
contributions
1.4
other
contributions
of
the
author
1.5
prior
publications
1.6
organization
motivation
ollowing
period
of
expedited
progress
in
the
capabilities
of
digital
systems
the
society
begins
to
realize
that
systems
designed
to
assist
people
in
various
tasks
can
also
harm
individuals
and
society
the
harm
may
occur
across
number
of
dimensions
ranging
from
privacy
intrusion
caused
by
massive
collection
of
personal
data
discrimination
caused
by
algorithms
trained
on
biased
data
marginalization
of
certain
groups
in
online
communities
polarization
of
society
caused
by
massive
personalization
disinformation
caused
by
viral
spread
of
false
information
all
the
way
to
addiction
caused
by
systems
aiming
to
aggressively
monetize
people
attention
these
problems
have
gained
the
attention
of
an
interdisciplinary
community
of
researchers
including
computer
scientists
social
scients
and
legal
scholars1
the
information
retrieval
ir
community
has
also
recently
recognized
fate
standing
for
fairness
accountability
transparency
and
ethics
and
the
societal
impact
of
ir
technology
as
one
of
the
crucial
directions
for
the
field
culpepper
et
al
2018
in
line
with
that
direction
user
rights
in
search
systems
motivate
the
work
carried
out
in
this
thesis
in
particular
we
focus
on
the
issues
of
privacy
and
fairness
1.1
search
systems
search
systems
mediate
access
to
information
figure
1.1
schematically
describes
search
environment
people
may
participate
in
this
environment
in
two
different
roles
as
searchers
see
for
instance
fatconference
org
ainow
com
chapter
introduction
or
search
subjects
searchers
are
the
users
who
turn
to
search
engines
to
find
information
typically
they
phrase
their
information
needs
as
keyword
queries
which
are
issued
to
the
search
system
the
ranking
mechanism
computes
the
relevance
of
each
document
in
the
underlying
collection
to
the
issued
search
query
and
returns
ranked
list
of
documents
likely
to
be
relevant
to
the
searcher
information
need
if
search
system
observes
searcher
over
time
and
collects
all
the
queries
she
issues
the
relevance
and
the
document
ranking
mechanism
can
be
personalized
for
instance
it
is
possible
to
determine
that
user
querying
for
python
is
interested
in
the
programming
language
rather
than
the
animal
if
she
has
issued
other
queries
related
to
programming
in
the
past
while
traditionally
documents
are
thought
of
as
text
without
necessarily
any
person
associated
with
them
many
search
systems
nowadays
implicitly
or
explicitly
rank
people
those
people
might
be
job
seekers
on
human
resource
support
platforms
such
as
linkedin
or
content
creators
on
platforms
like
spotify
music
rankings
amazon
product
rankings
airbnb
apartment
rankings
or
twitter
social
media
posting
rankings
we
call
these
ranked
users
search
subjects
search
subjects
are
exposed
to
searchers
in
ranking
results
and
the
currency
in
which
they
are
being
paid
on
the
platform
is
the
searcher
attention
attention
can
be
measured
in
terms
of
click
rates
gaze
fixation
times
measured
in
eyetracking
studies
or
more
directly
by
the
total
amount
of
income
earned
by
search
subjects
from
successful
transactions
because
search
subjects
are
exposed
to
searchers
in
response
to
queries
search
queries
determine
the
context
in
which
exposure
happens
such
context
can
be
positive
or
negative
yielding
exposure
desirable
in
some
scenarios
and
undesirable
in
others
exposure
might
be
desirable
for
instance
on
hiring
support
platforms
where
job
candidates
want
to
be
exposed
to
recruiters
searching
for
new
employees
exposure
might
be
undesirable
however
in
social
media
search
engines
when
searchers
issue
sensitive
queries
related
to
diseases
or
controversial
political
issues
since
search
systems
collect
vast
amounts
of
data
about
both
searchers
and
search
subjects
they
have
the
potential
to
violate
the
privacy
of
both
of
these
groups
of
users
moreover
by
controlling
the
exposure
of
different
search
subjects
and
the
quality
of
results
for
different
searchers
they
have
an
immense
power
to
deliver
unfairly
disparate
levels
of
service
and
experience
to
different
people
the
increasing
dependence
on
search
systems
in
various
platforms
and
areas
of
life
thus
calls
for
investigation
of
the
issues
of
privacy
and
fairness
in
search
1.1
privacy
in
search
privacy
of
searchers
the
potential
to
violate
the
privacy
of
searchers
is
result
of
search
systems
collecting
search
queries
and
aggregating
them
into
detailed
user
profiles
because
search
engines
are
often
the
first
source
people
refer
to
when
seeking
information
necessary
for
their
work
or
hobbies
when
seeking
information
related
to
health
issues
or
personal
problems
or
when
planning
travels
search
histories
often
paint
very
intimate
picture
of
searcher
life
having
all
of
this
information
aggregated
per
user
profile
leads
to
number
of
privacy
risks
including
linking
of
sensitive
queries
to
real-world
individuals
1.1
motivation
query
ranking
mechanism
ex
nt
co
searchers
search
subjects
osur
exp
ntio
atte
figure
1.1
schematic
depiction
of
search
system
users
participate
in
the
system
either
as
searchers
or
search
subjects
inference
of
additional
user
attributes
that
were
not
disclosed
to
the
search
system
directly
or
profiling
and
targeting
we
describe
these
risks
in
detail
in
the
following
paragraphs
linking
of
search
histories
to
individuals
is
possible
through
queries
containing
pieces
of
individual-specific
information
this
harm
was
exemplified
when
aol
released
naively
anonymized
querylog
with
usernames
replaced
by
random
ids
in
20062
following
the
release
journalists
were
able
to
deanonymize
some
individuals
by
cross-referencing
queries
containing
phone
numbers
some
users
might
query
for
their
own
phone
numbers
either
deliberately
or
through
copy-pasting
mistakes
with
phone
book
entries
once
deanonymized
search
histories
enable
further
linking
of
individuals
to
sensitive
information
including
queries
related
to
topics
like
health
or
hygiene
such
attacks
were
demonstrated
to
be
viable
beyond
just
search
data
for
instance
it
is
possible
to
match
anonymized
netflix
movie
recommendations
with
publicly
available
imdb
movie
rating
data
thus
matching
real-world
identities
to
possibly
sensitive
ratings
revealing
political
or
sexual
orientations
narayanan
and
shmatikov
2008
collection
of
large
amounts
of
user
data
might
also
enable
inference
of
information
that
is
not
present
in
the
data
and
perhaps
explicitly
protected
by
the
users
it
is
feasible
for
instance
to
infer
demographic
information
using
search
logs
bi
et
al
2013
even
beyond
relatively
rich
and
complex
search
histories
very
private
data
such
as
personality
traits
can
be
inferred
from
items
user
likes
on
platform
like
facebook3
kosinski
et
al
2013
detailed
user
profiles
might
also
be
made
available
to
third-parties
often
without
the
knowledge
of
the
profile
owner
data
can
be
passed
on
beyond
the
original
intentions
in
case
of
company
mergers
or
if
the
search
provider
infrastructure
gets
compromised
https://en.wikipedia.org/wiki/aol_search_data_leak
https://facebook.com
chapter
introduction
beyond
unintentional
leaks
and
breaches
user
data
might
also
be
intentionally
used
against
their
interest
for
instance
search
providers
use
query
histories
for
profiling
and
targeted
advertising
especially
if
the
topic
of
an
ad
is
sensitive
such
advertisement
being
displayed
in
user
browser
might
lead
to
privacy
breaches
if
seen
by
external
observers
privacy
of
search
subjects
privacy
problems
of
search
subjects
are
tied
to
exposure
in
the
ranking
results
of
sensitive
queries
as
depicted
in
figure
1.1
the
query
of
searcher
determines
the
context
in
which
search
subjects
are
exposed
sensitive
queries
will
as
result
lead
to
sensitive
exposure
examples
of
such
queries
include
those
topically
related
to
health
finance
or
other
personal
issues
those
which
are
unique
to
user
such
as
phone
numbers
or
e-mail
addresses
or
those
which
are
rather
uncommon
for
given
user
profile
sensitive
exposure
enabled
hackers
to
scrape
the
profile
data
of
around
billion
facebook
users
in
april
20184
scraping
user
data
on
such
massive
scale
faces
fundamental
problem
how
to
enumerate
all
users
in
the
system
to
get
their
profile
urls
the
hackers
had
reportedly
acquired
database
of
e-mail
addresses
and
phone
numbers
on
the
dark
web
and
issued
these
as
queries
to
facebook
search
engine
as
response
to
these
queries
the
engine
returned
links
to
the
profiles
of
users
to
whom
the
e-mail
or
the
phone
number
belonged
there
exist
other
scenarios
of
this
kind
with
adversaries
not
targeting
any
particular
individual
but
rather
searching
for
targets
matching
their
relevance
criteria
examples
include
bloggers
looking
for
examples
to
their
stories
or
governments
looking
for
politically
controversial
statements
adversarial
situations
like
these
could
be
potentially
avoided
if
the
search
engines
computed
the
exposure
information
computing
search
exposure
means
reversing
search
and
for
each
user
profile
finding
all
the
queries
that
yield
the
profile
in
the
top-k
results
1.1
fairness
in
search
fairness
for
searchers
delivering
search
results
of
disparate
quality
to
different
demographic
groups
might
mean
that
historically
disadvantaged
groups
receive
worse
access
to
information
thus
fairness
for
searchers
has
been
understood
as
lack
of
disparity
in
the
quality
of
results
in
this
spirit
mehrotra
et
al
2017
proposed
methodology
to
measure
whether
search
engine
delivers
less
satisfactory
results
to
searchers
from
different
groups
determined
by
attributes
such
as
gender
or
age
it
is
worth
noting
that
search
engine
might
underperform
for
searchers
from
minority
groups
not
necessarily
intentionally
but
because
it
might
have
less
observational
data
about
these
groups
at
its
disposal
to
train
the
algorithms
or
perhaps
because
the
relevance
feedback
collected
from
the
majority
groups
is
biased
against
the
minority
fairness
for
search
subjects
fairness
for
search
subjects
matters
especially
in
scenarios
where
rankings
influence
people
lives
outside
of
the
platform
such
is
the
case
for
two-sided
economy
platforms
including
airbnb
or
uber
or
hiring
support
platforms
such
as
linkedin
in
each
of
these
systems
subjects
seek
to
be
displayed
high
in
the
rankings
as
it
increases
https://www.independent.co.uk/news/world/americas/facebook-hackers-personal-datacollection-users-cambridge-analytica-trump-mark-zuckerberg-latest-a8289816.html
1.2
challenges
their
chances
of
getting
real-world
advantage
be
it
higher
income
or
being
contacted
by
recruiters
with
such
tangible
influence
over
people
lives
search
engines
in
these
scenarios
should
make
sure
their
results
are
fair
or
more
specifically
that
subjects
get
fair
representation
in
the
ranked
results
most
papers
thus
far
have
proposed
to
quantify
such
fair
representation
using
different
forms
of
diversity
and
exposure
in
practice
exposure
can
be
determined
in
eye-tracking
studies
by
measuring
the
time
the
searchers
spend
investigating
result
or
by
estimating
click
probabilities
for
different
ranking
results
to
ensure
fairness
to
individuals
system
should
provide
each
subject
the
amount
of
exposure
that
is
proportional
to
her
relevance
biega
et
al
2018
unfairness
however
often
falls
along
the
lines
of
historical
inequities
ensuring
fairness
on
group
level
for
groups
defined
by
legally
protected
attributes
such
as
gender
or
race
means
granting
equal
exposure
to
different
groups
singh
and
joachims
2018
zehlike
et
al
2017
1.2
challenges
in
the
context
of
the
described
privacy
and
fairness
problems
this
thesis
tackles
the
following
specific
challenges
fair
exposure
for
search
subjects
to
be
individually
fair
to
each
subject
search
system
should
grant
subjects
exposure
that
is
proportional
to
their
relevance
however
if
many
subjects
have
similar
relevance
in
given
search
task
it
is
impossible
to
grant
everyone
the
attention
they
deserve
in
single
ranking
this
problem
arises
because
of
phenomenon
called
position
bias
where
the
searchers
pay
disproportionately
more
attention
to
subjects
ranked
higher
often
irrespective
of
their
relevance
as
result
it
is
impossible
to
be
individually
fair
to
subjects
in
single
ranking
we
can
instead
look
at
sequences
of
rankings
and
amortize
exposure
over
time
this
thesis
tackles
the
challenge
of
granting
every
subject
in
ranking
system
the
amortized
exposure
they
deserve
sensitive
exposure
of
search
subjects
if
user
post
is
returned
as
top-k
answer
to
sensitive
search
query
the
user
is
exposed
in
sensitive
context
the
richness
and
volume
of
the
content
we
post
online
make
it
challenging
to
maintain
awareness
of
the
contexts
in
which
our
posts
are
returned
as
top-k
results
in
search
systems
online
users
have
very
limited
information
about
the
queries
that
lead
others
to
their
profiles
yet
from
the
privacy
perspective
such
information
is
crucial
if
these
exposing
queries
are
of
sensitive
nature
this
thesis
tackles
the
problem
of
privacy-sensitive
search
exposure
that
is
finding
the
sensitive
queries
for
which
any
post
of
given
user
is
returned
as
top-k
search
result
quantifying
privacy
risks
from
textual
data
prior
work
on
privacy
has
largely
focused
on
structured
data
such
as
databases
or
graphs
these
solutions
prove
insufficient
for
users
in
online
communities
that
allow
for
creation
of
textual
contents
in
particular
quantifying
sensitive
exposure
requires
methodology
for
quantifying
privacy-sensitivity
in
text
this
thesis
tackles
the
problem
of
quantifying
privacy
risks
from
textual
data
chapter
introduction
privacy-preserving
personalization
for
searchers
information
accumulated
within
single
user
account
often
draws
an
exact
picture
of
person
life
such
massive
accumulation
of
personal
data
leads
to
significant
privacy
concerns
at
the
same
time
while
caring
about
privacy
many
users
feel
compelled
to
give
in
all
of
this
information
in
exchange
for
quality
personalized
results
this
thesis
tries
to
challenge
the
assumption
that
detailed
user
profiles
are
necessary
to
personalize
the
results
and
tackles
the
problem
of
designing
mechanisms
for
delivering
personalized
search
results
without
the
need
for
accurate
user
profiling
1.3
thesis
contributions
equity
of
attention
in
rankings
this
dissertation
develops
mechanism
for
reordering
rankings
such
that
each
subject
in
the
system
receives
attention
from
the
searchers
that
is
proportional
to
their
relevance
it
is
however
impossible
to
achieve
such
proportionality
in
single
ranking
searchers
are
susceptible
to
position
bias
which
makes
them
pay
disproportionately
more
attention
to
subjects
ranked
at
the
top
irrespective
of
relevance
we
thus
propose
to
amortize
attention
over
time
by
reordering
consecutive
rankings
while
addressing
fairness
concerns
reordering
subjects
in
the
ranking
will
lead
to
accuracy
loss
when
order
is
no
longer
determined
by
relevance
trying
to
balance
both
of
these
dimensions
we
formalize
reordering
as
constrained
optimization
problem
where
we
minimize
unfairness
measured
as
disparity
between
attention
and
relevance
subject
to
constraints
on
ranking
accuracy
loss
choosing
appropriate
fairness
and
quality
measures
the
problem
can
be
solved
as
an
integer
linear
program
ilp
we
apply
and
analyze
the
behavior
of
the
proposed
mechanism
on
synthetic
and
real-world
data
of
rental
apartments
from
the
airbnb
platform5
this
work
was
published
as
full
paper
at
sigir
2018
biega
et
al
2018
sensitive
search
exposure
this
dissertation
develops
methodology
for
quantifying
sensitive
search
exposure
we
define
search
exposure
as
the
problem
of
finding
all
the
queries
that
expose
any
of
user
posts
in
the
top-k
results
in
community
search
engine
with
this
formulation
the
problem
can
be
seen
as
reverse
search
thus
if
we
think
about
search
as
the
problem
finding
k-nearest-neighbors
documents
closest
to
the
search
query
by
given
similarity
or
relevance
metric
one
can
cast
search
exposure
as
an
instance
of
well-defined
problem
of
reverse-k-nearest-neighbors
generating
such
queries
is
not
enough
our
empirical
analysis
with
user
profiles
from
twitter
reveals
that
exposure
sets
for
some
users
might
be
enormous
and
largely
contain
noisy
and
meaningless
queries
to
make
the
outputs
useful
to
end
users
we
design
weakly-supervised
learning-to-rank
method
ordering
the
queries
such
that
those
at
the
top
are
most
concerning
we
show
that
the
queries
can
be
effectively
ranked
using
only
implicit
signals
which
are
readily
available
to
service
providers
this
work
was
published
as
full
paper
at
cikm
2017
biega
et
al
2017a
r-susceptibility
this
dissertation
develops
methodology
for
quantifying
privacy
risks
from
textual
data
in
an
online
community
we
propose
to
quantify
the
risks
using
skeleton
https://airbnb.com
1.4
other
contributions
of
the
author
of
topic
model
which
is
set
of
distributions
over
words
each
topic
is
annotated
with
privacy
sensitivity
score
determined
in
crowdsourcing
study
the
model
provides
each
user
with
the
information
on
how
relevant
her
postings
are
to
each
of
the
sensitive
topics
relevance
is
determined
using
number
of
measures
capturing
how
personal
user
interest
in
given
topic
is
to
this
end
beyond
pure
lexical
relevance
we
model
how
broad
user
interest
in
domain
the
topic
comes
from
is
attempting
to
differentiate
professional
from
personal
interests
and
how
temporally
spread
user
interest
is
attempting
to
differentiate
occasional
and
recurring
interest
we
moreover
propose
notion
of
r-susceptibility
as
measure
showing
the
user
how
high
they
rank
in
given
community
with
respect
to
given
sensitive
topic
we
evaluate
the
approach
in
user
study
over
profiles
from
three
different
online
communities
this
work
was
published
as
full
paper
at
sigir
2016
biega
et
al
2016
privacy-preserving
personalization
this
dissertation
proposes
framework
of
mediator
accounts
allowing
for
personalization
of
search
results
without
the
need
to
store
exact
user
interaction
histories
mediator
platform
splits
and
merges
queries
of
different
users
into
synthetic
user
profiles
guided
by
privacy-utility
trade-off
privacy
is
achieved
by
random
assignments
and
utility
by
keeping
semantically
coherent
contexts
intact
that
is
topically
similar
queries
of
user
kept
together
the
thesis
moreover
proposes
formalization
of
the
notions
of
profiling
privacy
and
individual
user
utility
our
experimental
results
using
querylog
synthesized
from
the
questions
on
the
stackexchange
platform6
provided
detailed
analysis
of
the
trade-offs
from
the
perspective
of
individual
users
which
should
be
contrasted
to
much
of
the
previous
works
focusing
on
system
utility
our
results
showed
that
it
is
indeed
possible
to
reconcile
big
profiling
privacy
gains
with
low
personalization
utility
loss
particularly
for
users
with
rich
profiles
and
diversified
interests
this
work
was
published
as
full
paper
at
sigir
2017
biega
et
al
2017b
in
summary
the
contributions
of
the
thesis
complement
each
other
in
number
of
ways
first
we
are
investigating
two
different
societal
problems
fairness
chapter
and
privacy
chapters
second
we
cover
the
problems
of
both
search
subjects
chapters
and
searchers
chapter
third
in
the
context
of
exposure
specifically
we
propose
mechanisms
for
dealing
with
both
wanted
chapter
and
unwanted
exposure
chapters
1.4
other
contributions
of
the
author
the
author
of
this
thesis
has
co-authored
number
of
other
papers
and
initiatives
related
to
fairness
and
privacy
which
are
not
included
as
contributions
of
this
thesis
our
fatrec
recsys
2017
paper
chakraborty
et
al
2017
focused
on
two-sided
match-making
platforms
such
as
uber
we
argued
that
single
match
cannot
be
fair
as
there
are
many
relevant
providers
yet
only
one
provider
receives
the
benefit
of
http://stackexchange.com
chapter
introduction
the
match
to
allow
for
more
uniform
distribution
of
the
benefits
we
proposed
to
evaluate
fairness
over
time
by
making
sure
the
cumulative
ratios
of
the
deserved
benefit
and
the
actual
benefit
are
the
same
for
all
the
providers
in
system
interpreting
the
problem
this
way
allowed
us
to
draw
parallel
to
fair
resource
sharing
algorithms
which
have
been
well
studied
in
the
networking
community
we
have
demonstrated
the
generalizability
of
the
mediator
accounts
framework
biega
et
al
2017b
applying
it
to
the
problem
of
privacy
of
hidden
profiles
which
we
identified
and
defined
in
our
cikm
2017
paper
eslami
et
al
2017
hidden
profiles
are
the
profiles
of
users
who
decided
to
leave
an
online
community
but
whose
data
was
retained
by
the
service
providers
for
analytic
purposes
such
data
still
poses
privacy
risks
for
the
users
as
it
can
easily
be
passed
on
beyond
the
original
intentions
upon
governmental
inquiry
company
merger
or
when
the
infrastructure
of
the
provider
is
compromised
our
results
show
that
it
is
possible
to
protect
the
hidden
profiles
by
scrambling
user
data
at
the
same
time
keeping
the
analytic
utility
of
the
data
minimally
affected
our
work
on
mediator
accounts
biega
et
al
2017b
used
querylog
synthesized
from
an
online
community
question
answering
community
the
derivation
methodology
employed
simple
heuristic
for
converting
user
questions
to
queries
to
design
better
querylog
derivation
methods
we
conducted
user
study
with
the
goal
of
understanding
the
query
formulation
process
we
moreover
proposed
methodology
for
deriving
other
characteristics
of
information
retrieval
collections
such
as
relevance
judgments
from
the
structure
of
the
cqa
forums
this
work
is
under
submission
to
facilitate
further
work
on
fairness
in
rankings
the
author
of
this
thesis
has
coauthored
successful
proposal
for
trec
track
focusing
on
the
problem
of
fairness7
trec
is
an
information
retrieval
conference
whose
goal
is
to
design
bechmarks
document
collections
with
relevance
judgments
as
well
as
metrics
and
standardized
experimentation
protocols
for
the
most
important
information
retrieval
tasks
this
track
will
run
for
the
first
time
in
trec
2019
our
psbd
cikm
2014
paper
proposes
method
to
probabilisticaly
predict
whether
users
are
personally
afflicted
by
privacy
sensitive
states
such
as
depression
or
pregnancy
feeding
the
lexical
information
from
their
search
histories
into
probabilistic
graphical
model
preliminary
experimental
analysis
in
this
paper
showed
that
the
method
can
achieve
good
accuracy
in
predicting
privacy
sensitive
states
this
work
laid
foundation
for
the
r-susceptibility
project
biega
et
al
2016
https://fair-trec.github.io/
1.5
prior
publications
1.5
prior
publications
the
results
of
this
thesis
have
been
published
in
the
following
articles
asia
biega
krishna
gummadi
and
gerhard
weikum
equity
of
attention
amortizing
individual
fairness
in
rankings
in
proceedings
of
the
41st
international
acm
sigir
conference
on
research
and
development
in
information
retrieval
sigir
2018
ann
arbor
mi
usa
july
08
12
2018
pages
405
414
asia
biega
azin
ghazimatin
hakan
ferhatosmanoglu
krishna
gummadi
and
gerhard
weikum
learning
to
un-rank
quantifying
search
exposure
for
users
in
online
communities
in
proceedings
of
the
2017
acm
conference
on
information
and
knowledge
management
cikm
2017
singapore
november
06
10
2017
pages
267
276
the
efficient
algorithm
for
generating
exposure
sets
and
the
corresponding
experiments
sections
5.2
and
5.3
in
this
publication
are
not
contributions
of
this
thesis
joanna
asia
biega
krishna
gummadi
ida
mele
dragan
milchevski
christos
tryfonopoulos
and
gerhard
weikum
r-susceptibility
an
ir-centric
approach
to
assessing
privacy
risks
for
users
in
online
communities
in
proceedings
of
the
39th
international
acm
sigir
conference
on
research
and
development
in
information
retrieval
sigir
2016
pisa
italy
july
17
21
2016
pages
365
374
asia
biega
rishiraj
saha
roy
and
gerhard
weikum
privacy
through
solidarity
user-utility-preserving
framework
to
counter
profiling
in
proceedings
of
the
40th
international
acm
sigir
conference
on
research
and
development
in
information
retrieval
shinjuku
tokyo
japan
august
11
2017
pages
675
684
the
experiments
on
applying
the
mediator
account
framework
to
the
scenario
of
recommender
systems
sections
and
in
this
publication
are
excluded
from
this
dissertation
1.6
organization
the
remainder
of
the
thesis
is
organized
as
follows
chapters
and
provide
background
on
user
privacy
and
algorithmic
fairness
chapter
describes
our
contributions
related
to
fairness
in
rankings
chapter
describes
our
contributions
related
to
sensitive
search
exposure
chapter
describes
our
contributions
related
to
quantifying
privacy
risks
from
textual
data
chapter
describes
our
contributions
related
to
privacy-preserving
personalization
for
searchers
finally
appendices
and
provide
additional
details
on
the
users
studies
conducted
in
this
thesis
which
were
omitted
in
the
corresponding
publications
due
to
space
constraints
chapter
background
user
privacy
contents
2.1
preliminaries
2.2
privacy
risks
and
notions
12
2.3
2.1
11
2.2
information
leakage
12
2.2
profiling
13
2.2
exposure
13
achieving
privacy
14
2.3
limiting
information
leakage
14
2.3
limiting
profiling
15
2.3
limiting
exposure
16
2.4
cost
of
privacy
17
2.5
privacy
in
search
systems
18
2.6
selected
other
dimensions
in
privacy
research
19
preliminaries
this
background
chapter
provides
an
overview
of
privacy
notions
and
methods
for
achieving
them
in
various
systems
we
are
concerned
with
the
privacy
of
an
individual
user
whose
data
is
collected
by
the
system
the
data
may
be
created
or
generated
by
the
user
as
is
the
case
for
social
network
postings
or
web
browsing
histories
or
by
others
as
is
the
case
for
medical
databases
with
patient
information
collected
by
hospitals
types
of
user
data
user
data
may
consist
of
structured
attributes
as
well
as
unstructured
text
structured
attributes
may
be
binary
for
instance
whether
user
liked
certain
item
categorical
for
instance
marital
status
or
numerical
for
instance
user
age
textual
data
may
occur
in
the
form
of
search
queries
or
social
media
postings
certain
attributes
may
also
encode
connections
between
multiple
users
for
instance
in
the
form
of
friendship
edges
in
social
networks
privacy-sensitivity
of
data
certain
items
in
user
data
might
be
considered
personally
identifiable
information
pii
while
determining
what
constitutes
pii
is
generally
context
specific
one
might
assume
attributes
such
as
username
or
social
security
number
are
personally
identifying
these
attributes
are
often
referred
to
as
identifiers
certain
attributes
12
chapter
background
user
privacy
constitute
quasi-identifiers
these
attributes
are
not
pii
on
their
own
but
may
uniquely
identify
user
when
combined
with
other
quasi-identifiers
for
instance
given
combination
of
surname
birth
date
and
zip
code
might
describe
unique
individual
we
call
certain
attributes
sensitive
this
is
the
information
user
would
like
to
protect
in
given
context
for
instance
it
might
be
undesirable
to
link
diseases
to
patients
in
which
case
the
attribute
disease
would
be
considered
sensitive
sensitive
attributes
do
not
necessarily
need
to
be
explicitly
present
in
the
data
inferring
the
value
of
sensitive
attribute
using
the
available
data
would
also
be
considered
privacy
breach
data
usage
scenarios
user
data
might
be
sanitized
by
service
provider
if
they
want
to
make
public
release
data
publishing
or
if
they
provide
an
interface
for
querying
the
data
by
analysts
users
might
want
to
protect
their
data
from
the
service
providers
in
which
case
sanitization
is
performed
either
by
the
user
or
trusted
third-party
before
the
data
reaches
the
service
provider
2.2
privacy
risks
and
notions
2.2
information
leakage
linkability
linkability
or
identity
disclosure
is
risk
of
matching
data
to
realworld
individual
who
is
the
owner
of
the
data
or
whom
the
data
describes
while
the
most
straightforward
way
to
prevent
this
breach
is
to
remove
any
personally
identifying
information
such
protection
is
often
not
enough1
because
of
the
possibility
of
matching
quasi-identifiers
with
external
data
sources
the
protected
data
might
contain
sensitive
information
with
quasi-identifiers
but
without
personally
identifiable
information
external
public
data
sources
might
contain
personally
identifiable
information
together
with
quasiidentifiers
making
it
possible
to
mach
anonymized
records
by
quasi-identifier
values
such
strategy
was
used
to
deanonymize
medical
records
of
the
governor
of
massachusetts
using
public
employee
records
sweeney
2002b
moreover
research
shows
it
is
possible
to
de-anonymize
individuals
from
social
network
graph
data
by
correlating
anonymized
graphs
with
publicly
available
graphs
narayanan
and
shmatikov
2009
from
browser
fingerprints
constructed
from
browser
settings
and
plugins
which
are
available
to
any
website
user
visits
eckersley
2010
or
from
movie
rating
data
by
correlating
anonymized
ratings
with
ratings
publicly
available
on
the
imdb2
film
website
narayanan
and
shmatikov
2008
attribute
disclosure
even
if
matching
of
an
individual
to
specific
data
record
is
not
possible
it
might
still
be
possible
to
learn
the
value
of
sensitive
attribute
of
given
individual
machanavajjhala
et
al
2007
such
breach
is
called
attribute
disclosure
for
instance
imagine
we
know
an
individual
with
the
quasi-identifier
values
of
66123
male
07.09
1982
who
has
been
hospitalized
at
an
institution
releasing
patient
records
even
when
we
cannot
uniquely
link
the
person
to
single
row
in
the
dataset
attribute
disclosure
https://en.wikipedia.org/wiki/aol_search_data_leak
htpps
imdb
com
2.2
privacy
risks
and
notions
13
will
occur
if
each
row
the
individual
possibly
maps
to
has
the
same
value
of
the
sensitive
attribute
attribute
disclosure
can
also
be
understood
as
gaining
additional
information
about
the
value
of
sensitive
attribute
from
dataset
when
compared
to
the
prior
knowledge
li
et
al
2007
for
instance
if
an
individual
has
heart
disease
with
the
probability
0.6
according
to
the
dataset
while
the
prior
probability
in
given
population
for
having
heart
disease
is
0.1
the
adversary
increases
her
certainty
about
the
sensitive
value
even
though
she
does
not
learn
the
exact
value
attribute
inference
privacy
may
also
be
violated
when
attributes
and
information
not
directly
observable
or
recorded
in
the
data
are
inferred
from
the
observable
data
of
multiple
users
using
machine
learning
methods
while
the
two
concepts
are
related
the
main
conceptual
difference
between
attribute
inference
and
disclosure
is
that
disclosure
typically
refers
to
recovering
the
value
of
sensitive
attribute
that
is
present
in
an
anonymized
dataset
while
inference
refers
to
learning
the
attributes
not
present
in
the
data
based
on
observations
of
attribute
patterns
in
user
populations
various
types
of
attribute
inference
have
been
demonstrated
in
the
literature
for
instance
it
is
possible
to
predict
psychological
and
demographic
traits
from
the
items
people
like
in
social
network
such
as
facebook
kosinski
et
al
2013
predict
whether
two
accounts
in
two
different
online
communities
belong
to
the
same
individual
goga
et
al
2015
predict
user
location
from
the
tags
they
add
to
their
online
postings
zhang
et
al
2018
or
predict
sensitive
information
such
as
whether
person
is
on
vacation
driving
drunk
or
having
certain
disease
from
the
textual
contents
of
their
social
media
postings
mao
et
al
2011
classifiers
based
on
stylometric
techniques
for
text
such
as
the
analysis
of
usage
of
different
words
or
syntactic
and
linguistic
patterns
have
been
shown
to
enable
authorship
inference
abbasi
and
chen
2008
narayanan
et
al
2012
2.2
profiling
loss
of
privacy
can
also
occur
when
large
amount
of
data
is
collected
about
user
as
the
entirety
of
such
data
for
instance
search
history
spanning
multiple
years
may
paint
very
intimate
picture
of
person
life
the
risk
might
be
defined
for
instance
as
the
total
amount
of
data
collected
singla
et
al
2014
biega
et
al
2017b
or
the
total
number
of
topics
present
in
user
profile
biega
et
al
2017b
meng
et
al
2016b
such
detailed
data
is
usually
collected
to
enable
personalization
biega
et
al
2017b
singla
et
al
2014
or
targeted
advertising
yu
et
al
2016
meng
et
al
2016b
2.2
exposure
privacy
breaches
include
inappropriate
exposure
of
user
data
inappropriate
exposure
might
mean
that
data
is
accessible
by
unintended
audience
sandhu
et
al
1996
either
shortly
after
data
creation
or
long
thereafter
when
user
does
not
necessarily
remember
about
the
data
existence
and
exposure
possibility
mondal
et
al
2016
moreover
access
to
data
might
be
made
easier
through
various
platform
features
examples
include
facebook
news
14
chapter
background
user
privacy
feed
where
updates
to
the
content
of
user
profiles
are
actively
broadcast
to
other
users
or
search
engines
where
access
to
user
profiles
by
is
enabled
by
matching
of
keyword
queries
see
chapter
2.3
achieving
privacy
2.3
limiting
information
leakage
k-anonymity
the
success
ratio
of
linkability
based
on
quasi-identifiers
depends
on
how
many
individuals
share
unique
combinations
of
values
this
insight
underlies
the
anonymization
technique
called
k-anonymity
sweeney
2002b
dataset
is
k-anonymous
if
each
combination
of
quasi-identifier
values
appears
at
in
the
dataset
at
least
times
the
protection
offered
by
this
mechanism
is
that
the
probability
of
correctly
mapping
an
individual
to
row
in
the
database
is
lower
than
k1
means
of
preventing
linkability
include
removal
of
any
personally
identifiable
information
or
perturbation
of
data
so
as
to
satisfy
the
k-anonymity
requirement
sweeney
2002a
jr
and
agrawal
2005
lefevre
et
al
2005
2006
such
perturbations
include
generalization
where
values
are
replaced
by
sets
of
values
for
instance
zip
code
66123
might
become
66
and
suppression
where
individual
user
records
are
fully
removed
from
the
data
alternative
approaches
include
generation
of
synthetic
datasets
that
satisfy
privacy
criteria
at
the
same
time
preserving
patterns
from
the
original
data
this
idea
has
been
explored
in
the
context
of
preserving
frequent
itemsets
while
ensuring
k-anonymity
vreeken
et
al
2007
or
preserving
the
distribution
of
attribute
values
while
adding
controlled
noise
to
the
values
generated
from
these
distributions
howe
et
al
2017
l-diversity
while
mitigating
the
threat
of
linkability
k-anonymity
does
not
offer
full
protection
against
sensitive
attribute
disclosure
to
prevent
such
attribute
disclosure
machanavajjhala
et
al
2007
proposed
the
notion
of
l-diversity
machanavajjhala
et
al
2007
which
requires
that
within
each
equivalence
class
of
rows
defined
by
given
combination
of
quasiidentifier
values
that
is
within
each
k-anonymous
block
there
exist
at
least
different
values
of
the
sensitive
attribute
as
result
even
if
an
adversary
is
able
to
map
an
individual
to
given
k-anonymous
block
unambiguously
she
still
faces
uncertainty
about
the
individual
sensitive
data
t-closeness
l-diversity
does
not
protect
against
attribute
disclosure
in
probabilistic
sense
aggregate
statistics
over
the
whole
dataset
provide
the
prior
probability
over
the
values
of
sensitive
attributes
in
the
population
if
the
distribution
within
the
equivalence
class
an
individual
is
mapped
to
is
different
from
the
prior
distribution
the
certainty
about
the
value
of
the
sensitive
attribute
of
the
individual
changes
to
prevent
this
kind
of
disclosure
the
notion
of
t-closeness
li
et
al
2007
requires
that
the
distributions
of
sensitive
values
within
anonymous
blocks
are
within
distance
of
at
most
from
the
global
distribution
in
the
whole
dataset
distribution
distance
can
be
captured
by
metrics
like
the
kl-divergence
or
the
earth
mover
distance
2.3
achieving
privacy
15
differential
privacy
the
notion
of
differential
privacy
dwork
2008
requires
that
the
presence
or
absence
of
an
individual
data
in
dataset
does
not
significantly
change
the
output
of
mechanism
applied
to
the
data
more
precisely
mechanism
satisfies
εdifferential
privacy
if
the
following
inequality
holds
for
any
two
neighboring
datasets
d1
and
d2
that
differ
by
at
most
one
row
d1
eε
d2
for
any
set
that
the
mechanism
may
compute
note
that
this
requirement
is
imposed
over
mechanism
applied
to
the
data
and
not
over
the
data
itself
and
is
studied
mostly
in
scenarios
where
an
analyst
uses
data
querying
interface
for
example
assume
an
analyst
wants
to
learn
from
census
data
how
many
people
in
given
town
have
an
income
over
100k
let
us
denote
this
query
function
as
and
the
mechanism
the
presence
of
an
individual
with
an
income
over
100k
in
the
dataset
will
change
this
value
by
if
the
answer
of
the
system
for
the
dataset
without
the
individual
is
then
and
thus
violating
the
differential
privacy
requirement
for
any
to
satisfy
the
requirement
of
differential
privacy
system
needs
to
add
random
noise
to
mechanism
results
for
count
queries
is
has
been
shown
that
the
privacy
requirement
can
be
satisfied
by
adding
noise
from
the
laplace
distribution
with
the
scale
parameter
where
maxd1
d2
d1
d2
also
called
sensitivity
determines
the
maximum
difference
in
the
value
of
when
applied
to
neighboring
datasets
d1
d2
dwork
2008
in
the
aforementioned
example
instead
of
returning
the
system
returns
where
laplace
the
scale
of
the
noise
that
needs
to
be
added
depends
on
the
sensitivity
of
the
function
the
higher
the
sensitivity
the
bigger
the
scale
of
the
noise
as
well
as
the
privacy
parameter
the
lower
the
and
thus
the
stricter
the
privacy
requirement
the
bigger
the
scale
of
noise
because
differential
privacy
prevents
inference
of
an
individual
presence
in
the
data
it
offers
protection
from
both
linkability
and
attribute
disclosure
decreasing
inference
accuracy
in
the
context
of
sensitive
attribute
inference
using
machine
learning
models
privacy
loss
is
usually
quantified
as
the
accuracy
of
the
applied
model
the
more
accurately
sensitive
attribute
can
be
predicted
the
more
user
privacy
is
at
stake
protections
against
inference
attacks
focus
on
perturbing
the
data
to
decrease
the
accuracy
of
the
predictions
for
instance
zheleva
and
getoor
2009
studied
how
friendship
and
group
membership
information
influences
the
accuracy
of
sensitive
attribute
prediction
in
social
networks
zhang
et
al
2018
propose
method
to
select
tags
appended
to
social
posting
to
prevent
the
inference
of
the
posting
user
location
decreasing
inference
accuracy
is
also
used
to
prevent
authorship
attribution
solutions
along
these
lines
include
stylistic
suggestions
for
the
authors
to
decrease
the
uniqueness
of
their
style
kacmarcik
and
gamon
2006
mcdonald
et
al
2012
or
crowdsourcing
text
reformulations
almishari
et
al
2014
2.3
limiting
profiling
limiting
data
collection
to
limit
the
total
amount
of
data
collected
from
users
singla
et
al
2014
propose
the
notion
of
stochastic
privacy
stochastic
privacy
limits
the
probability
16
chapter
background
user
privacy
that
different
pieces
of
user
data
will
be
stored
to
enable
further
personalized
service
thus
effectively
limiting
the
size
of
user
profiles
obfuscating
data
profiling
privacy
might
be
protected
by
hiding
real
user
interactions
within
fake
data
such
an
approach
is
taken
for
instance
in
the
tackmenot
browser
extension
which
issues
synthetic
search
queries
on
user
behalf
howe
and
nissenbaum
2009
similarly
number
of
approaches
have
been
proposed
to
obfuscate
the
topical
interest
of
search
users
by
issuing
fake
queries
on
topics
not
covered
in
user
real
search
history
pang
et
al
2012
wang
and
ravishankar
2014
masood
et
al
2018
propose
profile
obfuscation
method
where
sensitive
user
data
is
replaced
by
semantically
similar
non-sensitive
data
data
grouping
and
splitting
an
early
idea
of
grouping
user
interactions
was
implemented
in
the
crowds
system
in
which
requests
were
passed
on
in
random
walk
over
network
of
users
before
being
passed
on
to
server
reiter
and
rubin
1998
procedure
like
that
results
in
requests
of
individuals
being
split
across
multiple
identities
this
thesis
pursues
related
idea
by
proposing
mediator
accounts
framework
chapter
where
the
goal
is
to
to
split
and
merge
search
queries
of
different
users
such
that
the
personalization
quality
is
minimally
reduced
at
the
same
time
we
want
to
create
synthetic
profiles
which
do
not
resemble
original
user
profiles
instead
of
merging
user
profiles
or
interactions
it
is
also
possible
to
split
them
into
smaller
chunks
such
ideas
have
been
investigated
in
the
context
of
personalized
search
where
search
histories
were
divided
into
chunks
with
topically
related
queries
chen
et
al
2011
xu
et
al
2007
as
result
for
instance
instead
of
seeing
an
individual
interested
in
programming
cooking
and
sports
search
engine
would
see
three
individuals
each
interested
in
one
of
the
three
aforementioned
topics
anti-tracking
beyond
service
providers
directly
collecting
data
about
their
users
there
are
third
parties
who
track
users
when
they
browse
the
web
such
trackers
collect
information
about
the
websites
users
visit
thus
learning
about
their
topical
interests
over
time
such
data
is
then
used
to
deliver
targeted
advertising
to
the
users
practice
referred
to
as
online
behavioral
advertising
several
protection
mechanisms
have
been
proposed
to
protect
user
privacy
in
this
context
either
by
requiring
the
website
publishers
to
mediate
between
users
and
trackers
by
adding
noise
to
user
data
akkus
et
al
2012
by
designing
targeting
architectures
where
user
data
is
stored
on
local
device
toubiana
et
al
2010
by
preventing
collection
of
unique
user
attributes
by
the
trackers
yu
et
al
2016
or
by
allowing
users
to
select
the
information
they
share
with
the
trackers
acknowledging
that
users
might
want
to
receive
personalized
ads
for
certain
topics
meng
et
al
2016b
2.3
limiting
exposure
limiting
data
audience
early
approaches
to
privacy
revolved
around
limiting
access
to
data
to
pre-specified
audience
such
access
control
lists
acls
were
defined
either
by
specifying
individuals
or
groups
of
individuals
role-based
acls
sandhu
et
al
1996
such
approaches
might
be
too
cumbersome
and
give
little
flexibility
to
users
with
hundreds
of
2.4
cost
of
privacy
17
connections
in
online
social
networks
to
overcome
this
limitation
number
of
solutions
have
been
proposed
to
help
users
statically
predefine
acls
based
on
the
network
structure
using
community
detection
approaches
mazzia
et
al
2012
or
by
suggesting
friends
to
share
the
content
with
on
the
fly
when
adding
new
posts
using
machine
learning
approaches
fang
and
lefevre
2010
limiting
data
lifetime
even
when
exposure
is
desirable
at
the
time
uploading
the
content
it
might
become
undesirable
when
the
content
is
re-discovered
some
time
after
publication
during
this
time
user
might
forget
such
content
is
present
in
her
digital
traces
while
her
preferences
and
views
change
an
evolution
like
this
is
especially
prominent
when
young
adult
enters
the
job
market
with
long
history
of
teenage
social
media
postings
motivated
by
such
scenarios
among
others
mondal
et
al
2016
proposes
an
inactivity-based
content
withdrawal
mechanism
where
postings
are
automatically
withdrawn
after
the
initial
audience
interest
fades
exposure
awareness
apart
from
strict
exposure
control
it
is
important
to
help
users
be
aware
of
the
exposure
of
their
content
especially
when
it
happens
through
complex
and
often
non-transparent
mechanisms
number
of
studies
have
motivated
the
need
for
exposure
support
showing
that
users
consistently
underestimate
the
size
of
their
content
audience
bernstein
et
al
2013
or
that
people
have
strong
feelings
regarding
exposure
thousands
of
facebook
users
protested
when
the
platform
introduced
the
news
feed
thinking
their
privacy
was
breached
when
the
updates
to
the
content
of
their
profiles
were
actively
broadcast
to
other
users
even
though
the
content
was
accessible
to
those
same
users
upon
visit
to
individual
profiles
boyd
2008
service
providers
do
realize
that
such
support
is
crucial
privacy
awareness
feature
for
instance
facebook
allows
its
users
to
preview
how
their
profile
looks
like
to
other
people
via
functionality
called
view
as
several
interface
designs
were
proposed
to
make
users
aware
of
the
size
of
their
content
audience
including
showing
pair
of
eyes
whose
size
is
proportional
to
the
size
of
the
audience
schlegel
et
al
2011
arguably
in
the
context
of
search
the
information
on
which
keyword
queries
return
user
posts
in
platform
search
engine
results
is
equally
important
as
the
information
on
who
can
see
user
personal
content
the
work
presented
in
chapter
contributes
to
the
line
of
work
on
exposure
awareness
in
search
2.4
cost
of
privacy
achieving
privacy
comes
at
the
cost
of
utility
loss
for
instance
the
goal
of
releasing
structured
data
is
for
people
to
be
able
to
compute
certain
statistics
and
gain
insights
from
the
data
when
trying
to
achieve
the
requirements
of
k-anonymity
l-diversity
t-closeness
or
differential
privacy
these
computations
become
inaccurate
when
the
attribute
values
are
generalized
when
rows
get
suppressed
or
when
noise
is
added
to
the
results
of
queries
generally
the
higher
the
privacy
the
lower
the
resulting
utility
of
the
data
because
there
can
be
lot
of
different
anonymizations
satisfying
chosen
privacy
criterion
one
usually
chooses
the
one
which
offers
the
highest
utility
for
models
such
as
k-anonymity
l-diversity
18
chapter
background
user
privacy
or
t-closeness
utility
is
measured
using
proxy
measures
such
as
the
number
of
resulting
abstraction
classes
the
average
number
of
rows
in
abstraction
classes
lefevre
et
al
2005
machanavajjhala
et
al
2007
li
et
al
2007
the
accuracy
of
classifiers
predicting
sensitive
attribute
brickell
and
shmatikov
2008
or
the
difference
between
the
distributions
of
sensitive
attributes
in
the
original
and
the
sanitized
datasets
li
and
li
2009
techniques
for
achieving
differential
privacy
control
the
amount
of
noise
added
to
the
data
through
the
parameter
the
lower
the
value
of
the
bigger
the
amount
of
noise
one
needs
to
add
to
achieve
ε-differential
privacy
thus
the
higher
the
privacy
the
lower
the
utility
of
the
data
that
is
the
accuracy
of
the
mechanism
results
utility
loss
caused
by
obfuscation
of
user
profiles
is
often
measured
using
various
personalization
quality
measures
singla
et
al
2014
wang
and
ravishankar
2014
chen
et
al
2011
zhu
et
al
2010
biega
et
al
2017b
2.5
privacy
in
search
systems
in
the
context
of
the
main
theme
of
this
thesis
it
is
worth
reiterating
over
the
privacy
problems
specific
to
search
systems
obfuscating
searcher
profiles
one
of
the
goals
in
privacy-preserving
ir
is
that
of
privacy-preserving
search
personalization
to
this
end
various
approaches
for
obfuscating
user
profiles
with
constraints
on
the
personalization
utility
were
proposed
different
types
of
such
obfuscation
approaches
include
removing
parts
of
the
logs
singla
et
al
2014
generating
fake
search
queries
and
mixing
them
with
the
user-issued
search
queries
howe
and
nissenbaum
2009
pang
et
al
2012
wang
and
ravishankar
2014
splitting
logs
into
multiple
logs
chen
et
al
2011
xu
et
al
2007
or
grouping
the
logs
of
different
users
biega
et
al
2017b
zhu
et
al
2010
anonymizing
search
logs
if
service
provider
wants
to
release
query
log
the
log
needs
to
be
sanitized
to
ensure
anonymity
to
the
searchers
whose
data
is
being
made
public
crucial
step
is
the
removal
of
any
personally
identifiable
information
assuming
any
query
which
appears
in
the
log
infrequently
can
be
personally
identifying
adar
2007
proposed
scheme
where
queries
in
the
logs
are
masked
until
they
appear
in
certain
number
of
user
profiles
stronger
anonymization
techniques
apply
differential
privacy
mechanisms
over
raw
query
logs
and
publish
the
results
returned
by
these
mechanisms
instead
of
the
original
log
for
example
zhang
and
yang
2017
proposes
publishing
of
query
sessions
small
subsets
of
user
profiles
encompassing
sequences
of
queries
issued
within
short
time
frame
to
satisfy
single
information
need
with
differentially
private
session
counts
while
zhang
et
al
2016b
propose
differentially
private
mechanism
that
results
in
publishing
query
counts
without
user
profiles
götz
et
al
2012
provides
summary
of
guarantees
offered
by
query
log
anonymization
mechanisms
whose
goal
is
to
publish
frequent
query
log
elements
2.6
selected
other
dimensions
in
privacy
research
19
adversarial
inference
using
search
logs
another
line
of
work
investigates
various
adversarial
attacks
using
search
logs
for
instance
peddinti
and
saxena
2010
and
gervais
et
al
2014
have
demonstrated
machine
learning
approaches
that
enable
distinguishing
real
and
fake
queries
in
obfuscated
user
search
logs
while
jones
et
al
2007
showed
that
it
is
possible
to
infer
demographic
and
location
information
from
query
histories
private
information
retrieval
related
theme
in
security
research
is
that
of
private
information
retrieval
where
user
wants
to
retrieve
an
item
from
database
stored
on
server
without
revealing
to
the
server
which
item
is
being
requested
chor
et
al
1995
the
goal
in
this
field
is
to
design
protocols
better
than
the
baseline
approach
where
the
server
sends
full
copy
of
the
database
to
the
requester
sensitive
search
exposure
this
thesis
tackles
novel
problem
of
sensitive
search
exposure
for
search
subjects
in
chapter
we
propose
methodology
for
finding
all
the
sensitive
queries
that
expose
subject
in
the
top-k
results
of
given
search
system
in
chapter
we
show
how
sensitive
exposure
can
serve
as
tool
for
quantifying
privacy
risks
in
textual
data
2.6
selected
other
dimensions
in
privacy
research
sensitivity
analysis
for
textual
data
automated
privacy
mechanisms
should
be
able
to
determine
which
content
is
sensitive
to
this
end
several
approaches
proposed
the
idea
that
content
is
sensitive
if
people
tend
to
create
it
anonymously
in
this
spirit
correa
et
al
2015
showed
that
linguistic
factors
such
as
usage
of
the
first
person
singular
pronoun
or
semantic
factors
such
as
the
topics
of
money
work
emotions
and
sexuality
can
be
used
to
train
machine
learning
methods
to
distinguish
anonymous
and
non-anonymous
social
media
posts
peddinti
et
al
2014
studied
the
differences
between
anonymous
and
non-anonymous
posts
in
the
online
question
and
answer
community
quora
finding
that
beyond
conventional
sensitive
topics
such
as
sex
health
or
religion
people
often
choose
to
post
anonymously
on
topics
such
as
education
and
educational
institutions
or
the
patent
law
longitudinal
privacy
beyond
the
privacy
threats
stemming
from
occasional
data
release
it
is
important
to
understand
long-term
effects
of
information
disclosure
mondal
et
al
2016
studied
the
content
deletion
behavior
of
twitter
users
and
proposed
automatic
methods
to
control
the
longitudinal
privacy
by
automatically
hiding
inactive
content
rizoiu
et
al
2016
studied
the
longitudinal
privacy
of
wikipedia
editors
measured
as
the
prediction
accuracy
of
features
such
as
gender
education
or
religion
the
paper
demonstrates
that
the
privacy
of
editors
who
become
inactive
and
do
not
contribute
any
new
data
still
decreases
over
time
as
the
accuracy
of
predictors
increases
thanks
to
data
contributed
by
other
users
eslami
et
al
2017
proposed
mechanism
for
perturbing
information
that
stays
in
the
system
after
user
decides
to
close
her
account
so
as
to
minimize
the
effect
of
privacy
breaches
over
data
she
has
no
control
over
20
chapter
background
user
privacy
human
perceptions
of
privacy
research
in
privacy
is
often
guided
by
user
perceptions
and
privacy
needs
to
that
end
researchers
in
the
field
of
usable
privacy
perform
user
studies
and
interviews
to
understand
these
preferences
as
well
as
misconceptions
people
have
about
the
way
systems
deal
with
user
data
in
the
context
of
online
identity
management
for
instance
leavitt
2015
has
found
that
people
who
feel
non-anonymous
using
their
primary
identity
on
reddit
are
more
likely
to
create
temporary
throwaway
accounts
to
post
content
in
the
context
of
targeted
advertising
ur
et
al
2012
have
found
that
users
consider
such
advertising
techniques
both
useful
and
creepy
incorrectly
believing
that
personally
identifiable
information
is
collected
as
part
of
the
process
following
up
on
this
study
agarwal
et
al
2013
found
that
user
concerns
are
context-dependent
and
that
users
are
generally
only
concerned
about
topically
embarrassing
ads
moreover
users
do
not
generally
want
to
opt-out
of
targeted
advertising
considering
some
of
the
personalized
ads
as
useful
these
results
highlight
that
users
do
not
want
to
completely
lose
the
utility
of
online
services
to
preserve
their
privacy
economics
of
privacy
one
of
the
interesting
lines
of
thought
in
privacy
is
that
of
economics
of
privacy
for
instance
data
can
be
seen
as
product
users
need
to
be
remunerated
for
li
et
al
2014
have
proposed
pricing
mechanism
where
analysts
pay
for
making
queries
over
dataset
and
the
payments
are
distributed
to
the
dataset
users
in
proportion
to
the
contribution
of
their
data
to
the
query
answer
behavioral
economics
techniques
have
been
applied
to
study
how
much
users
value
privacy
or
how
they
make
data
sharing
decisions
acquisti
2009
acquisti
et
al
2016
provide
broad
literature
survey
in
this
area
chapter
background
algorithmic
fairness
contents
3.1
preliminaries
21
3.2
algorithmic
fairness
notions
23
3.2
group
fairness
23
3.2
individual
fairness
24
3.3
achieving
algorithmic
fairness
24
3.4
accountability
25
3.5
cost
of
fairness
25
3.6
sources
of
algorithmic
unfairness
25
3.7
fairness
in
search
systems
27
3.8
selected
other
dimensions
in
algorithmic
fairness
research
28
nti-discrimination
laws
have
been
introduced
to
account
for
the
fact
that
certain
groups
of
people
have
been
historically
subordinated
regulations
specify
attributes
such
as
gender
race
or
religion
along
which
it
is
illegal
to
discriminate
in
domains
including
education
employment
credit
or
housing
the
society
begins
to
realize
that
digital
systems
can
unfairly
discriminate
as
well
the
realization
that
seemingly
objective
computer
systems
can
be
biased
has
led
to
number
of
questions
the
research
community
has
sought
to
answer
how
to
define
fairness
mathematically
how
to
design
mechanisms
that
are
fair
how
to
audit
black-box
systems
to
hold
them
accountable
what
constitutes
undesired
bias
and
how
can
it
be
measured
3.1
preliminaries
we
investigate
algorithmic
fairness
for
individuals
or
groups
of
individuals
defined
by
one
of
the
aforementioned
protected
attributes
issues
of
fairness
matter
in
tasks
such
as
classification
or
search
and
applications
that
involve
people
as
subjects
or
system
users
classification
and
regression
classification
and
regression
methods
are
increasingly
used
in
finance
to
predict
customer
creditworthiness
in
hiring
to
predict
whether
candidate
is
going
to
make
good
employee
or
in
justice
systems
to
predict
whether
convict
will
22
chapter
background
algorithmic
fairness
reoffend
on
parole
because
in
each
of
such
scenarios
algorithmic
decisions
influence
the
lives
and
opportunities
of
the
subjects
fairness
of
these
decisions
has
become
concern
to
illustrate
most
important
fairness
notions
we
focus
on
binary
classification
in
this
setup
one
of
the
classification
outcomes
is
usually
considered
positive
assume
classifier
is
to
make
hiring
decision
whether
to
hire
an
individual
or
not
each
individual
is
represented
using
feature
vector
describing
various
characteristics
the
designer
of
the
classifier
thought
were
important
for
the
task
for
instance
age
gender
highest
degree
received
gpa
score
etc
values
can
be
categorical
or
numerical
the
goal
is
to
train
classifier
to
make
binary
hiring
decisions
hire
or
no
hire
the
classifier
is
trained
using
data
in
the
form
of
pairs
of
feature
vectors
of
past
hires
annotated
with
binary
ground-truth
decisions
specifying
whether
individual
had
good
performance
reviews
from
her
manager
two
years
after
being
hired
the
performance
score
is
proxy
definition
for
being
good
employee
and
ground
for
positive
hiring
decision
classifier
learns
patterns
from
collection
of
vectors
distinguishing
people
with
positive
and
negative
ground-truth
values
we
further
choose
gender
as
the
protected
attribute
and
denote
xg
as
the
value
of
the
gender
feature
of
individual
the
setup
for
regression
task
is
similar
to
that
of
classification
the
difference
being
that
we
predict
real-valued
target
attribute
in
the
hiring
context
we
might
want
to
predict
for
example
how
many
years
person
is
likely
to
stay
at
the
company
search
and
recommendation
in
many
domains
search
engines
rank
people
explicitly
or
implicitly
by
ranking
the
content
and
products
people
produce
since
ranking
positions
in
scenarios
like
this
influence
people
real-world
economic
livelihood
issues
of
fair
representation
in
ranking
have
become
major
concern
in
the
hiring
context
for
example
employers
might
screen
for
potential
employees
using
search
engines
on
hiring
support
platforms
as
response
to
keyword
query
issued
by
an
employer
such
as
machine
learning
engineer
the
platform
returns
ranked
list
of
candidates
e1
ek
ordered
by
relevance
score
ei
computed
by
ranking
algorithm
the
ranking
method
can
be
based
on
data
statistics
or
employ
machine
learning
techniques
machine
learning
approaches
use
training
data
with
labels
provided
by
expert
annotators
an
annotator
determines
which
user
profiles
are
relevant
to
which
queries
or
implicitly
inferred
from
user
click
patterns
for
example
user
is
likely
to
click
on
profiles
she
deems
relevant
to
her
query
chuklin
et
al
2015
provide
detailed
overview
of
various
click
models
used
to
infer
relevance
hiring
platform
might
also
proactively
recommend
potential
employees
to
recruiters
in
such
context
recommendation
algorithm
can
be
thought
of
as
search
system
where
the
employer
is
query
recommendation
strategies
can
recommend
candidates
to
employers
based
on
candidate
similarity
to
previous
candidates
the
employer
interacted
with
item-item
recommendation
because
the
candidate
interacted
with
other
employers
similar
to
the
given
employer
user-user
recommendation
or
using
mix
of
both
approaches
collaborative
filtering
3.2
algorithmic
fairness
notions
3.2
algorithmic
fairness
notions
3.2
group
fairness
23
notions
of
group
fairness
broadly
aim
at
making
sure
that
algorithms
do
not
disproportionately
adversely
impact
members
of
the
protected
groups
demographic
parity
the
notion
of
demographic
parity
requires
that
xg
xg
for
example
in
the
context
of
job
application
classification
with
the
protected
attribute
gender
this
requirement
means
that
groups
of
people
of
different
genders
have
an
equal
chance
of
being
accepted
beyond
demographic
or
statistical
parity
this
notion
has
appeared
in
the
literature
under
variety
of
different
names
including
avoiding
disparate
impact
feldman
et
al
2015
independence
barocas
et
al
2018
and
anti-classification
corbett-davies
and
goel
2018
for
tasks
other
than
classification
demographic
parity
is
often
understood
as
equal
representation
in
the
results
for
instance
clustering
algorithms
should
make
sure
that
different
groups
are
similarly
represented
in
all
the
clusters
chierichetti
et
al
2017
recommendation
algorithms
should
make
sure
different
groups
are
similarly
represented
in
recommendation
sets
mehrotra
et
al
2018
or
that
group
proportions
in
recommendation
sets
should
be
similar
to
group
proportions
in
input
ratings
ekstrand
et
al
2018b
while
ranking
algorithms
should
make
sure
groups
are
similarly
represented
in
ranking
prefixes
yang
and
stoyanovich
2017
celis
et
al
2018
zehlike
et
al
2017
singh
and
joachims
2018
performance
parity
another
category
of
group
fairness
definitions
revolves
around
the
idea
of
equal
error
rates
thus
requiring
equal
performance
of
an
algorithm
for
different
groups
of
people
since
error
can
be
captured
using
variety
of
different
metrics
various
papers
have
focused
on
satisfying
different
metric
equalities
notable
examples
include
equality
of
true
positive
rates
also
known
as
equality
of
opportunity
hardt
et
al
2016
xg
xg
equality
of
both
true
positive
and
false
positive
rates
also
known
as
equalized
odds
hardt
et
al
2016
xg
xg
and
xg
xg
equality
of
missclassification
rates
including
equality
of
false
negative
rates
also
know
as
lack
of
disparate
mistreatment
zafar
et
al
2017
xg
xg
or
equality
of
positive
predictive
values
also
known
as
calibration
xg
xg
fairness
has
also
been
studied
as
error
parity
for
different
groups
in
recommendations
ekstrand
et
al
2018a
yao
and
huang
2017
and
search
using
measures
of
satisfaction
for
searchers
mehrotra
et
al
2017
it
has
been
shown
that
satisfying
different
mathematical
notions
of
fairness
simultaneously
is
generally
not
feasible
kleinberg
et
al
2017b
chouldechova
2017
these
results
highlight
the
importance
of
analyzing
the
context
of
given
application
and
choosing
fairness
definition
best
serving
the
cause
24
3.2
chapter
background
algorithmic
fairness
individual
fairness
dwork
et
al
2012
observed
that
satisfying
the
requirement
of
demographic
parity
might
be
achieved
by
accepting
qualified
individuals
from
one
group
and
random
individuals
from
another
thus
satisfying
certain
notions
of
group
fairness
might
mean
degrading
fairness
on
an
individual
level
this
observation
has
led
to
the
notion
of
individual
fairness
which
posits
that
individuals
similar
with
respect
to
the
task
at
hand
should
have
similar
probabilities
of
positive
classification
outcomes
definitions
along
these
lines
have
also
been
investigated
in
other
algorithmic
scenarios
for
instance
kearns
et
al
2017
proposed
notion
of
individual
fairness
for
the
problem
of
candidate
set
selection
from
diverse
incomparable
source
sets
an
example
of
such
problem
is
choosing
faculty
interview
candidates
from
number
of
diverse
research
communities
which
are
not
directly
comparable
to
each
other
in
terms
of
research
metrics
for
instance
citation
rates
are
different
in
different
research
communities
the
proposed
notion
of
meritocratic
fairness
requires
that
less
qualified
candidates
are
probabilistically
almost
never
preferred
over
more
qualified
candidates
when
selecting
the
candidate
subsets
this
thesis
contributes
to
the
individual
fairness
line
of
research
by
developing
methods
for
making
rankings
individually
fair
assuming
search
relevance
can
be
used
to
determine
similarity
of
individuals
with
respect
to
the
task
we
propose
fairness
notion
where
each
ranked
individual
receives
the
attention
from
searchers
that
is
proportional
to
their
relevance
this
contribution
is
presented
in
chapter
3.3
achieving
algorithmic
fairness
to
achieve
algorithmic
fairness
interventions
can
be
made
at
different
steps
of
the
processing
pipeline
broader
overview
of
various
approaches
along
these
lines
is
provided
by
friedler
et
al
2018
pre-processing
methods
pre-processing
methods
aim
at
compensating
for
biases
in
the
data
which
might
contribute
to
algorithmic
unfairness
some
of
the
approaches
focus
on
balancing
the
datasets
for
instance
feldman
et
al
2015
modify
the
numerical
attributes
in
the
data
to
equalize
marginal
distributions
of
these
attributes
conditioned
on
the
sensitive
attributes
hajian
and
domingo-ferrer
2013
propose
modifying
the
values
of
attributes
and
labels
in
dataset
to
prevent
mining
of
unfair
association
rules
from
the
datasets
pedreschi
et
al
2008
other
approaches
construct
intermediary
lower-dimensional
representations
of
the
data
so
as
to
strip
the
information
about
sensitive
attributes
while
keeping
the
utility
of
the
modified
data
for
the
task
at
hand
zemel
et
al
2013
lahoti
et
al
2018
in-processing
methods
in-processing
approaches
try
to
prevent
unfair
outcomes
by
modifying
the
algorithms
interventions
along
these
lines
most
commonly
take
the
form
of
regularizers
reflecting
certain
soft
constraints
when
defining
an
optimization
objective
for
the
algorithm
training
beyond
component
controlling
the
error
regularizers
are
introduced
to
control
certain
structural
properties
of
models
while
primarily
used
to
reduce
model
complexity
and
prevent
overfitting
regularizers
can
also
capture
unfairness
of
the
model
3.4
accountability
25
fairness
regularization
has
been
for
example
considered
for
classification
and
regression
berk
et
al
2017
kamishima
et
al
2012
and
recommendation
yao
and
huang
2017
zafar
et
al
2017
propose
encoding
fairness
notions
as
additional
constrains
added
on
top
of
accuracy
optimization
objectives
post-processing
methods
post-processing
approaches
modify
the
outputs
of
algorithms
to
satisfy
fairness
criteria
for
example
fish
et
al
2016
propose
method
which
shifts
decision
boundaries
of
trained
classifiers
to
achieve
statistical
parity
while
ensuring
minimal
decrease
in
accuracy
hardt
et
al
2016
modify
the
decision
score
thresholds
of
trained
model
to
balance
the
true
positive
rates
of
different
groups
kamiran
et
al
2010
propose
method
for
relabeling
the
nodes
of
decision
tree
classifiers
to
ensure
demographic
parity
3.4
accountability
once
fairness
criteria
for
algorithms
are
specified
question
remains
whether
systems
actually
adhere
to
such
standards
and
how
one
can
audit
systems
externally
to
hold
them
accountable
audit
mechanisms
have
been
proposed
to
examine
whether
protected
features
influence
the
outcomes
of
algorithmic
decisions
in
black-box
systems
adler
et
al
2018
kilbertus
et
al
2018
proposed
method
based
on
encryption
of
sensitive
attributes
that
enables
auditing
machine
learning
models
for
absence
of
disparate
impact
without
having
the
users
disclose
the
values
of
their
sensitive
attributes
kroll
et
al
2016
provide
an
overview
of
computational
techniques
that
could
be
applied
for
assuring
compliance
of
algorithmic
outcomes
with
legal
requirements
taking
into
account
that
transparency
should
be
limited
by
the
business
incentives
of
service
providers
3.5
cost
of
fairness
satisfying
different
algorithmic
fairness
requirements
might
lead
to
decrease
in
the
quality
and
utility
of
the
algorithmic
outputs
this
trade-off
has
been
explored
for
all
common
algorithmic
tasks
including
classification
hardt
et
al
2016
zafar
et
al
2017
regression
berk
et
al
2017
and
ranking
zehlike
et
al
2017
singh
and
joachims
2018
biega
et
al
2018
leonhardt
et
al
2018
and
mehrotra
et
al
2018
show
how
increasing
the
diversity
of
groups
represented
in
recommendation
sets
might
lead
to
decrease
in
the
satisfaction
for
recommendation
consumers
3.6
sources
of
algorithmic
unfairness
in
search
systems
implicit
relevance
information
is
often
collected
from
click
data
if
searchers
exhibit
bias
towards
certain
groups
or
individuals
algorithms
will
learn
to
imitate
these
biases
in
the
displayed
results
researchers
have
uncovered
that
advertisements
of
high-paying
jobs
are
shown
more
often
to
men
than
women
datta
et
al
2015
or
that
advertisements
for
criminal
record
checks
are
more
often
shown
as
response
to
queries
with
names
commonly
associated
with
african
americans
sweeney
2013
the
roots
of
both
of
26
chapter
background
algorithmic
fairness
these
phenomena
can
be
traced
to
biased
click
behaviors
of
search
engine
users
algorithmic
unfairness
is
not
necessarily
result
of
unfair
mechanisms
but
also
of
various
forms
of
data
and
human
biases
model
biases
when
translating
complex
real-world
problems
into
computational
tasks
we
necessarily
need
to
make
certain
assumptions
and
simplifications
for
instance
as
pointed
out
by
barocas
and
selbst
2016
it
is
not
straightforward
to
determine
what
creditworthiness
or
good
employee
exactly
mean
in
terms
of
machine
learning
prediction
variables
moreover
very
often
humans
need
to
be
described
using
simplistic
low-dimensional
representations
with
only
selected
features
present
some
of
the
features
for
instance
even
when
unproblematic
on
the
surface
might
be
strongly
correlated
with
the
protected
attributes
evaluation
metrics
will
furthermore
determine
which
aspects
models
optimize
for
and
which
will
be
ignored
biases
might
also
emerge
from
the
mismatch
between
the
modeling
assumptions
and
the
reality
of
system
use
contexts
for
example
platform
creator
might
assume
that
when
recruiter
likes
candidate
profile
on
hiring
platform
she
thinks
the
profile
is
relevant
to
her
search
requirement
in
reality
however
recruiters
might
use
the
feature
to
simply
mark
profiles
for
further
investigation
the
development
choices
regarding
the
task
abstraction
features
target
variables
and
metrics
will
influence
the
bias
of
the
resulting
models
data
biases
unfairness
may
stem
from
underrepresentation
of
certain
populations
in
the
data
for
instance
when
ranking
programming
job
candidates
more
data
may
be
available
about
male
programmers
leading
to
better
system
performance
for
male
applications
note
that
such
underrepresentation
might
be
result
of
biased
sampling
processes
or
activity
and
self-selection
biases
of
platform
users
for
instance
the
platform
might
be
unpopular
with
female
programmers
or
women
might
share
less
data
with
the
platform
on
average
data
might
also
contribute
to
algorithmic
unfairness
when
it
is
re-purposed
for
new
task
system
developers
working
with
such
data
might
not
understand
the
methods
and
metrics
used
when
collecting
the
data
or
the
technical
and
normative
limitations
of
the
platform
on
which
the
data
was
generated
gebru
et
al
2018
propose
standardized
dataset
description
template
which
could
help
foster
more
conscious
data
reuse
practices
olteanu
et
al
2016
provide
detailed
discussion
of
various
data
biases
and
limitations
human
biases
human
biases
may
enter
digital
systems
in
various
ways
machine
learning
algorithms
might
be
trained
on
data
encoding
certain
stereotypes
for
instance
training
labels
for
the
hiring
decision
task
might
be
provided
by
annotators
with
strong
gender
bias
or
generated
from
historical
training
data
of
hiring
decisions
made
when
such
gender
bias
was
reflection
of
the
societal
reality
various
cognitive
biases
influence
the
way
people
interact
with
information
and
interfaces
for
instance
the
fact
that
people
tend
to
scan
information
from
the
top
down
when
investigating
ranked
results
leads
to
position
bias
where
users
pay
most
of
their
attention
to
items
ranked
high
joachims
et
al
2005
eickhoff
2018
has
studied
how
human
cognitive
biases
might
influence
the
results
of
crowdsourcing
studies
baeza-yates
2018
discusses
further
forms
of
user
interaction
bias
3.7
fairness
in
search
systems
27
caliskan
et
al
2017
has
demonstrated
that
human
association
biases
perceiving
certain
semantic
concepts
as
more
related
than
others
are
replicated
in
embeddings
trained
on
text
corpora
while
the
goal
of
word
embeddings
is
to
capture
such
similarities
certain
associations
are
socially
undesirable
for
instance
bolukbasi
et
al
2016
show
that
word
embeddings
associate
men
more
than
women
with
words
related
to
programming
an
association
of
this
kind
would
be
problematic
if
the
embeddings
were
used
as
plug-in
component
in
downstream
applications
such
as
resume
ranking
quantifying
bias
number
of
efforts
have
been
directed
towards
measuring
and
auditing
systems
for
presence
of
undesired
bias
these
includes
for
instance
empirical
studies
into
gender
influencing
ranks
in
ranked
outputs
in
various
human
resource
platforms
chen
et
al
2018
auditing
biased
practices
of
surge
pricing
in
ride-hailing
platforms
chen
et
al
2015
frameworks
for
deconstructing
input
and
output
biases
in
search
over
political
social
media
postings
kulshrestha
et
al
2017
or
auditing
bias
in
political
personalized
search
results
robertson
et
al
2018
note
that
the
biases
discussed
here
differ
from
the
notion
of
bias
known
in
statistics
whereby
the
expected
value
of
statistical
parameter
estimator
differs
from
the
true
parameter
value
in
particular
even
if
an
estimator
is
unbiased
in
the
statistical
sense
the
estimated
value
might
represent
an
undesirable
social
phenomenon
for
instance
even
if
certain
minority
population
underperforms
in
school
admission
test
we
might
want
to
modify
statistically
unbiased
predictor
of
the
performance
knowing
that
the
worse
performance
of
the
minority
is
result
of
worse
access
to
educational
resources
reversely
statistically
biased
performance
predictor
might
not
violate
any
societal
fairness
notions
if
for
instance
it
underestimates
performance
equally
for
everyone
friedman
and
nissenbaum
1996
barocas
and
selbst
2016
olteanu
et
al
2016
baezayates
2018
provide
comprehensive
overviews
of
the
sources
of
technical
human
and
data
biases
3.7
fairness
in
search
systems
in
the
context
of
the
main
theme
of
this
thesis
it
is
worth
reiterating
over
the
fairness
problems
specific
to
search
systems
work
in
this
area
has
primarily
focused
on
fairness
for
the
search
subjects
fair
representation
through
diversity
zehlike
et
al
2017
focused
on
fair
representation
of
protected
groups
in
ranking
prefixes
and
proposed
statistical
fairness
test
for
determining
whether
given
ranking
was
generated
according
to
bernoulli
trial
as
well
as
post-processing
algorithm
for
reshuffling
rankings
to
pass
the
fairness
test
celis
et
al
2018
study
the
complexity
of
the
problem
of
fair
representation
of
groups
in
rankings
28
chapter
background
algorithmic
fairness
fair
representation
through
exposure
apart
from
the
notions
of
diversity
fairness
based
on
equal
exposure
has
been
proposed
in
parallel
in
our
work
biega
et
al
2018
discussed
in
chapter
and
by
singh
and
joachims
2018
singh
and
joachims
2018
focus
on
the
notions
of
group
fairness
and
develop
probabilistic
mechanism
guaranteeing
ex-ante
group
exposure
fairness
in
expectation
zehlike
and
castillo
2018
follow
up
on
this
work
by
incorporating
group-fair
exposure
regularizers
in
learning
to
rank
algorithms
the
work
conducted
in
this
thesis
proposes
notion
of
individual
fairness
where
each
ranked
subject
should
get
the
attention
from
searchers
that
is
proportional
to
her
relevance
is
explicitly
amortized
across
sequence
of
rankings
for
ex-post
fairness
quantifying
and
detecting
unfairness
yang
and
stoyanovich
2017
proposed
measures
to
quantify
bias
in
ranked
outputs
inspired
by
standard
ir
evaluation
measures
where
instead
of
the
relevance
information
one
uses
the
protected
category
membership
information
wu
et
al
2018
propose
methodology
for
analyzing
the
causality
of
error
in
ranked
outputs
to
this
end
the
authors
construct
directed
graph
where
discrete
user
profile
attributes
influence
synthetic
score
derived
from
the
ranking
position
and
perform
causality
analysis
on
the
resulting
graph
notion
of
nutritional
label
wherein
different
quantitative
statistics
are
presented
to
the
users
has
been
proposed
both
for
web
documents
returned
as
search
results
fuhr
et
al
2017
as
well
as
the
rankings
themselves
yang
et
al
2018
fair
ranking
quality
on
the
searchers
side
fairness
has
been
understood
as
error
parity
mehrotra
et
al
2017
proposed
measurement
methodology
to
quantify
different
levels
of
satisfaction
from
the
search
results
for
different
demographic
groups
3.8
selected
other
dimensions
in
algorithmic
fairness
research
human
decision
making
while
the
majority
of
work
in
the
area
of
algorithmic
fairness
focuses
on
machine
learning
algorithms
that
replace
humans
in
decision
making
some
authors
have
investigated
how
decision
making
can
be
enhanced
with
humans
and
automated
predictions
working
in
concord
kleinberg
et
al
2017a
valera
et
al
2018
human
perceptions
grgic-hlaca
et
al
2018a
have
studied
human
perceptions
of
fairness
with
regard
to
the
usage
of
certain
features
in
machine
learning
algorithms
beyond
fairness
researchers
have
sought
to
understand
whether
increased
interpretability
of
machine
learning
models
increases
the
trust
people
have
of
these
models
poursabzi-sangdeh
et
al
2018
procedural
fairness
while
the
majority
of
literature
focuses
on
the
fairness
of
outcomes
separate
question
is
that
of
procedural
fairness
that
is
whether
the
model
itself
operates
in
fair
way
along
these
lines
grgic-hlaca
et
al
2018b
have
proposed
to
crowdsource
3.8
selected
other
dimensions
in
algorithmic
fairness
research
29
opinions
on
whether
the
usage
of
certain
features
is
fair
in
the
context
of
criminal
risk
prediction
and
designed
submodular
optimization
problem
to
minimize
the
unfairness
of
feature
use
while
preserving
classifier
accuracy
fair
matching
and
resource
division
work
on
fairness
in
computational
economics
includes
designing
incentives
for
two-sided
economy
producers
to
prevent
discriminating
treatment
of
consumers
kannan
et
al
2017
or
procedures
for
fair
division
of
resources
abebe
et
al
2017
chakraborty
et
al
2017
social
and
legal
scientists
have
also
investigated
problems
arising
from
power
asymmetries
in
two-sided
economy
platforms
rosenblat
and
stark
2016
calo
and
rosenblat
2017
ethics
of
experimentation
large
scale
experimentation
involving
humans
such
as
testing
raises
lot
of
ethical
concerns
bird
et
al
2016
propose
number
principles
the
design
of
such
experiments
should
follow
including
informed
consent
from
the
users
minimizing
the
potential
harm
done
to
the
users
while
maximizing
research
benefits
and
fairly
distributing
the
potential
harm
risks
among
the
users
predictive
policing
number
of
articles
point
out
the
problems
predictive
policing
might
lead
to
for
example
it
has
been
shown
that
there
might
exist
feedback
loops
leading
to
increased
police
presence
in
historically
over-policed
neighborhoods
lum
and
isaac
2016
ensign
et
al
2018
long-term
effects
of
fair
machine
learning
recent
efforts
have
begun
to
focus
on
the
long-term
impact
of
fairness
constrains
investigating
whether
fairness
interventions
proposed
in
the
literature
thus
far
might
have
undesired
effects
for
instance
enforcing
demographic
parity
in
credit
risk
prediction
might
lead
to
situation
where
members
of
protected
groups
default
more
often
liu
et
al
2018
chapter
equity
of
attention
contents
4.1
introduction
4.2
equity-of-attention
fairness
34
4.3
4.4
32
4.2
notation
34
4.2
defining
equity
of
attention
35
4.2
equality
of
attention
36
4.2
relation
to
group
fairness
in
rankings
36
rankings
with
equity
of
attention
36
4.3
measuring
un
fairness
36
4.3
measuring
ranking
quality
37
4.3
optimizing
fairness-quality
tradeoffs
37
4.3
an
ilp-based
fair
ranking
mechanism
38
experiments
40
4.4
data
40
4.4
position
bias
42
4.4
implementation
and
parameters
42
4.4
mechanisms
under
comparison
43
4.4
data
characteristics
relevance
vs
attention
43
4.4
performance
on
synthetic
data
43
4.4
performance
on
airbnb
data
48
4.4
performance
on
stackexchange
data
54
4.5
related
work
54
4.6
conclusion
55
ankings
of
people
and
items
are
at
the
heart
of
selection-making
match-making
and
recommender
systems
ranging
from
employment
sites
to
sharing
economy
platforms
as
ranking
positions
influence
the
amount
of
attention
the
ranked
subjects
receive
biases
in
rankings
can
lead
to
unfair
distribution
of
opportunities
and
resources
such
as
jobs
or
income
this
chapter
proposes
new
measures
and
mechanisms
to
quantify
and
mitigate
unfairness
from
bias
inherent
to
all
rankings
namely
the
position
bias
which
leads
to
disproportionately
less
attention
being
paid
to
low-ranked
subjects
our
approach
differs
from
recent
fair
ranking
approaches
in
two
important
ways
first
existing
works
measure
unfairness
at
32
chapter
equity
of
attention
the
level
of
subject
groups
while
our
measures
capture
unfairness
at
the
level
of
individual
subjects
and
as
such
subsume
group
unfairness
second
as
no
single
ranking
can
achieve
individual
attention
fairness
we
propose
novel
mechanism
that
achieves
amortized
fairness
where
attention
accumulated
across
series
of
rankings
is
proportional
to
accumulated
relevance
we
formulate
the
challenge
of
achieving
amortized
individual
fairness
subject
to
constraints
on
ranking
quality
as
an
online
optimization
problem
and
show
that
it
can
be
solved
as
an
integer
linear
program
our
experimental
evaluation
reveals
that
unfair
attention
distribution
in
rankings
can
be
substantial
and
demonstrates
that
our
method
can
improve
individual
fairness
while
retaining
high
ranking
quality
4.1
introduction
motivation
and
problem
rankings
of
subjects
like
people
hotels
or
songs
are
at
the
heart
of
selection
matchmaking
and
recommender
systems
such
systems
are
in
use
on
variety
of
platforms
that
affect
different
aspects
of
life
from
entertainment
and
dating
all
the
way
to
employment
and
income
notable
examples
of
platforms
with
tangible
impact
on
people
livelihood
include
two-sided
sharing
economy
websites
such
as
airbnb
or
uber
or
human-resource
matchmaking
platforms
such
as
linkedin
or
taskrabbit
the
ongoing
migration
to
online
markets
and
the
growing
dependence
of
many
users
on
these
platforms
in
securing
an
income
have
spurred
investigations
into
the
issues
of
bias
discrimination
and
fairness
in
the
platforms
mechanisms
calo
and
rosenblat
2017
levy
and
barocas
2017
one
aspect
in
particular
has
evaded
scrutiny
thus
far
to
be
successful
on
these
platforms
ranked
subjects
need
to
gain
the
attention
of
searchers
since
exposure
on
the
platform
is
prerequisite
for
attention
subjects
have
strong
desire
to
be
highly
ranked
however
when
inspecting
ranked
results
searchers
are
susceptible
to
position
bias
which
makes
them
pay
most
of
their
attention
to
the
top-ranked
subjects
as
result
lower-ranked
subjects
often
receive
disproportionately
less
attention
than
they
deserve
according
to
the
ranking
relevance
position
bias
has
been
studied
in
information
retrieval
in
scenarios
where
subjects
are
documents
such
as
web
pages
craswell
et
al
2008
chuklin
et
al
2015
it
has
been
shown
that
top-ranked
documents
receive
most
clicks
often
irrespective
of
their
actual
relevance
joachims
and
radlinski
2007
systemic
correction
for
the
bias
becomes
important
when
ranking
positions
potentially
translate
to
financial
gains
or
losses
this
is
the
case
when
ranking
people
on
platforms
like
linkedin
or
uber
products
on
platforms
like
amazon
or
creative
works
on
platforms
like
spotify
for
example
cumulating
the
exposure
on
subset
of
drivers
in
ride-hailing
platforms
might
lead
to
economic
starvation
of
others
while
low-ranked
artists
on
music
platforms
might
not
get
their
deserved
chance
of
earning
royalties
observing
that
attention
is
influenced
by
human
perception
bias
while
relevance
is
not
uncovers
fundamental
problem
there
necessarily
exists
discrepancy
between
the
attention
that
subjects
receive
at
their
respective
ranks
and
their
relevance
in
given
search
task
for
example
attention
could
decrease
geometrically
whereas
relevance
scores
may
decrease
linearly
as
the
rank
decreases
if
ranking
is
displayed
unchanged
to
many
searchers
4.1
introduction
33
over
time
the
lower-ranked
subjects
might
be
systematically
and
repeatedly
disadvantaged
in
terms
of
the
attention
they
receive
problem
statement
vast
body
of
ranking
models
literature
has
focused
on
aligning
system
relevance
scores
with
the
true
relevance
of
ranked
subjects
and
in
this
work
we
assume
the
two
are
proportional
what
we
focus
on
instead
is
the
relation
between
relevance
and
attention
since
relevance
can
be
thought
of
as
proxy
for
worthiness
in
the
context
of
given
search
task
the
attention
subject
receives
from
searchers
should
ideally
be
proportional
to
her
relevance
in
economics
and
psychology
similar
idea
of
proportionality
exists
under
the
name
of
equity
walster
et
al
1973
and
is
employed
as
fairness
principle
in
the
context
of
distributive
justice
greenberg
1987
thus
in
this
thesis
we
make
translational
normative
claim
and
argue
for
equity
of
attention
in
rankings
operationally
the
problem
we
address
in
this
thesis
is
to
devise
measures
and
mechanism
which
ensure
that
for
all
subjects
in
the
system
the
received
attention
approximately
equals
the
deserved
attention
while
preserving
ranking
quality
for
single
ranking
this
goal
is
infeasible
since
attention
is
influenced
by
the
position
bias
while
relevance
is
not
therefore
our
approach
looks
at
series
of
rankings
and
aims
at
measures
of
amortized
fairness
state
of
the
art
and
limitations
fairness
has
become
major
concern
for
decisionmaking
systems
based
on
machine
learning
methods
various
notions
of
group
fairness
have
been
investigated
kamishima
et
al
2012
pedreschi
et
al
2008
feldman
et
al
2015
hardt
et
al
2016
zafar
et
al
2017
with
the
goal
of
making
sure
that
protected
attributes
such
as
gender
or
race
do
not
influence
algorithmic
decisions
fair
classifiers
are
then
trained
to
maximize
accuracy
subject
to
group
fairness
constraints
these
approaches
however
do
not
distinguish
between
different
subjects
from
within
group
the
notion
of
individual
fairness
dwork
et
al
2012
zemel
et
al
2013
kearns
et
al
2017
aims
at
treating
each
individual
fairly
by
requiring
that
subjects
who
are
similar
to
each
other
receive
similar
decision
outcomes
for
instance
the
concept
of
meritocratic
fairness
requires
that
less
qualified
candidates
are
almost
never
preferred
over
more
qualified
ones
when
selecting
candidates
from
set
of
diverse
populations
relevance-based
rankings
where
more
relevant
subjects
are
ranked
higher
than
less
relevant
ones
also
satisfy
meritocratic
fairness
stronger
fairness
concept
however
is
needed
for
rankings
to
be
means
of
distributive
justice
prior
work
on
fair
rankings
is
scarce
and
includes
approaches
that
perturb
results
to
guarantee
various
types
of
group
fairness
this
goal
is
achieved
by
techniques
similar
to
those
for
ranking
result
diversification
celis
et
al
2018
yang
and
stoyanovich
2017
zehlike
et
al
2017
or
by
granting
equal
ranking
exposure
to
groups
singh
and
joachims
2018
individual
fairness
is
inherently
beyond
the
scope
of
group-based
perturbation
approach
and
contribution
our
approach
in
this
thesis
differs
from
the
prior
work
in
two
major
ways
first
the
measures
introduced
here
capture
fairness
at
the
level
of
individual
subjects
and
subsume
group
fairness
as
special
case
second
as
no
single
ranking
can
guarantee
fair
attention
to
every
subject
we
devise
novel
mechanism
that
ensures
amortized
fairness
where
attention
is
fairly
distributed
across
series
of
rankings
34
chapter
equity
of
attention
for
an
intuitive
example
consider
ranking
where
all
the
relevance
scores
are
almost
the
same
such
tiny
differences
in
relevance
will
push
subjects
apart
in
the
display
of
the
results
leading
to
considerable
difference
in
the
attention
received
from
searchers
to
compensate
for
the
position
bias
we
can
reorder
the
subjects
in
consecutive
rankings
so
that
everyone
who
is
highly
relevant
is
displayed
at
the
top
every
now
and
then
our
goal
is
not
just
to
balance
attention
but
to
keep
it
proportional
to
relevance
for
all
subjects
while
preserving
ranking
quality
to
this
end
we
permute
subjects
in
each
ranking
so
as
to
improve
fairness
subject
to
constraints
on
quality
loss
we
cast
this
approach
to
an
online
optimization
problem
formalizing
it
as
an
integer
linear
program
ilp
we
moreover
devise
filters
to
prune
the
combinatorial
space
of
the
ilp
which
ensures
that
it
can
be
solved
in
an
online
system
experiments
with
synthetic
and
real-life
data
demonstrate
the
viability
of
our
method
note
that
we
assume
that
searchers
are
indifferent
to
the
varying
ordering
in
the
ranking
except
for
the
utility
loss
in
practice
searchers
might
be
confused
if
they
see
very
different
results
to
the
same
queries
while
this
thesis
does
not
tackle
this
problem
possible
solutions
might
include
incremental
updates
to
ranking
changes
or
controlling
that
varying
results
to
given
query
are
shown
to
different
searchers
this
chapter
makes
the
following
novel
contributions
to
the
best
of
our
knowledge
we
are
the
first
to
formalize
the
problem
of
individual
equity-of-attention
fairness
in
rankings
and
define
measures
that
capture
the
discrepancy
between
the
deserved
and
received
attention
we
propose
online
mechanisms
for
fairly
amortizing
attention
over
time
in
consecutive
rankings
we
investigate
the
properties
and
behavior
of
the
proposed
mechanisms
in
experiments
with
synthetic
and
real-world
data
4.2
equity-of-attention
fairness
we
now
formally
define
equity
of
attention
accounting
for
position
bias
which
determines
how
attention
is
distributed
over
the
ranking
positions
we
consider
sequence
of
rankings
at
different
time
points
by
different
criteria
or
on
request
of
different
users
4.2
notation
we
use
the
following
notation
u1
un
is
set
of
subjects
ranked
in
system
ρ1
ρm
is
sequence
of
rankings
rij
is
the
normalized
relevance
score
of
subject
ui
in
ranking
ρj
aji
is
the
normalized
attention
value
received
by
subject
ui
in
ranking
ρj
pm
denotes
the
distribution
of
cumulated
attention
across
subjects
that
is
ai
aji
for
subject
ui
4.2
equity-of-attention
fairness
denotes
the
distribution
of
cumulated
relevance
across
subjects
that
is
ri
for
subject
ui
4.2
35
pm
ri
defining
equity
of
attention
our
fairness
notion
in
this
work
is
in
the
spirit
of
the
individual
fairness
proposed
by
dwork
et
al
2012
which
requires
that
similar
individuals
are
treated
similarly
where
similarity
between
individuals
is
metric
capturing
suitability
for
the
task
at
hand
in
the
context
of
rankings
we
consider
relevance
to
be
measure
of
subject
suitability
further
in
applications
where
rankings
influence
people
economic
livelihood
we
can
think
of
rankings
not
as
an
end
but
as
means
of
achieving
distributive
justice
that
is
fair
sharing
of
certain
real-world
resources
in
the
context
of
rankings
we
consider
the
attention
of
searchers
to
be
resource
to
be
distributed
fairly
there
exist
different
types
of
distributive
norms
one
of
them
being
equity
equity
encodes
the
idea
of
proportionality
of
inputs
and
outputs
walster
et
al
1973
and
might
be
employed
to
account
for
differences
in
effort
in
productivity
or
in
contribution
yaari
and
bar-hillel
1984
building
upon
these
ideas
we
make
translational
normative
claim
and
propose
new
notion
of
individual
fairness
for
rankings
called
equity
of
attention
which
requires
that
ranked
subjects
receive
attention
that
is
proportional
to
their
worthiness
in
given
search
task
as
proxy
for
worthiness
we
turn
to
the
currently
best
available
ground
truth
that
is
the
system-predicted
relevance
definition
equity
of
attention
ranking
offers
equity
of
attention
if
each
subject
receives
attention
proportional
to
its
relevance
ai1
ai2
ui1
ui2
4.1
ri1
ri2
note
that
this
definition
is
unlikely
to
be
satisfied
in
any
single
ranking
since
the
relevance
scores
of
subjects
are
determined
by
the
data
and
the
query
while
the
attention
paid
to
the
subjects
in
terms
of
views
or
clicks
is
strongly
influenced
by
position
bias
the
effects
of
this
mismatch
will
be
aggravated
if
multiple
subjects
are
similarly
relevant
yet
obviously
cannot
occupy
the
same
ranking
position
and
receive
similar
attention
to
operationalize
our
definition
in
practice
we
propose
an
alternative
fairness
definition
that
requires
attention
to
be
distributed
proportionally
to
relevance
when
amortized
over
sequence
of
rankings
definition
equity
of
amortized
attention
sequence
of
rankings
ρ1
ρm
offers
equity
of
amortized
attention
if
each
subject
receives
cumulative
attention
proportional
to
her
cumulative
relevance
pm
pm
ai1
ai2
pl
pl
ui1
ui2
4.2
i1
ri2
observe
that
this
modified
fairness
definition
allows
us
to
permute
individual
rankings
so
as
to
satisfy
fairness
requirements
over
time
the
deficiency
in
the
attention
received
by
subject
relative
to
her
relevance
in
given
ranking
instance
can
be
compensated
in
subsequent
ranking
where
the
subject
is
positioned
higher
relative
to
her
relevance
36
4.2
chapter
equity
of
attention
equality
of
attention
in
certain
scenarios
it
may
be
desirable
for
subjects
to
receive
the
same
amount
of
attention
irrespective
of
their
relevance
such
is
the
case
when
we
suspect
the
ranking
is
biased
and
cannot
confidently
correct
for
that
bias
or
when
the
subjects
are
not
shown
as
an
answer
to
any
query
but
need
to
be
visually
displayed
in
ranked
order
list
of
candidates
on
an
informational
website
for
an
election
in
such
scenarios
the
desired
notion
of
fairness
would
be
equality
of
attention
we
observe
that
this
egalitarian
version
of
fairness
is
special
case
of
equity
of
attention
where
the
relevance
distributions
are
uniform
ri1
ri2
ui1
ui2
as
equity
of
attention
subsumes
equality
of
attention
we
do
not
explicitly
discuss
it
further
in
this
thesis
4.2
relation
to
group
fairness
in
rankings
to
our
knowledge
all
prior
works
on
fairness
in
rankings
have
focused
on
notions
of
group
fairness
which
define
fairness
requirements
over
the
collective
treatment
received
by
all
members
of
demographic
group
like
women
or
men
our
motivation
for
tackling
fairness
at
the
individual
level
stems
from
the
fact
that
position
bias
affects
all
individuals
independently
of
their
group
membership
it
is
easy
to
see
however
that
when
equity
of
attention
is
achieved
for
individuals
it
will
also
be
achieved
at
the
group
level
the
cumulated
attention
received
by
all
members
of
group
will
be
proportional
to
their
cumulated
relevance
prior
works
on
fairness
in
rankings
celis
et
al
2018
yang
and
stoyanovich
2017
zehlike
et
al
2017
has
mostly
focused
on
diversification
of
the
results
these
approaches
are
geared
for
one-time
rankings
and
as
any
static
model
will
steadily
accumulate
equity-of-attention
unfairness
over
time
since
they
were
developed
with
different
goal
in
mind
they
are
not
directly
comparable
to
our
dynamic
approach
parallel
with
our
work
singh
and
joachims
2018
have
explored
similar
ideas
of
how
position
bias
influences
fairness
of
exposure
their
probabilistic
formulations
are
possibly
counterpart
of
our
amortization
ideas
and
it
will
be
interesting
to
see
to
what
extent
these
formulations
are
interchangeable
in
line
with
other
prior
works
on
fairness
in
rankings
and
different
from
our
work
however
they
focus
on
satisfying
constraints
on
group
rather
than
individual
fairness
and
on
notions
of
equality
rather
than
equity
4.3
rankings
with
equity
of
attention
4.3
measuring
un
fairness
to
be
able
to
optimize
ranking
fairness
we
need
to
measure
to
what
extent
sequence
of
rankings
ρ1
ρm
violates
definition
since
the
proposed
fairness
criterion
is
equivalent
to
the
requirement
that
the
empirical
distributions
and
be
equal
we
can
measure
unfairness
as
the
distance
between
these
two
distributions
variety
of
measures
can
be
applied
here
including
kl-divergence
or
l1-norm
distance
in
this
work
we
measure
fairness
using
the
latter
4.3
rankings
with
equity
of
attention
unfairness
ρ1
ρm
37
ai
ri
aji
rij
4.3
l1-norm
is
minimized
with
value
of
for
distributions
satisfying
the
fairness
criterion
from
definition
and
is
thus
useful
as
an
optimization
objective
however
since
the
measure
is
cumulative
and
indifferent
to
the
exact
distribution
of
unfairness
among
individuals
other
measures
could
be
developed
to
quantify
unfairness
in
the
system
at
any
given
point
4.3
measuring
ranking
quality
permuting
ranking
to
satisfy
fairness
criteria
can
lead
to
quality
loss
when
less
relevant
subjects
get
ranked
higher
than
more
relevant
ones
we
propose
to
quantify
ranking
quality
using
measures
that
draw
from
ir
evaluation
traditionally
ranking
models
are
evaluated
in
comparison
with
ground-truth
rankings
based
on
human-given
relevance
labels
here
we
are
interested
in
quantifying
the
divergence
from
the
original
ranking
thus
we
consider
the
original
ranking
to
be
the
ground-truth
reference
for
evaluating
the
quality
of
reordered
ranking
we
assume
that
the
ground
truth
scores
are
the
relevance
scores
returned
by
the
system
and
that
these
scores
reflect
the
best
ordering
of
subjects
these
considerations
lead
to
the
following
definitions
discounted
cumulative
gain
dcg
quantifies
the
quality
of
ranking
by
summing
the
relevance
scores
in
consecutive
positions
with
logarithmic
discount
for
the
values
at
lower
positions
the
measure
thus
puts
an
emphasis
on
having
higher
relevance
scores
at
top
positions
2r
dcg
4.4
log2
this
value
can
be
further
normalized
by
the
dcg
score
of
perfect
ranking
ordered
by
the
ground
truth
relevance
scores
the
normalized
discounted
cumulative
gain
ndcg
based
quality
measure
can
be
thus
expressed
as
ndcg-quality
dcg
dcg
4.5
this
measure
is
maximized
with
value
of
if
the
rankings
do
not
differ
or
if
swaps
are
only
made
within
ties
subjects
with
equal
relevance
other
measures
like
kendall
tau
or
appropriately
defined
ap
quality
could
be
applied
as
well
4.3
optimizing
fairness-quality
tradeoffs
as
discussed
in
the
previous
section
there
is
no
free
lunch
to
improve
fairness
we
need
to
perturb
relevance-based
rankings
which
might
lead
to
lower
ranking
quality
to
address
the
tradeoff
we
can
formulate
two
types
of
constrained
optimization
problems
one
where
we
minimize
unfairness
subject
to
constraints
on
quality
lower-bound
the
minimum
acceptable
quality
and
another
where
we
maximize
quality
subject
to
constraints
on
unfairness
upper-bound
the
maximum
acceptable
unfairness
measure
in
this
thesis
we
focus
on
the
former
since
at
the
moment
ranking
quality
measures
are
more
interpretable
and
so
are
the
constraints
on
quality
38
chapter
equity
of
attention
4.3
3.1
offline
optimization
let
ρ1
ρm
be
sequence
of
rankings
where
the
subjects
are
ordered
by
the
relevance
scores
these
rankings
induce
zero
quality
loss
we
wish
to
reorder
them
into
ρ1
ρm
so
as
to
minimize
the
distance
between
the
distributions
and
with
constraints
on
ndcg-quality
loss
in
each
ranking
minimize
ai
ri
4.6
subject
to
ndcg-quality
where
ai
and
ri
denote
the
cumulated
attention
and
relevance
scores
that
subject
ui
has
gained
across
all
the
rankings
instead
of
thresholding
the
loss
in
each
individual
ranking
an
alternative
would
be
to
threshold
the
average
loss
over
rankings
4.3
3.2
online
optimization
in
practice
ranking
amortization
needs
to
be
done
in
an
online
manner
one
query
at
time
without
the
knowledge
of
future
query
loads
the
goal
is
then
to
reorder
the
current
ranking
so
as
to
minimize
unfairness
over
the
cumulative
attention
and
relevance
distributions
in
rankings
seen
so
far
subject
to
constraint
on
the
quality
of
the
current
ranking
thus
in
the
l-th
ranking
we
want
to
minimize
al
ali
ril
ril
4.7
subject
to
ndcg-quality
where
al
and
ril
denote
the
cumulated
attention
and
relevance
scores
that
subject
ui
has
gained
up
to
and
including
ranking
4.3
an
ilp-based
fair
ranking
mechanism
4.3
4.1
ilp
for
online
attention
amortization
the
optimization
problem
defined
in
sec
4.3
3.2
can
be
solved
as
an
integer
linear
program
ilp
assume
we
are
to
rerank
the
l-th
ranking
in
series
of
rankings
we
introduce
n2
decision
variables
xi
which
are
set
to
if
subject
ui
is
assigned
to
the
ranking
position
and
set
to
otherwise
at
the
time
of
reordering
the
l-th
ranking
the
following
values
are
constants
relevance
scores
for
each
subject
ui
in
the
current
ranking
ril
attention
values
assigned
to
ranking
positions
wj
relevance
scores
accumulated
up
to
and
excluding
the
current
ranking
for
each
subject
ril
attention
values
accumulated
up
to
and
excluding
the
current
ranking
for
each
subject
al
4.3
rankings
with
equity
of
attention
39
idcg
value
computed
over
the
current
ranking
ρl
which
is
used
as
normalization
score
for
ndcg-quality
for
each
subject
ui
the
accumulated
attention
and
relevance
are
initialized
as
a0i
and
ri0
for
all
ui
the
ilp
is
then
defined
as
follows
minimize
al
wj
ril
ril
xi
subject
to
2ri
xi
idcg
log2
xi
xi
4.8
xi
the
first
constraint
bounds
the
loss
in
ranking
quality
in
terms
of
the
ndcg-quality
measure
by
the
multiplicative
threshold
the
other
constraints
ensure
that
the
solution
is
bijective
mapping
of
subjects
onto
ranking
positions
the
terms
al
wj
and
ri
ri
encode
the
updates
of
the
cumulative
attention
and
relevance
respectively
if
and
only
if
ui
is
mapped
to
position
it
is
worth
noting
that
when
we
do
not
allow
any
quality
loss
this
however
does
not
mean
that
the
ranking
will
remain
unchanged
subjects
can
be
reordered
within
ties
to
minimize
unfairness
when
any
permutation
of
the
ranking
is
allowed
striving
to
minimize
unfairness
in
the
current
iteration
4.3
4.2
ilp
with
candidate
pre-filtering
the
ilp
operates
on
huge
combinatorial
space
with
the
number
of
binary
variables
being
quadratic
in
the
number
of
subjects
real
systems
deal
with
millions
of
subjects
and
the
optimization
needs
to
be
carried
out
each
time
new
ranking
is
requested
such
problem
size
is
bottleneck
for
ilp
solvers
and
in
practice
the
optimization
needs
to
use
approximation
algorithms
such
as
lp
relaxations
or
greedy-style
heuristics
this
is
one
of
the
directions
for
further
research
to
deal
with
the
issue
in
this
work
instead
of
reranking
all
subjects
in
each
iteration
we
rerank
only
subjects
from
prefiltered
candidate
set
different
strategies
are
possible
for
selecting
the
candidate
sets
on
the
one
hand
prefiltering
the
top-ranked
subjects
by
relevance
scores
would
let
us
satisfy
the
quality
constraints
but
may
entail
small
fairness
gains
especially
for
near-uniform
relevance
distributions
on
the
other
hand
prefiltering
based
on
the
objective
function
might
lead
to
situations
where
the
ilp
cannot
find
any
solution
without
violating
the
constraints
without
prefiltering
the
ilp
always
has
at
least
one
feasible
solution
the
original
ranking
40
chapter
equity
of
attention
our
strategy
thus
is
as
follows
assume
we
want
to
select
subject
candidate
subset
of
size
to
be
reranked
and
we
constrain
the
quality
in
eq
4.8
at
rank
since
the
attention
weights
wj
are
positive
the
biggest
contributors
to
the
objective
function
are
the
subjects
with
the
smallest
values
of
ai
ri
ri
these
are
the
subjects
with
the
highest
deficit
negative
value
of
fair-share
attention
we
always
select
subjects
with
the
highest
relevance
scores
in
rl
to
make
sure
we
satisfy
the
quality
constraint
plus
other
subjects
with
the
lowest
ai
ri
ri
values
who
are
most
worthy
of
being
promoted
to
high
ranks
as
result
when
no
feasible
solution
can
be
found
by
reranking
the
most
worthy
subjects
the
ilp
will
default
to
choosing
the
top-k
candidates
by
relevance
scores
4.3
4.3
extensions
granularity
the
presented
model
assumes
that
attention
and
relevance
are
aggregated
per
ranked
subject
it
is
straightforward
to
extend
it
to
handle
higher-level
actors
such
as
product
brands
or
internet
domains
by
summing
the
relevance
and
attention
scores
over
the
corresponding
subjects
as
consequence
of
this
modification
bigger
organizations
would
obtain
higher
exposure
deciding
whether
this
effect
is
fair
is
policy
issue
handling
dynamics
in
real-world
system
the
size
of
the
population
will
vary
over
time
with
new
subjects
joining
and
existing
ones
dropping
out
our
model
is
capable
of
handling
this
kind
of
dynamics
since
new
users
starting
with
no
deserved
attention
will
be
positioned
in
between
the
users
who
got
more
than
they
deserved
and
those
who
got
less
moreover
ranking
quality
constraints
will
prevent
such
users
from
being
positioned
too
low
in
rankings
where
they
are
highly
relevant
4.4
experiments
4.4
data
the
datasets
we
use
are
either
synthetically
generated
or
derived
from
other
publicly
available
resources
they
are
freely
available
to
other
researchers
4.4
1.1
synthetic
datasets
we
create
synthetic
datasets
to
analyze
the
performance
of
the
model
in
controlled
setup
under
different
relevance
distributions
we
assume
the
following
distribution
shapes
uniform
where
every
user
has
the
same
relevance
score
ii
linear
where
the
scores
decrease
linearly
with
the
rank
position
and
iii
exponential
where
the
scores
decrease
exponentially
with
the
rank
position
each
dataset
has
100
subjects
4.4
1.2
airbnb
datasets
to
analyze
the
model
in
real-world
scenario
we
construct
rankings
based
on
airbnb2
apartment
listings
from
cities
located
in
different
parts
of
the
world
boston
geneva
and
https://www.airbnb.com/
4.4
experiments
41
hong
kong
airbnb
is
two-sided
sharing
economy
platform
allowing
people
to
offer
their
free
rooms
or
apartments
for
short-term
rental
it
is
prime
example
of
platform
where
exposure
and
attention
play
crucial
role
in
the
subjects
financial
success
the
data
we
use
is
freely
available
for
research
rankings
are
constructed
using
the
attribute
id
as
subject
identifier
and
various
review
ratings
as
the
ranking
criteria
with
the
rating
scores
serving
as
relevance
scores
such
crowd-sourced
judgments
serve
as
good
worthiness-of-attention
proxy
on
this
particular
platform
although
one
has
to
have
in
mind
that
rating
distributions
tend
to
be
skewed
towards
higher
scores
which
is
confirmed
by
our
experimental
analysis
for
each
of
the
datasets
we
run
the
amortization
model
on
two
types
of
ranking
sequences
single-query
we
examine
the
amortization
effects
when
single
ranking
is
repeated
multiple
times
to
construct
the
rankings
we
use
the
values
of
the
review_scores_rating
attribute
which
corresponds
to
the
overall
quality
of
the
listing
multi-query
we
examine
the
behavior
of
the
model
when
sequence
of
rankings
each
with
different
relevance
distribution
is
repeated
multiple
times
to
this
end
for
each
city
we
construct
rankings
based
on
different
rating
attributes
review_scores_rating
review_scores_accuracy
review_scores_cleanliness
review_scores_checkin
review_scores_communication
review_scores_location
and
review_scores_value
the
datasets
for
boston
geneva
and
hong
kong
contain
3944
1728
and
4529
subjects
respectively
note
that
for
the
purpose
of
model
performance
evaluation
the
queries
themselves
become
irrelevant
once
the
relevance
is
computed
since
the
values
of
the
aforementioned
attributes
serve
as
relevance
scores
the
queries
are
abstracted
out
4.4
1.3
stackexchange
dataset
we
create
another
dataset
from
querylog
and
document
collection
synthesized
from
the
stackexchange
dump
by
biega
et
al
2017b
please
refer
to
the
original
paper
for
details
we
choose
radom
subset
of
users
and
order
their
queries
by
timestamps
creating
workload
of
around
20k
queries
we
use
indri4
to
retrieve
500
most
relevant
answers
for
each
query
and
treat
the
author
of
the
answer
as
the
subject
to
be
ranked
using
this
dataset
helps
us
gain
an
insight
into
the
performance
of
the
method
in
core
ir
tasks
and
with
different
sets
of
subjects
ranked
in
each
iteration
downloaded
from
http://insideairbnb.com/
https://www.lemurproject.org/indri/
42
chapter
equity
of
attention
4.4
position
bias
our
model
requires
that
we
assign
weight
to
each
ranking
position
denoting
the
fraction
of
the
total
attention
the
position
gets
these
weights
will
depend
on
the
application
and
platform
and
may
be
estimated
from
historical
click
data
in
this
thesis
we
study
the
behavior
of
the
equity-of-attention
mechanism
under
generic
models
of
attention
distribution
we
focus
on
the
following
distributions
geometric
the
weights
of
the
positions
are
distributed
geometrically
with
the
parameter
up
to
the
position
and
are
for
positions
lower
than
geometrically
distributed
weights
are
special
case
of
the
cascade
model
craswell
et
al
2008
where
each
subject
has
the
same
probability
of
being
clicked
setting
the
weights
of
lower
positions
to
is
based
on
an
assumption
that
low-ranked
subjects
are
not
inspected
wj
4.9
singular
the
top-ranked
subject
receives
all
the
attention
this
is
special
case
of
the
geometric
attention
model
with
parameters
studying
this
attention
model
is
motivated
by
systems
such
as
uber
which
present
only
top-1
matches
to
the
searchers
by
default
wj
4.10
before
being
passed
on
to
the
model
the
weights
are
rescaled
such
that
wj
studying
the
effects
of
position
bias
on
individual
fairness
under
more
complex
attention
models
is
future
work
4.4
implementation
and
parameters
we
implement
the
ilp-based
amortization
defined
in
section
4.3
using
the
gurobi
software
constraints
are
set
to
be
satisfied
up
to
feasibility
threshold
of
1e
we
prefilter
100
candidates
for
reranking
in
each
iteration
as
described
in
section
4.3
4.2
in
the
singular
attention
model
since
all
the
attention
is
assumed
to
go
to
the
first
ranking
position
the
ilp
constrains
the
ndcg-quality
at
rank
we
construct
the
geometric
attention
model
with
0.5
and
and
in
this
case
the
ilp
constraints
the
ndcg-quality
at
rank
in
the
single-query
mode
where
single
ranking
is
repeated
multiple
times
we
set
the
number
of
iterations
to
20k
in
the
multi-query
mode
with
repeated
sequence
of
different
rankings
we
repeat
the
whole
sequence
3k
times
which
leads
to
total
of
21k
rankings
relevance
scores
in
the
framework
need
to
be
normalized
to
form
distribution
in
this
work
we
assume
relevance
is
direct
proxy
for
worthiness
and
rescale
the
rating
scores
linearly
note
however
that
if
additional
knowledge
is
available
to
the
platform
regarding
http://www.gurobi.com/
4.4
experiments
43
the
correspondence
between
relevance
and
worthiness
other
transformations
can
be
applied
as
well
4.4
mechanisms
under
comparison
we
compare
the
performance
of
the
ilp-based
online
mechanism
against
two
baseline
heuristics
relevance
the
first
heuristic
is
to
allow
only
relevance-based
ranking
completely
disregarding
fairness
objective
the
second
heuristics
is
an
objective-driven
ranking
strategy
which
orders
subjects
by
the
increasing
priority
value
ai
ri
ri
see
sec
4.3
4.2
for
each
ranking
since
all
position
weights
wj
are
positive
assigning
highest
weights
to
subjects
with
the
lowest
preference
value
is
in
line
with
the
minimization
goal
this
ranking
strategy
aims
at
strong
fairness
amortization
without
any
quality
constraints
and
is
expected
to
perform
similarly
to
the
ilp
with
4.4
data
characteristics
relevance
vs
attention
figure
4.1
shows
the
relevance
score
distributions
in
the
single-query
airbnb
datasets
for
boston
geneva
and
hong
kong
the
seemingly
flatter
shape
of
the
boston
and
hong
kong
distributions
is
the
result
of
bigger
size
of
these
datasets
when
compared
to
the
geneva
dataset
where
each
individual
has
on
average
larger
fraction
of
the
total
relevance
overall
the
distributions
have
shape
which
complements
the
uniform
linear
and
exponential
shapes
of
distributions
in
the
synthetic
datasets
figure
4.2
presents
an
example
strongly
motivating
our
research
namely
it
compares
the
distribution
of
relevance
in
the
geneva
dataset
with
the
distribution
of
attention
according
to
the
geometric
model
with
0.5
where
the
weights
closely
follow
the
empirical
observations
made
in
previous
position
bias
studies
joachims
and
radlinski
2007
observe
that
the
relevance
distribution
plotted
in
green
is
the
same
as
that
in
figure
4.1
there
is
huge
discrepancy
between
these
two
distributions
while
as
argued
in
this
thesis
they
should
ideally
be
equal
to
ensure
individual
fairness
similar
discrepancy
exists
in
the
two
other
airbnb
datasets
4.4
performance
on
synthetic
data
singular
attention
model
figure
4.3
reveals
number
of
interesting
properties
of
the
mechanism
for
the
uniform
relevance
distribution
we
plot
the
iteration
number
on
the
x-axis
and
the
value
of
the
unfairness
measure
defined
by
equation
4.3
on
the
y-axis
first
since
reshuffling
does
not
lead
to
any
quality
loss
when
all
the
relevance
scores
are
equal
all
the
reshuffling
methods
perform
equally
well
irrespective
of
their
amortizing
behavior
should
be
contrasted
with
the
black
line
denoting
the
relevance
baseline
unfairness
for
this
method
always
increases
linearly
by
constant
factor
incurred
by
the
single
ranking
second
amortization
methods
periodically
bring
unfairness
to
the
minimum
occurs
every
44
chapter
equity
of
attention
figure
4.1
relevance
distributions
in
the
airbnb
datasets
figure
4.2
comparison
of
the
attention
and
relevance
distributions
for
the
top-10
ranking
positions
in
the
geneva
dataset
note
that
the
relevance
distribution
presented
here
is
the
same
as
in
fig
4.1
to
satisfy
equity-of-attention
fairness
the
two
distributions
would
have
to
be
the
same
4.4
experiments
45
iterations
where
is
the
number
of
subjects
in
the
dataset
within
the
cycle
each
subject
is
placed
in
the
top
position
receiving
all
the
attention
exactly
once
figure
4.4
with
the
results
for
the
linear
dataset
confirms
another
anticipated
behavior
with
no
ties
in
the
relevance
scores
it
is
not
possible
to
improve
fairness
without
incurring
quality
loss
thus
all
methods
with
lead
to
higher
unfairness
when
compared
to
the
objective
baseline
although
the
unfairness
is
still
lower
in
ilp
with
0.8
than
in
the
relevance
baseline
when
the
relevance
scores
decrease
exponentially
figure
4.5
the
ilp
is
not
able
to
satisfy
the
quality
constraint
with
any
0.5
and
thus
these
rerankings
become
equivalent
to
those
of
the
relevance
heuristic
figure
4.3
model
performance
on
the
synthetic
uniform
dataset
attention
singular
figure
4.4
model
performance
on
the
synthetic
linear
dataset
attention
singular
46
chapter
equity
of
attention
figure
4.5
model
performance
on
the
synthetic
exponential
dataset
attention
singular
figure
4.6
model
performance
on
the
synthetic
uniform
dataset
attention
geometric
4.4
experiments
47
figure
4.7
model
performance
on
the
synthetic
linear
dataset
attention
geometric
figure
4.8
model
performance
on
the
synthetic
exponential
dataset
attention
geometric
48
chapter
equity
of
attention
geometric
attention
model
as
shown
in
figures
4.6
4.7
and
4.8
the
periodicity
effect
becomes
less
pronounced
under
the
general
geometric
attention
model
figure
4.9
helps
to
understand
this
behavior
by
showing
the
unfairness
values
achieved
by
the
objective
heuristic
with
different
values
of
the
attention
cut-off
see
equation
4.9
with
the
model
is
equivalent
to
singular
as
we
increase
the
distribution
of
the
position
weights
becomes
smoother
smoothing
also
the
periodicity
of
the
unfairness
values
the
very
good
performance
of
the
ilp-based
rerankings
with
any
in
figure
4.8
stems
from
the
fact
that
the
relevance
and
attention
distributions
are
almost
the
same
the
only
difference
being
that
the
scores
in
the
relevance
distribution
are
non-zero
for
more
positions
our
results
show
that
in
this
case
the
ilp
performs
reordering
only
every
now
and
then
when
the
subjects
ranked
lower
than
position
in
the
original
ranking
gather
enough
deserved
attention
this
causes
the
unfairness
to
go
up
and
down
periodically
4.4
performance
on
airbnb
data
4.4
7.1
single-query
singular
attention
we
first
analyze
the
model
performance
on
the
airbnb
datasets
where
single
ranking
is
repeated
multiple
times
and
the
attention
model
is
set
to
singular
the
results
are
shown
in
figures
4.10
4.11
4.12
for
boston
geneva
and
hong
kong
respectively
as
in
the
analysis
with
the
synthetic
data
we
plot
the
iteration
number
on
the
x-axis
and
the
value
of
the
unfairness
measure
defined
by
equation
4.3
on
the
y-axis
there
are
number
of
observations
as
noted
before
the
loss
in
the
relevance
baseline
plotted
in
black
increases
linearly
by
the
constant
unfairness
factor
incurred
by
the
single
ranking
figure
4.9
performance
of
the
objective
heuristic
on
the
synthetic
uniform
dataset
under
the
geometric
attention
model
with
different
attention
cut-off
points
4.4
experiments
49
relaxing
the
quality
constraint
by
decreasing
allows
us
to
achieve
lower
unfairness
values
in
the
corresponding
ranking
iterations
the
objective
heuristic
with
no
quality
constraints
and
the
ilp
where
are
able
to
amortize
fairness
over
time
well
with
no
significant
growth
of
unfairness
over
time
the
periodicity
effect
we
observed
on
synthetic
uniform
data
appears
here
as
well
this
is
due
to
the
relative
closeness
of
the
relevance
distributions
in
the
airbnb
data
to
the
uniform
distribution
unfairness
achieved
by
the
amortizing
methods
is
close
to
every
iterations
the
frequency
of
the
minimum
indeed
corresponds
to
the
size
of
the
respective
datasets
in
some
methods
unfairness
starts
to
grow
linearly
after
certain
number
of
iterations
see
the
blue
curve
in
figure
4.10
this
is
side
effect
of
the
candidate
prefiltering
heuristic
we
chose
when
the
ilp
receives
filtered
candidate
set
where
no
subjects
filtered
based
on
the
objective
can
be
placed
at
the
top
of
the
ranking
without
violating
the
quality
constraint
the
ilp
defaults
to
placing
the
most
relevant
subjects
at
the
top
which
causes
the
quality
loss
to
be
and
the
unfairness
growing
linearly
this
effect
persists
until
some
of
the
more
relevant
subjects
gather
enough
deserved
attention
to
be
pre-selected
note
the
variability
that
occurs
in
the
blue
curve
again
starting
around
the
17k-th
iteration
for
number
of
iterations
at
the
beginning
equal
to
the
number
of
ties
at
the
top
of
the
ranking
all
the
methods
perform
the
same
irrespective
of
the
quality
constraints
this
is
due
to
the
fact
that
unfairness
is
minimized
by
reshuffling
the
most
deserving
relevant
subjects
first
which
does
not
incur
any
quality
loss
figure
4.10
model
performance
on
the
single-query
boston
dataset
attention
singular
50
chapter
equity
of
attention
figure
4.11
model
performance
on
the
single-query
geneva
dataset
attention
singular
figure
4.12
model
performance
on
the
single-query
hong
kong
dataset
attention
singular
4.4
experiments
51
figure
4.13
model
performance
on
the
multi-query
boston
dataset
attention
singular
figure
4.14
model
performance
on
the
multi-query
geneva
dataset
attention
singular
52
4.4
7.2
chapter
equity
of
attention
multi-query
singular
attention
our
methods
amortize
fairness
better
achieving
lower
unfairness
on
the
airbnb
multi-query
datasets
figures
4.13
4.14
and
4.15
when
compared
to
the
single-query
datasets
for
two
reasons
first
the
variability
in
subject
relevance
and
ordering
in
different
iterations
is
factor
helpful
in
smoothing
the
deserved
attention
distributions
over
time
second
distributions
of
the
rating
attributes
in
the
airbnb
datasets
used
to
construct
the
rankings
are
more
uniform
than
the
global
rating
score
and
have
more
ties
at
the
top
of
the
ranking
these
relevance
distribution
characteristics
enable
methods
with
conservative
quality
constraints
even
the
ilp
with
to
perform
very
well
4.4
7.3
single-query
geometric
attention
the
general
geometric
attention
distribution
is
closer
to
the
relevance
distributions
in
the
airbnb
datasets
than
the
singular
distribution
is
as
noted
in
the
analysis
with
synthetic
data
the
closeness
of
the
two
distributions
helps
amortize
fairness
at
lower
quality
loss
we
can
observe
similar
effect
in
figure
4.16
with
more
ilp-based
methods
reaching
the
performance
of
the
objective
heuristic
note
however
that
the
improved
performance
here
is
also
partly
due
to
the
fact
that
we
constrain
the
quality
at
higher
rank
when
assuming
the
geometric
attention
which
is
easier
to
satisfy
4.4
7.4
unfairness
vs
quality
loss
the
results
presented
so
far
show
the
performance
of
the
ilp-based
fairness
amortization
under
different
quality
thresholds
since
the
thresholds
bound
the
maximum
quality
loss
over
all
iterations
the
actual
loss
in
most
cases
might
be
lower
to
investigate
these
effects
we
plot
the
actual
ndcg-quality
values
of
the
rerankings
done
by
different
methods
on
the
boston
dataset
under
the
singular
attention
model
in
figure
4.17
the
results
confirm
that
the
actual
loss
is
often
lower
than
the
threshold
enforced
by
the
ilp
observe
that
figure
4.15
model
performance
on
the
multi-query
hong
kong
dataset
attention
singular
4.4
experiments
53
ndcg-quality
is
for
number
of
initial
iterations
in
all
the
methods
this
is
where
reshuffling
of
the
top
ties
happens
the
quality
starts
decreasing
as
less
relevant
subjects
gather
enough
deserved
attention
and
periodically
goes
back
to
when
the
top-relevant
subjects
gain
priority
again
similar
conclusions
regarding
the
absolute
loss
hold
under
the
general
geometric
attention
model
note
that
without
explicit
control
the
results
with
lower
utility
could
be
consistently
delivered
to
the
same
users
leading
to
unfairness
in
the
search
quality
for
searchers
mitigating
this
problem
would
require
two-sided
fairness
model
for
searched
subjects
and
searchers
figure
4.16
model
performance
on
the
single-query
boston
dataset
attention
geometric
results
are
similar
for
the
geneva
and
hong
kong
datasets
figure
4.17
actual
values
of
ranking
quality
boston
dataset
attention
singular
54
4.4
chapter
equity
of
attention
performance
on
stackexchange
data
the
relative
trends
in
the
performance
of
our
method
are
the
same
here
as
in
the
results
for
other
datasets
one
of
the
characteristics
that
distinguish
the
stackexchange
dataset
is
that
each
individual
subject
occurs
in
relatively
few
rankings
an
observation
that
follows
is
that
longer
amortization
timeframe
is
necessary
under
such
conditions
subject
obviously
needs
to
appear
in
number
of
rankings
so
that
the
model
can
reposition
them
to
fairly
distribute
attention
4.5
related
work
fairness
the
growing
ubiquity
of
data-driven
learning
models
in
algorithmic
decisionmaking
has
recently
boosted
concerns
about
the
issues
of
fairness
and
bias
the
problem
of
discrimination
in
data
mining
and
machine
learning
has
been
studied
for
number
of
years
pedreschi
et
al
2008
kamishima
et
al
2012
romei
and
ruggieri
2014
the
goal
there
is
to
analyze
and
counter
data
bias
and
unfair
decisions
that
may
lead
to
discrimination
much
prior
work
has
centered
around
various
notions
of
group
fairness
preserving
certain
ratios
of
members
of
protected
vs
unprotected
groups
in
the
decision
making
outcomes
with
the
groups
derived
from
discrimination-prone
attributes
like
gender
race
nationality
etc
feldman
et
al
2015
hardt
et
al
2016
for
example
the
criterion
of
statistical
parity
requires
that
classifier
outcomes
do
not
depend
on
the
membership
in
the
protected
group
state-of-the-art
mechanisms
for
dealing
with
such
group
fairness
requirements
are
to
solve
constrained
optimization
maximize
prediction
accuracy
subject
to
certain
bounds
on
group
membership
in
the
output
labels
this
has
led
to
classification
models
with
fairnessaware
regularization
zafar
et
al
2017
beyond
the
fairness
of
outcomes
researchers
have
looked
into
the
fairness
of
process
in
the
decision-making
systems
grgic-hlaca
et
al
2018b
individual
fairness
dwork
et
al
2012
requires
that
individual
subjects
who
have
similar
attributes
should
with
high
probability
receive
the
same
prediction
outcomes
literature
to
this
end
has
so
far
focused
on
classification
and
selection
problems
zemel
et
al
2013
kearns
et
al
2017
other
lines
of
work
investigate
mechanisms
for
fair
division
of
resources
abebe
et
al
2017
or
how
automated
systems
can
assist
humans
in
decision
making
kleinberg
et
al
2017a
fairness
in
rankings
prior
work
on
fair
rankings
is
scarce
and
recent
some
proposals
show
how
to
incorporate
various
notions
of
group
fairness
into
ranking
quality
measures
yang
and
stoyanovich
2017
there
have
been
approaches
that
diversify
the
ranking
results
in
terms
of
presence
of
members
of
different
groups
in
ranking
prefixes
at
the
same
time
keeping
the
ranking
quality
high
zehlike
et
al
2017
this
problem
has
also
been
studied
from
theoretical
perspective
with
the
results
provided
for
the
computational
complexity
of
the
problem
celis
et
al
2018
all
of
these
approaches
consider
static
rankings
only
and
all
focus
on
group
fairness
parallel
with
our
work
singh
and
joachims
2018
have
proposed
notion
of
group
fairness
based
on
equality
of
exposure
for
demographic
groups
while
4.6
conclusion
55
technically
complementary
and
similar
in
spirit
to
our
approach
this
method
is
also
geared
for
purpose
different
than
individual
fairness
and
does
not
aim
at
binding
attention
to
relevance
bias
in
ir
the
existence
of
position
bias
in
rankings
of
search
results
has
been
revealed
by
number
of
eye-tracking
and
other
empirical
studies
craswell
et
al
2008
dupret
and
piwowarski
2008
guo
et
al
2009
top-ranked
answers
have
much
higher
probability
of
being
viewed
and
clicked
than
those
at
lower
ranks
the
effect
persist
even
if
the
elements
at
different
ranks
are
randomly
permuted
joachims
and
radlinski
2007
these
observations
have
led
to
variety
of
click
models
chuklin
et
al
2015
provide
comprehensive
survey
and
several
methods
for
bias-aware
re-ranking
wang
et
al
2016
joachims
et
al
2017
however
position
bias
has
been
primarily
studied
in
the
context
of
document
ranking
and
no
prior
work
has
investigated
the
influence
of
the
bias
on
the
fairness
of
ranked
results
large
search
engine
has
been
investigated
for
presence
of
differential
quality
of
results
across
demographic
groups
mehrotra
et
al
2017
similar
studies
have
been
carried
out
on
other
kinds
of
tasks
such
as
credit
worthiness
or
recidivism
prediction
adler
et
al
2018
relation
to
other
models
fairness
dimension
has
been
considered
for
job
dispatching
at
the
os
level
for
packet-level
network
flows
ghodsi
et
al
2012
for
production
planning
in
factories
ghodsi
et
al
2011
and
even
for
two-sided
matchmaking
in
call
centers
armony
and
ward
2010
fairness
understood
as
envy-freeness
is
also
investigated
in
computational
advertising
including
generalized
second-price
auctions
edelman
et
al
2007
in
the
context
of
rankings
potential
connection
between
fair
rankings
and
fair
queuing
has
recently
been
suggested
chakraborty
et
al
2017
4.6
conclusion
this
thesis
argues
for
equity
of
attention
new
notion
of
fairness
in
rankings
which
requires
that
the
attention
ranked
subjects
receive
from
searchers
is
proportional
to
their
relevance
as
this
definition
cannot
be
satisfied
in
single
ranking
because
of
the
position
bias
we
propose
to
amortize
fairness
over
time
by
reordering
consecutive
rankings
and
formulate
constrained
optimization
problem
which
achieves
this
goal
our
experimental
study
using
real-world
data
shows
that
the
discrepancy
between
the
attention
received
from
searchers
and
the
deserved
attention
can
be
substantial
and
that
many
subjects
have
equal
relevance
scores
these
observations
suggest
that
improving
equity
of
attention
is
crucial
and
can
often
be
done
without
sacrificing
much
quality
in
the
rankings
incorporating
such
fairness
mechanisms
is
especially
important
on
sharing
economy
or
two-sided
market
platforms
where
rankings
influence
people
economic
livelihood
and
our
work
addresses
this
gap
equity
of
attention
opens
number
of
interesting
directions
for
future
work
including
calibration
of
ranker
scores
in
economically-themed
applications
all
the
way
down
the
ir
stack
to
properly
training
judges
to
provide
relevance
labels
with
fairness
in
mind
chapter
sensitive
search
exposure
contents
5.1
introduction
5.2
problem
statement
5.3
generating
exposure
sets
60
5.4
ranking
of
queries
in
exposure
sets
61
5.4
learning
to
rank
the
exposing
queries
61
5.4
features
62
5.4
relevance
64
5.5
5.6
experiments
58
59
65
5.5
dataset
65
5.5
rknn
generation
65
5.5
query
ranking
in
exposure
sets
65
5.5
user-study
evaluation
67
insights
into
search
exposure
relevance
70
5.6
tweet
context
70
5.6
search
exposure
relevance
vs
topical
sensitivity
70
5.7
related
work
71
5.8
conclusion
73
earch
engines
in
online
communities
such
as
twitter
or
facebook
not
only
return
matching
posts
but
also
provide
links
to
the
profiles
of
the
authors
thus
when
user
appears
in
the
top-k
results
for
sensitive
keyword
query
she
becomes
widely
exposed
in
sensitive
context
the
effects
of
such
exposure
can
result
in
serious
privacy
violation
ranging
from
embarrassment
all
the
way
to
becoming
victim
of
organizational
discrimination
in
this
chapter
we
propose
the
first
model
for
quantifying
search
exposure
on
the
service
provider
side
casting
it
into
reverse
k-nearest-neighbor
problem
moreover
since
single
user
can
be
exposed
by
large
number
of
queries
we
also
devise
learning-to-rank
method
for
identifying
the
most
critical
queries
and
thus
making
the
warnings
user-friendly
we
develop
efficient
algorithms
and
present
experiments
with
large
number
of
user
profiles
from
twitter
that
demonstrate
the
practical
viability
and
effectiveness
of
our
framework
58
5.1
chapter
sensitive
search
exposure
introduction
motivation
query
search
engine
in
online
communities
such
as
twitter
or
facebook
not
only
returns
matching
posts
but
also
identifies
the
users
who
have
written
the
posts
this
search
exposure
risk
is
particularly
pronounced
when
user
post
appears
in
the
top-k
results
for
sensitive
keyword
query
note
that
exposure
is
different
from
just
having
contents
visible
within
community
when
facebook
introduced
the
news
feed
feature
lot
of
users
responded
with
outrage
they
felt
their
privacy
was
being
violated
even
though
the
new
feature
only
meant
that
newly
generated
content
would
be
broadcasted
to
people
who
would
have
access
to
that
content
anyway
boyd
2008
analogously
in
the
context
of
search
systems
while
user
may
be
fine
with
posting
about
health
problems
controversial
political
issues
or
using
swearwords
she
may
feel
very
uncomfortable
with
the
posts
being
returned
as
top-ranked
results
content
found
this
way
could
be
used
for
example
in
stories
written
by
journalists
or
bloggers
and
attract
uninvited
attention
to
the
user
account
beyond
topically
sensitive
queries
there
are
also
risks
regarding
search
exposure
by
unique
strings
an
adversary
could
search
for
people
posting
urls
of
sensitive
domains
such
as
pirate
websites
or
certain
price
tokens
such
as
1k
an
adversary
with
list
of
e-mails
could
issue
these
to
find
answers
to
security
questions
necessary
to
reset
passwords
an
adversary
with
list
of
generated
credit
card
numbers
could
issue
these
as
queries
to
find
other
personal
information
necessary
for
credit
card
transactions
state
of
the
art
and
limitations
despite
the
existence
of
such
threats
to
the
best
of
our
knowledge
there
is
no
support
for
users
to
find
out
about
their
search
exposure
risks
the
only
way
would
be
to
try
out
all
possible
queries
and
inspect
their
top-k
results
yet
this
is
all
but
practical
the
service
providers
search
engines
or
social
network
platforms
do
not
provide
such
support
at
all
work
in
the
broad
area
of
exposure
has
been
tangibly
motivated
by
study
showing
the
discrepancy
between
the
expected
and
actual
audience
of
user-generated
content
bernstein
et
al
2013
exposure
has
been
addressed
in
other
contexts
so
far
including
information
exposure
among
friends
in
social
networks
mondal
et
al
2014
location
exposure
shokri
et
al
2011
longitudinal
information
exposure
mondal
et
al
2016
controlled
information
sharing
schlegel
et
al
2011
or
exposure
with
respect
to
sensitive
topics
biega
et
al
2016
the
importance
of
exposure
control
has
led
service
providers
to
introduce
features
such
as
facebook
view
as
which
informs
user
how
her
profile
appears
to
other
people
however
this
does
not
quantify
the
exposure
and
the
problem
of
search
exposure
in
particular
has
been
disregarded
completely
problem
and
challenges
to
the
best
of
our
knowledge
this
dissertation
is
the
first
to
address
the
problem
of
modeling
analyzing
and
quantifying
search
exposure
risks
as
the
risk
is
most
significant
when
user
is
spotted
in
the
top-k
results
of
query
our
goal
is
to
identify
these
top-k
exposing
queries
for
each
user
such
information
can
then
be
used
to
guide
the
user
for
example
in
deleting
posts
or
restricting
their
visibility
in
an
online
5.2
problem
statement
59
setting
tool
based
on
our
model
could
even
alert
the
user
about
the
exposure
before
submitting
post
the
search
exposure
problem
poses
number
of
challenges
efficiency
user
could
possibly
be
found
by
millions
of
distinct
queries
an
algorithm
to
identify
the
critical
queries
thus
faces
huge
scalability
and
efficiency
problem
dynamics
with
the
high
rate
of
new
online
contents
the
critical
queries
cannot
simply
be
computed
offline
from
query
log
the
exposure
of
users
keeps
continuously
shifting
usability
showing
all
queries
for
which
user
appears
in
the
top-k
results
would
in
many
cases
flood
the
user
with
millions
of
irrelevant
or
small-risk
queries
and
miss
the
point
of
guiding
the
user
thus
it
is
crucial
that
the
queries
are
ranked
by
an
informative
measure
of
possibly
user-specific
sensitivity
an
interesting
thing
to
note
is
that
from
the
perspective
of
user
reducing
search
exposure
can
be
seen
as
problem
of
inverse
search
engine
optimization
inverse
seo
for
short
seo
aims
to
push
user
to
the
top-ranked
results
for
certain
queries
here
the
goal
is
the
opposite
the
users
would
like
to
be
moved
to
the
low-ranked
tail
of
answers
or
even
completely
removed
from
the
search
results
of
particularly
sensitive
queries
approach
and
contributions
we
model
search
exposure
as
problem
of
reverse
search
instead
of
starting
with
query
and
finding
top-k
documents
relevant
to
the
query
we
start
with
document
and
want
to
find
all
the
queries
that
return
the
document
in
the
top-k
results
if
we
then
think
of
keyword
search
with
answer
ranking
as
the
problem
of
finding
the
top-k
nearest-neighbor
posts
according
to
given
similarity
function
search
exposure
becomes
reverse
k-nearest-neighbor
problem
rknn
to
assist
user
in
understanding
her
search
exposure
risks
we
devise
an
algorithm
for
ranking
the
queries
in
the
user
rknn
set
which
potentially
contains
hundreds
of
queries
to
this
end
we
combine
informative
features
ranging
from
topical
sensitivity
usually
higher
for
queries
about
health
problems
than
for
those
about
movies
through
query
selectivity
and
entropy
higher
for
queries
containing
birth
dates
or
social
security
numbers
to
user
surprisal
high
for
queries
matching
post
about
user
children
in
an
otherwise
professional
profile
the
salient
contributions
of
this
chapter
are
model
of
the
search
exposure
problem
learning
to
rank
method
with
informative
features
for
ranking
the
queries
in
the
exposure
sets
according
to
new
notion
of
search
exposure
relevance
an
experimental
study
with
large
set
of
twitter
profiles
providing
insights
on
the
exposure
sets
and
the
effectiveness
of
our
query
ranking
methods
5.2
problem
statement
preliminaries
assume
we
have
set
of
users
and
set
of
documents
posted
by
the
users
we
denote
the
fact
that
post
is
written
by
the
user
by
the
profile
of
60
chapter
sensitive
search
exposure
each
user
is
defined
as
the
set
of
all
documents
she
has
posted
in
community
search
exposure
the
problem
of
search
exposure
of
user
can
be
formalized
as
finding
all
the
reverse
k-nearest
neighbors
of
the
set
of
all
the
queries
for
which
any
of
the
posts
of
comes
among
the
top-k
results
we
call
the
sets
of
such
queries
as
exposure
sets
generation
of
exposure
sets
before
defining
the
exposure
sets
of
all
users
we
first
define
rkn
for
each
document
as
follows
rkn
is
the
rth
nn
of
5.1
where
is
the
set
of
all
queries
and
is
the
rank
of
for
the
query
rank
according
to
emrich
et
al
the
above
equation
is
equivalent
to
the
definition
of
bichromatic
rknn
emrich
et
al
2015
accordingly
we
define
the
exposure
set
of
each
user
as
the
union
of
the
exposure
sets
of
all
the
documents
in
her
profile
we
denote
the
exposure
set
of
the
user
by
rkn
which
is
defined
as
follows
rkn
rkn
5.2
an
efficient
algorithm
for
generating
exposure
sets
developed
by
biega
et
al
2017a
is
not
contribution
of
this
thesis
ranking
of
queries
in
exposure
sets
exposure
sets
of
certain
users
might
be
big
and
dominated
by
rare
non-informative
or
non-critical
queries
on
the
other
hand
exposure
by
certain
sensitive
queries
might
leave
the
user
uncomfortable
therefore
to
make
the
exposure
sets
user-friendly
we
want
to
rank
the
triples
in
rkn
such
that
the
queries
the
users
would
not
want
to
be
searched
by
appear
at
the
top
this
defines
the
notion
of
relevance
in
our
ranking
problem
termed
search
exposure
relevance
we
discuss
the
exposure
set
ranking
methods
and
our
notion
of
relevance
in
sec
5.4
5.3
generating
exposure
sets
biega
et
al
2017a
develop
an
efficient
algorithm
for
computing
exposure
sets
defined
by
equation
5.2
under
the
assumption
that
the
search
engine
uses
ranking
mechanism
based
on
language
models
this
algorithm
is
not
contribution
of
this
thesis
instead
to
present
the
further
contributions
of
this
chapter
we
assume
we
have
the
exposure
sets
equation
5.2
computed
for
all
the
users
in
system
since
considering
all
possible
queries
makes
the
problem
intractable
we
similarly
limit
the
considered
queries
to
unigram
and
bigram
queries
ii
and
only
those
queries
for
which
there
exists
at
least
one
document
in
the
underlying
collection
containing
all
the
query
terms
note
that
such
exposure
sets
can
be
generated
by
the
algorithm
proposed
by
biega
et
al
2017a
or
in
brute-force
manner
by
first
computing
top-k
rankings
for
all
considered
queries
and
then
re-aggregating
the
results
5.4
ranking
of
queries
in
exposure
sets
61
aim
oshtitsbaj
asleep
oshtitsbaj
http://ra*.com/teh_ba
splash
mac
vanilla
suck
wake
mood
sick
emma
sun
watch
xxxxxx
forget
toast
jeff
fall
heavyweight
ladder
omg
tan
alcohol
nice
blown
death
comin
lake
parilla
wait
bathroom
wanna
crush
hannah
friend
lord
record
woman
table
5.1
example
queries
from
unprocessed
exposure
sets
5.4
ranking
of
queries
in
exposure
sets
generating
the
exposure
sets
is
not
enough
for
the
results
to
be
presentable
to
end
users
for
two
reasons
first
of
all
for
many
users
the
size
of
their
rkn
set
is
simply
too
big
for
easy
consumption
our
experiments
on
sample
of
50k
user
profiles
from
twitter
later
confirm
this
even
when
only
unigram
and
bigram
queries
are
considered
more
than
35k
users
are
exposed
by
more
than
100
queries
with
some
users
exposed
by
millions
figure
5.1
in
the
upcoming
experimental
section
of
this
chapter
shows
the
distribution
of
exposure
set
size
for
users
from
the
sample
moreover
since
we
do
not
priori
exclude
queries
such
as
infrequent
or
numerical
tokens
most
rknn
sets
will
end
up
dominated
by
garbage
queries
leaving
such
queries
in
during
the
generation
phase
is
design
choice
motivated
by
the
worst
case
scenario
principle
that
often
guides
privacy
and
security
research
while
most
users
will
find
these
queries
uninformative
for
some
people
it
might
be
important
to
know
they
are
searchable
by
certain
urls
when
the
domain
is
known
to
contain
sensitive
content
or
numbers
their
year
of
birth
or
the
prices
of
products
they
buy
table
5.1
shows
examples
of
the
top
queries
in
the
raw
exposure
sets
where
queries
are
ordered
by
the
rank
position
of
the
corresponding
user
post
these
examples
illustrate
the
need
for
ranking
the
queries
before
presentation
to
end
users
raw
sets
are
uninformative
when
mostly
garbage
queries
are
shown
to
the
users
first
5.4
learning
to
rank
the
exposing
queries
recall
the
search
exposure
sets
defined
by
eq
5.2
we
want
to
rank
the
triples
within
these
sets
according
to
search
exposure
relevance
such
that
the
queries
the
users
would
not
want
to
be
searched
by
appear
at
the
top
the
traditional
ir
learning
to
rank
setup
in
which
the
learned
function
orders
the
documents
by
relevance
to
queries
is
replaced
by
one
where
we
rank
the
queries
according
to
relevance
to
users
each
user-document-query
triple
can
be
represented
as
feature
vector
for
each
user
together
with
the
relevance
score
annotations
these
form
partial
rankings
determining
pairwise
relevance
constraints
between
the
data
points
for
user
an
exposing
query
q1
matching
document
d1
should
be
ranked
higher
than
the
query
q2
matching
document
d2
we
want
to
learn
ranking
function
that
minimizes
loss
measure
over
these
partial
training
rankings
for
example
when
learning
to
rank
using
sv
rank
joachims
2006
it
is
the
number
of
violated
pairwise
constraints
that
is
minimized
which
implicitly
leads
to
62
chapter
sensitive
search
exposure
maximization
of
kendall
between
the
golden
and
learned
rankings
we
describe
the
features
and
relevance
scores
we
used
to
learn
the
ranking
function
in
the
following
two
sections
5.4
features
5.4
2.1
semantic
features
the
meaning
of
words
plays
an
important
role
in
determining
criticality
of
search
exposure
in
similar
context
user
studies
have
shown
topical
sensitivity
to
be
useful
in
the
context
of
privacy
risk
quantification
from
text
biega
et
al
2016
to
capture
the
coarse-grained
semantics
of
the
queries
we
annotate
them
with
categories
from
the
liwc
dictionaries
tausczik
and
pennebaker
2010
liwc
categorizes
words
into
80
linguistically
and
psychologically
meaningful
categories
such
as
positive
emotion
love
nice
sweet
affective
processes
happy
cry
abandon
swear
words
damn
piss
fuck
anxiety
worried
fearful
nervous
or
sexual
horny
love
incest
we
create
one
binary
feature
based
on
each
category
with
value
of
if
any
of
the
query
words
matches
any
of
the
words
from
the
category
5.4
2.2
uniqueness
of
queries
while
any
query
generated
from
community
text
contents
search-exposes
some
of
its
members
from
the
perspective
of
single
user
these
are
the
rare
tokens
that
are
more
likely
to
lead
to
exposure
while
considerable
portion
of
rare
queries
are
simply
meaningless
noise
it
is
possible
that
there
are
meaningful
infrequent
tokens
with
the
potential
to
violate
privacy
recall
some
of
our
motivating
examples
where
an
adversary
searches
for
information
associated
with
given
sensitive
domain
or
an
e-mail
address
we
propose
two
features
to
capture
how
rare
query
is
query
selectivity
and
query
entropy
we
define
the
query
selectivity
as
the
number
of
documents
matching
the
query
exactly
selectivity
5.3
this
measure
will
be
low
for
queries
which
appear
infrequently
another
aspect
of
query
being
unique
is
how
skewed
the
distribution
of
the
relevance
scores
is
we
capture
this
by
measuring
the
entropy
over
the
distribution
of
ranking
scores
of
the
top-k
returned
results
let
be
the
distribution
of
the
relevance
scores
of
the
top-k
results
we
measure
the
entropy
of
the
query
as
score
di
entropy
where
pk
score
dj
5.4
note
that
these
measures
are
not
dependent
on
given
user
but
are
dependent
on
the
community
as
whole
the
relative
rankings
of
queries
in
different
communities
might
differ
for
instance
while
the
query
lyme
borreliosis
might
be
an
infrequent
query
on
twitter
it
could
be
more
popular
in
medical
forum
5.4
ranking
of
queries
in
exposure
sets
5.4
2.3
63
user
surprisal
the
lexical
context
of
user
might
also
matter
when
determining
the
criticality
of
query
imagine
user
with
twitter
profile
where
she
posts
mostly
professional
content
it
would
not
be
surprising
and
perhaps
even
desirable
that
the
user
posts
are
returned
as
top
results
to
the
queries
from
that
professional
domain
however
if
it
turns
out
that
the
user
profile
comes
up
at
the
top
only
to
the
query
funny
cats
that
matches
that
single
post
the
user
has
ever
made
outside
of
the
professional
domain
this
might
be
both
unexpected
and
undesirable
we
propose
to
capture
this
intuition
using
surprisal
which
is
measured
by
reversing
the
probability
of
the
query
being
generated
from
user
vocabulary
distribution
estimated
from
the
posts
surprisal
log
log
5.5
to
account
for
the
sparsity
of
user
profiles
we
compute
these
probabilities
using
dirichlet
smoothing
5.4
2.4
document
surprisal
even
though
these
are
the
queries
that
are
ranked
the
users
might
not
want
to
be
matched
to
non-critical
query
when
it
exposes
critical
post
similarly
to
surprisal
of
queries
we
define
the
surprisal
of
posts
that
are
matched
by
the
exposing
queries
by
replacing
by
in
eq
5.5
5.4
2.5
rknn
features
two
traditional
methods
for
ranking
the
reverse
nearest
neighbors
by
relevance
to
the
user
are
the
proximity
of
the
reverse
neighbor
to
the
user
and
the
rank
of
the
reverse
neighbor
while
not
likely
to
be
useful
when
the
relevance
is
defined
as
criticality
we
include
these
features
for
comparison
we
measure
proximity
using
the
probability
of
generating
the
query
from
the
posting
history
of
proximity
log
5.6
let
du
be
the
post
of
user
that
is
returned
as
an
answer
to
query
at
position
rank
du
rankposition
rank
du
5.4
2.6
5.7
syntactic
features
we
also
introduce
number
of
binary
post-dependent
features
that
characterize
emotional
display
or
content
the
users
might
not
want
to
be
exposed
by
through
search
these
include
has_url
set
to
if
the
post
contains
url
has_at_mention
set
to
if
the
post
mentions
another
user
64
chapter
sensitive
search
exposure
has_hashtag
set
to
of
the
query
contains
hashtag
has_emoticon
set
to
if
the
post
contains
an
emoticon
has_repeated_punctuation
set
to
is
any
token
in
the
post
ends
with
double
exclamation
mark
double
question
mark
or
an
ellipsis
has_repeated_vowels
set
to
if
any
token
in
post
contains
vowel
repeated
at
least
three
times
in
row
has_laughter
set
to
if
any
token
contains
substring
like
haha
with
different
vowels
5.4
relevance
search
exposure
relevance
differs
in
many
ways
from
the
topical
relevance
of
traditional
ir
tasks
query
might
be
relevant
not
only
because
it
topically
sensitive
but
also
because
it
could
embarrass
offend
or
otherwise
violate
the
privacy
of
the
exposed
person
the
subjective
nature
of
such
judgments
makes
the
manual
collection
of
relevance
at
scale
an
extremely
time-consuming
task
especially
if
done
by
external
evaluators
to
decide
which
queries
would
be
relevant
judge
would
have
to
put
themselves
in
the
shoes
of
the
evaluated
user
imagine
who
that
person
is
based
on
the
contents
of
the
profile
and
decide
which
queries
would
concern
her
moreover
judge
would
have
to
come
up
with
likely
threat
scenarios
it
is
non-trivial
task
to
prime
the
judges
regarding
these
issues
without
biasing
them
with
all
these
considerations
we
derive
implicit
relevance
scores
from
other
user-generated
signals
that
indicate
reluctance
to
be
associated
with
given
content
implicit
relevance
signals
especially
in
the
form
of
clickthrough
patterns
are
commonly
used
in
traditional
retrieval
tasks
carterette
and
jones
2007
the
remainder
of
this
section
presents
our
method
for
synthesizing
the
search
exposure
relevance
scores
user
score
if
user
deletes
post
it
is
signal
she
does
not
want
to
be
associated
with
its
content
thus
query
matching
post
that
got
deleted
after
publication
receives
user
score
of
whereas
query
matching
non-deleted
post
receives
user
score
of
while
service
provider
quantifying
exposure
would
have
direct
access
to
this
information
there
are
also
ways
for
collecting
it
outside
of
the
system
mondal
et
al
2016
we
describe
our
collection
method
in
more
detail
in
the
experimental
section
community
score
the
deletion
information
is
noisy
signal
however
as
users
delete
posts
for
variety
of
reasons
including
language
or
double
posting
errors
we
want
to
sanitize
these
scores
using
stronger
community-wide
signals
that
encode
the
differences
in
language
distributions
in
anonymous
and
non-anonymous
communities
these
linguistic
differences
have
been
observed
for
instance
when
comparing
posts
from
twitter
and
whisper
an
anonymous
microposting
platform
correa
et
al
2015
having
estimated
the
vocabulary
distributions
in
an
anonymous
panon
and
non-anonymous
pnon
anon
community
we
treat
the
relative
probability
of
query
being
generated
from
these
distributions
as
5.5
experiments
65
community-wide
signal
that
users
do
not
want
to
be
associated
with
the
keywords
more
precisely
we
set
the
community
score
of
query
to
community_score
panon
panon
pnon
anon
pnon
anon
5.8
golden
ranking
finally
we
derive
the
relevance
as
linear
combination
of
both
scores
score
user_score
community_score
5.9
combining
both
scores
allows
us
to
discount
the
relevance
of
noisy
queries
that
match
deleted
posts
as
well
as
add
relevance
to
sensitive
queries
matching
posts
that
did
not
get
deleted
as
the
user
perhaps
did
not
have
any
privacy
concerns
in
mind
5.5
experiments
in
this
section
we
discuss
our
insights
into
the
search
exposure
problem
through
evaluation
of
the
ranking
methods
as
well
as
an
analysis
of
user
perceptions
regarding
exposing
queries
collected
in
an
experiment
on
amazon
mechanical
turk
5.5
dataset
for
our
experiments
we
use
sample
of
twitter
profiles
from
the
longitudinal
exposure
study
by
mondal
et
al
2016
it
consists
of
51
550
user
profiles
with
total
of
about
5.5
million
tweets
posted
over
the
year
2009
5.5
rknn
generation
the
experiments
on
rknn
generation
reported
by
biega
et
al
2017a
are
not
part
of
this
thesis
however
we
use
the
exposure
sets
the
authors
generated
as
an
input
for
the
ranking
algorithm
experiments
presented
in
this
thesis
we
thus
report
on
the
data
preparation
techniques
applied
before
generating
the
exposure
sets
the
cleaning
included
stop
words
removal
lemmatization
and
stemming
resulting
in
around
millions
unique
tokens
the
query
filtering
strategy
described
in
section
5.3
resulted
in
45
million
queries
considered
for
exposure
sets
figure
5.1
shows
the
distribution
of
the
size
of
exposure
sets
of
the
users
in
the
dataset
for
different
values
of
we
assume
10
for
the
experiments
in
this
chapter
5.5
query
ranking
in
exposure
sets
5.5
3.1
exposure
sets
cleaning
for
the
evaluation
results
to
be
meaningful
we
excluded
the
following
queries
from
the
exposure
sets
queries
with
tokens
shorter
than
letters
queries
for
which
none
of
the
tokens
is
an
english
word
queries
with
numerical
tokens
urls
and
references
to
other
accounts
we
also
excluded
users
whose
posts
are
primarily
written
in
language
other
than
english
while
all
of
these
queries
could
be
search
exposure
relevant
in
certain
contexts
it
is
unlikely
66
chapter
sensitive
search
exposure
figure
5.1
distribution
of
the
size
of
exposure
sets
the
values
on
axis
are
in
logarithmic
scale
with
base
10
that
human
judges
who
evaluate
the
ranking
outputs
would
be
able
to
associate
any
meaning
with
them
5.5
3.2
relevance
score
statistics
we
construct
the
relevance
scores
as
described
in
sec
5.4
community
scores
are
derived
from
the
whisper
dataset
collected
by
correa
et
al
2015
and
the
twitter
dataset
collected
by
mondal
et
al
2016
the
twitter
dataset
moreover
comes
with
the
information
regarding
tweet
deletion
more
precisely
by
querying
the
twitter
api
using
subset
of
the
tweet
ids
the
authors
were
able
to
determine
which
tweets
got
deleted
after
publication
this
information
was
collected
for
11m
tweets
400k
of
which
turned
out
to
have
been
removed
we
use
these
signals
as
the
user
score
because
the
information
about
post
deletion
is
limited
the
ground
truth
provides
us
with
only
partial
ranking
over
rknn
queries
we
therefore
exclude
the
queries
for
which
we
cannot
infer
relevance
from
the
evaluation
in
this
part
these
include
the
queries
matching
posts
for
which
we
do
not
have
the
deletion
information
ii
the
queries
with
only
partial
overlap
with
the
source
post
it
might
happen
that
post
is
returned
in
the
top-k
results
for
query
even
though
not
all
query
words
appear
in
the
post
for
such
queries
we
do
not
assume
the
deletion
information
signals
not
wanting
to
be
associated
with
the
words
excluding
exposure
sets
with
less
than
30
queries
which
do
not
need
ranking
to
be
5.5
experiments
feature
sexual
humans
friend
anger
67
example
queries
gross
kiss
breast
whitney
gay
shirt
dumbest
guy
girl
xoxo
chess
kid
pal
wife
fellow
fool
ummm
honey
buy
weapon
mad
scientist
idiot
vegetarian
table
5.2
most
important
semantic
features
learned
by
the
l2r
model
together
with
example
queries
presentable
to
users
we
are
left
with
around
15k
profiles
under
evaluation
5.5
3.3
ranking
algorithm
to
learn
the
ranking
function
we
use
sv
rank
joachims
2006
with
the
linear
kernel
parameter
is
tuned
on
random
sample
of
10
rknn
sets
and
the
rest
of
the
data
is
used
to
evaluate
the
l2r
method
in
10
fold
cross-validation
5.5
3.4
feature
analysis
the
weights
of
the
decision
boundary
vector
learned
using
svm
with
linear
kernel
can
be
interpreted
as
feature
importance
weights
table
5.2
lists
the
most
important
features
learned
by
our
model
together
with
example
queries
exhibiting
the
features
the
model
captures
well
that
the
categories
related
to
personal
issues
are
the
ones
people
feel
more
uncomfortable
sharing
high
importance
of
words
related
to
sexuality
stems
from
the
bias
of
the
whisper
data
large
majority
of
anonymous
posts
from
this
community
regard
sexuality
however
the
methodology
we
propose
is
general
enough
to
handle
different
types
of
anonymous
contents
for
instance
as
an
alternative
it
would
be
possible
to
collect
anonymous
posts
from
more
general
question
answer
communities
such
as
quora
5.5
user-study
evaluation
because
the
relevance
scores
used
for
training
the
algorithm
constitute
noisy
signals
for
search
exposure
relevance
we
evaluate
the
reranked
exposure
sets
in
user
study
the
leading
question
is
whether
users
themselves
would
find
the
output
useful
feeling
that
exposure
by
top-ranked
keywords
would
make
them
feel
uncomfortable
this
section
provides
the
details
of
the
study
5.5
4.1
evaluation
setup
to
evaluate
the
rankings
we
sample
number
of
exposure
sets
and
number
of
queries
from
each
user
sampling
the
first
important
thing
to
note
is
that
not
all
of
the
exposure
sets
contain
sensitive
queries
to
account
for
this
and
make
sure
we
cover
the
sensitive
users
in
the
evaluation
we
sample
users
non-uniformly
in
the
following
way
queries
within
exposure
sets
are
ordered
by
the
predicted
relevance
scores
the
score
of
the
highest
ranking
query
within
set
can
be
thought
of
as
an
indicator
of
how
sensitive
the
exposure
set
is
overall
68
chapter
sensitive
search
exposure
the
lower
the
highest
score
the
less
sensitive
content
there
is
overall
for
evaluation
we
choose
the
50
most
sensitive
exposure
sets
and
50
exposure
sets
sampled
from
the
remaining
tail
with
the
probability
proportional
to
the
predicted
relevance
of
the
highest
scoring
query
we
thus
evaluate
100
exposure
sets
in
total
query
sampling
to
construct
assignments
with
reasonable
workloads
we
evaluate
50
queries
from
each
of
the
sampled
exposure
sets
having
the
queries
ranked
by
the
l2r
method
under
evaluation
we
choose
25
highest
scoring
queries
to
see
how
useful
the
top
of
the
ranking
is
and
25
queries
chosen
uniformly
randomly
from
the
remaining
tail
to
control
if
the
head
of
the
ranking
does
not
miss
critical
queries
5.5
4.2
amt
survey
each
set
of
50
sampled
queries
was
shown
to
amazon
mechanical
turk
workers
the
queries
were
displayed
in
random
order
we
required
that
the
workers
have
master
qualification
to
ensure
the
quality
of
annotations
and
are
located
in
the
usa
to
prevent
language
misunderstanding
upon
explaining
the
basic
pipeline
of
the
twitter
search
engine
and
priming
the
users
about
what
exposure
is
the
survey
asked
the
following
question
would
you
feel
concerned
uncomfortable
embarrassed
privacy-violated
or
threatened
if
your
tweet
was
returned
as
one
of
the
top
answers
to
these
search
terms
yes
no
having
three
people
evaluate
each
query
leads
to
graded
relevance
scale
based
on
how
many
people
chose
yes
out
of
5k
evaluated
queries
10
had
score
of
12
had
score
of
24
had
score
of
54
had
score
of
inter-annotator
agreement
measured
by
fleiss
was
0.376
which
corresponds
to
fair
agreement
5.5
4.3
results
we
report
the
values
for
ndcg
10
20
and
kendall
moreover
since
the
collected
scores
offer
good
interpretability
in
terms
of
binary
relevance
as
well
we
also
report
precision
10
20
assuming
query
is
search
exposure
relevant
if
it
was
marked
by
at
least
one
judge
table
5.3
shows
the
results
of
the
user-study
evaluation
note
that
although
the
queries
were
sampled
from
the
l2r-ranked
exposure
sets
the
collected
judgments
also
let
us
evaluate
other
ranking
heuristics
we
use
the
rankings
based
on
the
values
of
several
high-level
features
as
baselines
majority
of
these
perform
significantly
worse
than
the
l2r
method
differences
significant
by
paired
t-test
with
0.05
are
marked
with
the
symbol
the
strongest
heuristics
include
document
surprisal
and
selectivity
both
of
these
quantities
capture
different
aspect
of
the
rareness
of
the
content
and
thus
shine
in
situations
where
for
instance
the
judges
thought
that
exposure
by
typo
might
lead
to
embarrassment
we
also
observed
that
number
of
query
tokens
are
typos
that
can
be
mapped
to
sensitive
word
such
queries
were
often
marked
by
the
judges
as
relevant
and
because
of
their
rareness
heuristics
such
as
selectivity
gain
in
performance
prec
10
0.566
0.449
0.471
0.489
0.508
0.463
prec
20
0.509
0.447
0.470
0.494
0.489
0.466
ndcg
0.515
0.210
0.229
0.209
0.278
0.204
ndcg
10
0.496
0.245
0.262
0.262
0.305
0.248
ndcg
20
0.530
0.316
0.350
0.347
0.378
0.330
kendall
0.107
0.035
0.016
0.026
0.037
0.018
table
5.3
exposure
set
ranking
user-study
results
averaged
over
all
users
methods
marked
with
perform
significantly
worse
than
l2r
on
given
metric
paired
t-test
0.05
l2r
surprisal
document
surprisal
entropy
selectivity
rank
prec
0.636
0.448
0.480
0.472
0.548
0.460
5.5
experiments
69
70
5.5
4.4
chapter
sensitive
search
exposure
anecdotal
examples
of
sensitive
exposure
sets
table
5.4
presents
examples
of
exposure
sets
with
the
top-10
queries
ranked
by
the
l2r
method
and
is
meant
as
an
overview
of
the
types
of
sensitive
keywords
user
might
be
exposed
by
in
twitter
queries
were
generated
from
the
contents
of
user
posts
which
means
that
each
presented
word
combination
matches
at
least
one
post
in
our
sample
we
resort
to
showing
manually
chosen
subset
of
examples
as
the
top
sensitive
exposure
sets
were
highly
explicit
and
offensive
5.6
insights
into
search
exposure
relevance
5.6
tweet
context
an
interesting
question
regarding
search
exposure
relevance
is
whether
it
is
influenced
by
the
context
of
the
returned
tweet
it
might
happen
that
query
that
looks
sensitive
is
constructed
from
words
that
do
not
form
coherent
context
within
post
thus
being
false
alarm
on
the
other
hand
innocent
looking
queries
might
bring
out
posts
that
do
contain
sensitive
content
otherwise
to
gain
preliminary
insight
into
this
problem
we
conducted
second
survey
on
amt
in
which
the
workers
assessed
the
relevance
of
queries
also
knowing
the
tweet
that
is
being
returned
as
result
the
rest
of
the
setup
remained
analogous
comparison
of
these
two
surveys
is
summarized
in
figure
5.2
existence
of
dark
squares
outside
of
the
diagonal
suggests
indeed
that
the
context
might
change
the
exposure
relevance
judgement
this
happens
both
ways
suggesting
that
both
scenarios
we
mentioned
in
the
previous
paragraph
are
plausible
we
believe
that
investigating
the
factors
that
influence
the
search
exposure
relevance
is
an
interesting
topic
for
future
work
5.6
search
exposure
relevance
vs
topical
sensitivity
topical
sensitivity
is
concept
introduced
for
studying
privacy
risks
of
text
in
particular
for
quantifying
r-susceptibility
rank-susceptibility
in
communities
where
user
profiles
consist
of
textual
contents
biega
et
al
2016
it
measures
how
likely
the
presence
of
words
from
different
topics
understood
as
distributions
over
words
leads
to
privacy
risks
irrespective
of
the
user
or
community
context
we
want
to
understand
if
there
is
correlation
between
topical
sensitivity
defined
this
way
and
the
search
exposure
relevance
we
thus
annotate
each
query
from
our
evaluation
set
using
the
topical
sensitivity
annotations
sensitivity
collected
in
the
r-susceptibility
paper
biega
et
al
2016
we
define
the
sensitivity
of
query
as
xx
sensitivity
sensitivity
5.10
where
is
the
probability
of
word
in
the
topic
we
measure
the
correlation
between
these
sensitivity-annotations
and
the
collected
relevance
scores
using
the
pearson
correlation
coefficient
we
find
strong
correlation
between
these
scores
in
case
of
the
relevance
collected
for
queries
without
the
tweet
context
5.7
related
work
71
figure
5.2
influence
of
the
tweet
context
on
search
exposure
relevance
the
number
in
square
denotes
the
number
of
tweets
that
received
the
score
of
in
the
study
with
queries
only
and
the
score
of
in
the
study
with
queries
in
context
pearson
coefficient
of
0.44
and
little
lower
correlation
pearson
coefficient
of
0.32
in
case
of
the
relevance
judgments
for
queries
with
the
tweet
context
this
result
reconfirms
the
findings
from
the
evaluation
of
the
l2r
method
the
meaning
of
the
query
is
an
important
factor
in
determining
search
exposure
relevance
and
topical
sensitivity
is
viable
alternative
for
implicit
relevance
scores
5.7
related
work
exposure
although
to
the
best
of
our
knowledge
the
problem
of
search
exposure
has
not
been
addressed
in
the
past
there
are
different
aspects
of
user
and
data
exposure
that
have
been
studied
in
the
prior
literature
mondal
et
al
2016
proposed
exposure
control
as
an
alternative
solution
to
access
control
in
social
networks
mondal
et
al
2014
and
later
devised
solutions
for
longitudinal
exposure
control
biega
et
al
2016
quantify
privacy
risks
for
sensitive
topics
in
rankings
based
on
textual
posts
using
the
notion
of
r-susceptibility
exposure
has
also
been
studied
in
the
context
of
individual
attribute
leakage
such
as
location
shokri
et
al
2011
another
interesting
problem
is
that
of
usability
of
exposure
warnings
example
solutions
include
depicting
the
current
size
of
content
audience
by
the
size
of
displayed
pair
of
eyes
schlegel
et
al
2011
72
chapter
sensitive
search
exposure
blame
gay
dutch
gay
gay
rabo
gay
guy
blame
dutch
suck
teacher
start
tht
rider
tour
donald
duck
attack
bad
gay
racist
fuckin
young
deal
gay
simon
watchin
fuckin
kinda
guy
note
kind
sum
live
net
bcoz
gay
dnt
season
adopt
convert
adopt
religion
convert
religion
convert
essay
essay
religion
bon
convert
bon
religion
bon
essay
river
tonight
adult
love
lesbian
pregnant
lesbian
music
lesbian
live
boat
lesbian
gay
norway
end
lesbian
fritt
gay
bell
page
star
trend
lesbian
uuum
oooh
virgin
virgin
wen
video
virgin
crack
oooh
oooh
wen
normal
tom
normal
smith
smith
tom
swine
year
outfit
xoxo
gay
israel
bit
web
gay
gunman
michael
pant
hat
pant
attack
bit
e-mail
match
israel
wtf
china
tale
obama
recov
david
queer
queer
ted
asian
queer
queer
warhol
david
folk
model
race
keith
york
driver
rule
kind
remix
jean
odd
camera
stick
stick
tape
rep
usa
china
rep
stick
tehran
governor
tehran
governor
stick
prayer
tehran
prayer
tehran
israel
rep
detail
obama
alex
detail
alex
obama
box
long
bloomberg
flash
dubai
investor
dubai
investor
june
real
june
real
alybi
gmail
com
investor
union
mexico
union
canada
union
american
union
demand
democrat
agenda
reform
nasa
obama
american
borderless
nazi
obama
demand
overhaul
table
5.4
top-10
sensitive
exposing
queries
returned
by
the
l2r
model
for
subset
of
users
privacy-preserving
ir
problems
studied
in
privacy-preserving
ir
include
sanitization
of
query
logs
prior
to
release
götz
et
al
2012
zhang
et
al
2016a
or
obfuscation
of
query
histories
through
broadened
or
dummy
queries
gervais
et
al
2014
wang
and
ravishankar
2014
number
of
works
also
investigate
the
viability
of
personalized
search
under
privacy
constraints
chen
et
al
2011
shen
et
al
2007
xu
et
al
2007
zhu
et
al
2010
user
protection
and
internal
audits
service
providers
increasingly
come
under
close
scrutiny
by
external
organizations
and
observers
including
journalists
and
researchers
this
pressure
encourages
the
sps
to
perform
proactive
internal
audits
to
improve
their
services
and
infrastructure
new
solutions
for
increased
privacy
are
constantly
introduced
to
mitigate
the
threats
for
users
from
external
adversaries
in
services
like
maps
huang
et
al
2017
user
data
itself
has
also
been
analyzed
for
example
to
deliver
better
security
protections
in
the
context
of
account
recovery
personal
questions
bonneau
et
al
2015
beyond
privacy
there
are
also
other
societal
issues
that
press
sps
to
audit
their
services
including
the
issues
of
fairness
and
bias
feldman
et
al
2015
or
user
satisfaction
with
search
results
mehrotra
et
al
2017
search
exposure
can
be
seen
as
another
dimension
for
internal
audits
along
these
lines
we
believe
more
work
can
be
done
to
examine
which
types
of
search
queries
should
be
blocked
altogether
and
which
search
results
should
be
removed
to
protect
against
finding
users
in
5.8
conclusion
73
sensitive
contexts
while
certain
ad-hoc
protections
are
already
in
place
for
instance
it
seems
impossible
to
explicitly
query
for
credit
card
numbers
in
google
twitter
or
facebook
since
these
tokens
get
post-processed
and
end
up
matching
other
numerical
tokens
as
well
there
is
need
for
more
direct
examination
and
protection
mechanisms
regarding
the
exposure
of
users
in
search
systems
reverse
k-nearest-neighbors
problems
the
problem
of
finding
reverse
nearest
neighbors
has
been
studied
in
scenarios
different
from
the
one
proposed
in
this
thesis
these
scenarios
include
matching
the
user
preferences
to
products
vlachou
et
al
2011
or
assigning
new
publications
to
subscribers
basik
et
al
2015
chen
and
cong
2015
reverse
nearest
neighbors
problem
can
be
studied
in
two
different
setups
monochromatic
or
bichromatic
the
setup
is
determined
by
whether
sets
of
queries
and
sets
of
reverse
nearest
neighbors
are
the
same
monochromatic
or
disjoint
bichromatic
emrich
et
al
2015
the
model
proposed
in
this
thesis
is
an
instance
of
bichromatic
rknn
since
the
sets
of
queries
and
documents
are
disjoint
existing
algorithms
for
finding
reverse
nearest
neighbors
are
not
sufficient
for
application
in
the
context
of
search
exposure
due
to
high
dimensionality
large
cardinality
and
sparsity
of
the
query
space
most
approaches
heavily
depend
on
geometric
properties
of
the
underlying
space
to
perform
efficient
pruning
vlachou
et
al
2011
5.8
conclusion
this
chapter
introduces
the
problem
of
quantifying
user
search
exposure
that
is
finding
the
queries
for
which
any
of
the
user
posts
is
returned
as
top-ranked
result
in
given
search
system
we
cast
the
problem
formally
as
reverse
search
and
propose
method
for
ranking
the
queries
in
the
resulting
exposure
sets
to
make
the
output
user-friendly
the
ranking
task
moreover
uses
newly
defined
concept
of
search
exposure
relevance
which
we
studied
in
series
of
amt
surveys
we
believe
there
are
number
of
fascinating
research
questions
that
could
be
studied
as
an
extension
to
the
work
presented
in
this
chapter
on
the
generation
side
considering
various
ranking
models
expanding
the
query
length
and
efficient
stream
processing
of
search
exposure
requests
including
parallel
computation
caching
and
request
partitioning
would
be
necessary
in
real-world
deployment
on
the
usability
and
ranking
side
further
understanding
of
exposure
relevance
designing
better
ranking
methods
incorporating
the
probabilities
of
queries
being
asked
to
the
overall
setup
or
detecting
exposure
in
black-box
systems
are
only
few
of
such
extension
possibilities
finally
further
investigating
layman
perceptions
regarding
search
exposure
as
well
as
developing
the
expert
understanding
of
the
possible
threats
would
give
us
better
grip
of
this
newly
defined
privacy
question
chapter
rank-susceptibility
contents
6.1
introduction
6.2
r-susceptibility
model
78
6.3
6.4
6.2
sensitive
states
and
adversaries
78
6.2
sensitive
topics
78
6.2
background
knowledge
79
6.2
r-susceptibility
79
risk
assessment
measures
79
6.3
entropy
baseline
measure
80
6.3
differential-privacy
baseline
measure
80
6.3
topical
risk
measure
81
identifying
sensitive
topics
85
6.4
6.5
76
experiments
on
topic
sensitivity
experiments
85
87
6.5
setup
87
6.5
traditional
vs
ir
risk
scoring
90
6.5
risk
scoring
with
dimensions
of
interest
90
6.5
robustness
to
configuration
changes
91
6.5
discussion
92
6.6
related
work
94
6.7
conclusion
96
rivacy
of
internet
users
is
at
stake
because
they
expose
personal
information
in
posts
created
in
online
communities
in
search
queries
and
other
activities
an
adversary
that
monitors
community
may
identify
the
users
with
the
most
sensitive
properties
and
utilize
this
knowledge
against
them
by
adjusting
the
pricing
of
goods
or
targeting
ads
of
sensitive
nature
existing
privacy
models
for
structured
data
are
inadequate
to
capture
privacy
risks
from
user
posts
this
chapter
presents
ranking-based
approach
to
the
assessment
of
privacy
risks
emerging
from
textual
contents
in
online
communities
focusing
on
sensitive
topics
such
as
being
depressed
we
propose
ranking
as
means
of
modeling
rational
adversary
who
targets
the
most
afflicted
users
to
capture
the
adversary
background
knowledge
regarding
vocabulary
and
correlations
we
use
latent
topic
models
we
cast
these
considerations
into
the
new
model
of
r-susceptibility
which
can
inform
and
alert
users
about
their
potential
76
chapter
rank-susceptibility
for
being
targeted
and
devise
measures
for
quantitative
risk
assessment
experiments
with
real-world
data
show
the
feasibility
of
our
approach
6.1
introduction
the
goal
of
this
chapter
is
to
provide
privacy
risk
motivation
and
background
assessments
from
textual
data
for
users
in
online
communities
an
online
post
may
directly
or
indirectly
disclose
personal
information
such
as
gender
age
political
affiliation
or
interests
an
adversary
can
combine
such
observations
with
his
background
knowledge
of
correlations
between
different
attributes
to
infer
privacy-sensitive
information
and
discriminate
against
users
we
argue
that
existing
privacy
models
for
structured
data
such
as
k-anonymity
sweeney
2002b
l-diversity
machanavajjhala
et
al
2007
t-closeness
li
et
al
2007
membership
privacy
li
et
al
2013
and
differential
privacy
dwork
2008
are
inherently
inappropriate
to
capture
these
situations
one
reason
is
that
user
posts
in
social
media
are
mostly
of
textual
form
inducing
high-dimensional
data
space
of
word-level
or
phrase-level
features
second
reason
is
that
users
might
not
want
to
be
prevented
from
posting
contents
but
instead
be
selectively
warned
about
emerging
privacy
risks
in
our
setting
certain
assumptions
also
differ
from
the
assumptions
of
prior
work
on
privacy-preserving
data
publishing
fung
et
al
2010
users
do
want
to
post
information
but
they
should
be
aware
of
possible
exposure
and
targeting
risks
for
these
reasons
we
pursue
an
ir-centric
approach
to
privacy
in
this
chapter
making
novel
use
of
topic
models
and
ranking
scenario
to
understand
why
adversaries
and
user
risks
are
different
from
the
privacy
concerns
for
structured
databases
consider
the
following
scenario
an
unscrupulous
drug
company
wishes
to
advertise
its
new
anxiety-reducing
drug
to
facebook
users
it
decides
to
target
ads
at
million
users
that
are
most
susceptible
to
be
afflicted
by
depression
within
the
billion
population
of
facebook
the
company
plans
to
infer
users
demographics
by
text
mining
their
posts
and
combine
it
with
the
background
knowledge
correlating
demographics
and
certain
vocabulary
usage
with
depression
obtained
from
text
mining
an
archive
of
medical
journals
in
such
scenario
how
can
facebook
user
estimate
her
risk
of
being
targeted
similar
issues
arise
also
within
specialized
online
communities
such
as
healthboards
com
or
patient
co
uk
although
these
have
much
smaller
scale
smart
adversary
would
still
target
only
subset
of
highly
susceptible
users
to
avoid
the
impression
of
mass
spamming
targeted
ads
of
sensitive
nature
constitute
one
kind
of
risk
but
there
are
even
more
severe
threats
with
real
cases
reported
scoring
users
for
financial
credit
worthiness
or
insurance
payments
factoring
user
social-media
posts
in
assessing
her
job
application
and
more
despite
these
being
big
trends
most
users
do
not
need
hard
guarantees
regarding
privacy
preventing
de-anonymization
by
all
means
and
perfect
anonymity
cannot
be
guaranteed
without
severely
diminishing
the
utility
of
social
media
for
example
someone
who
always
posts
using
one-off
anonymous
identity
cannot
build
up
reputation
as
credible
information
source
conversely
even
making
all
posts
under
pseudonym
is
insufficient
to
prevent
tracking-and-rating
companies
www.spokeo.com)
from
linking
6.1
introduction
77
user
accounts
across
different
social
platforms
therefore
we
focus
on
the
assessment
of
privacy
risks
and
on
alerting
users
to
support
their
awareness
rather
than
pursuing
the
elusive
goal
of
enforcing
privacy
existing
privacy
models
fail
to
capture
theses
issues
along
the
following
dimensions
data
model
privacy
models
like
k-anonymity
or
differential
privacy
are
primarily
geared
for
structured
data
or
content
that
can
be
cast
into
low-dimensional
feature
spaces
capturing
risks
from
textual
contents
in
online
communities
faces
the
problem
of
high-dimensional
feature
vectors
word
bigrams
prior
work
that
coped
with
text
in
specific
settings
such
as
predicting
sensitive
posts
peddinti
et
al
2014
sanitizing
the
information
from
query
logs
carpineto
and
romano
2015
navarroarribas
et
al
2012
or
publishing
high-dimensional
datasets
day
and
li
2015
our
goal
on
the
other
hand
is
to
be
able
to
quantify
privacy
risks
from
text
in
generic
way
adversary
background
knowledge
prior
work
on
privacy
assumes
computationally
powerful
adversaries
but
disregards
or
makes
special
assumptions
about
the
background
knowledge
that
an
adversary
may
have
beyond
the
dataset
at
hand
however
adversaries
may
easilly
tap
into
many
datasets
including
large
text
corpora
thus
obtaining
model
of
the
typical
vocabulary
used
by
potential
targets
as
well
as
semantic
dependencies
or
statistical
correlations
between
topics
disclosure
vs
discrimination
risk
existing
privacy
models
focus
on
limiting
information
disclosure
but
they
do
not
capture
the
exposure
within
community
with
regard
to
sensitive
properties
standing
out
in
community
this
way
may
result
in
discriminatory
treatment
such
as
being
rejected
for
loans
or
job
applications
or
receiving
ads
of
sensitive
nature
approach
and
challenges
this
thesis
introduces
r-susceptibility
ranking-based
privacy
risk
model
for
assessing
users
privacy
risks
in
online
communities
accompanied
by
ir-style
risk
measures
for
quantifying
risks
from
textual
contents
the
model
is
very
versatile
in
this
chapter
we
demonstrate
how
it
can
capture
user
posts
or
search
queries
but
it
can
also
be
used
with
click
streams
and
other
online
activities
semantic
dependencies
and
statistical
correlations
among
words
and
sensitive
topics
are
represented
using
latent
topic
models
such
as
lda
blei
et
al
2003
or
skip-grams
mikolov
et
al
2013
this
way
we
anticipate
adversaries
with
rich
background
knowledge
adversaries
are
assumed
to
be
rational
they
target
only
fraction
of
promising
users
therefore
we
model
the
risk
of
user
as
the
ranking
position
in
the
community
when
all
the
users
are
ordered
by
the
relevance
of
their
contents
to
sensitive
topics
such
as
pregnancy
depression
financial
debts
etc
this
ranking-based
model
is
meant
to
alert
the
users
whenever
critical
situations
arise
we
posit
that
users
might
be
then
guided
to
selectively
post
anonymously
our
model
addresses
several
technical
challenges
sensitive
vs
general
topics
trained
latent
topic
model
does
not
indicate
which
of
the
topics
are
privacy-sensitive
we
carried
out
crowdsourcing
study
to
identify
78
chapter
rank-susceptibility
sensitive
topics
our
study
differs
from
the
prior
work
of
peddinti
et
al
2014
as
the
latter
relied
on
explicit
categories
personal
vs
professional
interest
user
who
posts
about
sensitive
topic
may
merely
have
professional
or
educational
interest
without
being
personally
afflicted
to
be
able
to
rank
such
users
lower
our
model
introduces
the
notion
of
topical
breadth
of
interest
complementing
the
user
strength
of
interest
in
sensitive
topic
personal
interest
vs
curiosity
user
may
become
interested
in
topic
out
of
curiosity
perhaps
prompted
by
an
external
event
celebrity
scandal
to
be
able
to
rank
such
non-critical
users
lower
our
model
also
considers
the
temporal
variation
of
interest
in
topic
the
chapter
salient
contributions
are
novel
approach
to
privacy
risks
focusing
on
exposure
in
user
rankings
within
online
communities
and
emphasizing
risk
awareness
framework
for
quantifying
privacy
risks
from
textual
contents
in
online
communities
based
on
latent
topic
models
and
user
rankings
measures
for
computing
risk
scores
with
regard
to
sensitive
topics
based
on
users
posts
or
search
queries
6.2
r-susceptibility
model
6.2
sensitive
states
and
adversaries
we
assess
the
risk
of
user
being
perceived
as
afflicted
by
sensitive
state
such
as
depression
pregnancy
or
financial
debts
an
adversary
in
our
model
attempts
to
find
the
most
susceptible
users
that
is
the
users
who
are
most
exposed
with
regard
to
sensitive
state
for
instance
an
adversarial
insurance
company
might
want
to
identify
the
users
who
are
likely
afflicted
by
certain
diseases
an
adversarial
hr
department
of
company
might
want
to
screen
for
the
users
with
likely
drug
or
alcohol
problems
while
seller
of
illegal
anti-depressants
might
want
to
find
the
users
most
likely
to
be
depressed
and
thus
prospective
customers
we
therefore
propose
ranking
as
means
of
modeling
rational
adversary
trying
to
identify
the
most
susceptible
users
to
rank
the
users
with
respect
to
given
sensitive
state
an
adversary
needs
to
choose
measure
of
quantitative
risk
assessment
based
on
the
contents
of
user
profiles
we
discuss
several
such
measures
in
section
6.3
6.2
sensitive
topics
we
associate
sensitive
states
with
vocabulary
distribution
distributional
vectors
of
related
words
for
example
the
topic
financial
debts
could
be
captured
by
related
words
and
phrases
like
loan
mortgage
money
problem
sorrows
or
sleepless
night
such
salient
phrases
related
to
sensitive
state
can
be
obtained
by
unsupervised
or
semi-supervised
6.3
risk
assessment
measures
79
training
of
latent
topic
models
over
external
datasets
such
as
news
archives
digital
libraries
or
large
crawls
of
social
media
this
way
we
capture
the
adversaries
background
knowledge
about
the
vocabulary
for
topic
and
about
semantic
dependencies
and
correlations
sensitive
states
might
manifest
themselves
in
the
online
contents
of
users
user
posts
can
also
be
characterized
as
distributional
vectors
of
salient
words
then
the
similarity
between
the
distributional
vectors
of
the
user
posts
and
sensitive
topic
can
be
used
to
assess
the
user
susceptibility
to
being
exposed
with
regard
to
that
topic
6.2
background
knowledge
an
adversary
in
our
model
is
assumed
to
be
interested
in
sensitive
state
and
aims
to
target
fraction
of
the
most
afflicted
users
the
adversary
has
background
knowledge
characterized
by
statistical
language
and
topic
models
this
is
natural
form
of
useful
knowledge
for
rational
adversary
who
wants
rank
the
users
based
on
the
textual
contents
and
to
bound
the
cost
of
his
targeting
efforts
in
this
dissertation
we
consider
three
versions
of
adversary
background
knowledge
the
basic
version
is
the
knowledge
of
the
most
salient
words
for
different
topics
which
is
assumed
in
all
the
solutions
we
explore
the
more
advanced
version
assumes
that
the
adversary
is
able
to
compute
similarities
between
words
in
the
sense
of
semantic
relatedness
finally
in
some
of
the
solutions
we
assume
an
adversary
is
able
to
assign
latent
topics
to
broader
thematic
domains
the
topic
of
depression
to
the
domain
of
psychiatry
we
believe
that
this
model
reflects
wide
class
of
adversaries
whose
goal
is
to
discriminate
and
target
the
most
susceptible
users
in
online
communities
6.2
r-susceptibility
we
propose
r-susceptibility
rank-susceptibility
as
measure
of
user
privacy
risk
to
measure
r-susceptibility
with
respect
to
sensitive
topic
we
first
rank
all
users
within
an
online
community
based
on
their
decreasing
susceptibility
of
being
exposed
with
regard
to
sensitive
topic
as
described
above
and
then
compute
the
position
where
the
user
is
ranked
intuitively
the
r-susceptibility
model
could
also
have
the
following
ir
interpretation
we
rank
the
users
according
to
the
relevance
of
their
posts
to
query
containing
the
words
of
sensitive
topic
and
choose
the
top-ranked
who
should
be
the
most
likely
to
be
personally
afflicted
6.3
risk
assessment
measures
risk
measures
are
plug-in
components
in
the
framework
and
orthogonal
to
the
idea
of
r-susceptibility
in
this
dissertation
we
begin
by
investigating
three
kinds
of
risk
scores
leaving
an
extended
risk-measure
study
as
future
work
the
first
two
of
the
risk
scores
are
baselines
inspired
by
standard
measures
in
privacy
research
namely
the
entropy
of
attribute
value
distributions
as
used
in
the
t-closeness
model
and
the
changes
in
the
global
probability
distributions
of
attribute
values
incurred
by
the
inclusion
of
an
individual
user
data
as
used
in
the
differential
privacy
model
the
80
chapter
rank-susceptibility
third
measure
is
novel
ir-centric
score
based
on
topic
models
capturing
lexical
correlations
and
three
different
characteristics
of
user
interest
in
topic
the
strength
of
interest
the
breadth
of
interest
and
the
temporal
variation
of
interest
desired
properties
by
considering
the
community
and
interpreting
risk
with
respect
to
user
rank
in
the
community
our
framework
does
not
impose
any
restrictions
on
the
absolute
values
or
the
value
domains
of
valid
risk
measures
intuitively
for
the
framework
to
function
we
expect
good
measure
to
correlate
with
human
assessments
on
the
sensitivity
of
user
profiles
the
more
human
observers
agree
that
user
might
be
in
sensitive
state
the
higher
the
value
of
the
risk
score
should
be
6.3
entropy
baseline
measure
the
entropy
baseline
measure
is
inspired
by
comparing
global
probability
distribution
for
an
entire
community
against
local
distribution
for
an
individual
user
using
relative
entropy
aka
kl
divergence
we
apply
this
measure
to
textual
data
as
follows
let
be
sensitive
topic
and
x1
xj
be
the
salient
words
and
phrases
of
the
knowledge
of
this
vocabulary
for
different
topics
is
assumed
to
be
part
of
the
adversarial
background
knowledge
derived
from
latent
topic
models
we
treat
x1
xj
as
database
attributes
and
represent
users
as
database
records
where
the
value
of
an
attribute
xi
equals
to
if
the
word
appears
in
the
user
contents
and
to
otherwise
let
u0
be
the
user
for
whom
we
wish
to
compute
the
risk
score
with
respect
to
and
u1
uk
be
the
set
of
other
users
in
the
community
let
further
be
u0
and
let
pu
pu
denote
the
distributions
of
attribute
values
for
and
respectively
we
compute
the
risk
score
by
averaging
the
relative
entropy
of
the
univariate
distributions
pu
pu
for
the
individual
attributes
x1
xj
note
that
measuring
the
relative
entropy
over
the
multivariate
joint
distributions
of
attributes
could
be
an
alternative
but
we
do
not
pursue
this
here
because
of
the
data
sparseness
that
we
would
face
definition
entropy
baseline
risk
score
of
topic
for
u0
the
entropy
baseline
risk
score
of
the
user
u0
with
respect
to
topic
is
riskent
u0
1x
pu
xi
pu
xi
log
pu
xi
6.1
the
ranking
method
based
on
this
definition
is
being
referred
to
as
ent
measure
properties
it
holds
that
riskent
u0
the
lowest
value
of
is
reached
when
the
user
does
not
have
any
of
the
topic
salient
attributes
in
her
observable
contents
otherwise
the
risk
score
is
lowest
when
half
of
the
community
users
exhibit
an
attribute
in
their
contents
and
highest
when
all
or
none
of
the
users
have
the
attribute
6.3
differential-privacy
baseline
measure
the
differential-privacy-based
measure
is
inspired
by
the
definition
of
differential
privacy
that
is
calculating
the
changes
of
attribute
probabilities
incurred
by
the
inclusion
of
user
6.3
risk
assessment
measures
81
data
let
x1
xj
u0
pu
and
pu
be
defined
as
in
the
previous
section
the
differential
privacy
principle
requires
that
pu
xi
2ε
pu
xi
and
pu
xi
2ε
pu
xi
6.2
for
small
to
give
an
ε-differential-privacy
guarantee
existing
methods
would
perturb
the
data
by
laplacian
noise
if
the
inequalities
are
not
already
satisfied
however
our
attributes
are
words
in
user
posts
that
the
user
intentionally
chose
and
our
goal
is
to
quantify
risk
rather
than
perturb
the
data
we
thus
aim
to
determine
the
best
possible
value
of
for
which
the
guarantee
holds
without
perturbation
this
is
the
minimum
for
each
xi
but
the
guarantee
is
only
as
strong
as
the
weakest
xi
leading
to
the
following
formulation
definition
differential-privacy
baseline
risk
score
of
topic
for
u0
the
differentialprivacy
baseline
risk
score
of
the
user
u0
with
respect
to
topic
is
pu
xi
pu
xi
riskd-p
u0
max
max
log
log
6.3
xi
pu
xi
pu
xi
the
ranking
method
based
on
this
definition
is
being
referred
to
as
diff-priv
measure
properties
it
holds
that
riskd-p
u0
the
risk
value
is
lowest
for
user
who
does
not
have
any
of
the
sensitive
topic
salient
attributes
in
her
contents
and
highest
for
user
who
has
critical
attribute
that
is
not
present
in
the
contents
of
any
other
user
6.3
topical
risk
measure
to
this
end
we
construct
distributional
representation
of
each
of
the
sensitive
topics
financial
debts
user
contents
from
an
online
community
such
as
quora
com
and
each
post
the
user
authors
in
the
online
community
we
model
and
as
vectors
in
distributional
vector
space
6.3
3.1
distributional
vectors
for
topics
and
users
topic
vectors
topics
are
represented
as
vocabulary
distributions
found
by
collecting
word
statistics
over
suitably
chosen
corpora
definition
sensitive
topic
vector
for
sensitive
topic
the
topic
vector
is
distribu
constructed
using
words
or
bigrams
weighted
by
topic
relevance
tional
vector
for
example
hiv
and
positive
are
salient
for
the
topic
of
hiv
infection
such
topics
and
their
salient
phrases
can
be
automatically
extracted
by
applying
latent
topic
analysis
to
large
thematically
broad
text
corpora
user
vectors
to
be
able
to
relate
posts
and
users
to
topics
we
map
each
user
and
post
created
by
the
user
in
an
online
community
to
vector
82
chapter
rank-susceptibility
definition
user
post
and
user
vectors
the
content
of
post
of
user
is
modeled
as
distributional
vector
user
in
the
context
of
topic
is
modeled
as
distributional
defined
as
vector
max
cos
6.4
vector
construction
the
exact
mapping
of
topics
and
posts
to
vectors
depends
on
the
vector
space
in
which
we
are
operating
we
use
three
different
configurations
in
our
experiments
bag-of-words
model
bow
ii
an
lda
model
lda
and
iii
skip-gram
model
w2v
note
that
the
use
of
lda
here
is
to
construct
lower-dimensional
vector
space
this
is
orthogonal
to
using
lda
for
obtaining
topics
with
their
salient
phrases
which
we
discussed
above
in
the
bow
vector
space
we
create
topic
vectors
directly
over
the
characteristic
topic
words
with
binary
scoring
we
also
use
these
words
as
features
with
tf-scoring
for
user
and
post
vectors
in
the
lda
model
topic
vectors
are
indicator
vectors
of
for
the
latent
dimensions
users
and
posts
are
treated
as
documents
that
lda
maps
into
its
low-dimensional
latent
space
the
third
technique
that
we
consider
w2v
is
model
based
on
learning
word
relatedness
which
can
be
trained
over
large
text
corpora
mikolov
et
al
2013
to
create
the
topic
vectors
in
this
word-centric
vector
space
we
compute
weighted
sum
of
words
from
the
previously
computed
sensitive
topic
distributions
since
there
is
no
natural
mapping
of
documents
to
vectors
in
this
setting
the
procedure
for
posts
is
similar
however
to
discount
the
impact
of
words
unrelated
to
the
topics
at
hand
we
introduce
topic-dependent
weighting
scheme
for
user
vectors
namely
for
topic
and
post
containing
the
set
of
words
v1
v2
the
post
vector
is
cos
risk
scoring
given
these
vectors
we
can
now
compare
user
posting
history
against
sensitive
topic
by
vector-based
similarity
measures
like
the
cosine
similarity
an
advantage
of
this
risk
measure
is
that
unlike
the
entropy
or
diff-priv
measures
it
does
not
require
any
community-level
data
as
the
risk
score
of
user
is
independent
of
other
users
data
thus
each
user
can
compute
her
score
locally
and
privately
and
send
the
value
to
server
to
obtain
an
r-susceptibility
rank
in
addition
to
quantifying
the
strength
of
user
interest
in
sensitive
topic
we
also
capture
the
breadth
and
temporal
variation
of
that
interest
this
is
crucial
to
avoid
erroneously
ranking
higher
those
users
who
have
professional
interest
in
topic
without
being
personally
afflicted
or
are
temporarily
interested
out
of
curiosity
in
our
previous
preliminary
work
in
this
area
we
identified
these
two
components
to
be
crucial
for
reducing
classification
error
in
similar
setup
biega
et
al
2014
6.3
risk
assessment
measures
6.3
3.2
83
strength
of
interest
having
vector
representation
of
user
we
can
now
compute
the
similarity
between
and
topic
vector
definition
topic-aware
risk
score
the
strength-of-interest
risk
score
for
user
with
respect
to
topic
is
risk
cos
6.5
we
further
refer
to
methods
based
on
this
definition
as
bow
lda
and
w2v
measure
properties
it
holds
that
risk
high
value
of
this
measure
means
the
user
has
at
least
one
post
with
vocabulary
related
to
the
topic
thus
the
strength
of
interest
is
reflected
by
the
presence
of
the
topic
salient
vocabulary
in
user
posts
6.3
3.3
breadth
of
interest
when
ranking
users
an
adversary
might
want
to
distinguish
between
users
who
show
focused
interest
in
topic
and
users
who
show
broad
interest
in
many
topics
within
domain
ranking
the
former
higher
than
the
latter
applying
this
strategy
could
help
for
instance
to
capture
users
who
are
not
personally
afflicted
but
rather
showing
educational
hobbyist
or
professional
interest
in
topic
for
example
for
the
topic
of
financial
debts
bank
agent
or
finance
hobbyist
could
offer
advice
in
communities
similarly
medical
doctor
or
student
could
engage
herself
in
health
forums
the
posts
of
user
with
broad
interest
should
exhibit
diversity
of
topics
within
their
respective
domain
we
aim
to
capture
this
behavior
by
means
of
distributional
vectors
assigning
each
topic
to
broader
domain
like
finance
medicine
psychology
etc
definition
domain
vectors
domain
is
set
of
topics
x1
and
its
vector
representation
is
set
of
corresponding
topic
vectors
to
assess
the
risk
taking
into
account
whether
user
has
focused
or
broad
interest
in
topic
we
compute
is
to
and
how
similar
is
to
the
domain
by
computing
the
distances
between
and
how
dissimilar
for
and
taking
the
dk
e-th
largest
value
for
some
if
both
of
these
measures
are
high
then
we
conclude
that
is
personally
afflicted
by
topic
definition
domain-aware
risk
score
the
domain-aware
risk
score
for
user
with
respect
to
topic
from
the
domain
is
maxdk
cos
riskd
cos
6.6
we
further
refer
to
methods
based
on
this
definition
as
bow-d
lda-d
and
w2v-d
84
chapter
rank-susceptibility
measure
properties
it
holds
that
riskd
the
value
would
be
high
for
user
who
has
post
containing
topic
salient
vocabulary
but
whose
contents
do
not
exhibit
any
vocabulary
from
other
topics
in
the
respective
domain
low
value
occurs
in
situation
where
the
user
has
not
written
any
posts
related
to
the
topic
at
hand
but
has
contents
related
to
other
topics
in
the
domain
studying
the
relative
importance
of
the
two
components
in
different
online
communities
is
an
interesting
topic
of
future
work
the
intuition
for
parameter
is
that
personally
afflicted
user
would
not
have
high
posting
activities
in
k-fraction
of
different
topics
within
the
same
domain
the
value
of
the
parameter
controls
how
large
the
domain
coverage
should
be
for
the
users
to
be
considered
broadly
interested
in
practice
setting
this
parameter
requires
the
knowledge
of
the
breadth
of
topics
discussed
in
particular
community
6.3
3.4
temporal
variation
of
interest
being
interested
in
users
most
likely
afflicted
by
given
state
we
would
like
to
rank
the
users
who
exhibit
recurring
activity
regarding
topic
higher
than
the
non-afflicted
possibly
curious
or
exploratory
users
exhibiting
short-term
interest
in
the
topic
such
bursty
activity
might
be
prompted
by
prominent
news
related
to
be
it
sex
scandals
in
the
press
or
social
campaigns
about
depression
over
the
entire
user
history
to
capture
this
issue
rather
than
computing
user
vector
using
the
we
divide
the
history
into
time
buckets
and
compute
sequence
of
vectors
contents
from
each
bucket
separately
in
our
model
bucketization
may
be
realized
at
different
granularity
levels
depending
on
the
user
observation
period
and
the
characteristics
of
the
community
we
then
identify
the
top-m
time
buckets
with
the
highest
risk
level
representing
different
time
periods
such
as
days
or
weeks
let
us
denote
these
buckets
of
the
user
model
as
u1
um
user
whose
interest
in
is
clearly
above
the
level
of
bursty
interest
signifying
occasional
curiosity
would
consistently
have
high
risk
scores
in
all
of
the
top-m
buckets
this
leads
us
to
our
next
definition
of
user
privacy
risk
regarding
topic
definition
10
time-aware
risk
score
the
time-aware
risk
score
for
user
in
time
period
with
respect
to
topic
is
riskt
avgi
cos
6.7
we
further
refer
to
methods
based
on
this
definition
as
bow-t
lda-t
and
w2v-t
measure
properties
it
holds
that
riskt
the
value
would
be
high
for
user
whose
posts
contain
relevant
topic
vocabulary
in
at
least
observation
buckets
and
low
for
user
who
does
not
exhibit
topic
vocabulary
in
their
contents
the
choice
of
particular
value
of
the
parameter
depends
on
the
available
observation
timeline
and
the
characteristics
of
given
community
the
parameter
controls
how
often
the
activity
regarding
topic
should
occur
in
order
to
not
be
considered
occasional
6.4
identifying
sensitive
topics
6.3
3.5
85
combining
domain
and
time-awareness
the
final
measure
we
introduce
combines
all
the
aforementioned
dimensions
of
interest
note
that
we
use
bucketized
user
contents
for
computing
the
temporal
variation
component
but
the
breadth-of-interest
component
is
computed
over
the
full
contents
definition
11
domain
and
time-aware
risk
score
the
risk
of
user
in
time
period
for
topic
in
domain
is
riskdt
avgi
cos
cos
6.8
we
further
refer
to
methods
based
on
this
definition
as
bow-dt
lda-dt
and
w2v-dt
6.4
identifying
sensitive
topics
to
complete
our
framework
we
need
to
train
background
knowledge
model
and
answer
the
remaining
question
of
how
to
identify
sensitive
topics
although
our
model
is
applicable
to
any
topic
irrespective
of
its
sensitivity
in
practice
users
would
only
be
interested
in
their
r-susceptibility
ranks
for
truly
sensitive
topics
there
is
indeed
systematic
way
of
gathering
such
information
in
reasonably
inter-subjective
manner
training
latent
topic
model
on
background
corpus
and
crowdsourcing
sensitivity
judgments
for
each
topic
this
section
presents
our
results
along
these
lines
6.4
experiments
on
topic
sensitivity
datasets
we
trained
lda
models
using
the
mallet
topic
modeling
toolkit
with
500
topics
on
600k
quora
posts
we
crawled
ii
with
200
topics
on
3m
posts
from
health
online
forums
and
iii
with
500
topics
on
sample
of
700k
articles
from
the
new
york
times
nyt
news
archive
crowdsourcing
sensitivity
and
domain
judgements
we
collected
human
judgements
regarding
the
sensitivity
and
the
domains
of
topics
using
amazon
mechanical
turk
amt
employing
only
master
workers
from
the
usa
and
collecting
judgements
per
topic
for
each
of
the
topics
the
workers
were
shown
the
20
most
salient
words
computed
by
lda
and
asked
whether
they
would
consider
post
in
social
media
containing
these
words
privacy-sensitive
we
explained
that
by
privacy-sensitive
we
mean
that
person
uses
these
words
because
he
she
is
in
privacy-sensitive
situation
alcohol
addicted
or
that
the
usage
of
these
words
might
lead
to
privacy-sensitive
situation
political
extremism
the
first
condition
can
capture
for
instance
words
related
to
diseases
the
second
can
capture
words
related
to
political
or
religious
positions
we
computed
fleiss
kappa
to
measure
the
inter-annotator
agreement
for
this
task
obtaining
0.241
for
the
quora
topics
0.294
for
the
hf
topics
and
0.157
for
the
nyt
topics
these
low
values
confirm
that
sensitivity
is
rather
subjective
however
there
is
considerable
number
of
topics
in
all
of
these
corpora
which
were
unanimously
or
almost
unanimously
rated
as
sensitive
these
were
mostly
related
to
health
private
relationships
86
chapter
rank-susceptibility
judges
topics
quora
topics
nyt
topics
hf
29
43
48
56
68
99
106
51
27
60
84
73
90
111
47
38
32
30
21
22
28
23
table
6.1
topics
with
judges
agreeing
on
the
topic
being
sensitive
topic
clinical
depression
drug
addiction
pregnancy
hiv
and
viral
diseases
financial
debts
vocabulary
depression
depress
suicide
feel
depressed
suffer
suicidal
commit
drug
addiction
addict
cocaine
heroin
substance
meth
addictive
baby
birth
pregnancy
pregnant
mother
woman
born
child
hiv
disease
aids
virus
spread
infection
cure
vaccine
debt
loan
pay
student
interest
payment
money
owe
table
6.2
examples
vocabulary
of
sensitive
topics
political
and
religious
convictions
personal
finance
legal
problems
and
others
table
6.1
shows
the
numbers
of
topics
on
which
certain
numbers
of
judges
agree
on
their
sensitivity
the
judges
were
also
asked
to
assign
topic
to
one
of
seven
high-level
categories
six
of
these
potentially
containing
some
sensitive
topics
were
chosen
based
on
the
top-level
microsoft
academic
search
categories
the
annotators
could
also
choose
generic
category
other
topics
for
evaluation
in
section
6.5
for
our
further
experiments
to
make
the
much
more
laborious
and
costly
evaluation
of
user
profiles
feasible
we
leverage
the
above
study
to
restrict
the
evaluation
to
topics
from
the
group
of
the
most
sensitive
topics
the
choice
of
particular
topics
is
guided
by
the
reported
cases
of
social
media
screening
by
insurance
companies
employers
and
credit
companies
mentioned
in
section
7.1
these
are
clinical
depression
drug
addiction
hiv
pregnancy
and
financial
debts
assigned
to
the
domains
of
psychology
medicine
and
finance
economy
table
6.2
shows
the
most
prominent
words
for
each
of
the
chosen
topics
from
the
quora
topic
model
6.5
experiments
6.5
experiments
6.5
setup
6.5
1.1
data
sources
87
to
test
our
methods
in
variety
of
scenarios
we
constructed
three
datasets
using
online
communitites
of
different
nature
as
first
data
source
we
used
the
aol
query
log
collected
between
march
and
may
2006
the
resulting
data
source
amounts
to
around
107k
users
and
more
than
13m
queries
the
second
data
source
consisted
of
over
5m
posts
spanning
13
years
2000
2013
from
healthboards
and
ehealthforum
health
communities
we
also
collected
data
from
the
quora
community
over
period
of
three
months
between
february
and
may
2015
the
crawl
focused
on
quora
users
who
were
active
in
categories
related
to
the
considered
sensitive
topics
and
their
domains
and
comprised
more
than
200k
users
and
3m
posts
ethics
to
adhere
to
ethical
standards
concerning
incorporation
of
user
data
into
research
we
decided
to
only
use
data
that
is
publicly
available
either
as
online
profiles
quora
health
or
as
datasets
used
in
numerous
other
studies
aol
we
never
attempted
to
identify
the
individuals
whose
profiles
we
analyzed
6.5
1.2
user
sampling
we
created
our
datasets
by
sampling
the
users
from
the
data
sources
described
above
however
we
encounter
technical
challenge
as
the
number
of
sensitive
users
for
given
topic
is
very
small
when
compared
to
the
size
of
the
whole
community
sampling
users
uniformly
would
not
constitute
good
benchmark
for
risk
scoring
methods
for
example
we
could
achieve
high
accuracy
in
misleading
way
by
the
simplistic
prediction
that
all
users
are
non-sensitive
what
we
want
though
is
ranking
evaluation
our
goal
is
to
see
how
sensitive
the
users
are
in
different
ranking
regions
therefore
our
sampling
method
is
non-uniform
and
proceeds
as
follows
we
first
rank
all
users
for
each
of
the
datasets
using
our
basic
strength-of-interest
method
from
section
6.3
3.2
and
then
sample
users
from
this
ranking
to
pick
user
the
sampling
procedure
orders
users
by
their
score
then
computes
prefix
sums
σi
for
all
users
up
to
user
with
σn
being
the
score
sum
for
all
users
then
we
draw
random
number
between
and
σn
if
the
number
falls
between
σi
and
σi
we
choose
user
with
users
numbered
from
to
however
given
that
risk
scores
are
extremely
skewed
this
sampling
does
still
not
yield
good
coverage
of
all
the
ranking
regions
therefore
we
transform
the
original
risk
score
into
aq
where
constant
needs
to
be
determined
based
on
the
score
skew
in
data
source
the
intuition
is
to
give
higher
probability
of
being
sampled
to
users
with
higher
scores
so
that
the
final
sample
set
has
good
coverage
of
users
with
both
high
and
low
scores
figure
6.1
depicts
the
depression
risk
scores
of
our
100
samples
from
the
aol
data
vs
the
scores
of
the
original
dataset
of
170k
users
in
our
case
value
of
102
for
the
health
and
value
of
103
for
the
aol
were
reasonable
to
compensate
the
skew
for
each
of
these
datasets
we
sampled
100
users
88
chapter
rank-susceptibility
figure
6.1
example
comparison
of
risk
scores
of
sample
vs
full
data
for
each
sensitive
topic
we
did
not
perform
this
kind
of
sampling
for
quora
as
our
dataset
was
based
on
focused
crawl
in
the
first
place
with
focus
on
sensitive
discussion
threads
since
evaluating
sizeable
quora
profiles
requires
much
more
effort
for
this
data
source
we
constructed
smaller
datasets
with
40
users
per
topic
in
total
our
datasets
comprised
1100
user
profiles
personal
histories
of
posts
or
queries
6.5
1.3
user
study
for
ground-truth
labels
to
assign
sensitivity
labels
for
user-topic
pairs
as
ground
truth
we
used
crowdsourcing
and
asked
human
judges
to
examine
user
profiles
with
chronologically
ordered
textual
posts
specifically
we
asked
whether
based
on
the
content
of
the
profile
the
judge
suspects
that
the
user
or
family
member
is
in
given
sensitive
state
to
evaluate
the
aol
and
health
datasets
we
employed
amt
master
workers
from
the
usa
and
collected
judgements
for
each
of
the
profiles
since
the
majority
of
quora
profiles
contain
hundreds
of
posts
to
ensure
that
proper
care
is
given
to
evaluating
them
we
collected
the
judgements
employing
19
students
from
our
institution
we
computed
fleiss
kappa
to
quantify
the
global
inter-annotator
agreement
across
all
the
topics
the
respective
values
for
the
aol
health
forums
and
quora
datasets
were
0.442
0.444
and
0.468
respectively
all
corresponding
to
moderate
agreement
table
6.3
shows
the
number
of
users
who
were
marked
by
the
human
judges
as
sensitive
by
majority
vote
6.5
experiments
89
aol
hf
quora
depression
drugs
pregnancy
hiv
debts
24
22
15
14
24
42
31
42
19
20
11
21
11
total
99
500
134
400
68
200
table
6.3
number
of
sensitive
users
according
to
judges
assessments
means
sensitive
users
out
of
in
total
6.5
1.4
configuration
of
methods
to
evaluate
the
topic-model-based
method
we
used
three
different
distributional
vector
spaces
bag-of-word
vector
space
as
well
as
two
500
dimensional
vector
spaces
trained
with
the
lda
implementation
from
the
mallet
toolkit
mccallum
2002
and
ii
word2vec1
tool
mikolov
et
al
2013
the
latter
two
models
were
trained
on
nyt
and
quora
corpora
described
in
section
6.4
in
the
breadth-of-interest
model
from
section
6.3
3.3
we
set
the
parameter
to
0.3
we
want
user
of
broad
interest
in
domain
to
have
at
least
30
coverage
of
topics
from
the
domain
in
the
temporal-variance-of-interest
models
described
in
section
6.3
3.4
we
compute
the
results
using
weekly
time
buckets
and
set
the
number
of
buckets
parameter
to
we
later
analyze
the
robustness
of
the
ranking
methods
with
respect
to
these
parameters
6.5
1.5
ranking
effectiveness
metrics
r-precision
for
given
sensitive
topic
where
users
were
identified
by
the
judges
as
sensitive
we
compute
the
precision
when
computing
the
average
precision
over
all
sensitive
topics
we
report
both
micro
and
macro
average
scores
summing
over
individual
samples
and
summing
over
topic
precisions
respectively
to
apply
this
measure
for
each
of
the
profiles
we
have
to
cast
the
five
collected
judgements
to
binary
score
we
assume
that
an
average
of
more
than
0.5
classifies
user
as
sensitive
note
that
r-precision
imitates
an
adversary
who
for
instance
knowing
that
of
the
population
is
depressed
ranks
the
users
according
to
depression-risk
measure
and
chooses
the
top
of
the
users
for
further
investigation
mean
average
precision
map
for
given
sensitive
topic
we
compute
the
average
precision
computed
at
the
ranking
positions
of
sensitive
users
normalized
discounted
cumulative
gain
ndcg
to
asses
the
effectiveness
of
our
methods
using
the
actual
non-binary
judge
assessments
we
employ
ndcg
which
compares
the
rankings
our
methods
yield
with
perfect
ranking
obtained
using
the
crowdsourced
scores
https://code.google.com/p/word2vec/
90
6.5
1.6
chapter
rank-susceptibility
significance
testing
the
number
of
topics
in
our
experiments
is
too
small
to
perform
significance
tests
over
macroaveraged
metrics
we
thus
resort
to
performing
paired
t-test
over
r-precision
differences
on
individual
test
samples
within
dataset
marking
the
significance
in
the
micro-averaged
r-precision
columns
in
the
result
tables
the
symbols
denote
the
case
when
the
gain
of
given
ranking
method
over
the
baseline
ent
and
diff-priv
in
table
6.4
strength-of-interest
baselines
in
table
6.5
is
statistically
significant
with
p-value
0.05
this
lets
us
conclude
that
good
r-precision
score
of
ranking
method
does
not
likely
depend
on
the
particular
choice
of
user
profiles
6.5
1.7
research
questions
the
remainder
of
the
experimental
section
seeks
to
answer
the
following
research
questions
rq
do
the
proposed
topical
risk
measures
perform
better
than
the
entropy
and
diff-priv
methods
in
predicting
human
risk
judgements
sec
6.5
rq
does
the
topical
risk
scoring
measure
perform
better
when
extended
with
the
breadth
and
temporal
dimensions
of
user
interest
sec
6.5
rq
how
robust
is
the
proposed
method
against
changes
in
the
parameter
configuration
and
the
background
knowledge
of
the
adversary
sec
6.5
6.5
traditional
vs
ir
risk
scoring
we
begin
the
risk
scoring
methods
analysis
by
comparing
the
effectiveness
of
the
baseline
entropy
diff-priv
and
the
strength-of-interest
topical
risk
scoring
methods
here
we
choose
the
baseline
ir-based
methods
for
comparison
while
exteding
the
measures
with
dimensions
of
interest
will
be
addressed
in
the
sections
to
follow
table
6.4
shows
that
the
lda
risk
scoring
outperforms
the
alternatives
similar
observation
holds
for
w2v
which
confirms
that
these
methods
are
not
naturally
applicable
to
textual
data
in
the
context
of
risk
scoring
the
relatively
good
precision
of
these
measures
indicates
that
the
most
sensitive
users
tend
to
use
highly
salient
words
however
operating
on
explicitly
given
salient
attributes
for
each
topic
the
baseline
measures
do
not
capture
any
lexical
correlations
an
important
prerequisite
to
capture
users
manifesting
their
sensitivity
in
less
direct
way
this
result
validates
the
need
to
design
new
privacy
risk
measures
better
tuned
to
textual
contents
6.5
risk
scoring
with
dimensions
of
interest
we
posited
that
extending
the
topical
risk
measures
with
the
breadth
and
the
temporalvariation
dimensions
of
interest
can
help
to
predict
sensitivity
judgements
better
table
6.5
shows
the
evaluation
results
averaged
over
all
topics
confirming
that
incorporating
breadth
and
temporal
variation
into
the
risk
score
indeed
improves
the
ranking
performance
we
observe
that
breadth-of-interest
is
especially
important
for
quora
which
is
community
with
very
wide
variety
of
topics
many
quora
users
seem
to
frequently
post
6.5
experiments
91
r-precision
micro
macro
entropy
diff-priv
w2v
entropy
diff-priv
w2v
entropy
diff-priv
w2v
0.495
0.475
0.556
prec
map
ndcg
aol
0.496
0.760
0.465
0.480
0.533
0.720
0.524
0.492
0.589
0.819
0.789
0.836
0.613
0.542
0.696
0.870
0.794
0.894
0.317
0.310
0.352
0.632
0.623
0.637
health
forums
0.560
0.537
0.750
0.560
0.559
0.500
0.664
0.634
0.750
quora
0.239
0.205
0.240
0.239
0.223
0.200
0.343
0.341
0.280
table
6.4
average
metrics
over
all
sensitive
topics
for
different
risk
assessment
measures
replies
prompted
by
others
rather
than
by
their
personal
situation
hence
the
lower
impact
of
the
temporal
component
contrary
in
aol
the
temporal
component
takes
over
with
merely
implicit
cues
in
the
form
of
queries
the
temporal
dimension
is
an
important
indicator
of
user
sensitivity
also
for
the
annotators
the
breadth-of-interest
component
performs
worse
for
aol
possibly
due
to
the
short
time
span
of
the
query
log
months
note
that
in
case
of
the
proposed
breadth-of-interest
score
an
underlying
assumption
is
that
an
adversary
is
able
to
assign
latent
topics
to
broader
thematic
domains
thus
the
best
performing
dt
methods
imply
stronger
background
knowledge
of
an
adversary
risk
scoring
for
different
topics
table
6.6
shows
the
values
of
r-precisions
split
by
the
topic
for
different
variants
of
lda-based
risk
scoring
the
trends
observed
in
the
results
averaged
over
all
topics
can
be
seen
here
as
well
there
are
consistent
improvements
across
topics
when
incorporating
the
temporal
and
breadth
dimensions
these
results
constitute
anecdotal
evidence
that
the
proposed
methods
are
general
enough
to
be
potentially
applied
to
variety
of
topics
6.5
robustness
to
configuration
changes
model
changes
the
bow
vector
space
models
only
an
adversarial
knowledge
of
salient
words
for
different
topics
whereas
the
latent
vector
spaces
additionally
enable
an
adversary
to
compute
similarities
between
arbitrary
words
the
results
presented
in
table
6.5
show
that
this
has
direct
consequence
in
the
risk
ranking
performance
the
methods
with
the
latent
models
as
the
background
knowledge
outperform
the
methods
with
the
bow
background
knowledge
while
being
comparable
with
each
other
thus
the
model
seems
resilient
to
rational
background
knowledge
model
changes
capturing
wide
class
of
adversaries
the
rational
cost-aware
adversaries
adopting
latent
models
92
chapter
rank-susceptibility
training
corpus
changes
the
results
presented
in
the
experimental
section
were
obtained
using
the
quora
topic
model
as
the
background
knowledge
model
we
ran
additional
experiments
using
the
nyt
topic
model
described
in
section
6.4
and
noticed
that
for
the
topics
which
were
captured
in
the
other
latent
model
as
well
we
observe
similar
trends
and
dependencies
in
the
results
this
would
suggest
that
an
adversary
has
the
freedom
to
choose
among
the
inputs
where
his
topics
of
interest
are
well
captured
parameter
changes
in
risk
measures
the
topical
risk
measures
introduce
two
parameters
for
coverage
of
domain
topics
and
for
the
number
of
weekly
time
buckets
observing
the
values
of
r-precision
and
ndcg
obtained
when
varying
these
parameters
between
0.1
0.2
1.0
and
12
yields
the
following
observations
first
when
the
parameters
are
set
to
values
from
the
lower
half
of
the
ranges
we
still
observe
improvements
over
the
baseline
strength-of-interest
measure
second
when
the
parameters
are
set
to
higher
values
the
results
tend
to
deteriorate
possibly
due
to
the
incompleteness
of
user
profiles
in
our
datasets
third
we
observe
higher
sensitivity
to
parameters
when
given
dimension
of
interest
is
important
for
given
community
temporal
for
aol
breadth
for
quora
this
result
suggests
that
there
is
room
for
improvement
within
the
framework
of
r-susceptibility
in
that
community-specific
risk
measures
could
be
employed
6.5
discussion
the
presented
experimental
results
suggest
that
r-susceptibility
with
appropriate
risk
measures
is
able
to
identify
sensitive
users
with
reasonable
accuracy
the
topical
risk
measures
that
quantify
user
exposure
with
respect
to
different
topics
work
well
especially
when
the
domain
and
time-awareness
components
are
included
the
r-susceptibility
framework
allows
the
plugging
of
different
risk
measures
and
in
the
future
more
advanced
measures
could
be
studied
to
address
some
of
the
limitations
of
this
work
these
could
for
instance
model
semi-experts
subtle
vocabulary
correlations
user
contexts
or
specific
characteristics
of
community
6.5
5.1
user
guidance
the
r-susceptibility
model
and
risk
measures
can
work
on
user
history
in
streaming
manner
considering
all
contents
up
to
given
point
and
periodically
or
continuously
repeating
the
risk
assessment
these
methods
could
also
be
embedded
in
privacy
advisor
tool
that
would
help
users
assess
their
privacy
risk
raising
an
alert
when
they
become
too
exposed
with
regard
to
sensitive
topic
6.5
5.2
possible
countermeasures
by
the
platform
to
prevent
the
risks
describe
in
this
chapter
the
platform
could
prevent
displaying
the
results
related
to
certain
sensitive
topics
however
countermeasure
like
this
could
also
be
considered
as
censorship
middle-ground
approach
might
be
then
for
the
platform
to
allow
the
users
to
select
the
topics
for
which
they
do
not
wish
to
be
ranked
bow
bow-d
bow-t
bow-dt
w2v
w2v-d
w2v-t
w2v-dt
lda
lda-d
lda-t
lda-dt
macro
0.420
0.358
0.546
0.372
0.533
0.395
0.580
0.530
0.518
0.563
0.567
0.616
0.434
0.364
0.556
0.374
0.556
0.414
0.586
0.545
0.525
0.566
0.576
0.616
r-prec
micro
0.759
0.700
0.843
0.758
0.836
0.738
0.859
0.860
0.796
0.803
0.879
0.859
ndcg
0.642
0.612
0.582
0.612
0.664
0.642
0.619
0.687
0.649
0.716
0.709
0.716
micro
0.625
0.580
0.574
0.597
0.634
0.600
0.616
0.678
0.636
0.703
0.704
0.709
macro
r-prec
0.620
0.610
0.619
0.667
0.696
0.647
0.643
0.768
0.724
0.772
0.748
0.825
map
health
forums
0.833
0.832
0.873
0.894
0.894
0.874
0.884
0.939
0.913
0.921
0.925
0.957
ndcg
0.262
0.398
0.285
0.444
0.341
0.465
0.312
0.434
0.362
0.485
0.264
0.389
0.319
0.400
0.317
0.440
0.352
0.532
0.401
0.489
0.428
0.489
0.378
0.481
map
quora
macro
r-prec
micro
0.284
0.418
0.284
0.463
0.343
0.493
0.313
0.463
0.358
0.493
0.299
0.418
table
6.5
results
averaged
over
all
sensitive
topics
0.459
0.394
0.574
0.441
0.589
0.427
0.645
0.601
0.557
0.557
0.655
0.649
map
aol
0.605
0.672
0.605
0.688
0.637
0.776
0.695
0.763
0.715
0.752
0.669
0.751
ndcg
6.5
experiments
93
94
6.6
chapter
rank-susceptibility
related
work
data-centric
privacy
methods
for
privacy-preserving
data
publishing
fung
et
al
2010
aim
at
preventing
the
disclosure
of
individuals
sensitive
attribute
values
while
maintaining
data
utility
for
data
mining
bertino
et
al
2008
using
concepts
like
k-anonymity
sweeney
2002b
l-diversity
machanavajjhala
et
al
2007
t-closeness
li
et
al
2007
and
membership
privacy
li
et
al
2013
all
these
models
are
geared
for
and
limited
to
dealing
with
structured
data
and
this
holds
also
for
the
most
powerful
and
versatile
privacy
model
differential
privacy
dwork
2008
in
the
field
of
private
information
retrieval
the
goal
of
retrieving
data
from
database
without
revealing
the
query
is
mainly
addressed
by
query
encryption
or
obfuscation
yekhanin
2010
generating
dummy
queries
to
obscure
user
activity
is
another
technique
studied
in
this
area
pang
et
al
2012
sensitivity
prediction
there
is
little
research
on
characterizing
what
constitutes
sensitive
topic
the
recent
work
of
peddinti
et
al
2014
analyzed
features
of
posts
and
user
behavior
in
quora
and
developed
classifier
that
can
predict
the
sensitivity
of
individual
posts
however
the
solution
is
largely
based
on
explicit
categories
rather
than
latent
embeddings
and
the
go
anonymous
posting
option
that
users
may
choose
in
contrast
our
work
aims
to
understand
the
sensitivity
of
any
latently
represented
topic
and
provide
assessment
for
risk
understood
as
topical
exposure
in
community
query
log
sanitization
this
line
of
work
tackles
the
challenge
of
an
adversary
using
session
information
to
infer
user
identities
from
queries
adar
2007
variety
of
techniques
have
been
proposed
for
anonymizing
query
logs
hashing
tokens
removing
identifiers
deleting
infrequent
queries
shortening
sessions
and
more
cooper
2008
fan
et
al
2014
hong
et
al
2012
korolova
et
al
2009
kumar
et
al
2007
götz
et
al
2012
compared
different
methods
for
publishing
frequent
keywords
queries
and
clicks
and
showed
that
most
methods
are
vulnerable
to
information
leakage
user-centric
privacy
stochastic
privacy
singla
et
al
2014
is
one
of
the
few
works
that
focus
on
users
rather
than
data
this
model
introduces
user-defined
threshold
for
sharing
data
to
be
obeyed
by
the
platform
provider
closest
in
spirit
to
our
approach
is
the
work
of
biega
et
al
2014
which
uses
probabilistic
graphical
models
to
infer
sensitive
user
properties
but
is
very
limited
in
scope
linkability
and
de-anonymization
privacy
research
for
social
networks
has
demonstrated
the
feasibility
of
linking
user
profiles
across
different
communities
goga
et
al
2013
and
de-anonymizing
users
narayanan
et
al
2012
narayanan
and
shmatikov
2009
zhang
et
al
2014
to
prevent
such
attacks
family
of
methods
eliminates
joinable
attributes
from
published
datasets
vatsalan
et
al
2013
user
behavior
modeling
it
has
been
shown
that
search
queries
can
often
be
used
to
predict
identity
of
users
as
well
as
their
gender
location
and
other
demographic
attributes
jones
et
al
2007
hu
et
al
2007
weber
and
castillo
2010
such
information
can
be
depression
drugs
pregnancy
hiv
debts
0.542
0.636
0.667
0.429
0.542
lda
0.542
0.545
0.533
0.429
0.542
0.667
0.636
0.733
0.500
0.542
lda-dt
0.762
0.710
0.571
0.526
lda
0.762
0.806
0.667
0.579
0.833
0.677
0.619
0.684
0.762
0.774
0.667
0.632
health
forums
lda-d
lda-t
lda-dt
0.650
0.364
0.095
0.400
0.300
lda
0.550
0.545
0.429
0.400
0.500
0.650
0.273
0.095
0.200
0.100
quora
lda-d
lda-t
table
6.6
comparison
of
r-precision
of
lda
lda-d
lda-t
and
lda-dt
for
different
topics
0.625
0.591
0.533
0.500
0.583
aol
lda-d
lda-t
0.600
0.364
0.381
0.400
0.200
lda-dt
6.6
related
work
95
96
chapter
rank-susceptibility
harnessed
for
personalization
but
may
also
incur
privacy
threats
pennacchiotti
and
popescu
2011
analyzed
twitter
profiles
and
network
information
to
predict
the
political
affiliation
and
race
of
users
expertise
identification
and
trust
analysis
expert
and
trustworthy
users
can
be
identified
based
on
their
questions
answers
contents
and
community
votes
adamic
et
al
2008
or
by
analyzing
user
interaction
graphs
jurczyk
and
agichtein
2007
zhang
et
al
2007
unlike
in
these
works
our
aim
is
not
to
identify
experts
but
to
push
the
users
who
have
broad
interest
in
domain
down
the
privacy
risk
ranking
6.7
conclusion
this
chapter
proposes
framework
for
quantifying
privacy
risks
from
textual
contents
of
user
profiles
in
online
communities
by
employing
ir
techniques
such
as
ranking
and
latent
topic
models
it
specifically
addresses
the
risk
of
exposure
with
respect
to
sensitive
topics
and
targeting
by
rational
adversary
with
rich
background
knowledge
about
topic
vocabulary
and
word
correlations
although
more
large
scale
studies
of
adversarial
risk
scoring
strategies
are
needed
our
experiments
constitute
proof
of
concept
that
the
approach
is
viable
basis
for
privacy
risk
assessment
for
users
who
want
to
post
about
sensitive
topics
but
would
like
to
be
warned
when
the
risk
of
being
targeted
becomes
high
in
the
future
r-susceptibility
can
be
extended
to
incorporate
other
forms
of
online
activities
and
be
integrated
in
framework
for
risk
mitigation
through
appropriately
guided
user
actions
our
vision
is
trusted
personal
privacy
advisor
which
assesses
risks
alerts
the
user
when
critical
situations
arise
and
guides
her
in
appropriate
countermeasures
chapter
privacy
through
solidarity
contents
7.1
introduction
7.2
framework
overview
7.3
7.4
7.5
98
99
7.2
architecture
99
7.2
incentives
of
participating
parties
100
7.2
trusted
and
adversarial
parties
101
assignment
model
101
7.3
concepts
and
notation
102
7.3
objective
102
7.3
measuring
privacy
gain
102
7.3
measuring
user
utility
loss
103
7.3
assignment
algorithms
104
mediator
accounts
in
search
systems
105
7.4
framework
elements
105
7.4
service
provider
model
106
experiments
106
7.5
experimental
setup
106
7.5
results
and
insights
108
7.6
related
work
111
7.7
conclusion
113
nline
service
providers
gather
vast
amounts
of
data
to
build
user
profiles
such
profiles
improve
service
quality
through
personalization
but
may
also
intrude
on
user
privacy
and
incur
discrimination
risks
as
the
next
contribution
of
the
thesis
we
propose
framework
which
leverages
solidarity
in
large
community
to
scramble
user
interaction
histories
while
this
is
beneficial
for
anti-profiling
the
potential
downside
is
that
individual
user
utility
in
terms
of
the
quality
of
search
results
may
severely
degrade
to
reconcile
privacy
and
user
utility
and
control
their
trade-off
we
develop
quantitative
models
for
these
dimensions
and
effective
strategies
for
assigning
user
queries
to
mediator
accounts
we
demonstrate
the
viability
of
our
framework
by
experiments
using
querylog
with
rich
user
profiles
synthesized
from
the
stackexchange
community
question
answering
cqa
forum
98
7.1
chapter
privacy
through
solidarity
introduction
motivation
users
are
profiled
and
targeted
in
virtually
every
aspect
of
their
digital
lives
when
searching
browsing
shopping
or
posting
on
social
media
the
gathered
information
is
used
by
service
providers
to
personalize
search
results
customize
ads
provide
differential
pricing
and
more
hannak
et
al
2013
teevan
et
al
2005
since
such
practices
can
greatly
intrude
on
an
individual
privacy
the
goal
of
our
research
is
to
devise
mechanism
to
counter
such
extensive
profiling
careful
user
can
largely
preserve
her
privacy
by
taking
measures
like
anonymizing
communication
or
using
online
services
only
in
non-linkable
manner
for
instance
by
changing
accounts
or
pseudonyms
on
regular
basis
however
this
comes
at
the
cost
of
greatly
reducing
utility
both
for
the
service
providers
and
the
user
on
the
one
hand
the
service
provider
will
miss
out
on
learning
from
the
same
user
long-term
behavior
which
may
result
in
less
effective
systems
this
issue
of
system-level
utility
has
been
studied
in
the
past
research
on
privacy
krause
and
horvitz
2010
he
et
al
2014
on
the
other
hand
the
individual
user
will
experience
degraded
service
quality
such
as
poor
search
results
as
the
service
provider
would
not
understand
the
user
interests
and
intentions
this
notion
of
user-level
utility
has
not
been
extensively
explored
in
prior
work
this
dissertation
formalizes
the
trade-off
between
user
profiling
privacy
and
her
individual
utility
state
of
the
art
and
its
limitations
research
in
privacy
has
primarily
addressed
the
disclosure
of
critical
properties
in
data
publishing
bertino
et
al
2008
chen
et
al
2009
fung
et
al
2010
common
techniques
include
coarsening
the
data
so
that
different
users
become
indistinguishable
k-anonymity
sweeney
2002b
l-diversity
machanavajjhala
et
al
2007
and
t-closeness
li
et
al
2007
or
perturbing
the
answers
of
an
algorithm
so
that
the
absence
or
presence
of
any
record
does
not
significantly
influence
the
output
the
principle
of
differential
privacy
dwork
2008
these
methods
consider
notions
of
utility
that
reflect
system-level
error
in
an
analytical
task
such
as
classification
in
contrast
our
goal
is
to
prevent
detailed
profiling
and
targeting
while
keeping
the
individual
user
utility
as
high
as
possible
for
example
in
terms
of
the
quality
of
personalized
search
results
or
product
recommendations
for
privacy-preserving
search
many
approaches
have
been
proposed
based
on
query
obfuscation
gervais
et
al
2014
peddinti
and
saxena
2014
in
these
solutions
queries
are
generalized
to
hide
user
intentions
or
additional
dummy
queries
are
generated
to
prevent
accurate
profiling
both
techniques
come
at
the
cost
of
largely
reducing
user
utility
however
none
of
the
prior
work
addressed
the
trade-off
between
privacy
and
user
utility
in
quantitative
manner
few
methods
chen
et
al
2011
peddinti
and
saxena
2014
have
considered
an
entire
user
community
as
means
for
query
obfuscation
this
idea
is
related
to
our
approach
in
this
dissertation
we
generalize
it
and
make
it
applicable
in
the
context
of
anti-profiling
approach
and
contribution
our
approach
to
reconcile
privacy
and
user
utility
builds
on
the
following
observation
service
providers
often
do
not
need
complete
and
accurate
user
profile
to
return
personalized
results
thus
in
accordance
with
the
need-to-know
principle
7.2
framework
overview
99
we
assign
user
requests
to
mediator
accounts
ma
mimicking
real
users
such
that
individual
user
profiles
are
scrambled
across
mas
to
counter
profiling
while
ii
coherent
fragments
of
user
profile
are
kept
intact
in
the
mas
to
keep
user
utility
high
we
call
this
paradigm
privacy
through
solidarity
specifically
mas
are
constructed
by
split-merge
assignment
strategies
splitting
the
interaction
history
of
user
and
merging
pieces
of
different
users
together
mediator
accounts
are
meant
as
an
intermediate
layer
between
users
and
the
service
provider
so
that
the
provider
only
sees
mas
instead
of
the
real
users
ideas
along
these
lines
have
been
around
in
the
prior
literature
reiter
and
rubin
1998
santos
et
al
2008
xu
et
al
2009
goodrich
et
al
2012
rebollo-monedero
et
al
2012
but
the
formalization
of
the
trade-off
between
privacy
and
user-utility
has
never
been
worked
out
in
particular
to
make
this
idea
viable
one
needs
to
devise
quantitative
measures
for
the
effects
of
mediator
accounts
on
privacy
and
utility
in
addition
strategy
is
needed
for
assigning
user
requests
to
such
accounts
the
simplest
approach
of
uniform
randomization
would
be
ideal
for
privacy
but
could
prove
disastrous
for
user
utility
this
dissertation
addresses
these
challenges
within
framework
of
mediator
accounts
our
ideas
are
general
enough
to
be
applied
to
search
engines
recommender
systems
and
other
online
services
where
personalization
is
based
on
the
user
interaction
history
the
salient
contributions
of
this
chapter
are
model
with
measures
for
quantifying
the
trade-off
between
profiling
privacy
and
user
utility
the
mediator
accounts
framework
together
with
strategies
for
assigning
user
interactions
to
mas
comprehensive
experiments
using
large
query
log
derived
from
the
stackexchange
cqa
community
7.2
framework
overview
7.2
architecture
the
architecture
of
the
mediator
accounts
framework
is
shown
in
fig
7.1
it
consists
of
three
parties
users
service
provider
sp
and
mediator
accounts
proxy
ma-proxy
user
profile
consists
of
set
of
objects
such
as
queries
product
ratings
or
other
forms
of
user
interactions
with
the
sp
instead
of
issuing
objects
directly
to
the
sp
users
pass
them
on
to
the
ma-proxy
together
with
some
context
information
the
goal
of
the
ma-proxy
is
to
redistribute
the
incoming
objects
on
to
mediator
profiles
mimicking
real
users
the
ma-proxy
assigns
each
incoming
object
to
mediator
account
offering
the
right
context
for
the
current
object
and
user
and
issues
the
object
to
the
sp
from
the
chosen
ma
upon
receiving
response
for
example
result
page
or
product
recommendation
from
the
sp
the
ma-proxy
passes
it
back
to
the
user
when
an
interaction
is
over
the
ma-proxy
discards
all
linking
information
about
the
original
user
and
the
object
and
remembers
only
the
association
between
the
mediator
account
and
the
object
as
result
the
original
user
100
chapter
privacy
through
solidarity
figure
7.1
overview
of
the
ma
framework
profiles
are
scrambled
across
multiple
mas
and
each
ma
consists
of
data
from
multiple
users
7.2
incentives
of
participating
parties
users
the
goal
of
user
participating
in
an
ma
system
is
to
be
able
to
get
high-quality
personalized
results
while
not
letting
any
online
provider
neither
sps
nor
the
ma-proxy
keep
her
interaction
history
and
link
it
to
her
as
an
individual
the
ma-proxy
has
the
user
interaction
history
scrambled
across
multiple
accounts
and
no
links
between
the
objects
and
the
real
users
are
stored
users
of
anonymous
services
that
do
not
offer
topical
personalization
such
as
the
duckduckgo
startpage
or
qwant
search
engines
may
be
open
to
trading
off
some
privacy
for
enhanced
results
through
the
ma
framework
non-profiling
service
providers
the
incentive
of
non-profiling
service
provider
would
be
to
enhance
personalization
in
the
results
without
compromising
on
the
nonprofiling
principle
profiling
service
providers
big
question
is
whether
profiling
service
providers
would
allow
third-party
like
an
ma-proxy
to
mediate
between
them
and
the
users
while
examples
of
such
third-parties
already
exist
the
startpage
search
engine
uses
google
as
source
of
search
results
we
believe
that
an
ma-proxy
being
able
to
group
objects
into
realistic
profiles
that
yield
similar
analytics
results
for
the
sp
and
ii
an
ma-proxy
being
able
to
attract
privacy-wary
users
who
would
not
otherwise
use
the
profiling
sp
would
be
viable
incentives
for
an
sp
not
to
block
an
ma
service
7.3
assignment
model
101
ma-proxy
an
ma-proxy
could
be
set
up
by
individuals
or
cooperatives
of
non-profiling
sps
to
provide
personalization
without
accumulating
real
user
profiles
or
by
non-governmental
organizations
that
promote
online
privacy
the
electronic
frontier
foundation
is
such
an
organization
non-profit
organization
that
has
built
privacy-preserving
solutions
like
privacy
badger
7.2
trusted
and
adversarial
parties
ma-proxy
users
opting
for
an
ma
service
would
need
to
trust
that
it
scrambles
their
profiles
across
mediator
accounts
and
discards
the
original
profiles
as
well
as
any
identifying
information
once
an
interaction
single
request
or
session
is
complete
standard
approach
to
gain
such
trust
would
be
to
make
the
ma
solution
open-source
enabling
the
code
to
be
vetted
by
the
community
real
implementation
of
an
ma
framework
would
have
to
take
into
account
secure
end-to-end
communication
channels
between
users
and
sps
via
the
ma-proxy
these
issues
may
be
resolved
using
encryption
and
security
techniques
secure
browser
onion
routing
etc
and
are
outside
the
scope
of
this
thesis
provider
the
service
provider
is
not
exactly
distrusted
but
there
have
been
cases
where
user-related
information
has
been
leaked
or
passed
on
beyond
the
original
intentions
by
sabotage
acquisition
by
other
companies
or
enforcement
by
government
agencies
by
detaching
users
from
profiles
and
limiting
their
accuracy
the
potential
damage
is
bounded
other
risks
might
result
from
service
providers
displaying
privacy-sensitive
personalized
ads
such
as
ads
related
to
pregnancy
or
health
issues
especially
when
observed
by
others
on
user
screen
the
architecture
would
allow
an
ma-proxy
to
support
filtering
ads
and
adjusting
them
to
users
topical
interest
such
configuration
has
indeed
been
found
to
be
preferable
ad-serving
setup
in
user
study
agarwal
et
al
2013
ad
filtering
however
is
orthogonal
to
this
research
third
parties
profiling
companies
that
operate
outside
the
user-provider
connections
are
considered
untrusted
the
same
holds
for
agglomerates
of
providers
that
aggregate
and
exchange
user
data
conceivable
attack
could
be
to
guess
user
attribute
whether
she
is
pregnant
by
combining
observations
on
the
mas
and
ii
observations
on
set
of
accounts
in
social
network
using
statistical
inference
methods
the
ma
framework
aims
to
keep
such
risks
low
by
breaking
observable
associations
between
mas
and
real
users
and
limiting
the
profiling
accuracy
of
the
split-merge
superpositions
of
different
users
that
cannot
be
easily
disentangled
7.3
assignment
model
the
core
of
the
ma
framework
is
an
algorithm
for
assigning
user
objects
to
mediator
accounts
to
guide
it
on
the
privacy-utility
trade-offs
and
to
assess
the
quality
of
the
output
we
need
measures
for
quantifying
the
effect
of
an
assignment
on
privacy
and
user
utility
this
section
presents
such
measures
and
the
algorithm
for
object
assignment
based
on
the
split-merge
concept
102
7.3
chapter
privacy
through
solidarity
concepts
and
notation
we
use
the
following
notations
set
of
users
u1
up
set
of
objects
o1
os
issued
by
users
the
objects
are
treated
as
unique
even
if
they
represent
the
same
content
for
instance
query
folk
music
issued
by
user
ui
is
treated
as
an
object
distinct
from
the
same
query
issued
by
uj
analogously
product
rating
for
book
folk
music
history
3.0
by
ui
is
distinct
from
the
rating
by
uj
for
the
same
book
irrespective
of
the
rating
value
set
of
mediator
accounts
m1
mt
to
which
objects
are
assigned
by
the
ma-proxy
we
reserve
the
symbols
for
subscripts
of
users
objects
and
mas
if
user
ui
issues
object
oj
we
write
oj
ui
similarly
if
oj
is
assigned
to
ma
mk
we
write
oj
mk
assignments
an
assignment
of
objects
on
to
mas
can
be
denoted
as
an
matrix
of
values
where
aij
means
that
oi
is
assigned
to
mj
if
we
think
of
the
cartesian
product
as
bipartite
graph
then
the
assignment
can
be
conceptualized
as
subgraph
where
each
node
of
type
has
exactly
one
edge
with
one
of
the
nodes
7.3
objective
in
real
application
an
ma-proxy
has
to
assign
objects
to
accounts
in
an
online
manner
one
object
at
time
as
input
arrives
in
this
chapter
we
focus
on
analyzing
the
model
and
assignments
in
an
offline
setting
although
the
algorithm
we
devise
can
be
applied
in
both
offline
and
online
scenarios
the
offline
case
is
useful
for
two
reasons
first
it
is
foundation
for
understanding
the
underlying
privacy-utility
trade-offs
second
performing
offline
assignment
on
set
of
initial
user
profiles
can
address
the
cold-start
problem
that
new
ma-proxy
would
face
using
the
notation
from
sec
7.3
the
ma
offline
assignment
problem
can
be
defined
as
follows
given
set
of
objects
belonging
to
set
of
users
and
the
set
of
mediator
accounts
compute
an
assignment
matrix
that
optimizes
desired
objective
function
for
the
privacy-utility
trade-off
the
ma
online
assignment
problem
is
given
an
assignment
of
past
user
objects
to
mas
and
newly
arriving
object
of
user
find
the
best
ma
to
which
should
be
assigned
with
regard
to
desired
goal
for
the
privacy-utility
trade-off
7.3
measuring
privacy
gain
an
ideal
situation
from
the
perspective
of
privacy
is
when
the
objects
from
user
profile
are
spread
across
mas
uniformly
at
random
this
minimizes
the
object-level
similarity
of
any
ma
to
the
original
profile
we
thus
measure
privacy
as
the
entropy
of
the
user
distribution
over
mas
formalizing
these
notions
as
follows
7.3
assignment
model
103
entropy
we
introduce
for
each
user
ui
an
ma-per-user
vector
mu
n0
with
one
counter
per
ma
written
as
mu
hxi1
xij
xit
where
xij
is
the
number
of
pt
objects
by
user
ui
in
account
mj
such
that
xij
ui
we
can
cast
this
into
an
maper-user
probability
distribution
φi
hφi1
φij
φit
by
setting
φij
xij
ui
followed
pt
by
smoothing
laplace
smoothing
so
that
φij
for
each
and
φij
the
degree
of
ui
profile
fragmentation
can
be
captured
by
the
entropy
of
the
distribution
φi
we
can
define
the
ma-per-user
entropy
as
measure
of
privacy
gain
gain
over
having
each
user
exhibit
her
full
individual
profile
privacy
gain
ui
hi
φij
log
φij
7.1
this
quantifies
the
spread
of
the
user
objects
across
accounts
the
higher
the
entropy
value
the
higher
the
gain
in
profiling
privacy
profile
overlap
if
use-case
requires
more
user-interpretable
measure
of
privacy
an
alternative
is
to
minimize
the
maximum
profile
overlap
for
user
ui
this
measure
can
be
expressed
as
ui
mj
oi
max
7.2
ui
this
measure
of
overlap
can
directly
tell
user
how
much
error
could
be
made
by
an
adversary
who
assumes
one
of
the
mas
is
the
user
profile
the
optimum
for
this
measure
as
with
entropy
is
achieved
when
the
objects
are
uniformly
spread
across
accounts
thus
in
the
following
we
use
entropy
as
our
privacy
measure
and
leave
maximum
profile
overlap
as
design
alternative
7.3
measuring
user
utility
loss
user
utility
loss
measures
to
what
extent
an
object
ok
of
user
ui
is
placed
out
of
context
by
mapping
it
to
account
mj
we
define
real-valued
function
sim
to
measure
the
coherence
of
user
and
ma
profiles
sim
oi
oj
is
symmetric
measure
of
the
relatedness
between
objects
represented
by
oi
and
oj
in
practice
different
notions
of
relatedness
can
be
used
based
on
object
properties
or
usage
in
settings
where
labels
for
topics
or
categories
are
available
we
can
set
sim
oi
oj
if
oi
and
oj
are
issued
by
the
same
user
and
have
the
same
topic
category
label
and
otherwise
generally
we
assume
that
sim
measures
are
normalized
with
values
between
and
the
objects
of
user
ui
form
context
typically
with
high
pairwise
relatedness
among
the
objects
when
considering
sets
of
objects
as
whole
rather
than
time-ordered
sequences
of
object
posts
we
can
measure
the
normalized
context
coherence
of
an
object
ok
in
the
profile
of
user
ui
by
ol
ui
k6
sim
ok
ol
coh
ok
ui
7.3
ui
when
ok
is
placed
in
ma
mj
we
analogously
define
ol
mj
k6
sim
ok
ol
coh
ok
mj
mj
7.4
104
chapter
privacy
through
solidarity
the
utility
loss
of
ui
in
given
ma
assignment
is
then
measured
as
an
average
coherence
loss
over
all
user
objects
coh
ok
ui
coh
ok
mj
7.5
utility
loss
ui
ok
ui
ui
where
mj
is
the
account
containing
ok
in
the
given
assignment
the
normalization
helps
to
account
for
varying
sizes
of
user
profiles
as
result
coherence
values
are
always
between
and
and
utility
loss
is
normalized
to
take
values
between
and
note
that
our
utility
measure
assumes
that
the
context
coherence
can
increase
if
an
object
is
assigned
to
an
ma
with
more
similar
objects
coherence
increase
will
result
in
negative
utility
loss
7.3
assignment
algorithms
the
role
of
an
assignment
algorithm
is
to
scramble
user
objects
across
accounts
so
as
to
satisfy
desired
privacy-utility
tradeoff
or
optimize
corresponding
objective
function
in
this
chapter
we
experiment
with
number
of
assignment
algorithms
and
study
their
output
quality
7.3
5.1
optimal
assignment
offline
the
trade-off
can
be
expressed
as
joint
non-linear
optimization
problem
as
follows
max
min
privacy_gain
utility_loss
7.6
alternatively
one
could
optimize
one
of
the
two
measures
with
constraint
on
the
other
solving
this
problem
exactly
however
is
computationally
expensive
if
we
use
the
less
complex
overlap
privacy
measure
we
could
cast
the
problem
into
quadratic
integer
program
however
this
would
have
millions
of
variables
so
it
would
remain
intractable
in
practice
we
thus
do
not
pursue
this
direction
in
this
dissertation
and
instead
consider
number
of
heuristics
the
following
are
also
suitable
for
the
online
case
7.3
5.2
profiling-tradeoff
assignment
we
aim
to
approximate
the
combined
objective
function
as
follows
let
be
an
object
we
want
to
assign
to
one
of
the
accounts
mj
if
we
want
to
optimize
for
privacy
entropy
we
should
choose
an
ma
at
random
from
uniform
distribution
over
mas
ppriv
mj
7.7
if
we
want
to
optimize
for
utility
we
could
choose
an
ma
that
offers
the
best
coherence
if
max
putil
mj
7.8
otherwise
where
mmax
arg
maxmk
coh
mk
7.4
mediator
accounts
in
search
systems
105
let
be
parameter
that
controls
the
trade-off
between
privacy
and
utility
we
sample
an
ma
according
to
the
distribution
mj
ppriv
mj
putil
mj
7.9
in
the
offline
case
we
may
choose
an
arbitrary
order
of
objects
to
feed
into
this
assignment
heuristic
in
the
online
case
we
process
objects
ordered
by
the
timestamps
in
which
they
are
issued
to
the
ma-proxy
it
is
also
worth
noting
that
in
an
online
setting
users
could
choose
different
for
each
object
deciding
that
some
should
be
assigned
randomly
and
some
with
the
best
possible
context
7.3
5.3
random
assignment
in
this
assignment
objects
are
assigned
to
accounts
uniformly
at
random
this
is
special
case
of
the
profiling-tradeoff
algorithm
with
this
assignment
maximizes
privacy
7.3
5.4
coherent
assignment
personalization
is
usually
based
on
semantically
coherent
parts
of
user
profiles
if
we
retain
such
coherent
fragments
of
profile
within
the
accounts
individual
utility
should
be
preserved
better
than
in
completely
random
assignment
the
mode
in
which
we
assign
an
object
to
the
account
that
offers
the
best
coherence
is
special
case
of
the
profiling-tradeoff
algorithm
in
which
we
set
we
refer
to
this
method
as
coherent
this
assignment
explicitly
aims
for
the
best
utility
only
yet
some
privacy
is
gained
as
chunks
of
user
profiles
get
assigned
to
mas
randomly
7.4
mediator
accounts
in
search
systems
by
analyzing
query-and-click
logs
search
engines
can
customize
results
to
individual
users
such
user
profiling
however
may
reveal
detailed
picture
of
person
life
posing
potential
privacy
risks
at
the
same
time
personalization
of
single
query
is
often
based
on
only
subset
of
user
history
thus
as
first
use
case
we
apply
the
ma
framework
in
search
engine
setting
scrambling
the
query
histories
of
different
users
across
accounts
7.4
framework
elements
in
the
search
scenario
the
elements
of
the
framework
described
in
sec
7.3
are
instantiated
as
follows
the
objects
are
keyword
queries
and
user
profiles
consist
of
sets
or
sequences
of
queries
possibly
with
timestamps
accounts
contain
re-assigned
queries
of
different
users
object
similarity
can
be
understood
as
topical
similarity
between
queries
with
topics
being
either
explicit
such
as
categories
or
classifier
labels
or
latent
based
on
embeddings
as
query
is
characterized
by
set
or
weight
vector
of
topics
the
similarity
can
be
computed
for
instance
using
weighted
jaccard
overlap
or
vector
cosine
the
service
provider
in
this
setting
is
search
engine
which
upon
receiving
query
from
given
user
profile
returns
ranked
list
of
documents
personalized
for
that
user
user
utility
is
measured
by
the
quality
of
the
result
list
106
7.4
chapter
privacy
through
solidarity
service
provider
model
the
ability
of
the
ma
framework
to
preserve
utility
while
splitting
user
profiles
across
accounts
depends
on
retrieval
model
for
ranking
query
answers
we
use
the
languagemodel-based
retrieval
technique
croft
et
al
2009
as
described
below
let
be
query
of
user
consisting
of
number
of
words
and
be
the
document
collection
the
model
retrieves
the
results
in
two
steps
first
it
fetches
set
of
top-k
documents
do
each
document
being
scored
by
the
query-likelihood
model
with
dirichlet
smoothing
parameter
µd
croft
et
al
2009
tfw
µd
score
log
log
7.10
vd
µd
where
tfw
is
the
count
of
in
is
the
probability
that
occurs
in
and
vd
is
the
count
of
all
words
in
for
every
user
we
compute
personalization
score
as
the
log-probability
of
the
document
being
generated
from
the
user
language
model
using
dirichlet
smoothing
with
parameter
µu
where
is
the
set
of
all
users
or
equivalently
the
collection
of
their
search
histories
tfw
µu
score
log
log
7.11
vu
µu
where
tfw
is
the
count
of
in
the
search
history
of
is
the
probability
that
occurs
in
and
vu
is
the
count
of
all
words
in
the
search
history
of
in
the
second
step
documents
do
are
re-ranked
using
linear
combination
of
the
two
scores
scoreu
score
score
7.12
in
practice
would
be
set
to
low
value
to
put
more
importance
on
personalization
when
we
use
the
ma
framework
the
computations
are
similar
the
notion
of
user
is
simply
replaced
by
an
account
the
personalization
stage
is
adjusted
as
follows
we
compute
score
using
which
in
turn
is
computed
using
tfw
µm
and
vm
with
eq
7.11
definitions
of
these
quantities
are
analogous
to
their
user
counterparts
7.5
experiments
7.5
experimental
setup
7.5
1.1
dataset
for
lack
of
publicly
available
query
logs
with
user
profiles
we
created
query
log
and
document
collection
using
the
data
from
the
stack
exchange
community
dump
as
of
13
06
2016
we
excluded
the
large
software
subforums
from
outside
the
stack
exchange
web
domain
such
as
stackoverflow
as
they
would
dominate
and
drastically
reduce
the
topical
diversity
the
final
dataset
consists
of
ca
6m
posts
of
type
question
or
answer
in
142
diverse
subforums
astronomy
security
christianity
politics
parenting
and
travel
7.5
experiments
107
document
collection
we
use
all
posts
of
type
answer
as
our
collection
the
resulting
corpus
contains
9m
documents
user
query
histories
we
construct
query
log
from
posts
of
type
question
as
these
reflect
users
information
needs
each
question
is
cast
into
keyword
query
selecting
the
top-l
question
words
with
the
highest
tf-idf
scores
where
is
random
integer
between
and
we
consider
only
users
with
at
least
150
questions
which
yields
total
of
975
users
and
253k
queries
each
query
is
assigned
topical
label
used
for
object
similarity
we
set
this
label
to
the
subforum
where
the
original
question
was
posted
7.5
1.2
service
provider
for
reproducible
experiments
we
base
our
search
engine
model
on
the
open-source
ir
system
indri
strohman
et
al
2005
indri
ranks
query
answers
based
on
state-of-the-art
statistical
language
models
with
dirichlet
smoothing
croft
et
al
2009
we
use
indri
to
retrieve
the
top-100
results
for
every
query
from
the
entire
corpus
and
implement
userpersonalized
re-ranking
ourselves
see
sec
7.4
we
compute
per-user
language
models
from
the
original
questions
to
tackle
sparsity
the
dirichlet
smoothing
parameter
is
set
to
the
average
document
length
56
words
and
is
set
to
0.1
7.5
1.3
empirical
measures
privacy
gain
the
model
entropy
reflects
how
scrambled
the
user
profiles
are
yet
from
the
perspective
of
profiling
adversary
it
is
rather
the
distribution
over
semantic
topics
that
matters
empirically
proper
way
to
measure
privacy
then
is
to
compare
the
original
topic
distribution
per
user
against
the
topic
distributions
of
the
mas
the
minimum
kl-divergence
between
pairs
of
these
distributions
signifies
the
privacy
level
emp
priv
gain
ui
min
dkl
ui
qmj
mj
7.13
where
ui
and
qmj
refer
to
the
user
and
ma
profile
distributions
over
topics
with
add-one
laplace
smoothing
we
use
subforums
as
explicit
labels
for
topics
utility
loss
rankings
of
documents
for
query
are
derived
from
scoreu
and
scorem
eq
7.12
respectively
where
the
former
refers
to
the
query
being
issued
by
user
and
the
latter
to
the
query
being
issued
by
the
mediator
account
see
sec
7.4
we
quantify
the
empirical
utility
loss
as
the
divergence
between
the
two
rankings
we
compute
two
measures
the
loss
in
kendall
tau
over
the
top-100
document
rankings
kt
au
100
as
the
personalization
step
considers
the
top-100
documents
and
the
loss
in
jaccard
similarity
coefficient
over
the
first
20
ranking
positions
jaccard
20
as
end-users
typically
care
only
about
short
prefix
of
ranked
results
for
each
user
we
average
these
scores
over
all
queries
108
chapter
privacy
through
solidarity
m-priv-gain
entropy
m-util-loss
coherence
loss
e-priv-gain
min
kl-div
e-util-loss
ktau
100
original
0.000
0.000
0.000
0.000
0.0
coh
0.2
0.4
0.6
0.8
1.0
rand
1.180
2.208
3.130
3.975
4.731
5.287
0.178
0.293
0.389
0.463
0.515
0.535
0.320
0.319
0.346
0.389
0.494
0.863
0.170
0.203
0.228
0.246
0.260
0.266
table
7.1
results
with
trade-off
parameter
for
the
model
and
empirical
measures
7.5
1.4
assignment
methods
object
similarity
we
set
sim
oi
oj
if
both
oi
and
oj
belong
to
the
same
user
and
to
the
same
topic
and
otherwise
during
the
assignment
this
measure
helps
to
keep
related
parts
of
user
profile
together
assignment
algorithms
we
run
the
profiling-tradeoff
algorithm
varying
between
and
with
0.1
increment
and
setting
the
number
of
mas
to
be
the
number
of
users
975
with
the
chosen
object
similarity
the
special
case
of
the
coherent
assignment
results
in
splitting
user
profiles
into
subforum
chunks
and
assigning
each
chunk
to
randomly
chosen
account
7.5
results
and
insights
aggregate
trends
table
7.1
presents
the
results
on
the
model
measures
and
empirical
measures
for
different
values
of
the
assignment
trade-off
parameter
macro-averaged
over
users
recall
that
0.0
and
1.0
correspond
to
the
special
cases
of
coherent
and
random
assignments
respectively
these
results
need
to
be
contrasted
with
the
baseline
denoted
original
in
the
table
where
each
original
user
forms
exactly
one
account
no
scrambling
at
all
compared
to
the
baseline
all
numbers
are
statistically
significant
by
paired
t-tests
with
0.01
for
empirical
utility
loss
we
report
kendall
tau
the
results
for
the
jaccard
coefficient
are
similar
the
results
show
that
the
profiling-tradeoff
assignments
improve
privacy
over
the
original
baseline
the
topical
kl-div
between
original
users
and
mas
is
increased
while
keeping
the
utility
loss
low
this
is
largely
true
regardless
of
the
exact
choice
of
so
the
ma
framework
provides
fairly
robust
solution
to
reconciling
privacy
and
utility
supporting
the
observation
that
high-quality
topical
personalization
does
not
require
complete
user
profiles
7.5
experiments
109
figure
7.2
model
measures
per
user
with
the
increasing
assignments
become
more
random
so
the
privacy
increases
and
utility
is
reduced
but
with
low
gradient
in
this
regard
the
empirical
measures
reflect
the
expected
behavior
according
to
the
model
measures
well
results
per
user
figs
7.2
and
7.3
show
privacy
and
utility
values
of
each
user
for
the
model
and
empirical
measures
respectively
different
colors
represent
different
assignments
and
each
dot
represents
user
with
measures
averaged
over
the
user
queries
we
have
several
observations
higher
privacy
gain
is
correlated
with
higher
utility
loss
the
original
assignment
maps
each
user
to
the
origin
utility
loss
but
also
privacy
gain
no
assignment
reaches
the
bottom-right
area
of
the
chart
which
would
be
an
ideal
varying
not
only
tunes
the
privacy-utility
tradeoff
at
the
community
aggregate
level
but
also
affects
the
variance
over
individual
user
scores
this
suggests
that
we
should
further
explore
choosing
on
an
individual
per-user
basis
which
is
easily
feasible
in
our
framework
but
is
not
studied
in
this
thesis
even
the
random
assignment
1.0
keeps
utility
reasonably
high
this
is
due
to
the
fact
that
random
mas
sampled
from
queries
in
the
community
end
up
being
averaged
rather
than
random
profiles
110
chapter
privacy
through
solidarity
figure
7.3
empirical
measures
per
user
some
users
achieve
high
privacy
gains
without
losing
hardly
any
utility
and
vice
versa
we
investigate
this
further
below
effect
of
profile
size
and
diversity
we
analyze
how
different
user
profile
characteristics
affect
the
assignment
results
figure
7.4
presents
the
empirical
trade-offs
for
the
coherent
top
row
and
random
bottom
row
assignments
where
each
dot
is
user
and
the
dot
color
represents
the
logarithm
of
the
number
of
queries
in
the
user
profile
left
column
or
ii
the
diversity
of
the
profile
measured
by
the
entropy
of
the
distribution
of
queries
across
topics
right
column
we
make
the
following
observations
users
with
more
queries
darker
dots
in
the
coherent
assignment
clearly
gain
privacy
at
the
cost
of
losing
utility
whereas
for
the
smaller
profiles
lighter
dots
the
trade-off
is
not
as
pronounced
in
the
random
assignment
this
trade-off
is
less
pronounced
irrespective
of
the
size
of
the
profile
in
the
right
column
one
can
see
the
lighter
dots
profiles
with
little
diversity
moving
from
the
bottom-left
for
the
coherent
assignment
little
privacy
gain
little
utility
loss
to
the
top-right
for
the
random
assignment
higher
privacy
gain
higher
utility
loss
this
suggests
that
our
framework
does
not
offer
much
help
to
the
users
with
uniform
and
focused
interests
this
is
an
inherent
limitation
regardless
of
which
privacy
protection
is
chosen
such
homogeneous
users
cannot
hide
their
specific
interests
7.6
related
work
111
figure
7.4
effect
of
profile
size
and
diversity
unless
they
give
up
on
personalization
utility
our
split-merge
assignments
offer
good
results
for
users
with
high
diversity
as
suggested
by
the
darker
dots
the
coherent
assignment
leads
to
lower
utility
loss
and
higher
privacy
gain
for
users
with
diverse
profiles
when
compared
to
the
random
assignment
this
is
because
such
users
have
more
independent
and
internally
coherent
chunks
that
can
be
split
without
affecting
utility
this
class
of
users
is
exactly
where
the
right
balance
of
utility
and
privacy
matters
most
and
where
we
can
indeed
reconcile
the
two
dimensions
to
fair
degree
7.6
related
work
grouping
for
privacy
the
idea
of
masking
the
traces
of
individual
users
by
combining
them
into
groups
has
been
around
since
the
crowds
proposal
by
reiter
and
rubin
1998
however
this
early
work
solely
focused
on
anonymity
of
web-server
requests
narayanan
and
shmatikov
2005
devised
an
abstract
framework
for
group
privacy
over
obfuscated
databases
but
did
not
address
utility
for
search
engines
specifically
jones
et
al
2008
proposed
notion
of
query
bundles
as
an
implicit
grouping
of
users
but
focused
on
countering
de-anonymization
in
the
presence
of
so-called
vanity
queries
the
short
paper
by
zhu
et
al
2010
sketches
preliminary
approach
where
semantically
similar
queries
by
different
users
112
chapter
privacy
through
solidarity
are
grouped
for
enhancing
privacy
aggregation
of
users
website-specific
privacy
preferences
through
centralized
server
yu
et
al
2016
can
also
be
perceived
as
type
of
privacy
through
solidarity
the
principle
of
solidarity
has
moreover
been
explored
through
game-theoretic
framework
over
recommender
systems
halkidi
and
koutsopoulos
2011
tracking
and
profiling
good
body
of
work
investigates
to
what
extent
and
how
users
are
tracked
by
third
parties
in
web
browsers
lerner
et
al
2016
meng
et
al
2016b
yu
et
al
2016
or
through
mobile
apps
meng
et
al
2016a
these
are
primarily
empirical
studies
with
an
emphasis
on
identifying
the
tracking
mechanisms
the
interactions
with
service
providers
where
users
log
in
and
leave
extensive
traces
have
been
largely
disregarded
in
contrast
our
framework
helps
counter
both
tracking
and
individual
profiling
by
detaching
users
from
online
accounts
to
reduce
the
scale
of
profiling
model
called
stochastic
privacy
has
been
proposed
to
selectively
sample
user
profiles
for
use
by
personalizing
algorithms
singla
et
al
2014
to
counter
profiling
by
search
engines
in
particular
xu
et
al
2007
has
proposed
to
issue
queries
anonymously
but
provide
the
engine
with
coarse
topical
profile
for
answer
quality
on
the
tracking
front
the
non-tracking
web
analytics
system
reconciles
users
need
of
privacy
and
online
providers
need
of
accurate
analytics
akkus
et
al
2012
although
these
various
works
address
the
privacy-utility
trade-off
no
explicit
control
mechanism
has
been
proposed
for
user
utility
privacy-preserving
ir
the
intersection
of
privacy
and
ir
has
received
some
attention
in
the
past
years
yang
et
al
2016
one
of
the
key
problems
studied
in
the
field
is
that
of
post-hoc
log
sanitization
for
data
publishing
cooper
2008
götz
et
al
2012
zhang
et
al
2016a
online
sanitization
on
the
other
hand
aims
at
proactively
perturbing
and
blurring
user
profiles
techniques
along
these
lines
typically
include
query
broadening
or
dummy
query
generation
shen
et
al
2007
balsa
et
al
2012
peddinti
and
saxena
2014
wang
and
ravishankar
2014
it
has
also
been
proposed
to
perturb
user
profiles
by
making
users
swap
queries
and
execute
them
on
behalf
of
each
other
rebollo-monedero
et
al
2012
very
few
of
these
prior
works
consider
the
adverse
impact
that
obfuscation
has
on
utility
and
the
usual
focus
is
on
the
utility
of
single
query
results
to
the
best
of
our
knowledge
none
of
them
focuses
on
personalization
utility
or
offers
quantitative
measures
for
the
trade-off
another
privacy
concept
studied
in
ir
is
that
of
exposure
recently
the
notions
of
r-susceptibility
and
topical
sensitivity
have
been
proposed
to
quantify
user
exposure
in
sensitive
contexts
within
given
community
biega
et
al
2016
privacy-preserving
data
mining
there
is
vast
body
of
literature
on
preserving
privacy
in
mining
data
for
rules
and
patterns
and
learning
classifiers
and
clustering
models
fan
et
al
2014
aggarwal
2015
in
this
context
utility
is
measured
from
the
provider
perspective
typically
an
error
measure
of
the
mining
task
at
hand
classification
error
bertino
et
al
2008
in
the
context
of
recommender
systems
rating
prediction
accuracy
mcsherry
and
mironov
2009
nikolaenko
et
al
2013
and
category
aggregates
shen
and
jin
2016
are
typically
used
as
proxies
for
utility
techniques
for
user
profile
perturbation
have
also
been
7.7
conclusion
113
studied
for
utility-preserving
differentially-private
recommeders
guerraoui
et
al
2015
7.7
conclusion
we
presented
mediator
accounts
mas
framework
to
counter
user
profiling
while
preserving
individual
user
utility
as
much
as
possible
the
framework
enables
decoupling
users
from
accounts
making
direct
targeting
impossible
and
profile
reconstruction
or
de-anonymization
much
harder
at
the
same
time
users
are
still
able
to
benefit
from
personalization
by
service
providers
the
versatility
of
the
framework
has
been
demonstrated
in
experiments
using
large
query
log
synthesized
from
the
stackexchange
platform
while
the
application
of
the
framework
to
recommeder
systems
is
not
contribution
of
this
thesis
biega
et
al
2017b
have
additionally
demonstrated
the
applicability
of
the
framework
in
that
scenario
while
our
model
allows
for
flexible
trade-offs
between
privacy
and
utility
key
question
in
our
empirical
study
has
been
to
understand
how
well
the
mas
can
preserve
the
utility
in
terms
of
high-quality
search
results
the
experiments
show
that
the
split-merge
approach
with
coherent
assignment
improves
the
privacy
while
incurring
little
user
utility
loss
these
benefits
are
most
pronounced
for
users
with
larger
profiles
more
activity
and
higher
diversity
of
interests
open
issues
for
future
work
include
practical
deployment
handling
of
other
personalization
features
and
exploring
the
options
for
tuning
assignments
and
framework
parameters
to
the
specific
needs
of
individual
users
on
top
of
that
analyzing
the
three-dimensional
trade-off
between
user
privacy
user
utility
and
the
traditional
service
provider
utility
could
help
ensure
that
the
resulting
mediator
profiles
are
useful
source
for
user
analytics
making
an
ma
proxy
tolerable
component
of
the
online
landscape
finally
we
would
hope
that
the
ma
proposal
stirs
up
the
investigation
of
how
the
need-to-know
principle
could
be
implemented
in
case
of
personalized
online
services
chapter
conclusions
and
outlook
his
thesis
broadly
investigates
privacy
and
fairness
problems
of
search
system
users
including
both
searchers
and
searched
subjects
the
models
we
propose
together
with
the
experimental
results
suggest
that
there
is
scope
for
search
systems
to
provide
better
experience
for
their
users
in
terms
of
privacy
and
fairness
without
the
need
to
sacrifice
much
of
the
search
utility
the
results
from
chapter
show
that
systems
could
provide
more
equitable
exposure
to
search
subjects
without
much
reduction
in
ranking
utility
especially
since
in
many
existing
scenarios
there
are
numerous
subjects
who
are
equally
relevant
to
various
queries
chapters
and
exemplify
how
systems
could
provide
their
users
with
more
privacy
awareness
by
computing
queries
which
expose
users
in
search
results
annotators
in
our
user
studies
found
exposure
by
topically
sensitive
queries
to
be
especially
problematic
while
media
reports
about
privacy
breaches
in
search
engines
highlight
the
problems
with
exposure
by
unique
queries
finally
chapter
shows
that
search
engines
do
not
need
to
accumulate
rich
query
histories
per
user
to
deliver
quality
personalization
particularly
for
users
with
topically
diverse
profiles
and
interests
going
forward
there
are
number
of
fascinating
questions
that
need
to
be
answered
to
design
privacy-friendly
and
fair
search
engines
fair
exposure
to
create
holistically
fair
systems
we
need
to
gain
deeper
understanding
of
the
intrinsic
properties
of
ranking
and
human
relevance
feedback
mechanisms
that
might
lead
to
bias
and
unfairness
moreover
the
existence
of
position
bias
calls
for
redesigning
display
interfaces
to
try
to
minimize
the
biasing
effects
of
visual
ranking
perceptions
in
applications
such
as
people
search
beyond
exposure
measured
through
ranking
position
interface
design
and
the
results
of
people
search
should
also
be
examined
for
representational
harms
it
might
be
possible
for
instance
that
various
demographic
groups
have
different
information
highlighted
in
the
snippets
on
the
search
results
to
aid
the
algorithm
and
system
design
inspired
by
social
comparison
effects
we
should
also
better
understand
human
perceptions
regarding
the
fairness
of
their
positions
in
ranking
sensitive
exposure
to
mitigate
the
consequences
of
exposure
without
reducing
the
utility
of
the
systems
topical
sensitivity
and
search
exposure
relevance
should
be
contextualized
to
this
end
we
need
to
better
understand
which
textual
contents
are
sensitive
for
which
types
of
users
in
which
situations
on
the
mechanism
side
developing
external
black-box
methods
for
auditing
search
exposure
is
an
important
complement
to
existing
privacy
support
methods
as
well
as
means
of
incentivizing
service
providers
to
develop
more
comprehensive
internal
tools
beyond
user
perceptions
it
is
also
vital
to
develop
116
chapter
conclusions
and
outlook
expert
understanding
of
the
risks
studying
the
consequences
of
exposure
by
different
types
of
queries
and
proposing
reasonable
mitigation
solutions
beyond
awareness
last
but
not
least
to
be
able
to
tangibly
raise
awareness
of
these
problems
we
should
investigate
user
perceptions
regarding
search
exposure
as
well
as
user
understanding
of
the
underlying
mechanisms
and
coping
strategies
minimizing
profiling
our
results
revealed
that
often
only
fraction
of
user
interaction
history
is
needed
to
deliver
quality
personalization
we
can
turn
this
observation
around
to
arrive
at
more
general
question
what
is
the
minimum
amount
of
information
needed
to
maintain
personalization
quality
to
answer
this
question
more
work
is
needed
to
define
generalized
framework-independent
notions
of
profiling
privacy
and
user
utility
and
inspect
the
interplay
between
user
utility
and
system
utility
moreover
not
less
important
is
understanding
which
solutions
would
provide
enough
incentives
for
service
providers
to
be
adopted
and
to
what
extent
users
would
be
willing
to
trade
some
personalization
utility
for
more
privacy
infrastructure
supporting
research
in
privacy
and
fairness
ironically
developing
solutions
for
user
privacy
and
fairness
often
requires
access
to
user
data
or
even
users
themselves
if
privacy
and
fairness-related
annotations
from
the
data
owners
are
necessary
while
more
readily
available
in
the
industry
access
to
real
user
data
is
limited
for
academic
researchers
developing
infrastructure
for
research
in
privacy
and
fairness
is
thus
crucial
factor
fostering
progress
in
these
areas
such
infrastructure
includes
for
instance
protocols
and
data
sanitization
algorithms
for
data
release
methods
for
synthesizing
realistic
data
this
thesis
contributes
to
such
infrastructure
by
creating
synthetic
query
log
and
providing
data
in
shared
benchmarks
we
envision
search
engines
that
serve
their
users
equitably
that
offer
support
mechanisms
for
their
users
to
understand
and
control
the
use
of
their
data
and
their
exposure
in
the
search
results
and
that
collect
the
minimum
amount
of
data
necessary
to
deliver
the
service
appendix
amt
user
study
topical
sensitivity
his
appendix
documents
the
details
of
the
amazon
mechanical
turk1
user
study
described
in
chapter
section
6.4
the
goal
of
the
study
was
to
collect
judgments
on
privacy
sensitivity
of
different
topics
in
topic
model
topic
models
were
trained
using
mallet
mccallum
2002
each
topic
was
represented
by
its
20
most
salient
words
that
is
the
words
with
the
highest
probability
from
the
topic
setup
details
title
survey
about
sensitivity
of
words
in
online
posts
warning
this
hit
may
contain
adult
content
worker
discretion
is
advised
description
we
like
to
collect
your
judments
on
how
privacy-sensitive
different
sets
of
words
might
be
when
used
in
online
posts
keywords
online
posts
sensitive
words
privacy
sensitivity
of
topics
reward
per
assignment
number
of
assigments
per
hit
time
alloted
per
assignment
90
minutes
master
workers
yes
hit
approval
rate
for
all
requester
hits
90
location
is
united
states
number
of
hits
approved
100
instructions
in
this
task
we
want
to
collect
your
judgements
on
whether
you
would
consider
public
posts
on
social
media
facebook
or
twitter
or
blog
containing
certain
sets
of
words
to
be
potentially
privacy
sensitive
we
consider
the
usage
of
set
of
words
to
be
privacy
sensitive
if
any
of
the
following
is
true
person
is
likely
to
use
these
words
because
they
are
in
situation
that
is
privacysensitive
for
example
if
you
use
words
related
to
diseases
it
might
mean
you
are
sick
which
is
privacy-sensitive
situation
https://www.mturk.com/
118
appendix
amt
user
study
topical
sensitivity
the
usage
of
these
words
might
create
privacy-sensitive
situation
or
some
problems
for
example
if
you
use
vocabulary
indicating
your
religious
views
the
information
might
easily
be
used
against
you
leading
to
violation
of
privacy
additionally
for
each
set
of
words
please
choose
best
suiting
thematic
domain
question
each
hit
consisted
of
50
sets
of
questions
of
the
following
form
do
you
think
post
in
social
media
containing
these
words
can
be
privacy-sensitive
yes
no
20
most
salient
words
from
the
topic
were
displayed
here
what
thematic
domain
do
these
words
come
from
law
and
politics
humanities
psychiatry
and
psychology
health
and
medicine
economy
and
finance
other
appendix
amt
user
study
search
exposure
his
appendix
documents
the
details
of
the
amazon
mechanical
turk1
user
study
described
in
chapter
section
5.5
the
goal
of
the
study
was
to
collect
judgments
on
the
search
exposure
relevance
of
different
queries
more
privacy-critical
queries
have
higher
search
exposure
relevance
setup
details
title
study
of
profile
exposure
through
keyword
search
warning
this
hit
may
contain
adult
content
worker
discretion
is
advised
description
we
like
to
collect
your
opinions
regarding
sensitivity
of
different
search
terms
on
twitter
keywords
exposure
of
tweets
keyword
search
masters
has
been
granted
yes
qualification
requirement
hit
approval
rate
for
all
requesters
hits
greater
than
or
equal
to
95
location
is
united
states
number
of
hits
approved
100
instructions
queries
only
websites
like
twitter
offer
their
users
the
option
to
search
for
tweets
using
keyword
queries
sets
of
words
upon
entering
the
keywords
you
receive
ranked
list
of
tweets
that
somehow
match
these
keywords
as
response
assume
for
now
you
are
twitter
user
with
number
of
tweets
in
your
profile
even
though
these
tweets
are
public
they
are
usually
exposed
just
to
your
followers
but
if
it
turns
out
that
one
of
your
tweets
is
returned
as
top-ranked
result
in
response
to
these
keyword
queries
your
tweet
and
profile
will
be
exposed
to
whoever
issues
these
keywords
there
is
variety
of
people
who
might
be
looking
for
user
profiles
or
tweets
that
match
certain
keywords
examples
include
journalists
looking
for
examples
to
their
stories
companies
building
databases
of
people
for
different
purposes
or
even
criminals
looking
for
victims
https://www.mturk.com/
120
appendix
amt
user
study
search
exposure
in
this
survey
we
will
ask
for
your
opinions
regarding
sensitivity
of
different
keyword
queries
in
the
above
context
more
specifically
we
will
show
you
number
of
keyword
queries
and
ask
whether
you
would
feel
concerned
uncomfortable
embarrassed
privacyviolated
or
threatened
if
your
tweet
was
returned
as
one
of
the
top
answers
to
these
search
terms
question
queries
only
would
you
feel
concerned
uncomfortable
embarrassed
privacyviolated
or
threatened
if
your
tweet
was
returned
as
one
of
the
top
answers
to
these
search
terms
please
try
to
choose
yes
for
at
least
10
12
search
terms
you
would
feel
most
uncomfortable
with
although
you
are
also
free
to
choose
more
search
terms
xxx
yes
no
instructions
queries
tweets
websites
like
twitter
offer
their
users
the
option
to
search
for
tweets
using
keyword
queries
sets
of
words
upon
entering
the
keywords
you
receive
ranked
list
of
tweets
that
somehow
match
these
keywords
as
response
assume
for
now
you
are
twitter
user
with
number
of
tweets
in
your
profile
even
though
these
tweets
are
public
they
are
usually
exposed
just
to
your
followers
but
if
it
turns
out
that
one
of
your
tweets
is
returned
as
top-ranked
result
in
response
to
these
keyword
queries
your
tweet
and
profile
will
be
exposed
to
whoever
issues
these
keywords
there
is
variety
of
people
who
might
be
looking
for
user
profiles
or
tweets
that
match
certain
keywords
examples
include
journalists
looking
for
examples
to
their
stories
companies
building
databases
of
people
for
different
purposes
or
even
criminals
looking
for
victims
in
this
survey
we
will
ask
for
your
opinions
regarding
sensitivity
of
different
keyword
queries
in
the
above
context
more
specifically
we
will
show
you
number
of
search
terms
together
with
the
tweets
that
are
returned
as
top
results
for
these
terms
the
question
is
in
your
opinion
should
user
be
concerned
uncomfortable
embarrassed
privacy-violated
or
threatened
if
the
tweet
was
returned
as
one
of
the
top
answers
to
the
search
terms
question
queries
only
in
your
opinion
should
user
be
concerned
uncomfortable
embarrassed
privacy-violated
or
threatened
if
their
tweet
below
was
returned
as
one
of
the
top
answers
to
these
search
terms
please
try
to
choose
yes
for
at
least
10
12
search
terms
you
would
feel
most
uncomfortable
with
although
you
are
also
free
to
choose
more
search
terms
xxx
yes
no
bibliography
ahmed
abbasi
and
hsinchun
chen
writeprints
stylometric
approach
to
identity-level
identification
and
similarity
detection
in
cyberspace
acm
transactions
on
information
systems
26
29
2008
13
rediet
abebe
jon
kleinberg
and
david
parkes
fair
division
via
social
comparison
in
proceedings
of
the
16th
conference
on
autonomous
agents
and
multiagent
systems
aamas
2017
são
paulo
brazil
may
12
2017
pages
281
289
acm
2017
29
54
alessandro
acquisti
nudging
privacy
the
behavioral
economics
of
personal
information
ieee
security
privacy
82
85
2009
20
alessandro
acquisti
curtis
taylor
and
liad
wagman
the
economics
of
privacy
journal
of
economic
literature
54
442
92
2016
20
lada
adamic
jun
zhang
eytan
bakshy
and
mark
ackerman
knowledge
sharing
and
yahoo
answers
everyone
knows
something
in
proceedings
of
the
17th
international
conference
on
world
wide
web
www
2008
beijing
china
april
21
25
2008
pages
665
674
acm
2008
96
eytan
adar
user
4xxxxx9
anonymizing
query
logs
in
proceedings
of
the
query
log
analysis
workshop
international
conference
on
world
wide
web
2007
18
94
philip
adler
casey
falk
sorelle
friedler
tionney
nix
gabriel
rybeck
carlos
scheidegger
brandon
smith
and
suresh
venkatasubramanian
auditing
black-box
models
for
indirect
influence
knowledge
and
information
systems
54
95
122
2018
25
55
lalit
agarwal
nisheeth
shrivastava
sharad
jaiswal
and
saurabh
panjwani
do
not
embarrass
re-examining
user
concerns
for
online
tracking
and
advertising
in
symposium
on
usable
privacy
and
security
soups
13
newcastle
united
kingdom
july
24
26
2013
pages
13
acm
2013
20
101
charu
aggarwal
data
mining
the
textbook
springer
2015
isbn
978
319
14141
112
istemi
ekin
akkus
ruichuan
chen
michaela
hardt
paul
francis
and
johannes
gehrke
non-tracking
web
analytics
in
the
acm
conference
on
computer
and
communications
security
ccs
12
raleigh
nc
usa
october
16
18
2012
pages
687
698
2012
16
112
mishari
almishari
ekin
oguz
and
gene
tsudik
fighting
authorship
linkability
with
crowdsourcing
in
proceedings
of
the
second
acm
conference
on
online
social
networks
cosn
2014
dublin
ireland
october
2014
pages
69
82
2014
15
mor
armony
and
amy
ward
fair
dynamic
routing
in
large-scale
heterogeneous-server
systems
operations
research
58
624
637
2010
55
122
bibliography
ricardo
baeza-yates
bias
on
the
web
communications
of
the
acm
61
54
61
2018
26
27
ero
balsa
carmela
troncoso
and
claudia
díaz
ob-pws
obfuscation-based
private
web
search
in
ieee
symposium
on
security
and
privacy
sp
2012
21
23
may
2012
san
francisco
california
usa
pages
491
505
ieee
computer
society
2012
112
solon
barocas
and
andrew
selbst
big
data
disparate
impact
california
law
review
104
671
2016
26
27
solon
barocas
moritz
hardt
and
arvind
narayanan
fairness
and
machine
learning
fairmlbook
org
2018
http://www.fairmlbook.org.
23
fuat
basik
bugra
gedik
hakan
ferhatosmanoglu
and
mert
emin
kalender
s3
tm
scalable
streaming
short
text
matching
vldb
journal
24
849
866
2015
73
richard
berk
hoda
heidari
shahin
jabbari
matthew
joseph
michael
kearns
jamie
morgenstern
seth
neel
and
aaron
roth
convex
framework
for
fair
regression
corr
abs
1706.02409
2017
25
michael
bernstein
eytan
bakshy
moira
burke
and
brian
karrer
quantifying
the
invisible
audience
in
social
networks
in
2013
acm
sigchi
conference
on
human
factors
in
computing
systems
chi
13
paris
france
april
27
may
2013
pages
21
30
acm
2013
17
58
elisa
bertino
dan
lin
and
wei
jiang
survey
of
quantification
of
privacy
preserving
data
mining
algorithms
in
privacy-preserving
data
mining
models
and
algorithms
volume
34
of
advances
in
database
systems
pages
183
205
springer
2008
94
98
112
bin
bi
milad
shokouhi
michal
kosinski
and
thore
graepel
inferring
the
demographics
of
search
users
social
data
meets
search
queries
in
22nd
international
world
wide
web
conference
www
13
rio
de
janeiro
brazil
may
13
17
2013
pages
131
140
2013
asia
biega
azin
ghazimatin
hakan
ferhatosmanoglu
krishna
gummadi
and
gerhard
weikum
learning
to
un-rank
quantifying
search
exposure
for
users
in
online
communities
in
proceedings
of
the
2017
acm
on
conference
on
information
and
knowledge
management
cikm
2017
singapore
november
06
10
2017
pages
267
276
2017a
60
65
asia
biega
rishiraj
saha
roy
and
gerhard
weikum
privacy
through
solidarity
user-utility-preserving
framework
to
counter
profiling
in
proceedings
of
the
40th
international
acm
sigir
conference
on
research
and
development
in
information
retrieval
shinjuku
tokyo
japan
august
11
2017
pages
675
684
2017b
13
18
41
113
asia
biega
krishna
gummadi
and
gerhard
weikum
equity
of
attention
amortizing
individual
fairness
in
rankings
in
proceedings
of
the
41st
international
acm
sigir
conference
on
research
development
in
information
retrieval
sigir
2018
ann
arbor
mi
usa
july
08
12
2018
pages
405
414
2018
25
28
bibliography
123
joanna
biega
ida
mele
and
gerhard
weikum
probabilistic
prediction
of
privacy
risks
in
user
search
histories
in
proceedings
of
the
first
international
workshop
on
privacy
and
secuirty
of
big
data
psbd
cikm
2014
shanghai
china
november
2014
pages
29
36
2014
82
94
joanna
asia
biega
krishna
gummadi
ida
mele
dragan
milchevski
christos
tryfonopoulos
and
gerhard
weikum
r-susceptibility
an
ir-centric
approach
to
assessing
privacy
risks
for
users
in
online
communities
in
proceedings
of
the
39th
international
acm
sigir
conference
on
research
and
development
in
information
retrieval
sigir
2016
pisa
italy
july
17
21
2016
pages
365
374
2016
58
62
70
71
112
sarah
bird
solon
barocas
kate
crawford
fernando
diaz
and
hanna
wallach
exploring
or
exploiting
social
and
ethical
implications
of
autonomous
experimentation
in
ai
available
at
ssrn
https://ssrn.com/abstract=2846909,
2016
29
david
blei
andrew
ng
and
michael
jordan
latent
dirichlet
allocation
journal
of
machine
learning
research
993
1022
2003
77
tolga
bolukbasi
kai-wei
chang
james
zou
venkatesh
saligrama
and
adam
tauman
kalai
man
is
to
computer
programmer
as
woman
is
to
homemaker
debiasing
word
embeddings
in
advances
in
neural
information
processing
systems
29
annual
conference
on
neural
information
processing
systems
2016
december
10
2016
barcelona
spain
pages
4349
4357
2016
27
joseph
bonneau
elie
bursztein
ilan
caron
rob
jackson
and
mike
williamson
secrets
lies
and
account
recovery
lessons
from
the
use
of
personal
knowledge
questions
at
google
in
proceedings
of
the
24th
international
conference
on
world
wide
web
www
2015
florence
italy
may
18
22
2015
pages
141
150
acm
2015
72
danah
boyd
facebook
privacy
trainwreck
exposure
invasion
and
social
convergence
convergence
14
13
20
2008
17
58
justin
brickell
and
vitaly
shmatikov
the
cost
of
privacy
destruction
of
data-mining
utility
in
anonymized
data
publishing
in
proceedings
of
the
14th
acm
sigkdd
international
conference
on
knowledge
discovery
and
data
mining
las
vegas
nevada
usa
august
24
27
2008
pages
70
78
2008
18
aylin
caliskan
joanna
bryson
and
arvind
narayanan
semantics
derived
automatically
from
language
corpora
contain
human-like
biases
science
356
6334
183
186
2017
26
ryan
calo
and
alex
rosenblat
the
taking
economy
uber
infrmation
and
power
columbia
law
review
117
1623
2017
29
32
claudio
carpineto
and
giovanni
romano
kθ
affinity
privacy
releasing
infrequent
query
refinements
safely
information
processing
management
51
74
88
2015
77
ben
carterette
and
rosie
jones
evaluating
search
engines
by
modeling
the
relationship
between
relevance
and
clicks
in
advances
in
neural
information
processing
systems
20
124
bibliography
proceedings
of
the
twenty-first
annual
conference
on
neural
information
processing
systems
vancouver
british
columbia
canada
december
2007
pages
217
224
curran
associates
inc
2007
64
elisa
celis
damian
straszak
and
nisheeth
vishnoi
ranking
with
fairness
constraints
in
45th
international
colloquium
on
automata
languages
and
programming
icalp
2018
july
13
2018
prague
czech
republic
pages
28
28
15
2018
23
27
33
36
54
abhijnan
chakraborty
asia
biega
aniko
hannak
and
krishna
gummadi
fair
sharing
for
sharing
economy
platforms
in
proceedings
of
the
fatrec
recsys
workshop
2017
29
55
bee-chung
chen
daniel
kifer
kristen
lefevre
and
ashwin
machanavajjhala
privacypreserving
data
publishing
foundations
and
trends
in
databases
167
2009
98
gang
chen
he
bai
lidan
shou
ke
chen
and
yunjun
gao
ups
efficient
privacy
protection
in
personalized
web
search
in
proceeding
of
the
34th
international
acm
sigir
conference
on
research
and
development
in
information
retrieval
sigir
2011
beijing
china
july
25
29
2011
pages
615
624
2011
16
18
72
98
le
chen
alan
mislove
and
christo
wilson
peeking
beneath
the
hood
of
uber
in
proceedings
of
the
2015
acm
internet
measurement
conference
imc
2015
tokyo
japan
october
28
30
2015
pages
495
508
2015
27
le
chen
ruijun
ma
anikó
hannák
and
christo
wilson
investigating
the
impact
of
gender
on
rank
in
resume
search
engines
in
proceedings
of
the
2018
chi
conference
on
human
factors
in
computing
systems
chi
2018
montreal
qc
canada
april
21
26
2018
page
651
2018
27
lisi
chen
and
gao
cong
diversity-aware
top-k
publish
subscribe
for
text
stream
in
proceedings
of
the
2015
acm
sigmod
international
conference
on
management
of
data
melbourne
victoria
australia
may
31
june
2015
pages
347
362
acm
2015
73
flavio
chierichetti
ravi
kumar
silvio
lattanzi
and
sergei
vassilvitskii
fair
clustering
through
fairlets
in
advances
in
neural
information
processing
systems
30
annual
conference
on
neural
information
processing
systems
2017
december
2017
long
beach
ca
usa
pages
5036
5044
2017
23
benny
chor
oded
goldreich
eyal
kushilevitz
and
madhu
sudan
private
information
retrieval
in
36th
annual
symposium
on
foundations
of
computer
science
milwaukee
wisconsin
usa
23
25
october
1995
pages
41
50
ieee
computer
society
1995
19
alexandra
chouldechova
fair
prediction
with
disparate
impact
study
of
bias
in
recidivism
prediction
instruments
big
data
153
163
2017
23
bibliography
125
aleksandr
chuklin
ilya
markov
and
maarten
de
rijke
click
models
for
web
search
synthesis
lectures
on
information
concepts
retrieval
and
services
morgan
claypool
publishers
2015
22
32
55
alissa
cooper
survey
of
query
log
privacy-enhancing
techniques
from
policy
perspective
tweb
19
19
27
2008
94
112
sam
corbett-davies
and
sharad
goel
the
measure
and
mismeasure
of
fairness
critical
review
of
fair
machine
learning
corr
abs
1808.00023
2018
23
denzil
correa
leandro
araújo
silva
mainack
mondal
fabrício
benevenuto
and
krishna
gummadi
the
many
shades
of
anonymity
characterizing
anonymous
social
media
content
in
proceedings
of
the
ninth
international
conference
on
web
and
social
media
icwsm
2015
university
of
oxford
oxford
uk
may
26
29
2015
pages
71
80
2015
19
64
66
nick
craswell
onno
zoeter
michael
taylor
and
bill
ramsey
an
experimental
comparison
of
click
position-bias
models
in
proceedings
of
the
international
conference
on
web
search
and
web
data
mining
wsdm
2008
palo
alto
california
usa
february
11
12
2008
pages
87
94
acm
2008
32
42
55
bruce
croft
donald
metzler
and
trevor
strohman
search
engines
information
retrieval
in
practice
pearson
education
2009
isbn
978
13
136489
106
107
shane
culpepper
fernando
diaz
and
mark
smucker
research
frontiers
in
information
retrieval
report
from
the
third
strategic
workshop
on
information
retrieval
in
lorne
swirl
2018
sigir
forum
52
34
90
2018
amit
datta
michael
carl
tschantz
and
anupam
datta
automated
experiments
on
ad
privacy
settings
popets
2015
92
112
2015
25
wei-yen
day
and
ninghui
li
differentially
private
publishing
of
high-dimensional
data
using
sensitivity
control
in
feng
bao
steven
miller
jianying
zhou
and
gail-joon
ahn
editors
proceedings
of
the
10th
acm
symposium
on
information
computer
and
communications
security
asia
ccs
15
singapore
april
14
17
2015
pages
451
462
acm
2015
77
georges
dupret
and
benjamin
piwowarski
user
browsing
model
to
predict
search
engine
click
data
from
past
observations
in
proceedings
of
the
31st
annual
international
acm
sigir
conference
on
research
and
development
in
information
retrieval
sigir
2008
singapore
july
20
24
2008
pages
331
338
acm
2008
55
cynthia
dwork
differential
privacy
survey
of
results
in
theory
and
applications
of
models
of
computation
5th
international
conference
tamc
2008
xi
an
china
april
25
29
2008
proceedings
pages
19
2008
15
76
94
98
cynthia
dwork
moritz
hardt
toniann
pitassi
omer
reingold
and
richard
zemel
fairness
through
awareness
in
innovations
in
theoretical
computer
science
2012
cambridge
ma
usa
january
10
2012
pages
214
226
2012
24
33
35
54
126
bibliography
peter
eckersley
how
unique
is
your
web
browser
in
privacy
enhancing
technologies
10th
international
symposium
pets
2010
berlin
germany
july
21
23
2010
proceedings
pages
18
2010
12
benjamin
edelman
michael
ostrovsky
and
michael
schwarz
internet
advertising
and
the
generalized
second-price
auction
selling
billions
of
dollars
worth
of
keywords
american
economic
review
97
242
259
2007
55
carsten
eickhoff
cognitive
biases
in
crowdsourcing
in
proceedings
of
the
eleventh
acm
international
conference
on
web
search
and
data
mining
wsdm
2018
marina
del
rey
ca
usa
february
2018
pages
162
170
acm
2018
26
michael
ekstrand
mucun
tian
ion
madrazo
azpiazu
jennifer
ekstrand
oghenemaro
anuyah
david
mcneill
and
maria
soledad
pera
all
the
cool
kids
how
do
they
fit
in
popularity
and
demographic
biases
in
recommender
evaluation
and
effectiveness
in
conference
on
fairness
accountability
and
transparency
fat
2018
23
24
february
2018
new
york
ny
usa
volume
81
of
proceedings
of
machine
learning
research
pages
172
186
pmlr
2018a
23
michael
ekstrand
mucun
tian
mohammed
imran
kazi
hoda
mehrpouyan
and
daniel
kluver
exploring
author
gender
in
book
rating
and
recommendation
in
proceedings
of
the
12th
acm
conference
on
recommender
systems
recsys
2018
vancouver
bc
canada
october
2018
pages
242
250
2018b
23
tobias
emrich
hans-peter
kriegel
peer
kröger
johannes
niedermayer
matthias
renz
and
andreas
züfle
on
reverse-k-nearest-neighbor
joins
geoinformatica
19
299
330
2015
60
73
danielle
ensign
sorelle
friedler
scott
neville
carlos
scheidegger
and
suresh
venkatasubramanian
runaway
feedback
loops
in
predictive
policing
in
conference
on
fairness
accountability
and
transparency
fat
2018
23
24
february
2018
new
york
ny
usa
volume
81
of
proceedings
of
machine
learning
research
pages
160
171
pmlr
2018
29
sedigheh
eslami
asia
biega
rishiraj
saha
roy
and
gerhard
weikum
privacy
of
hidden
profiles
utility-preserving
profile
removal
in
online
forums
in
proceedings
of
the
2017
acm
on
conference
on
information
and
knowledge
management
cikm
2017
singapore
november
06
10
2017
pages
2063
2066
2017
19
liyue
fan
luca
bonomi
li
xiong
and
vaidy
sunderam
monitoring
web
browsing
behavior
with
differential
privacy
in
proceedings
of
the
23rd
international
world
wide
web
conference
www
14
seoul
republic
of
korea
april
11
2014
pages
177
188
acm
2014
94
112
lujun
fang
and
kristen
lefevre
privacy
wizards
for
social
networking
sites
in
proceedings
of
the
19th
international
conference
on
world
wide
web
www
2010
raleigh
north
carolina
usa
april
26
30
2010
pages
351
360
2010
17
bibliography
127
michael
feldman
sorelle
friedler
john
moeller
carlos
scheidegger
and
suresh
venkatasubramanian
certifying
and
removing
disparate
impact
in
proceedings
of
the
21th
acm
sigkdd
international
conference
on
knowledge
discovery
and
data
mining
sydney
nsw
australia
august
10
13
2015
pages
259
268
2015
23
24
33
54
72
benjamin
fish
jeremy
kun
and
ádám
dániel
lelkes
confidence-based
approach
for
balancing
fairness
and
accuracy
in
proceedings
of
the
2016
siam
international
conference
on
data
mining
miami
florida
usa
may
2016
pages
144
152
siam
2016
25
sorelle
friedler
carlos
scheidegger
suresh
venkatasubramanian
sonam
choudhary
evan
hamilton
and
derek
roth
comparative
study
of
fairness-enhancing
interventions
in
machine
learning
corr
abs
1802.04422
2018
24
batya
friedman
and
helen
nissenbaum
bias
in
computer
systems
acm
transactions
on
information
systems
14
330
347
1996
27
norbert
fuhr
anastasia
giachanou
gregory
grefenstette
iryna
gurevych
andreas
hanselowski
kalervo
järvelin
rosie
jones
yiqun
liu
josiane
mothe
wolfgang
nejdl
isabella
peters
and
benno
stein
an
information
nutritional
label
for
online
documents
sigir
forum
51
46
66
2017
28
benjamin
fung
ke
wang
rui
chen
and
philip
yu
privacy-preserving
data
publishing
survey
of
recent
developments
acm
computing
surveys
42
14
14
53
2010
76
94
98
timnit
gebru
jamie
morgenstern
briana
vecchione
jennifer
wortman
vaughan
hanna
wallach
hal
daumé
iii
and
kate
crawford
datasheets
for
datasets
corr
abs
1803.09010
2018
26
arthur
gervais
reza
shokri
adish
singla
srdjan
capkun
and
vincent
lenders
quantifying
web-search
privacy
in
proceedings
of
the
2014
acm
sigsac
conference
on
computer
and
communications
security
scottsdale
az
usa
november
2014
pages
966
977
2014
19
72
98
ali
ghodsi
matei
zaharia
benjamin
hindman
andy
konwinski
scott
shenker
and
ion
stoica
dominant
resource
fairness
fair
allocation
of
multiple
resource
types
in
proceedings
of
the
8th
usenix
symposium
on
networked
systems
design
and
implementation
nsdi
2011
boston
ma
usa
march
30
april
2011
usenix
association
2011
55
ali
ghodsi
vyas
sekar
matei
zaharia
and
ion
stoica
multi-resource
fair
queueing
for
packet
processing
in
acm
sigcomm
2012
conference
sigcomm
12
helsinki
finland
august
13
17
2012
pages
12
acm
2012
55
oana
goga
howard
lei
sree
hari
krishnan
parthasarathi
gerald
friedland
robin
sommer
and
renata
teixeira
exploiting
innocuous
activity
for
correlating
users
across
sites
in
proceedings
of
the
22nd
international
world
wide
web
conference
www
13
rio
de
janeiro
brazil
may
13
17
2013
pages
447
458
international
world
wide
web
conferences
steering
committee
acm
2013
94
128
bibliography
oana
goga
patrick
loiseau
robin
sommer
renata
teixeira
and
krishna
gummadi
on
the
reliability
of
profile
matching
across
large
online
social
networks
in
proceedings
of
the
21th
acm
sigkdd
international
conference
on
knowledge
discovery
and
data
mining
sydney
nsw
australia
august
10
13
2015
pages
1799
1808
2015
13
michael
goodrich
michael
mitzenmacher
olga
ohrimenko
and
roberto
tamassia
privacy-preserving
group
data
access
via
stateless
oblivious
ram
simulation
in
proceedings
of
the
twenty-third
annual
acm-siam
symposium
on
discrete
algorithms
soda
2012
kyoto
japan
january
17
19
2012
pages
157
167
siam
2012
99
michaela
götz
ashwin
machanavajjhala
guozhang
wang
xiaokui
xiao
and
johannes
gehrke
publishing
search
logs
comparative
study
of
privacy
guarantees
ieee
transactions
on
knowledge
and
data
engineering
24
520
532
2012
18
72
94
112
jerald
greenberg
taxonomy
of
organizational
justice
theories
academy
of
management
review
12
22
1987
33
nina
grgic-hlaca
elissa
redmiles
krishna
gummadi
and
adrian
weller
human
perceptions
of
fairness
in
algorithmic
decision
making
case
study
of
criminal
risk
prediction
in
proceedings
of
the
2018
world
wide
web
conference
on
world
wide
web
www
2018
lyon
france
april
23
27
2018
pages
903
912
2018a
28
nina
grgic-hlaca
muhammad
bilal
zafar
krishna
gummadi
and
adrian
weller
beyond
distributive
fairness
in
algorithmic
decision
making
feature
selection
for
procedurally
fair
learning
in
proceedings
of
the
thirty-second
aaai
conference
on
artificial
intelligence
aaai-18
the
30th
innovative
applications
of
artificial
intelligence
iaai-18
and
the
8th
aaai
symposium
on
educational
advances
in
artificial
intelligence
eaai-18
new
orleans
louisiana
usa
february
2018
pages
51
60
2018b
28
54
rachid
guerraoui
anne-marie
kermarrec
rhicheek
patra
and
mahsa
taziki
d2p
distance-based
differential
privacy
in
recommenders
pvldb
862
873
2015
113
fan
guo
chao
liu
and
yi
min
wang
efficient
multiple-click
models
in
web
search
in
proceedings
of
the
second
international
conference
on
web
search
and
web
data
mining
wsdm
2009
barcelona
spain
february
11
2009
pages
124
131
acm
2009
55
sara
hajian
and
josep
domingo-ferrer
methodology
for
direct
and
indirect
discrimination
prevention
in
data
mining
ieee
transactions
on
knowledge
and
data
engineering
25
1445
1459
2013
24
maria
halkidi
and
iordanis
koutsopoulos
game
theoretic
framework
for
data
privacy
preservation
in
recommender
systems
in
machine
learning
and
knowledge
discovery
in
databases
european
conference
ecml
pkdd
2011
athens
greece
september
2011
proceedings
part
volume
6911
of
lecture
notes
in
computer
science
pages
629
644
springer
2011
112
bibliography
129
aniko
hannak
piotr
sapiezynski
arash
molavi
kakhki
balachander
krishnamurthy
david
lazer
alan
mislove
and
christo
wilson
measuring
personalization
of
web
search
in
22nd
international
world
wide
web
conference
www
13
rio
de
janeiro
brazil
may
13
17
2013
pages
527
538
international
world
wide
web
conferences
steering
committee
acm
2013
98
moritz
hardt
eric
price
and
nati
srebro
equality
of
opportunity
in
supervised
learning
in
advances
in
neural
information
processing
systems
29
annual
conference
on
neural
information
processing
systems
2016
december
10
2016
barcelona
spain
pages
3315
3323
2016
23
25
33
54
xi
he
ashwin
machanavajjhala
and
bolin
ding
blowfish
privacy
tuning
privacy-utility
trade-offs
using
policies
in
international
conference
on
management
of
data
sigmod
2014
snowbird
ut
usa
june
22
27
2014
pages
1447
1458
acm
2014
98
yuan
hong
jaideep
vaidya
haibing
lu
and
mingrui
wu
differentially
private
search
log
sanitization
with
optimal
output
utility
in
15th
international
conference
on
extending
database
technology
edbt
12
berlin
germany
march
27
30
2012
proceedings
pages
50
61
acm
2012
94
bill
howe
julia
stoyanovich
haoyue
ping
bernease
herman
and
matt
gee
synthetic
data
for
social
good
corr
abs
1710.08874
2017
14
daniel
howe
and
helen
nissenbaum
trackmenot
resisting
surveillance
in
web
search
lessons
from
the
identity
trail
anonymity
privacy
and
identity
in
networked
society
23
417
436
2009
16
18
jian
hu
hua-jun
zeng
hua
li
cheng
niu
and
zheng
chen
demographic
prediction
based
on
user
browsing
behavior
in
proceedings
of
the
16th
international
conference
on
world
wide
web
www
2007
banff
alberta
canada
may
12
2007
pages
151
160
acm
2007
94
danny
yuxing
huang
doug
grundman
kurt
thomas
abhishek
kumar
elie
bursztein
kirill
levchenko
and
alex
snoeren
pinning
down
abuse
on
google
maps
in
proceedings
of
the
26th
international
conference
on
world
wide
web
www
2017
perth
australia
april
2017
pages
1471
1479
acm
2017
72
thorsten
joachims
training
linear
svms
in
linear
time
in
proceedings
of
the
twelfth
acm
sigkdd
international
conference
on
knowledge
discovery
and
data
mining
philadelphia
pa
usa
august
20
23
2006
pages
217
226
acm
2006
doi
10.1145
1150402.1150429
61
67
thorsten
joachims
and
filip
radlinski
search
engines
that
learn
from
implicit
feedback
ieee
computer
40
34
40
2007
32
43
55
thorsten
joachims
laura
granka
bing
pan
helene
hembrooke
and
geri
gay
accurately
interpreting
clickthrough
data
as
implicit
feedback
in
sigir
2005
proceedings
of
the
28th
annual
international
acm
sigir
conference
on
research
and
development
in
information
retrieval
salvador
brazil
august
15
19
2005
pages
154
161
2005
26
130
bibliography
thorsten
joachims
adith
swaminathan
and
tobias
schnabel
unbiased
learning-to-rank
with
biased
feedback
in
proceedings
of
the
tenth
acm
international
conference
on
web
search
and
data
mining
wsdm
2017
cambridge
united
kingdom
february
10
2017
pages
781
789
acm
2017
55
rosie
jones
ravi
kumar
bo
pang
and
andrew
tomkins
know
what
you
did
last
summer
query
logs
and
user
privacy
in
proceedings
of
the
sixteenth
acm
conference
on
information
and
knowledge
management
cikm
2007
lisbon
portugal
november
10
2007
pages
909
914
2007
19
94
rosie
jones
ravi
kumar
bo
pang
and
andrew
tomkins
vanity
fair
privacy
in
querylog
bundles
in
proceedings
of
the
17th
acm
conference
on
information
and
knowledge
management
cikm
2008
napa
valley
california
usa
october
26
30
2008
pages
853
862
acm
2008
111
roberto
bayardo
jr
and
rakesh
agrawal
data
privacy
through
optimal
k-anonymization
in
proceedings
of
the
21st
international
conference
on
data
engineering
icde
2005
april
2005
tokyo
japan
pages
217
228
2005
14
pawel
jurczyk
and
eugene
agichtein
discovering
authorities
in
question
answer
communities
by
using
link
analysis
in
proceedings
of
the
sixteenth
acm
conference
on
information
and
knowledge
management
cikm
2007
lisbon
portugal
november
10
2007
pages
919
922
acm
2007
96
gary
kacmarcik
and
michael
gamon
obfuscating
document
stylometry
to
preserve
author
anonymity
in
acl
2006
21st
international
conference
on
computational
linguistics
and
44th
annual
meeting
of
the
association
for
computational
linguistics
proceedings
of
the
conference
sydney
australia
17
21
july
2006
2006
15
faisal
kamiran
toon
calders
and
mykola
pechenizkiy
discrimination
aware
decision
tree
learning
in
icdm
2010
the
10th
ieee
international
conference
on
data
mining
sydney
australia
14
17
december
2010
pages
869
874
ieee
computer
society
2010
doi
10.1109
icdm
2010.50
25
toshihiro
kamishima
shotaro
akaho
hideki
asoh
and
jun
sakuma
fairness-aware
classifier
with
prejudice
remover
regularizer
in
machine
learning
and
knowledge
discovery
in
databases
european
conference
ecml
pkdd
2012
bristol
uk
september
24
28
2012
proceedings
part
ii
pages
35
50
2012
25
33
54
sampath
kannan
michael
kearns
jamie
morgenstern
mallesh
pai
aaron
roth
rakesh
vohra
and
zhiwei
steven
wu
fairness
incentives
for
myopic
agents
in
proceedings
of
the
2017
acm
conference
on
economics
and
computation
ec
17
cambridge
ma
usa
june
26
30
2017
pages
369
386
acm
2017
29
michael
kearns
aaron
roth
and
zhiwei
steven
wu
meritocratic
fairness
for
crosspopulation
selection
in
proceedings
of
the
34th
international
conference
on
machine
learning
icml
2017
sydney
nsw
australia
11
august
2017
pages
1828
1836
2017
24
33
54
bibliography
131
niki
kilbertus
adrià
gascón
matt
kusner
michael
veale
krishna
gummadi
and
adrian
weller
blind
justice
fairness
with
encrypted
sensitive
attributes
in
proceedings
of
the
35th
international
conference
on
machine
learning
icml
2018
stockholmsmässan
stockholm
sweden
july
10
15
2018
pages
2635
2644
2018
25
jon
kleinberg
himabindu
lakkaraju
jure
leskovec
jens
ludwig
and
sendhil
mullainathan
human
decisions
and
machine
predictions
the
quarterly
journal
of
economics
133
237
293
2017a
28
54
jon
kleinberg
sendhil
mullainathan
and
manish
raghavan
inherent
trade-offs
in
the
fair
determination
of
risk
scores
in
8th
innovations
in
theoretical
computer
science
conference
itcs
2017
january
11
2017
berkeley
ca
usa
volume
67
of
lipics
pages
43
43
23
schloss
dagstuhl
leibniz-zentrum
fuer
informatik
2017b
23
aleksandra
korolova
krishnaram
kenthapadi
nina
mishra
and
alexandros
ntoulas
releasing
search
queries
and
clicks
privately
in
proceedings
of
the
18th
international
conference
on
world
wide
web
www
2009
madrid
spain
april
20
24
2009
pages
171
180
acm
2009
94
michal
kosinski
david
stillwell
and
thore
graepel
private
traits
and
attributes
are
predictable
from
digital
records
of
human
behavior
proceedings
of
the
national
academy
of
sciences
110
15
5802
5805
2013
issn
0027
8424
doi
10.1073
pnas
1218772110
13
andreas
krause
and
eric
horvitz
utility-theoretic
approach
to
privacy
in
online
services
journal
of
artificial
intelligence
research
39
633
662
2010
98
joshua
kroll
solon
barocas
edward
felten
joel
reidenberg
david
robinson
and
harlan
yu
accountable
algorithms
university
of
pennsylvania
law
review
165
633
2016
25
juhi
kulshrestha
motahhare
eslami
johnnatan
messias
muhammad
bilal
zafar
saptarshi
ghosh
krishna
gummadi
and
karrie
karahalios
quantifying
search
bias
investigating
sources
of
bias
for
political
searches
in
social
media
in
proceedings
of
the
2017
acm
conference
on
computer
supported
cooperative
work
and
social
computing
cscw
2017
portland
or
usa
february
25
march
2017
pages
417
432
2017
27
ravi
kumar
jasmine
novak
bo
pang
and
andrew
tomkins
on
anonymizing
query
logs
via
token-based
hashing
in
proceedings
of
the
16th
international
conference
on
world
wide
web
www
2007
banff
alberta
canada
may
12
2007
pages
629
638
acm
2007
94
preethi
lahoti
gerhard
weikum
and
krishna
gummadi
ifair
learning
individually
fair
data
representations
for
algorithmic
decision
making
corr
abs
1806.01059
2018
24
alex
leavitt
this
is
throwaway
account
temporary
technical
identities
and
perceptions
of
anonymity
in
massive
online
community
in
proceedings
of
the
18th
acm
conference
on
computer
supported
cooperative
work
social
computing
cscw
2015
vancouver
bc
canada
march
14
18
2015
pages
317
327
2015
20
132
bibliography
kristen
lefevre
david
dewitt
and
raghu
ramakrishnan
incognito
efficient
fulldomain
k-anonymity
in
proceedings
of
the
acm
sigmod
international
conference
on
management
of
data
baltimore
maryland
usa
june
14
16
2005
pages
49
60
2005
14
18
kristen
lefevre
david
dewitt
and
raghu
ramakrishnan
mondrian
multidimensional
k-anonymity
in
proceedings
of
the
22nd
international
conference
on
data
engineering
icde
2006
april
2006
atlanta
ga
usa
page
25
2006
14
jurek
leonhardt
avishek
anand
and
megha
khosla
user
fairness
in
recommender
systems
in
companion
of
the
the
web
conference
2018
on
the
web
conference
2018
www
2018
lyon
france
april
23
27
2018
pages
101
102
acm
2018
25
adam
lerner
anna
kornfeld
simpson
tadayoshi
kohno
and
franziska
roesner
internet
jones
and
the
raiders
of
the
lost
trackers
an
archaeological
study
of
web
tracking
from
1996
to
2016
in
25th
usenix
security
symposium
usenix
security
16
austin
tx
usa
august
10
12
2016
usenix
association
2016
112
karen
levy
and
solon
barocas
designing
against
discrimination
in
online
markets
berkeley
technology
law
journal
32
1183
2017
32
chao
li
daniel
yang
li
gerome
miklau
and
dan
suciu
theory
of
pricing
private
data
acm
transactions
on
database
systems
39
34
34
28
2014
20
ninghui
li
tiancheng
li
and
suresh
venkatasubramanian
t-closeness
privacy
beyond
k-anonymity
and
l-diversity
in
proceedings
of
the
23rd
international
conference
on
data
engineering
icde
2007
the
marmara
hotel
istanbul
turkey
april
15
20
2007
pages
106
115
2007
13
14
18
76
94
98
ninghui
li
wahbeh
qardaji
dong
su
yi
wu
and
weining
yang
membership
privacy
unifying
framework
for
privacy
definitions
in
2013
acm
sigsac
conference
on
computer
and
communications
security
ccs
13
berlin
germany
november
2013
pages
889
900
acm
2013
76
94
tiancheng
li
and
ninghui
li
on
the
tradeoff
between
privacy
and
utility
in
data
publishing
in
proceedings
of
the
15th
acm
sigkdd
international
conference
on
knowledge
discovery
and
data
mining
paris
france
june
28
july
2009
pages
517
526
2009
18
lydia
liu
sarah
dean
esther
rolf
max
simchowitz
and
moritz
hardt
delayed
impact
of
fair
machine
learning
in
proceedings
of
the
35th
international
conference
on
machine
learning
icml
2018
stockholmsmässan
stockholm
sweden
july
10
15
2018
volume
80
of
jmlr
workshop
and
conference
proceedings
pages
3156
3164
jmlr
org
2018
29
kristian
lum
and
william
isaac
to
predict
and
serve
significance
13
14
19
2016
29
bibliography
133
ashwin
machanavajjhala
daniel
kifer
johannes
gehrke
and
muthuramakrishnan
venkitasubramaniam
l-diversity
privacy
beyond
k-anonymity
tkdd
2007
12
14
18
76
94
98
huina
mao
xin
shuai
and
apu
kapadia
loose
tweets
an
analysis
of
privacy
leaks
on
twitter
in
proceedings
of
the
10th
annual
acm
workshop
on
privacy
in
the
electronic
society
wpes
2011
chicago
il
usa
october
17
2011
pages
12
2011
13
rahat
masood
dinusha
vatsalan
muhammad
ikram
and
mohamed
ali
kâafar
incognito
method
for
obfuscating
web
data
in
proceedings
of
the
2018
world
wide
web
conference
on
world
wide
web
www
2018
lyon
france
april
23
27
2018
pages
267
276
acm
2018
16
alessandra
mazzia
kristen
lefevre
and
eytan
adar
the
pviz
comprehension
tool
for
social
network
privacy
settings
in
symposium
on
usable
privacy
and
security
soups
12
washington
dc
usa
july
11
13
2012
page
13
2012
17
andrew
kachites
mccallum
mallet
machine
learning
for
language
toolkit
2002
89
117
andrew
mcdonald
sadia
afroz
aylin
caliskan
ariel
stolerman
and
rachel
greenstadt
use
fewer
instances
of
the
letter
toward
writing
style
anonymization
in
privacy
enhancing
technologies
12th
international
symposium
pets
2012
vigo
spain
july
11
13
2012
proceedings
pages
299
318
2012
15
frank
mcsherry
and
ilya
mironov
differentially
private
recommender
systems
building
privacy
into
the
netflix
prize
contenders
in
proceedings
of
the
15th
acm
sigkdd
international
conference
on
knowledge
discovery
and
data
mining
paris
france
june
28
july
2009
pages
627
636
acm
2009
112
rishabh
mehrotra
ashton
anderson
fernando
diaz
amit
sharma
hanna
wallach
and
emine
yilmaz
auditing
search
engines
for
differential
satisfaction
across
demographics
in
proceedings
of
the
26th
international
conference
on
world
wide
web
companion
perth
australia
april
2017
pages
626
633
acm
2017
23
28
55
72
rishabh
mehrotra
james
mcinerney
hugues
bouchard
mounia
lalmas
and
fernando
diaz
towards
fair
marketplace
counterfactual
evaluation
of
the
trade-off
between
relevance
fairness
satisfaction
in
recommendation
systems
in
proceedings
of
the
27th
acm
international
conference
on
information
and
knowledge
management
cikm
2018
torino
italy
october
22
26
2018
pages
2243
2251
2018
23
25
wei
meng
ren
ding
simon
chung
steven
han
and
wenke
lee
the
price
of
free
privacy
leakage
in
personalized
mobile
in-apps
ads
in
23rd
annual
network
and
distributed
system
security
symposium
ndss
2016
san
diego
california
usa
february
21
24
2016
the
internet
society
2016a
112
wei
meng
byoungyoung
lee
xinyu
xing
and
wenke
lee
trackmeornot
enabling
flexible
control
on
web
tracking
in
proceedings
of
the
25th
international
conference
on
world
wide
web
www
2016
montreal
canada
april
11
15
2016
pages
99
109
2016b
13
16
112
134
bibliography
tomas
mikolov
ilya
sutskever
kai
chen
gregory
corrado
and
jeffrey
dean
distributed
representations
of
words
and
phrases
and
their
compositionality
in
advances
in
neural
information
processing
systems
26
27th
annual
conference
on
neural
information
processing
systems
2013
proceedings
of
meeting
held
december
2013
lake
tahoe
nevada
united
states
pages
3111
3119
2013
77
82
89
mainack
mondal
peter
druschel
krishna
gummadi
and
alan
mislove
beyond
access
control
managing
online
privacy
via
exposure
in
proceedings
of
the
workshop
on
useable
security
pages
2014
58
71
mainack
mondal
johnnatan
messias
saptarshi
ghosh
krishna
gummadi
and
aniket
kate
forgetting
in
social
media
understanding
and
controlling
longitudinal
exposure
of
socially
shared
data
in
twelfth
symposium
on
usable
privacy
and
security
soups
2016
denver
co
usa
june
22
24
2016
pages
287
299
2016
13
17
19
58
64
65
66
71
arvind
narayanan
and
vitaly
shmatikov
obfuscated
databases
and
group
privacy
in
proceedings
of
the
12th
acm
conference
on
computer
and
communications
security
ccs
2005
alexandria
va
usa
november
11
2005
pages
102
111
acm
2005
111
arvind
narayanan
and
vitaly
shmatikov
robust
de-anonymization
of
large
sparse
datasets
in
2008
ieee
symposium
on
security
and
privacy
2008
18
21
may
2008
oakland
california
usa
pages
111
125
2008
12
arvind
narayanan
and
vitaly
shmatikov
de-anonymizing
social
networks
in
30th
ieee
symposium
on
security
and
privacy
2009
17
20
may
2009
oakland
california
usa
pages
173
187
2009
12
94
arvind
narayanan
hristo
paskov
neil
zhenqiang
gong
john
bethencourt
emil
stefanov
eui
chul
richard
shin
and
dawn
song
on
the
feasibility
of
internet-scale
author
identification
in
ieee
symposium
on
security
and
privacy
sp
2012
21
23
may
2012
san
francisco
california
usa
pages
300
314
2012
13
94
guillermo
navarro-arribas
vicenç
torra
arnau
erola
and
jordi
castellà-roca
user
k-anonymity
for
privacy
preserving
data
mining
of
query
logs
information
processing
management
48
476
487
2012
77
valeria
nikolaenko
stratis
ioannidis
udi
weinsberg
marc
joye
nina
taft
and
dan
boneh
privacy-preserving
matrix
factorization
in
2013
acm
sigsac
conference
on
computer
and
communications
security
ccs
13
berlin
germany
november
2013
pages
801
812
acm
2013
112
alexandra
olteanu
carlos
castillo
fernando
diaz
and
emre
kiciman
social
data
biases
methodological
pitfalls
and
ethical
boundaries
available
at
ssrn
https://ssrn.com/abstract=2886526,
2016
26
27
hweehwa
pang
xiaokui
xiao
and
jialie
shen
obfuscating
the
topical
intention
in
enterprise
text
search
in
ieee
28th
international
conference
on
data
engineering
icde
2012
bibliography
135
washington
dc
usa
arlington
virginia
april
2012
pages
1168
1179
2012
16
18
94
sai
teja
peddinti
and
nitesh
saxena
on
the
privacy
of
web
search
based
on
query
obfuscation
case
study
of
trackmenot
in
privacy
enhancing
technologies
10th
international
symposium
pets
2010
berlin
germany
july
21
23
2010
proceedings
pages
19
37
2010
19
sai
teja
peddinti
and
nitesh
saxena
web
search
query
privacy
evaluating
query
obfuscation
and
anonymizing
networks
journal
of
computer
security
22
155
199
2014
98
112
sai
teja
peddinti
aleksandra
korolova
elie
bursztein
and
geetanjali
sampemane
cloak
and
swagger
understanding
data
sensitivity
through
the
lens
of
user
anonymity
in
2014
ieee
symposium
on
security
and
privacy
sp
2014
berkeley
ca
usa
may
18
21
2014
pages
493
508
2014
19
77
78
94
dino
pedreschi
salvatore
ruggieri
and
franco
turini
discrimination-aware
data
mining
in
proceedings
of
the
14th
acm
sigkdd
international
conference
on
knowledge
discovery
and
data
mining
las
vegas
nevada
usa
august
24
27
2008
pages
560
568
2008
24
33
54
marco
pennacchiotti
and
ana-maria
popescu
machine
learning
approach
to
twitter
user
classification
in
proceedings
of
the
fifth
international
conference
on
weblogs
and
social
media
barcelona
catalonia
spain
july
17
21
2011
the
aaai
press
2011
96
forough
poursabzi-sangdeh
daniel
goldstein
jake
hofman
jennifer
wortman
vaughan
and
hanna
wallach
manipulating
and
measuring
model
interpretability
corr
abs
1802.07810
2018
28
david
rebollo-monedero
jordi
forné
and
josep
domingo-ferrer
query
profile
obfuscation
by
means
of
optimal
query
exchange
between
users
ieee
transactions
on
dependable
and
secure
computing
641
654
2012
99
112
michael
reiter
and
aviel
rubin
crowds
anonymity
for
web
transactions
acm
transactions
on
information
and
system
security
66
92
1998
16
99
111
marian-andrei
rizoiu
lexing
xie
tibério
caetano
and
manuel
cebrián
evolution
of
privacy
loss
in
wikipedia
in
proceedings
of
the
ninth
acm
international
conference
on
web
search
and
data
mining
san
francisco
ca
usa
february
22
25
2016
pages
215
224
2016
19
ronald
robertson
david
lazer
and
christo
wilson
auditing
the
personalization
and
composition
of
politically-related
search
engine
results
pages
in
proceedings
of
the
2018
world
wide
web
conference
on
world
wide
web
www
2018
lyon
france
april
23
27
2018
pages
955
965
acm
2018
27
andrea
romei
and
salvatore
ruggieri
multidisciplinary
survey
on
discrimination
analysis
knowledge
eng
review
29
582
638
2014
54
136
bibliography
alex
rosenblat
and
luke
stark
algorithmic
labor
and
information
asymmetries
case
study
of
uber
drivers
international
journal
of
communication
10
27
2016
29
ravi
sandhu
edward
coyne
hal
feinstein
and
charles
youman
role-based
access
control
models
ieee
computer
29
38
47
1996
13
16
nuno
santos
alan
mislove
marcel
dischinger
and
krishna
gummadi
anonymity
in
the
personalized
web
in
nsdi
posters
08
2008
99
roman
schlegel
apu
kapadia
and
adam
lee
eyeing
your
exposure
quantifying
and
controlling
information
sharing
for
improved
privacy
in
symposium
on
usable
privacy
and
security
soups
11
pittsburgh
pa
usa
july
20
22
2011
page
14
acm
2011
17
58
71
xuehua
shen
bin
tan
and
chengxiang
zhai
privacy
protection
in
personalized
search
sigir
forum
41
17
2007
72
112
yilin
shen
and
hongxia
jin
epicrec
towards
practical
differentially
private
framework
for
personalized
recommendation
in
proceedings
of
the
2016
acm
sigsac
conference
on
computer
and
communications
security
vienna
austria
october
24
28
2016
pages
180
191
acm
2016
112
reza
shokri
george
theodorakopoulos
george
danezis
jean-pierre
hubaux
and
jeanyves
le
boudec
quantifying
location
privacy
the
case
of
sporadic
location
exposure
in
privacy
enhancing
technologies
11th
international
symposium
pets
2011
waterloo
on
canada
july
27
29
2011
proceedings
volume
6794
of
lecture
notes
in
computer
science
pages
57
76
springer
2011
58
71
ashudeep
singh
and
thorsten
joachims
fairness
of
exposure
in
rankings
in
proceedings
of
the
24th
acm
sigkdd
international
conference
on
knowledge
discovery
data
mining
kdd
2018
london
uk
august
19
23
2018
pages
2219
2228
2018
23
25
28
33
36
54
adish
singla
eric
horvitz
ece
kamar
and
ryen
white
stochastic
privacy
in
proceedings
of
the
twenty-eighth
aaai
conference
on
artificial
intelligence
july
27
31
2014
québec
city
québec
canada
pages
152
158
2014
13
15
18
94
112
trevor
strohman
donald
metzler
howard
turtle
and
bruce
croft
indri
language
model-based
search
engine
for
complex
queries
in
proceedings
of
the
international
conference
on
intelligent
analysis
volume
pages
2005
107
latanya
sweeney
achieving
k-anonymity
privacy
protection
using
generalization
and
suppression
international
journal
of
uncertainty
fuzziness
and
knowledge-based
systems
10
571
588
2002a
14
latanya
sweeney
k-anonymity
model
for
protecting
privacy
international
journal
of
uncertainty
fuzziness
and
knowledge-based
systems
10
557
570
2002b
12
14
76
94
98
bibliography
137
latanya
sweeney
discrimination
in
online
ad
delivery
communications
of
the
acm
56
44
54
2013
25
yla
tausczik
and
james
pennebaker
the
psychological
meaning
of
words
liwc
and
computerized
text
analysis
methods
journal
of
language
and
social
psychology
29
24
54
2010
62
jaime
teevan
susan
dumais
and
eric
horvitz
personalizing
search
via
automated
analysis
of
interests
and
activities
in
in
proceedings
of
the
28th
annual
international
acm
sigir
conference
on
research
and
development
in
information
retrieval
sigir
2005
salvador
brazil
august
15
19
2005
pages
449
456
acm
2005
98
vincent
toubiana
arvind
narayanan
dan
boneh
helen
nissenbaum
and
solon
barocas
adnostic
privacy
preserving
targeted
advertising
in
proceedings
of
the
network
and
distributed
system
security
symposium
ndss
2010
san
diego
california
usa
28th
february
3rd
march
2010
2010
16
blase
ur
pedro
giovanni
leon
lorrie
faith
cranor
richard
shay
and
yang
wang
smart
useful
scary
creepy
perceptions
of
online
behavioral
advertising
in
symposium
on
usable
privacy
and
security
soups
12
washington
dc
usa
july
11
13
2012
page
acm
2012
20
isabel
valera
adish
singla
and
manuel
gomez
rodriguez
enhancing
the
accuracy
and
fairness
of
human
decision
making
in
advances
in
neural
information
processing
systems
31
annual
conference
on
neural
information
processing
systems
2018
neurips
2018
december
2018
montréal
canada
pages
1774
1783
2018
28
dinusha
vatsalan
peter
christen
and
vassilios
verykios
taxonomy
of
privacypreserving
record
linkage
techniques
information
systems
38
946
969
2013
94
akrivi
vlachou
christos
doulkeridis
yannis
kotidis
and
kjetil
nørvåg
monochromatic
and
bichromatic
reverse
top-k
queries
ieee
transactions
on
knowledge
and
data
engineering
23
1215
1229
2011
73
jilles
vreeken
matthijs
van
leeuwen
and
arno
siebes
preserving
privacy
through
data
generation
in
proceedings
of
the
7th
ieee
international
conference
on
data
mining
icdm
2007
october
28
31
2007
omaha
nebraska
usa
pages
685
690
2007
14
elaine
walster
ellen
berscheid
and
william
walster
new
directions
in
equity
research
journal
of
personality
and
social
psychology
25
151
1973
33
35
peng
wang
and
chinya
ravishankar
on
masking
topical
intent
in
keyword
search
in
ieee
30th
international
conference
on
data
engineering
chicago
icde
2014
il
usa
march
31
april
2014
pages
256
267
2014
16
18
72
112
xuanhui
wang
michael
bendersky
donald
metzler
and
marc
najork
learning
to
rank
with
selection
bias
in
personal
search
in
proceedings
of
the
39th
international
acm
sigir
conference
on
research
and
development
in
information
retrieval
sigir
2016
pisa
italy
july
17
21
2016
pages
115
124
acm
2016
55
138
bibliography
ingmar
weber
and
carlos
castillo
the
demographics
of
web
search
in
proceeding
of
the
33rd
international
acm
sigir
conference
on
research
and
development
in
information
retrieval
sigir
2010
geneva
switzerland
july
19
23
2010
pages
523
530
acm
2010
94
yongkai
wu
lu
zhang
and
xintao
wu
on
discrimination
discovery
and
removal
in
ranked
data
using
causal
graph
in
proceedings
of
the
24th
acm
sigkdd
international
conference
on
knowledge
discovery
data
mining
kdd
2018
london
uk
august
19
23
2018
pages
2536
2544
2018
28
yabo
xu
ke
wang
benyu
zhang
and
zheng
chen
privacy-enhancing
personalized
web
search
in
proceedings
of
the
16th
international
conference
on
world
wide
web
www
2007
banff
alberta
canada
may
12
2007
pages
591
600
2007
16
18
72
112
yabo
xu
ke
wang
guoliang
yang
and
ada
wai-chee
fu
online
anonymity
for
personalized
web
services
in
proceedings
of
the
18th
acm
conference
on
information
and
knowledge
management
cikm
2009
hong
kong
china
november
2009
pages
1497
1500
acm
2009
99
menahem
yaari
and
maya
bar-hillel
on
dividing
justly
social
choice
and
welfare
24
1984
35
grace
hui
yang
ian
soboroff
li
xiong
charles
clarke
and
simson
garfinkel
privacy-preserving
ir
2016
differential
privacy
search
and
social
media
in
proceedings
of
the
39th
international
acm
sigir
conference
on
research
and
development
in
information
retrieval
sigir
2016
pisa
italy
july
17
21
2016
pages
1247
1248
acm
2016
112
ke
yang
and
julia
stoyanovich
measuring
fairness
in
ranked
outputs
in
proceedings
of
the
29th
international
conference
on
scientific
and
statistical
database
management
chicago
il
usa
june
27
29
2017
pages
22
22
acm
2017
23
28
33
36
54
ke
yang
julia
stoyanovich
abolfazl
asudeh
bill
howe
jagadish
and
gerome
miklau
nutritional
label
for
rankings
in
proceedings
of
the
2018
international
conference
on
management
of
data
sigmod
conference
2018
houston
tx
usa
june
10
15
2018
pages
1773
1776
acm
2018
28
sirui
yao
and
bert
huang
beyond
parity
fairness
objectives
for
collaborative
filtering
in
advances
in
neural
information
processing
systems
30
annual
conference
on
neural
information
processing
systems
2017
december
2017
long
beach
ca
usa
pages
2925
2934
2017
23
25
sergey
yekhanin
private
information
retrieval
commununications
of
the
acm
53
68
73
2010
94
zhonghao
yu
sam
macbeth
konark
modi
and
josep
pujol
tracking
the
trackers
in
proceedings
of
the
25th
international
conference
on
world
wide
web
www
2016
montreal
canada
april
11
15
2016
pages
121
132
2016
13
16
112
bibliography
139
muhammad
bilal
zafar
isabel
valera
manuel
gomez-rodriguez
and
krishna
gummadi
fairness
beyond
disparate
treatment
disparate
impact
learning
classification
without
disparate
mistreatment
in
proceedings
of
the
26th
international
conference
on
world
wide
web
www
2017
perth
australia
april
2017
pages
1171
1180
2017
23
25
33
54
meike
zehlike
and
carlos
castillo
reducing
disparate
exposure
in
ranking
learning
to
rank
approach
corr
abs
1805.08716
2018
28
meike
zehlike
francesco
bonchi
carlos
castillo
sara
hajian
mohamed
megahed
and
ricardo
baeza-yates
fa
ir
fair
top-k
ranking
algorithm
in
proceedings
of
the
2017
acm
on
conference
on
information
and
knowledge
management
cikm
2017
singapore
november
06
10
2017
pages
1569
1578
acm
2017
23
25
27
33
36
54
richard
zemel
yu
wu
kevin
swersky
toniann
pitassi
and
cynthia
dwork
learning
fair
representations
in
proceedings
of
the
30th
international
conference
on
machine
learning
icml
2013
atlanta
ga
usa
16
21
june
2013
volume
28
of
jmlr
workshop
and
conference
proceedings
pages
325
333
jmlr
org
2013
24
33
54
aston
zhang
xing
xie
kevin
chen-chuan
chang
carl
gunter
jiawei
han
and
xiaofeng
wang
privacy
risk
in
anonymized
heterogeneous
information
networks
in
proceedings
of
the
17th
international
conference
on
extending
database
technology
edbt
2014
athens
greece
march
24
28
2014
pages
595
606
openproceedings
org
2014
94
jun
zhang
mark
ackerman
and
lada
adamic
expertise
networks
in
online
communities
structure
and
algorithms
in
proceedings
of
the
16th
international
conference
on
world
wide
web
www
2007
banff
alberta
canada
may
12
2007
pages
221
230
acm
2007
96
sicong
zhang
and
grace
hui
yang
deriving
differentially
private
session
logs
for
query
suggestion
in
proceedings
of
the
acm
sigir
international
conference
on
theory
of
information
retrieval
ictir
2017
amsterdam
the
netherlands
october
2017
pages
51
58
2017
18
sicong
zhang
grace
hui
yang
and
lisa
singh
anonymizing
query
logs
by
differential
privacy
in
proceedings
of
the
39th
international
acm
sigir
conference
on
research
and
development
in
information
retrieval
sigir
2016
pisa
italy
july
17
21
2016
pages
753
756
acm
2016a
72
112
sicong
zhang
grace
hui
yang
lisa
singh
and
li
xiong
safelog
supporting
web
search
and
mining
by
differentially-private
query
logs
in
2016
aaai
fall
symposia
arlington
virginia
usa
november
17
19
2016
2016b
18
yang
zhang
mathias
humbert
tahleen
rahman
cheng-te
li
jun
pang
and
michael
backes
tagvisor
privacy
advisor
for
sharing
hashtags
in
proceedings
of
the
2018
conference
on
world
wide
web
www
2018
lyon
france
april
23
27
2018
pages
287
296
2018
13
15
140
bibliography
elena
zheleva
and
lise
getoor
to
join
or
not
to
join
the
illusion
of
privacy
in
social
networks
with
mixed
public
and
private
user
profiles
in
proceedings
of
the
18th
international
conference
on
world
wide
web
www
2009
madrid
spain
april
20
24
2009
pages
531
540
2009
15
yun
zhu
li
xiong
and
christopher
verdery
anonymizing
user
profiles
for
personalized
web
search
in
proceedings
of
the
19th
international
conference
on
world
wide
web
www
2010
raleigh
north
carolina
usa
april
26
30
2010
pages
1225
1226
2010
18
72
111
list
of
figures
1.1
schematic
depiction
of
search
system
users
participate
in
the
system
either
as
searchers
or
search
subjects
4.1
4.2
relevance
distributions
in
the
airbnb
datasets
44
comparison
of
the
attention
and
relevance
distributions
for
the
top-10
ranking
positions
in
the
geneva
dataset
note
that
the
relevance
distribution
presented
here
is
the
same
as
in
fig
4.1
to
satisfy
equity-of-attention
fairness
the
two
distributions
would
have
to
be
the
same
44
4.3
model
performance
on
the
synthetic
uniform
dataset
attention
singular
45
4.4
model
performance
on
the
synthetic
linear
dataset
attention
singular
45
4.5
model
performance
on
the
synthetic
exponential
dataset
attention
singular
46
4.6
model
performance
on
the
synthetic
uniform
dataset
attention
geometric
46
4.7
model
performance
on
the
synthetic
linear
dataset
attention
geometric
47
4.8
model
performance
on
the
synthetic
exponential
dataset
attention
geometric
47
4.9
performance
of
the
objective
heuristic
on
the
synthetic
uniform
dataset
under
the
geometric
attention
model
with
different
attention
cut-off
points
48
4.10
model
performance
on
the
single-query
boston
dataset
attention
singular
49
4.11
model
performance
on
the
single-query
geneva
dataset
attention
singular
50
4.12
model
performance
on
the
single-query
hong
kong
dataset
attention
singular
50
4.13
model
performance
on
the
multi-query
boston
dataset
attention
singular
51
4.14
model
performance
on
the
multi-query
geneva
dataset
attention
singular
51
4.15
model
performance
on
the
multi-query
hong
kong
dataset
attention
singular
52
4.16
model
performance
on
the
single-query
boston
dataset
attention
geometric
results
are
similar
for
the
geneva
and
hong
kong
datasets
53
4.17
actual
values
of
ranking
quality
boston
dataset
attention
singular
53
5.1
5.2
distribution
of
the
size
of
exposure
sets
the
values
on
axis
are
in
logarithmic
scale
with
base
10
influence
of
the
tweet
context
on
search
exposure
relevance
the
number
in
square
denotes
the
number
of
tweets
that
received
the
score
of
in
the
study
with
queries
only
and
the
score
of
in
the
study
with
queries
in
context
66
71
6.1
example
comparison
of
risk
scores
of
sample
vs
full
data
88
7.1
7.2
7.3
7.4
overview
of
the
ma
framework
100
model
measures
per
user
109
empirical
measures
per
user
110
effect
of
profile
size
and
diversity
111
list
of
tables
5.1
5.2
5.3
5.4
7.1
example
queries
from
unprocessed
exposure
sets
most
important
semantic
features
learned
by
the
l2r
model
together
with
example
queries
exposure
set
ranking
user-study
results
averaged
over
all
users
methods
marked
with
perform
significantly
worse
than
l2r
on
given
metric
paired
t-test
0.05
top-10
sensitive
exposing
queries
returned
by
the
l2r
model
for
subset
of
users
61
67
69
72
results
with
trade-off
parameter
for
the
model
and
empirical
measures
108