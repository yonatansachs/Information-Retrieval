fairness
in
online
jobs
case
study
on
taskrabbit
and
google
sihem
amer-yahia
shady
elbassuoni
ahmad
ghizzawi
ria
mae
borromeo
emilie
hoareau
philippe
mulhem
to
cite
this
version
sihem
amer-yahia
shady
elbassuoni
ahmad
ghizzawi
ria
mae
borromeo
emilie
hoareau
et
al
fairness
in
online
jobs
case
study
on
taskrabbit
and
google
international
conference
on
extending
database
technologies
edbt
2020
copenhagen
denmark
10.5441
002
edbt
2020.62
hal-02972559
hal
id
hal-02972559
https://hal.science/hal-02972559v1
submitted
on
20
oct
2020
hal
is
multi-disciplinary
open
access
archive
for
the
deposit
and
dissemination
of
scientific
research
documents
whether
they
are
published
or
not
the
documents
may
come
from
teaching
and
research
institutions
in
france
or
abroad
or
from
public
or
private
research
centers
archive
ouverte
pluridisciplinaire
hal
est
destinée
au
dépôt
et
la
diffusion
de
documents
scientifiques
de
niveau
recherche
publiés
ou
non
émanant
des
établissements
enseignement
et
de
recherche
français
ou
étrangers
des
laboratoires
publics
ou
privés
industry
and
applications
paper
fairness
in
online
jobs
case
study
on
taskrabbit
and
google
applications
paper
sihem
amer-yahia
shady
elbassuoni
ahmad
ghizzawi
cnrs
univ
grenoble
alpes
france
sihem
amer-yahia
univ-grenoble-alpes
fr
american
university
of
beirut
lebanon
se58@aub.edu.lb
american
university
of
beirut
lebanon
ahg05@mail.aub.edu
ria
mae
borromeo
emilie
hoareau
philippe
mulhem
up
open
university
philippines
rhborromeo@up.edu.ph
iae
univ
grenoble
alpes
france
emilie
hoareau
univ-grenoble-alpes
fr
cnrs
univ
grenoble
alpes
france
philippe
mulhem
univ-grenoble-alpes
fr
abstract
in
online
job
search
either
jobs
are
ranked
for
people
or
people
are
ranked
for
jobs
for
instance
on
google
and
facebook
job
search
potential
employee
sees
ranked
list
of
jobs
while
on
taskrabbit
an
employer
sees
ranked
list
of
potential
employees
this
ranking
of
jobs
or
individuals
naturally
poses
the
question
of
fairness
for
instance
consider
two
different
users
searching
for
software
development
job
in
san
francisco
using
google
job
search
if
the
users
are
shown
different
jobs
based
on
their
search
and
browsing
history
which
could
correlate
with
their
demographics
such
as
race
or
gender
this
may
be
considered
unfair
similarly
ranking
of
job
seekers
in
nyc
might
be
unfair
if
it
is
biased
towards
certain
groups
of
people
say
where
white
males
are
consistently
ranked
above
black
males
or
white
females
this
can
commonly
happen
since
such
rankings
might
depend
on
the
ratings
of
individuals
and
the
number
of
jobs
they
completed
both
of
which
can
perpetuate
bias
against
certain
groups
of
individuals
in
this
paper
we
propose
to
quantify
unfairness
in
ranking
when
looking
for
jobs
online
we
develop
unified
framework
to
address
group
unfairness
which
is
defined
as
the
unequal
treatment
of
individuals
based
on
their
protected
attributes
such
as
gender
race
ethnicity
neighborhood
income
etc
11
to
quantify
unfairness
for
group
we
measure
the
difference
in
rankings
between
that
group
and
its
comparable
groups
those
groups
which
share
at
least
one
protected
attribute
value
with
the
given
group
for
instance
consider
the
group
black
females
comparable
groups
would
be
black
males
white
females
and
asian
females
the
difference
in
ranking
naturally
depends
on
what
is
being
ranked
jobs
or
people
and
we
formalize
various
measures
of
unfairness
on
different
types
of
sites
job
search
sites
and
online
job
marketplaces
figures
and
illustrate
examples
of
job
ranking
on
google
job
search
and
people
ranking
on
taskrabbit
respectively
for
given
query
on
google
job
search
home
cleaning
in
location
san
francisco
in
figure
we
quantify
unfairness
in
ranking
for
given
demographic
group
black
females
using
kendall
tau
we
also
use
jaccard
coefficient
in
our
data
model
between
the
search
results
of
black
females
and
all
other
users
in
comparable
groups
as
is
done
in
12
to
quantify
unfairness
for
black
females
on
taskrabbit
for
the
query
cleaning
services
in
location
new
york
city
we
compute
the
average
earth
mover
distance
20
between
the
distribution
of
rankings
of
black
females
and
all
comparable
groups
as
in
11
in
our
framework
we
also
compute
the
difference
of
exposure
of
workers
from
this
demographic
group
and
their
relevance
in
online
job
marketplaces
are
becoming
very
popular
either
jobs
or
people
are
ranked
by
algorithms
for
example
google
and
facebook
job
search
return
ranked
list
of
jobs
given
search
query
taskrabbit
and
fiverr
on
the
other
hand
produce
rankings
of
workers
for
given
query
qapa
an
online
marketplace
can
be
used
to
rank
both
workers
and
jobs
in
this
paper
we
develop
unified
framework
for
fairness
to
study
ranking
workers
and
jobs
we
case
study
two
particular
sites
google
job
search
and
taskrabbit
our
framework
addresses
group
fairness
where
groups
are
obtained
with
any
combination
of
protected
attributes
we
define
measure
for
unfairness
for
given
group
query
and
location
we
also
define
two
generic
fairness
problems
that
we
address
in
our
framework
quantification
such
as
finding
the
groups
resp
queries
locations
for
which
the
site
is
most
or
least
unfair
and
comparison
such
as
finding
the
locations
at
which
fairness
between
two
groups
differs
from
all
locations
or
finding
the
queries
for
which
fairness
at
two
locations
differ
from
all
queries
since
the
number
of
groups
queries
and
locations
can
be
arbitrarily
large
we
adapt
fagin
top-k
algorithms
to
address
our
fairness
problems
to
evaluate
our
framework
we
run
extensive
experiments
on
two
datasets
crawled
from
taskrabbit
and
google
job
search
introduction
online
job
search
is
gaining
popularity
as
it
allows
to
find
people
to
hire
for
jobs
or
to
find
jobs
to
apply
for
many
online
job
search
sites
exist
nowadays
such
as
facebook
job
search1
and
google
job
search2
on
those
sites
users
can
find
jobs
that
match
their
skills
in
nearby
businesses
on
the
other
hand
freelancing
platforms
such
as
taskrabbit3
and
fiverr4
are
examples
of
online
job
marketplaces
that
provide
access
to
pool
of
temporary
employees
in
the
physical
world
looking
for
plumber
or
employees
to
complete
virtual
micro-gigs
such
as
designing
logo
https://www.facebook.com/jobs/
https://jobs.google.com/about/
https://www.taskrabbit.com/
https://www.fiverr.com/
2020
copyright
held
by
the
owner
author
published
in
proceedings
of
the
23rd
international
conference
on
extending
database
technology
edbt
march
30
april
2020
isbn
978
89318
083
on
openproceedings
org
distribution
of
this
paper
is
permitted
under
the
terms
of
the
creative
commons
license
cc-by-nc-nd
4.0
series
issn
2367
2005
510
10.5441
002
edbt
2020.62
house
cleaner
than
as
gardener
and
which
jobs
are
the
most
likely
to
accept
hiring
asian
females
over
black
females
we
develop
efficient
fagin
top-k
algorithms
to
solve
our
problems
our
algorithms
make
use
of
three
types
of
indices
groupbased
query-based
and
location-based
that
pre-compute
unfairness
values
for
combinations
of
groups
queries
and
locations
for
faster
processing
to
evaluate
our
framework
we
run
extensive
experiments
on
two
datasets
crawled
from
google
job
search
and
taskrabbit
the
choice
of
these
two
platforms
is
justified
by
our
goal
to
show
the
applicability
of
our
framework
to
two
different
treatments
of
online
employment
namely
ranking
jobs
and
ranking
workers
we
ran
361
queries
on
taskrabbit
and
extracted
for
each
query
the
rank
of
each
tasker
their
profile
pictures
and
demographics
where
the
number
of
taskers
returned
per
query
was
limited
to
50
we
processed
the
results
and
recorded
unfairness
values
we
then
derived
user
groups
of
interest
and
equivalent
google
search
terms
from
data
crawled
from
taskrabbit
this
resulted
in
20
queries
the
top
10
and
bottom
10
frequently
searched
queries
and
their
corresponding
locations
from
data
crawled
in
taskrabbit
we
setup
60
user
studies
on
prolific
academic5
and
recruited
participants
who
belong
to
chosen
groups
to
control
for
noise
in
search
we
asked
those
participants
to
use
google
chrome
extension
we
developed
that
automatically
executes
on
google
the
search
queries
in
10
locations
we
processed
the
results
and
recorded
unfairness
values
our
results
are
organized
into
the
two
problems
we
solve
fairness
quantification
and
fairness
comparison
on
taskrabbit
we
found
that
asian
females
and
asian
males
are
the
ones
most
discriminated
against
we
also
found
that
handyman
and
yard
work
are
the
most
unfair
jobs
and
that
furniture
assembly
and
delivery
are
the
fairest
and
that
birmingham
uk
and
oklahoma
city
ok
are
the
least
fair
while
chicago
and
san
francisco
are
the
fairest
locations
across
all
jobs
we
also
quantified
the
fairest
unfairest
locations
for
some
jobs
and
the
fairest
unfairest
jobs
for
some
locations
our
taskrabbit
results
demonstratethe
flexibility
and
expressiveness
of
fairness
quantification
and
provided
the
ability
to
generate
hypotheses
to
be
tested
on
google
job
search
on
google
job
search
we
found
that
washington
dc
is
deemed
the
fairest
on
the
other
hand
london
uk
is
deemed
the
unfairest
location
for
queries
we
found
that
yard
work
jobs
are
deemed
the
most
unfair
whereas
furniture
assembly
jobs
are
deemed
the
most
fair
while
fairness
quantification
resulted
in
largely
known
results
our
fairness
comparison
experiment
on
both
platforms
revealed
new
results
for
instance
on
taskrabbit
in
chicago
nashville
and
san
francisco
females
are
treated
more
fairly
than
males
which
differs
from
the
overall
comparison
most
results
are
consistent
between
emd
and
exposure
similarly
for
google
job
search
most
results
are
consistent
between
jaccard
and
kendall
tau
this
is
quite
encouraging
and
and
merits
further
investigation
in
future
work
the
paper
is
organized
as
follows
we
review
related
work
in
section
in
section
we
present
our
data
model
in
section
we
describe
our
unfairness
problems
and
the
algorithms
we
use
to
solve
these
problems
section
describes
our
case
study
on
two
sites
google
job
search
and
taskrabbit
finally
we
conclude
and
present
future
work
in
section
contrast
to
comparable
groups
and
then
use
this
as
measure
of
unfairness
for
this
group
as
in
22
figure
the
unfairness
for
black
females
for
the
google
job
search
query
home
cleaning
in
location
san
francisco
using
kendall
tau
between
the
search
results
of
black
females
and
all
other
users
in
comparable
groups
is
0.70
0.50
0.30
0.50
figure
the
unfairness
for
black
females
for
the
query
cleaning
services
in
location
new
york
city
on
taskrabbit
using
earth
mover
distance
between
ranking
distributions
of
black
females
and
its
comparable
groups
is
0.45
0.25
0.65
0.45
various
fairness
questions
can
be
formulated
either
to
quantify
how
well
site
treats
groups
for
different
jobs
and
at
different
locations
or
to
compare
groups
queries
or
locations
our
framework
allows
us
to
define
two
generic
fairness
problems
quantification
such
as
finding
the
groups
resp
queries
locations
for
which
the
site
is
most
or
least
unfair
and
comparison
such
as
finding
the
locations
at
which
fairness
between
two
groups
differs
from
all
locations
or
finding
the
queries
for
which
fairness
at
two
locations
differ
from
all
queries
examples
of
quantification
questions
are
what
are
the
five
groups
for
which
google
job
search
is
most
unfair
what
are
the
five
fairest
queries
for
women
and
at
which
locations
do
asians
have
the
highest
chance
to
be
hired
for
given
job
examples
of
comparison
questions
are
how
differently
does
taskrabbit
treat
men
and
women
and
for
which
queries
is
the
treatment
different
at
which
locations
is
it
easiest
to
be
hired
as
https://prolific.co
511
related
work
there
is
wealth
of
work
that
empirically
assessed
fairness
in
online
markets
such
as
crowdsourcing
or
freelancing
platforms
13
17
17
21
for
instance
the
authors
in
17
analyze
ten
categories
of
design
and
policy
choices
through
which
platforms
may
make
themselves
more
or
less
conducive
to
discrimination
by
users
in
13
the
authors
found
evidence
of
bias
in
two
prominent
online
freelance
marketplace
taskrabbit
and
fiverr
precisely
in
both
marketplaces
they
found
that
gender
and
race
are
significantly
correlated
with
worker
evaluations
which
could
harm
the
employment
opportunities
afforded
to
the
workers
on
these
platforms
the
work
in
21
studies
the
uber
platform
to
explore
how
bias
may
creep
into
evaluations
of
drivers
through
consumer-sourced
rating
systems
they
concluded
that
while
companies
like
uber
are
legally
prohibited
from
making
employment
decisions
based
on
protected
characteristics
of
workers
their
reliance
on
potentially
biased
consumer
ratings
to
make
material
determinations
may
nonetheless
lead
to
disparate
impact
in
employment
outcomes
finally
discrimination
in
airbnb
was
studied
in
and
high
evidence
of
discrimination
against
african
american
guests
was
reported
in
the
authors
study
ethics
in
crowd
work
in
general
they
analyze
recent
crowdsourcing
literature
and
extract
ethical
issues
by
following
the
papa
privacy
accuracy
property
accessibility
of
information
concept
well-established
approach
in
information
systems
the
review
focuses
on
the
individual
perspective
of
crowd
workers
which
addresses
their
working
conditions
and
benefits
several
discrimination
scenarios
in
task
qualification
and
algorithmic
task
assignment
were
defined
in
that
includes
only
accounting
for
requester
preferences
without
quantifying
how
that
affects
workers
and
vice
versa
another
discriminatory
scenario
in
is
related
to
worker
compensation
since
requester
can
reject
work
and
not
pay
the
worker
or
worker
can
be
under-payed
discrimination
in
crowdsourcing
can
be
defined
for
different
processes
in
18
the
authors
study
how
to
reduce
unfairness
in
virtual
marketplaces
two
principles
must
be
adapted
platforms
should
track
the
composition
of
their
population
to
shed
light
on
groups
being
discriminated
against
and
platforms
should
experiment
on
their
algorithms
and
data-sets
in
timely
manner
to
check
for
discrimination
in
this
same
paper
the
authors
define
four
design
strategies
to
help
reduce
discrimination
platform
manager
should
first
answer
these
questions
are
we
providing
too
much
information
can
we
automate
the
transaction
process
further
can
we
remind
the
user
of
discriminatory
consequences
when
they
are
making
decision
should
the
algorithm
be
discrimination-aware
in
question
they
address
the
issue
of
transparency
discrimination
and
transparency
might
be
highly
correlated
but
their
correlation
has
yet
to
be
studied
profoundly
in
transparency
plug-ins
are
reviewed
those
plug-ins
disclose
computed
information
from
worker
performance
to
requester
ratings
such
as
turkbench
14
and
crowd-workers
such
plug-ins
might
be
helpful
in
more
detailed
study
of
the
effect
of
transparency
on
fairness
to
the
best
of
our
knowledge
our
work
is
the
first
to
formalize
group-fairness
query-fairness
location-fairness
and
fairness
comparisons
and
conduct
an
extensive
evaluation
of
job
search
on
virtual
marketplace
and
job
search
site
further
statistical
and
manual
investigations
are
necessary
for
causality
and
explainability
our
goal
is
to
reduce
initial
manual
effort
by
providing
necessary
tools
to
assess
fairness
fairness
has
been
trending
in
research
for
the
last
few
years
as
we
increasingly
rely
on
algorithms
for
decision
making
bias
has
been
identified
as
major
risk
in
algorithmic
decision
making
11
16
23
27
one
algorithmic
solution
is
based
on
the
formalization
in
16
to
quantify
unfairness
to
detect
unfairness
in
algorithms
framework
24
for
unwarranted
associations
was
designed
to
identify
associations
between
protected
attribute
such
as
person
race
and
the
algorithmic
output
using
the
fairtest
tool
in
11
the
notion
of
unfairness
was
defined
as
disparity
in
treatment
between
different
groups
of
people
based
on
their
protected
attributes
what
is
commonly
referred
to
as
group
unfairness
in
this
context
to
assess
unfairness
mathematically
one
needs
to
compare
distributions
of
decisions
across
different
groups
of
people
in
our
work
we
adapt
the
definition
of
unfairness
in
11
however
rather
than
trying
to
fix
it
the
goal
of
our
work
is
to
just
reveal
any
unfairness
by
the
ranking
process
which
in
some
cases
might
be
positive
discrimination
19
where
certain
disadvantaged
individuals
are
favored
based
on
their
protected
attributes
there
is
wealth
of
work
on
addressing
fairness
of
ranking
in
general
for
example
16
22
24
26
unlike
our
work
the
majority
of
these
works
that
focus
on
group
fairness
either
assume
the
presence
of
pre-defined
groups
based
on
protected
attributes
of
users
or
the
presence
of
ranking
constraints
that
bound
the
number
of
users
per
protected
attribute
value
in
the
top-k
ranking
on
the
other
hand
the
work
in
focuses
on
addressing
amortized
individual
fairness
in
series
of
rankings
in
15
the
authors
introduce
subgroup
fairness
and
formalize
the
problem
of
auditing
and
learning
classifiers
for
rich
class
of
subgroups
our
work
differs
in
many
ways
we
are
interested
in
ranking
individuals
and
not
classifying
them
as
well
as
ranking
jobs
and
we
seek
to
quantify
the
fairness
of
jobs
locations
and
groups
and
compare
fairness
across
different
dimensions
in
the
authors
develop
system
that
helps
users
inspect
how
assigning
different
weights
to
ranking
criteria
affects
ranking
each
ranking
function
can
be
expressed
as
point
in
multidimensional
space
for
broad
range
of
fairness
criteria
including
proportionality
they
show
how
to
efficiently
identify
groups
defined
as
combination
of
multiple
protected
attributes
their
system
tells
users
whether
their
proposed
ranking
function
satisfies
the
desired
fairness
criteria
and
if
it
does
not
suggests
the
smallest
modification
that
does
in
the
authors
studied
fairness
of
ranking
in
online
job
marketplaces
to
do
this
they
defined
an
optimization
problem
to
find
partitioning
of
the
individuals
being
ranked
based
on
their
protected
attributes
that
exhibits
the
highest
unfairness
by
given
scoring
function
they
used
the
earth
mover
distance
between
score
distributions
as
measure
of
unfairness
unlike
other
related
work
we
did
not
assume
pre-defined
partitioning
of
individuals
and
instead
developed
two
different
fairness
problems
one
aiming
at
quantifying
fairness
and
the
other
at
comparing
it
framework
3.1
unfairness
model
on
any
given
site
we
consider
set
of
groups
set
of
jobrelated
queries
and
set
of
locations
we
associate
to
each
group
label
label
in
the
form
of
conjunction
of
predicates
val
we
use
to
refer
to
all
attributes
used
in
label
for
512
table
top-3
results
for
10
users
for
the
query
home
cleaning
in
location
san
francisco
on
search
engine
example
if
label
is
gender
male
ethnicity
black
we
have
is
gender
ethnicity
we
define
variants
where
as
all
groups
whose
label
differs
from
on
the
value
of
for
instance
variants
gender
contains
single
group
whose
label
is
gender
female
ethnicity
black
variants
ethnicity
contains
two
groups
whose
labels
are
gender
male
ethnicity
asian
and
gender
male
ethnicity
white
respectively
we
define
the
set
of
comparable
groups
for
group
as
variants
in
our
example
it
is
variants
gender
variants
ethnicity
this
notion
of
comparable
groups
can
be
more
easily
leveraged
for
explanations
to
consider
other
notions
we
believe
we
would
need
to
extend
only
our
fairness
model
and
not
the
full
framework
each
query
contains
set
of
keywords
such
as
home
cleaning
or
logo
design
the
same
query
can
be
asked
at
different
geographic
locations
in
some
applications
such
as
taskrabbit
query
will
be
used
to
refer
to
set
of
jobs
in
the
same
category
such
as
handyman
furniture
assembly
and
delivery
services
we
denote
by
the
unfairness
value
of
the
triple
we
discuss
next
how
this
unfairness
value
is
computed
for
different
types
of
sites
3.2
worker
top-3
w1
w2
w3
w4
w5
w6
w7
w8
w9
w10
unfairness
measure
for
search
engines
in
search
engine
such
as
google
search
each
user
is
associated
with
ranked
list
of
search
results
eql
we
compute
unfairness
of
as
avgд
dist
variants
common
way
to
compare
search
results
is
to
use
measures
such
as
jaccard
index
or
kendall
tau
12
hence
we
define
dist
as
one
of
the
following
two
avg
eql
eql
where
eql
eql
is
the
kendall
tau
between
the
ranked
lists
eql
and
eql
avg
jaccard
eql
eql
where
jaccard
eql
eql
is
the
jaccard
index
between
the
ranked
lists
eql
and
eql
in
table
we
display
toy
example
of
the
top-3
results
for
10
users
on
search
engine
for
the
query
home
cleaning
in
location
san
francisco
figure
shows
how
the
unfairness
value
for
the
group
black
females
is
computed
using
jaccard
index
in
the
figure
the
jaccard
index
between
every
black
female
user
and
asian
female
user
is
computed
and
then
average
of
the
jaccard
index
is
used
to
measure
unfairness
value
between
the
two
groups
black
females
and
asian
females
to
compute
the
overall
unfairness
value
for
the
group
black
females
the
same
computation
must
be
done
between
black
females
and
all
other
comparable
groups
namely
black
males
and
white
females
and
then
the
average
of
the
individual
unfairness
values
between
groups
is
taken
3.3
figure
the
partial
unfairness
in
search
engine
for
black
females
in
table
with
respect
to
one
of
its
comparable
groups
asian
females
using
jaccard
index
is
0.8
0.5
0.65
we
can
use
one
of
two
methods
earth
mover
distance
emd
20
and
exposure
22
3.3
emd
unfairness
in
the
emd
notion
of
unfairness
the
unfairness
for
group
for
query
at
location
is
computed
as
the
distance
between
the
score
distributions
of
workers
in
group
and
all
its
comparable
groups
variants
as
follows
avgд
dist
variants
unfairness
measure
for
online
job
marketplaces
where
dist
emd
fql
fql
in
online
marketplaces
such
as
taskrabbit
we
are
given
set
of
workers
and
scoring
function
fql
each
worker
is
ranked
based
on
her
score
fql
to
measure
where
fql
is
histogram
of
the
scores
of
workers
in
using
fql
513
score
available
we
rely
on
the
rank
of
workers
rank
to
compute
their
relevance
for
query
and
location
the
rank
of
workers
for
pair
is
available
since
it
can
be
observed
in
the
results
of
running
at
we
can
hence
compute
relql
the
relevance
score
of
worker
as
follows
in
table
we
show
toy
example
consisting
of
10
workers
looking
for
home
cleaning
job
in
san
francisco
and
their
protected
attributes
the
ranking
of
these
workers
is
shown
in
table
figure
illustrates
how
the
emd
unfairness
of
black
females
is
calculated
since
is
gender
and
ethnicity
the
comparable
groups
in
the
toy
example
are
black
males
asian
females
and
white
females
rank
where
rank
denotes
the
rank
of
worker
for
query
at
location
as
shown
in
table
and
is
the
number
of
workers
in
the
resultset
here
set
to
10
the
relevance
scores
generated
for
all
workers
in
our
example
are
reported
in
table
to
compute
the
emd
unfairness
of
black
females
for
this
query
at
this
location
we
generate
histogram
for
black
females
and
each
of
the
comparable
groups
based
on
the
relevance
scores
relql
computed
for
workers
we
then
compute
the
average
emd
between
the
histogram
of
black
females
and
each
of
the
comparable
groups
histograms
relql
table
example
of
10
workers
looking
for
home
cleaning
job
in
san
francisco
and
their
protected
attributes
worker
gender
nationality
ethnicity
w1
w2
w3
w4
w5
w6
w7
w8
w9
w10
female
male
female
male
female
male
female
male
male
female
america
america
america
other
other
america
america
other
other
america
asian
white
white
asian
black
black
black
black
white
white
3.3
exposure
unfairness
in
the
exposure
notion
of
fairness
the
intuition
is
that
higher
ranked
workers
receive
more
exposure
as
people
tend
to
only
examine
top-ranked
results
thus
each
worker
receives
an
exposure
inversely
proportional
to
her
rank
as
follows
first
for
every
we
compute
her
exposure
as
table
ranking
of
the
10
workers
for
the
query
home
cleaning
in
san
francisco
on
an
online
job
marketplace
ranking
worker
fql
10
w3
w8
w6
w2
w1
w4
w7
w5
w9
w10
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
expql
loд
rank
we
also
compute
the
relevance
of
worker
as
relql
as
defined
above
now
the
exposure
of
group
of
workers
is
set
to
expql
expq
var
iant
expq
similarly
we
define
the
relevance
of
group
as
relq
relql
var
iant
relq
next
we
assume
that
each
group
should
receive
exposure
proportional
to
its
relevance
we
thus
measure
deviation
from
the
ideal
exposure
using
the
l1-norm
as
the
unfairness
of
group
expql
relql
figure
illustrates
how
the
exposure
unfairness
of
black
females
is
calculated
to
compute
the
exposure
unfairness
of
black
females
for
this
query
in
the
given
location
we
compute
the
exposure
and
relevance
of
all
black
female
workers
bold
in
table
and
the
workers
belonging
to
their
comparable
groups
in
table
using
fql
and
ranking
shown
in
we
then
sum
up
the
exposure
and
relevance
values
for
all
black
females
workers
and
the
comparable
groups
separately
3.4
notation
generalization
we
have
used
to
refer
to
the
unfairness
for
group
for
the
job-related
query
at
location
this
value
is
obtained
by
contrasting
the
ranking
for
group
with
the
ranking
of
all
its
comparable
groups
unfairness
can
also
be
computed
for
several
job-related
queries
and
at
multiple
locations
for
set
of
queries
and
set
of
locations
we
can
compute
the
unfairness
for
group
as
follows
figure
the
unfairness
of
black
females
based
on
the
ranking
in
table
using
emd
is
0.70
0.50
0.30
0.50
since
the
actual
scores
of
each
worker
for
query
and
location
fql
is
not
always
available
no
job
marketplace
makes
that
avgq
514
site
is
least
unfair
with
respect
to
all
queries
at
all
locations
or
to
answer
the
question
out
of
black
males
asian
males
asian
females
and
white
females
what
are
the
groups
for
which
the
site
say
google
job
search
is
the
most
unfair
when
is
set
of
queries
the
problem
referred
to
as
queryfairness
returns
queries
which
are
the
most
least
unfair
this
instance
of
the
problem
can
address
questions
such
as
what
are
the
least
unfair
queries
at
all
locations
or
which
queries
are
black
males
most
likely
to
get
in
the
west
coast
finally
when
refers
to
locations
the
problem
referred
to
as
location-fairness
addresses
questions
such
as
which
locations
are
the
easiest
to
find
job
at
or
out
of
nyc
boston
and
washington
dc
what
is
the
least
unfair
location
for
women
looking
for
an
event
staffing
job
on
given
site
say
taskrabbit
our
second
problem
formulation
aims
to
capture
comparisons
between
two
dimensions
it
admits
two
dimensions
to
compare
males
and
females
or
nyc
and
san
francisco
or
cleaning
services
and
event
staffing
and
it
returns
breakdown
of
comparison
dimensions
into
sub-dimensions
whose
fairness
comparison
differs
from
the
comparison
of
the
input
dimensions
figure
computing
the
unfairness
for
black
females
based
on
the
ranking
in
table
the
exposure
of
black
0.94
0.19
its
relevance
is
0.5
0.15
its
females
is
0.94
4.0
0.5
2.9
unfairness
is
0.19
0.15
0.04
problem
fairness
comparison
given
two
comparison
dimensions
and
and
breakdown
dimension
return
all
the
first
instance
of
our
comparison
problem
is
referred
to
as
group-comparison
in
which
and
are
demographic
groups
for
example
when
refers
to
males
to
females
and
to
locations
fairness
comparison
returns
all
locations
where
the
comparison
between
males
and
females
differs
from
that
of
all
males
and
females
table
shows
an
example
in
this
case
our
problem
returns
the
unfairness
values
of
males
and
females
at
those
two
locations
that
compare
differently
from
all
locations
similarly
we
could
compute
the
unfairness
for
set
of
groups
at
location
for
all
queries
in
as
follows
avgд
finally
we
could
also
compute
the
unfairness
for
set
of
groups
for
given
query
at
all
locations
as
follows
avgд
table
comparison
between
male
and
female
workers
in
oklahoma
city
and
salt
lake
city
differ
from
the
overall
problems
and
algorithms
in
this
section
we
first
provide
two
generic
problem
formulations
that
capture
the
variety
of
group
fairness
questions
we
may
ask
section
4.1
we
then
describe
the
algorithms
we
designed
to
solve
those
problems
section
4.2
4.1
problem
variants
to
formulate
generic
problem
we
will
use
the
term
dimension
to
refer
to
one
of
group
query
or
location
our
first
problem
aims
to
quantify
how
well
site
treats
groups
for
different
queries
and
at
different
locations
the
problem
returns
instances
of
chosen
dimension
groups
and
aggregates
their
unfairness
values
along
the
two
others
queries
and
locations
group-comparison
males
females
all
oklahoma
city
ok
salt
lake
city
ut
0.48
0.853
0.933
0.74
0.732
0.553
the
second
instance
of
our
comparison
problem
is
referred
to
as
query-comparison
for
example
if
is
lawn
mowing
and
furniture
mounting
and
is
ethnicity
fairness
comparison
returns
all
ethnicities
for
which
the
comparison
between
lawn
mowing
and
furniture
mounting
differs
from
the
whole
population
for
instance
our
problem
finds
that
ethnicity
black
must
be
returned
because
the
unfairness
values
between
lawn
mowing
and
furniture
mounting
for
blacks
compare
differently
from
all
ethnicities
the
third
instance
of
our
comparison
problem
is
referred
to
as
location-comparison
for
example
when
is
california
and
is
arizona
and
is
outdoor
home
services
fairness
comparison
returns
all
queries
related
to
outdoor
home
services
lawn
mowing
garage
cleaning
patio
painting
etc
for
which
the
comparison
in
california
and
arizona
differs
from
all
outdoor
home
services
our
problem
returns
the
jobs
garage
cleaning
and
patio
painting
because
the
unfairness
values
between
california
and
problem
fairness
quantification
given
dimension
to
be
returned
and
two
other
dimensions
agg1
and
agg2
to
be
aggregated
return
the
results
in
for
which
the
site
is
most
least
unfair
where
the
unfairness
for
each
result
agg1
agg2
is
computed
as
avgagg1
agg1
agg2
agg2
aдд1
aдд2
there
are
instances
of
this
problem
one
where
is
set
of
groups
one
where
it
is
set
of
queries
and
the
third
one
where
it
is
set
of
locations
when
is
set
of
groups
the
problem
referred
to
as
groupfairness
returns
groups
for
which
the
site
is
most
least
unfair
for
instance
it
could
be
used
to
find
the
groups
for
which
the
515
algorithm
findtopkgroups
set
of
groups
set
of
queries
set
of
locations
an
integer
arizona
for
those
two
jobs
are
different
from
all
outdoor
home
services
4.2
topk
createminheap
algorithms
initialize
cursors
to
the
computational
complexity
of
our
problems
calls
for
designing
scalable
solutions
in
this
section
we
propose
adaptations
of
fagin
algorithms
to
solve
our
problems
we
first
describe
the
indices
we
generate
group-based
query-based
and
location-based
the
group-based
indices
associate
to
every
pair
an
inverted
index
where
groups
are
sorted
in
descending
order
based
on
the
query-based
indices
associate
to
every
pair
an
inverted
index
where
queries
are
sorted
in
descending
order
based
on
the
location-based
indices
associate
to
every
pair
an
inverted
index
where
locations
are
sorted
in
descending
order
based
on
table
shows
an
illustration
of
the
three
types
of
indices
while
topk
minv
alue
or
topk
size
do
for
do
for
do
ind
cur
read
entry
in
pointed
to
by
cursor
cur
10
11
for
do
12
for
do
13
if
or
then
14
ind
perform
random
access
on
to
retrieve
the
unfairness
value
of
for
the
pair
15
16
end
if
17
end
for
18
end
for
19
20
if
topk
size
then
21
topk
insert
22
else
23
if
topk
minv
alue
then
24
topk
pop
25
topk
insert
26
end
if
27
end
if
28
cur
cur
29
end
for
30
end
for
31
32
end
while
33
return
topk
table
group-based
query-based
location-based
indices
дj
дj
qj
lj
algorithm
is
an
adaption
of
fagin
threshold
algorithm
10
for
the
group-fairness
instance
of
our
problem
it
finds
the
groups
for
which
the
site
is
most
unfair
the
algorithm
takes
as
input
set
of
groups
set
of
queries
and
set
of
locations
and
returns
groups
it
makes
use
of
the
group-based
indices
table
all
other
instances
of
problem
including
query-fairness
location-fairness
and
their
bottom
versions
are
adaptations
of
algorithm
algorithm
solves
our
second
problem
problem
for
the
group-comparison
instance
of
our
problem
it
takes
as
input
groups
д1
and
д2
and
breakdown
dimension
it
first
calls
algorithm
to
compute
the
fairness
values
of
д1
and
д2
for
all
values
of
and
all
queries
it
then
calls
the
query-based
index
to
sum
up
all
the
values
for
all
the
queries
by
scanning
the
index
for
each
location
and
for
each
of
the
two
groups
finally
it
returns
only
those
locations
for
which
the
order
on
unfairness
values
for
the
two
groups
is
reversed
all
other
instances
of
problem
including
query-comparison
and
location-comparison
are
adaptations
of
algorithm
algorithm
computes
the
fairness
for
group
for
all
queries
in
and
all
locations
in
it
takes
as
input
group
set
of
queries
and
set
of
locations
and
returns
the
average
unfairness
value
for
over
all
queries
and
locations
experiments
our
experiments
use
real
data
collected
from
taskrabbit
and
google
search
and
were
conducted
from
june
to
august
2019
we
first
describe
the
overall
setup
for
each
platform
and
then
report
the
results
5.1
figure
flow
of
taskrabbit
experiments
taskrabbit
is
supported
in
56
different
cities
mostly
in
the
us
for
each
location
we
retrieved
all
jobs
offered
in
that
location
we
thus
generated
total
of
361
job-related
queries
where
each
query
is
combination
of
job
and
location
home
cleaning
in
new
york
experimental
setup
5.1
taskrabbit
setup
taskrabbit
is
an
online
marketplace
that
matches
freelance
labor
with
local
demand
allowing
consumers
to
find
immediate
help
with
everyday
tasks
516
figure
gender
breakdown
figure
ethnic
breakdown
algorithm
comparegroups
groups
д1
д2
set
of
locations
as
breakdown
set
of
queries
amt
to
indicate
the
gender
and
ethnicity
of
the
taskrabbit
taskers
based
on
their
profile
pictures
the
taskers
were
given
pre-defined
categories
for
gender
male
female
and
ethnicity
asian
black
white
each
profile
picture
was
labeled
by
three
different
contributors
on
amt
and
majority
vote
determined
the
final
label
the
gender
and
ethnic
breakdowns
of
the
taskers
in
our
dataset
are
shown
in
figures
and
overall
we
had
total
of
311
unique
taskers
in
our
crawled
dataset
the
majority
of
which
were
male
72
and
white
66
loc
д1
computegroupunfairness
д1
д2
computegroupunfairness
д2
for
do
sum
sum
cur
cur
for
do
10
sum
д1
ind
cur
11
sum
д2
ind
cur
12
cur
cur
13
cur
cur
14
end
for
15
if
reversed
sum1
sum2
g1
g2
then
16
loc
17
end
if
18
end
for
19
return
loc
5.1
google
search
setup
google
search
personalizes
queries
based
on
user
profile
which
includes
user
data
activity
and
saved
preferences
while
personalization
can
be
beneficial
to
users
it
may
introduce
the
possibility
of
unfairness
which
we
aim
to
observe
algorithm
computegroupunfairness
group
set
of
queries
set
of
locations
sum
for
do
for
do
sum
sum
ind
perform
random
access
on
to
retrieve
the
unfairness
value
of
for
the
pair
end
for
end
for
return
sum
figure
flow
of
google
job
search
experiments
we
designed
the
experiments
to
ensure
that
variations
in
the
search
results
are
largely
based
on
differences
in
profiles
rather
than
other
known
noise
sources
identified
in
related
work
such
as
carry-over-effect
geolocation
distributed
infrastructure
and
testing
12
the
flow
of
the
google
search
experiment
is
summarized
in
figure
we
first
derived
user
groups
of
interest
and
equivalent
google
search
terms
from
data
crawled
from
taskrabbit
we
then
setup
user
studies
on
prolific
academic7
and
recruited
participants
who
belong
to
those
groups
we
asked
those
participants
figure
summarizes
the
flow
of
the
taskrabbit
experiment
our
algorithms
are
encapsulated
in
the
f-box
for
each
one
of
the
361
queries
we
extracted
the
rank
of
each
tasker
their
badges
reviews
profile
pictures
and
hourly
rates
where
the
number
of
taskers
returned
per
query
was
limited
to
50
since
the
demographics
of
the
taskers
were
not
readily
available
on
the
platform
we
asked
workers
on
amazon
mechanical
turk
https://mturk.com
https://prolific.co
517
table
sample
taskrabbit
queries
and
equivalent
google
search
terms
taskrabbit
query
location
equivalent
google
search
terms
run
errand
london
uk
yard
work
new
york
city
ny
run
errand
jobs
near
london
uk
errand
service
jobs
near
london
uk
errand
runner
jobs
near
london
uk
errands
and
odd
jobs
near
london
uk
jobs
running
errands
for
seniors
near
london
uk
yard
work
jobs
near
new
york
city
ny
yard
worker
near
new
york
city
ny
lawn
work
needed
near
new
york
city
ny
yard
help
needed
near
new
york
city
ny
yard
work
help
wanted
near
new
york
city
ny
table
number
of
locations
per
job
to
use
our
google
chrome
extension
that
automatically
executes
on
google
the
search
queries
derived
finally
we
processed
the
results
and
provided
them
as
input
to
the
f-box
and
recorded
unfairness
values
search
queries
for
our
google
search
experiments
we
selected
20
queries
the
top
10
and
bottom
10
frequently
searched
queries
and
their
corresponding
locations
from
data
crawled
in
taskrabbit
from
this
list
we
chose
those
from
10
unique
locations
we
then
generated
equivalent
search
terms
using
google
keyword
planner
tool
that
outputs
list
of
search
terms
similar
or
related
to
given
search
string
and
location
we
shortlisted
50
formulations
for
each
query
manually
examined
them
then
chose
search
terms
whose
results
are
similar
to
the
original
term
table
shows
sample
queries
from
taskrabbit
and
their
equivalent
google
search
terms
job
location
yard
work
general
cleaning
event
staffing
moving
job
run
errand
distributed
infrastructure
and
different
geolocations
the
search
results
are
then
inserted
to
google
sheets
document
we
emphasized
to
the
participants
that
we
store
no
identifying
information
about
them
groups
the
combination
of
pre-defined
categories
for
gender
male
female
and
ethnicity
asian
black
white
results
in
six
groups
asian
male
asian
female
black
male
black
female
white
male
and
white
female
we
recruited
an
average
of
participants
per
study
through
prolific
academic
crowdsourcing
platform
that
allows
researchers
to
recruit
participants
who
have
been
categorized
through
the
platform
screening
mechanism
user
study
given
the
search
terms
and
the
groups
we
have
total
of
60
studies
each
study
is
composed
of
two
tasks
in
the
first
task
participant
is
asked
to
set
her
browsing
language
to
english
and
install
our
google
chrome
extension
that
runs
the
search
terms
participants
who
are
able
to
successfully
complete
the
first
task
are
invited
to
do
second
task
where
they
are
asked
whether
they
think
the
instructions
of
the
first
task
were
clear
and
whether
the
reward
is
fair
the
reward
for
each
task
is
0.50
gbp
given
the
distribution
of
workers
on
prolific
academic
we
ended
up
with
10
locations
namely
london
uk
new
york
city
ny
los
angeles
ca
boston
ma
bristol
uk
charlotte
nc
pittsburg
pa
birmingham
uk
manchester
uk
and
detroit
mi
for
those
10
locations
we
have
five
categories
of
jobs
yard
work
general
cleaning
event
staffing
moving
job
and
run
errand
table
shows
the
number
of
locations
per
job
that
we
collected
search
results
for
google
chrome
extension
and
noise
handling
we
developed
google
chrome
extension
that
automatically
executes
the
google
search
terms
the
extension
runs
the
five
search
terms
every
12
minutes
to
minimize
noise
due
to
the
carry-over
effect
meanwhile
every
search
term
is
executed
at
least
twice
to
account
for
noise
caused
by
testing
the
extension
also
sets
the
browser
location
to
fixed
location
and
uses
proxy
so
that
all
queries
originate
from
the
same
location
thus
minimizing
noise
caused
by
518
5.2
fairness
quantification
5.2
taskrabbit
fairness
quantification
we
report
the
results
of
solving
our
fairness
quantification
problem
problem
in
section
4.1
for
groups
queries
and
locations
using
both
emd
and
exposure
to
measure
unfairness
see
sections
3.3
and
3.3
for
their
formal
definitions
table
reports
all
groups
in
taskrabbit
ranked
by
their
decreasing
unfairness
values
both
emd
and
exposure
we
can
see
that
the
two
measures
agree
on
the
top
groups
for
whom
taskrabbit
is
the
most
unfair
asian
females
and
asian
males
are
the
ones
most
discriminated
against
table
reports
all
job
types
in
taskrabbit
ranked
by
their
decreasing
unfairness
values
both
emd
and
exposure
the
two
measures
largely
agree
on
the
ranking
showing
that
handyman
and
yard
work
are
the
most
unfair
jobs
and
that
furniture
assembly
and
delivery
are
the
fairest
since
the
number
of
locations
is
large
we
report
the
top
and
bottom
10
locations
in
tables
10
and
11
respectively
the
results
show
that
birmingham
uk
and
oklahoma
city
ok
are
the
least
fair
while
chicago
and
san
francisco
are
the
fairest
locations
across
all
jobs
we
also
report
the
fairest
unfairest
locations
for
some
jobs
and
the
fairest
unfairest
jobs
for
some
locations
for
handyman
and
run
errands
the
fairest
location
is
san
francisco
bay
area
ca
for
both
when
using
emd
and
when
using
exposure
it
is
boston
ma
for
handyman
and
san
francisco
bay
area
ca
for
run
errands
the
unfairest
location
for
both
jobs
is
birmingham
uk
when
using
emd
for
birmingham
detroit
and
nashville
the
fairest
jobs
are
delivery
and
furniture
assembly
for
all
and
the
unfairest
are
yard
work
general
cleaning
and
general
cleaning
respectively
for
philadelphia
san
diego
and
chicago
the
fairest
jobs
are
delivery
furniture
assembly
and
delivery
respectively
and
the
unfairest
is
yard
work
for
birmingham
detroit
and
run
errands
for
nashville
table
emd
and
exposure
of
all
groups
in
taskrabbit
ranked
from
the
unfairest
to
the
fairest
group
emd
group
exposure
asian
female
asian
male
black
female
asian
black
male
white
female
black
male
female
white
white
male
0.876
0.755
0.726
0.694
0.578
0.542
0.498
0.468
0.468
0.448
0.421
asian
female
asian
male
black
female
asian
black
male
white
female
black
female
white
male
male
white
0.821
0.662
0.615
0.594
0.413
0.359
0.341
0.299
0.154
0.117
0.104
in
summary
our
results
demonstrate
the
flexibility
and
expressiveness
provided
by
solving
the
fairness
quantification
problem
for
groups
queries
and
locations
they
also
provide
the
ability
to
generate
hypotheses
to
be
tested
across
platforms
in
our
case
from
taskrabbit
to
google
job
search
5.2
google
fairness
quantification
we
ran
our
unfairness
quantification
algorithm
algorithm
on
the
data
crawled
from
google
search
our
algorithm
found
that
regardless
of
the
metrics
we
use
kendall
tau
or
jaccard
index
the
most
discriminated
against
group
is
white
females
and
the
least
is
black
males
this
indicates
that
search
results
between
white
females
were
the
most
different
whereas
those
for
black
males
were
the
most
similar
when
quantifying
unfairness
for
locations
we
found
that
washington
dc
is
deemed
the
fairest
indicating
no
difference
in
search
results
between
users
at
this
location
using
both
jaccard
index
and
kendall
tau
on
the
other
hand
london
uk
is
deemed
the
unfairest
location
finally
for
queries
we
found
that
using
both
metrics
yard
work
jobs
are
deemed
the
most
unfair
whereas
furniture
assembly
jobs
are
deemed
the
most
fair
table
emd
and
exposure
for
all
jobs
in
taskrabbit
ranked
from
the
unfairest
to
the
fairest
job
emd
job
exposure
handyman
event
staffing
general
cleaning
yard
work
moving
delivery
furniture
assembly
run
errands
0.692
0.639
0.611
0.672
0.604
0.499
0.541
0.519
handyman
event
staffing
general
cleaning
yard
work
moving
furniture
assembly
delivery
run
errands
0.515
0.504
0.456
0.5
0.418
0.383
0.331
0.352
5.3
table
10
10
unfairest
locations
using
emd
and
exposure
ranked
from
the
unfairest
to
the
fairest
city
emd
city
exposure
birmingham
uk
oklahoma
city
ok
bristol
uk
manchester
uk
new
haven
ct
milwaukee
wi
indianapolis
in
nashville
tn
detroit
mi
0.998
0.91
0.851
0.838
0.824
0.815
0.808
0.806
birmingham
uk
oklahoma
city
ok
bristol
uk
manchester
uk
new
haven
ct
memphis
tn
milwaukee
wi
charlotte
nc
nashville
tn
0.926
0.819
0.761
0.739
0.67
0.668
0.668
0.643
0.637
table
12
comparison
between
male
and
female
workers
after
including
locations
using
exposure
the
listed
locations
are
the
ones
for
which
females
are
treated
more
fairly
than
males
which
differs
from
the
overall
comparison
table
11
10
fairest
locations
using
emd
and
exposure
ranked
from
the
fairest
to
the
unfairest
city
emd
city
exposure
chicago
il
san
francisco
ca
washington
dc
los
angeles
ca
boston
ma
atlanta
ga
houston
tx
orlando
fl
philadelphia
pa
san
diego
ca
0.274
0.286
0.329
0.33
0.353
0.4
0.417
0.431
0.45
0.454
chicago
il
san
francisco
ca
boston
ma
washington
dc
los
angeles
ca
houston
tx
atlanta
ga
san
diego
ca
orlando
fl
philadelphia
pa
0.107
0.12
0.169
0.174
0.189
0.217
0.234
0.241
0.242
0.273
fairness
comparison
5.3
taskrabbit
fairness
comparison
we
report
the
results
of
solving
our
fairness
comparison
problem
problem
in
section
4.1
in
tables
12
13
14
and
15
the
tables
only
report
the
locations
demographics
and
jobs
that
differ
from
the
overall
comparison
group-comparison
males
females
all
charlotte
nc
chicago
il
nashville
tn
norfolk
va
san
francisco
bay
area
ca
st
louis
mo
0.117
0.399
0.062
0.330
0.331
0.084
0.255
0.299
0.345
0.062
0.309
0.168
0.084
0.190
table
13
comparison
between
lawn
mowing
and
event
decorating
workers
after
including
ethnicity
using
emd
caucasians
are
the
ones
for
which
the
comparison
between
lawn
mowing
jobs
and
event
decorating
jobs
is
different
from
the
whole
population
showing
that
lawn
mowing
jobs
are
fairer
than
event
decorating
for
caucasians
job-comparison
lawn
mowing
event
decorating
all
white
0.674
0.552
0.613
0.569
in
summary
we
can
conclude
that
overall
emd
and
exposure
yield
the
same
observations
when
solving
the
fairness
comparison
problem
on
taskrabbit
519
table
18
comparison
between
running
errands
jobs
and
general
cleaning
jobs
after
including
ethnicity
using
kendall
tau
table
14
comparison
between
lawn
mowing
and
event
decorating
jobs
after
including
ethnicity
using
exposure
unlike
table
13
in
this
case
blacks
are
the
ones
for
whom
lawn
mowing
jobs
are
fairer
than
event
decorating
this
warrants
further
investigation
in
the
future
job-comparison
lawn
mowing
event
decorating
all
black
0.500
0.445
0.442
0.453
job-comparison
running
errands
general
cleaning
all
black
asian
0.927
0.927
0.925
0.926
0.950
0.938
table
19
comparison
between
running
errands
jobs
and
general
cleaning
jobs
after
including
ethnicity
using
jaccard
the
results
differ
from
those
reported
in
table
18
this
warrants
further
investigation
in
the
future
table
15
comparison
between
san
francisco
bay
area
and
chicago
after
including
general
cleaning
jobs
using
emd
san
francisco
is
shown
to
be
fairer
for
all
jobs
but
the
trend
is
inverted
for
the
listed
jobs
location-comparison
san
francisco
bay
area
ca
chicago
il
all
back
to
organized
organize
declutter
organize
closet
0.213
0.198
0.224
0.174
0.233
0.135
0.191
0.153
job-comparison
running
errands
general
cleaning
all
black
0.902
0.903
0.887
0.94
table
20
comparison
between
boston
ma
and
bristol
uk
after
including
general
cleaning
jobs
using
kendall
tau
this
result
is
similar
to
the
one
reported
in
table
21
5.3
google
fairness
comparison
similarly
to
taskrabbit
we
report
the
results
of
solving
our
fairness
comparison
problem
problem
in
section
4.1
in
tables
16
17
18
19
20
and
21
the
tables
show
the
cases
that
differ
from
the
overall
comparison
table
16
comparison
between
male
and
female
workers
after
including
locations
using
kendall
tau
the
listed
locations
are
the
ones
for
which
females
are
treated
more
fairly
than
males
which
differs
from
the
overall
comparison
group
comparison
boston
ma
bristol
uk
all
office
cleaning
jobs
private
cleaning
jobs
0.641
0.735
0.572
0.689
0.627
0.398
table
21
comparison
between
boston
ma
and
bristol
uk
after
including
general
cleaning
jobs
using
jaccard
this
result
is
similar
to
the
one
reported
in
table
20
group-comparison
males
females
group
comparison
boston
ma
bristol
uk
all
birmingham
uk
bristol
uk
detroit
mi
new
york
city
ny
0.537
0.906
0.921
0.928
0.913
0.552
0.901
0.918
0.901
0.906
all
private
cleaning
jobs
0.447
0.403
0.603
0.364
table
17
comparison
between
male
and
female
workers
after
including
locations
using
jaccard
the
results
differ
from
the
ones
in
table
16
because
the
overall
results
differ
this
warrants
further
investigation
in
the
future
group-comparison
males
females
all
boston
ma
charlotte
nc
london
uk
los
angeles
ca
manchester
uk
pittsburgh
pa
0.395
0.894
0.893
0.776
0.875
0.869
0.877
0.393
0.896
0.901
0.785
0.878
0.875
0.88
conclusion
we
develop
framework
to
study
fairness
in
job
search
and
detailed
empirical
evaluation
of
two
sites
google
job
search
and
taskrabbit
we
formulate
two
generic
problems
our
first
problem
returns
the
least
most
unfair
dimensions
the
groups
for
which
site
is
most
least
unfair
the
least
most
unfair
jobs
queries
or
the
least
most
unfair
locations
our
second
problem
captures
comparisons
between
two
dimensions
it
admits
two
dimensions
to
compare
males
and
females
or
nyc
and
san
francisco
or
cleaning
services
and
event
staffing
and
it
returns
breakdown
of
those
dimensions
that
exhibits
different
unfairness
values
for
instance
on
taskrabbit
while
females
are
discriminated
against
when
compared
to
males
this
trend
is
inverted
in
california
we
apply
threshold-based
algorithms
to
solve
our
problems
we
report
the
results
of
extensive
experiments
on
real
datasets
from
taskrabbit
and
google
job
search
our
framework
can
be
used
to
generate
hypotheses
and
verify
them
across
sites
that
is
what
we
did
from
taskrabbit
to
google
job
search
it
can
also
be
used
to
verify
hypotheses
by
solving
the
comparison
problem
as
result
one
could
use
it
in
iterative
scenarios
where
the
purpose
is
to
explore
and
compare
fairness
we
are
currently
designing
such
exploratory
scenarios
in
summary
we
observed
that
kendall
tau
and
jaccard
report
mostly
similar
results
when
solving
the
fairness
comparison
problem
on
google
job
search
this
is
quite
encouraging
and
merits
further
investigation
in
future
work
520
acknowledgments
24
florian
tramèr
vaggelis
atlidakis
roxana
geambasu
daniel
hsu
jeanpierre
hubaux
mathias
humbert
ari
juels
and
huang
lin
2015
discovering
unwarranted
associations
in
data-driven
applications
with
the
fairtest
testing
toolkit
corr
abs
1510.02377
2015
http://arxiv.org/abs/1510.02377
25
ke
yang
and
julia
stoyanovich
2017
measuring
fairness
in
ranked
outputs
in
ssdm
22
26
meike
zehlike
francesco
bonchi
carlos
castillo
sara
hajian
mohamed
megahed
and
ricardo
baeza-yates
2017
fa
ir
fair
top-k
ranking
algorithm
in
cikm
1569
1578
27
indre
zliobaite
2015
survey
on
measuring
indirect
discrimination
in
machine
learning
corr
abs
1511.00148
2015
http://arxiv.org/abs/1511.
00148
this
work
is
partially
supported
by
the
american
university
of
beirut
research
board
urb
references
abolfazl
asudeh
jagadish
julia
stoyanovich
and
gautam
das
2019
designing
fair
ranking
schemes
in
proceedings
of
the
2019
international
conference
on
management
of
data
sigmod
conference
2019
amsterdam
the
netherlands
june
30
july
2019
1259
1276
asia
biega
krishna
gummadi
and
gerhard
weikum
2018
equity
of
attention
amortizing
individual
fairness
in
rankings
arxiv
preprint
arxiv
1805.01788
2018
ria
mae
borromeo
thomas
laurent
motomichi
toyama
and
sihem
ameryahia
2017
fairness
and
transparency
in
crowdsourcing
in
proceedings
of
the
20th
international
conference
on
extending
database
technology
edbt
2017
venice
italy
march
21
24
2017
466
469
https://doi.org/10.5441/002/
edbt
2017.46
toon
calders
and
sicco
verwer
2010
three
naive
bayes
approaches
for
discrimination-free
classification
data
mining
and
knowledge
discovery
21
01
sep
2010
277
292
https://doi.org/10.1007/s10618-010-0190-x
chris
callison-burch
2014
crowd-workers
aggregating
information
across
turkers
to
help
them
find
higher
paying
work
in
the
second
aaai
conference
on
human
computation
and
crowdsourcing
hcomp-2014
http
cis
upenn
edu
ccb
publications
crowd-workers
pdf
elisa
celis
damian
straszak
and
nisheeth
vishnoi
2017
ranking
with
fairness
constraints
arxiv
preprint
arxiv
1704.06840
2017
david
durward
ivo
blohm
and
jan
marco
leimeister
2016
is
there
papa
in
crowd
work
literature
review
on
ethical
dimensions
in
crowdsourcing
in
ubiquitous
intelligence
computing
advanced
and
trusted
computing
scalable
computing
and
communications
cloud
and
big
data
computing
internet
of
people
and
smart
world
congress
uic
atc
scalcom
cbdcom
iop
smartworld
2016
intl
ieee
conferences
ieee
823
832
benjamin
edelman
michael
luca
and
dan
svirsky
2017
racial
discrimination
in
the
sharing
economy
evidence
from
field
experiment
american
economic
journal
applied
economics
2017
22
shady
elbassuoni
sihem
amer-yahia
christine
el
atie
ahmad
ghizzawi
and
bilel
oualha
2019
exploring
fairness
of
ranking
in
online
job
marketplaces
in
advances
in
database
technology
22nd
international
conference
on
extending
database
technology
edbt
2019
lisbon
portugal
march
26
29
2019
646
649
10
ronald
fagin
amnon
lotem
and
moni
naor
2003
optimal
aggregation
algorithms
for
middleware
journal
of
computer
and
system
sciences
66
2003
614
656
11
sorelle
friedler
carlos
scheidegger
and
suresh
venkatasubramanian
2016
on
the
im
possibility
of
fairness
corr
abs
1609.07236
2016
http://arxiv.
org
abs
1609.07236
12
aniko
hannak
piotr
sapiezynski
arash
molavi
kakhki
balachander
krishnamurthy
david
lazer
alan
mislove
and
christo
wilson
2013
measuring
personalization
of
web
search
in
proceedings
of
the
22nd
international
conference
on
world
wide
web
acm
527
538
13
aniko
hannak
claudia
wagner
david
garcia
alan
mislove
markus
strohmaier
and
christo
wilson
2017
bias
in
online
freelance
marketplaces
evidence
from
taskrabbit
and
fiverr
in
proceedings
of
the
2017
acm
conference
on
computer
supported
cooperative
work
and
social
computing
cscw
2017
portland
or
usa
february
25
march
2017
1914
1933
14
benjamin
hanrahan
jutta
willamowski
saiganesh
swaminathan
and
david
martin
2015
turkbench
rendering
the
market
for
turkers
in
chi
bo
begole
jinwoo
kim
kori
inkpen
and
woontack
woo
eds
acm
1613
1616
http://dblp.uni-trier.de/db/conf/chi/chi2015.html#hanrahanwsm15
15
michael
kearns
seth
neel
aaron
roth
and
zhiwei
steven
wu
2018
preventing
fairness
gerrymandering
auditing
and
learning
for
subgroup
fairness
in
proceedings
of
the
35th
international
conference
on
machine
learning
icml
2018
stockholmsmässan
stockholm
sweden
july
10
15
2018
2569
2577
16
keith
kirkpatrick
2016
battling
algorithmic
bias
how
do
we
ensure
algorithms
treat
us
fairly
commun
acm
59
2016
16
17
17
karen
levy
and
solon
barocas
2017
designing
against
discrimination
in
online
markets
berkeley
tech
lj
32
2017
1183
18
michael
luca
and
rayl
fisman
2016
fixing
discrimination
in
online
marketplaces
harvard
business
review
dec
2016
https://hbr.org/product/
fixing-discrimination-in-online-marketplaces
r1612g-pdf-eng
19
mike
noon
2010
the
shackled
runner
time
to
rethink
positive
discrimination
work
employment
and
society
24
2010
728
739
20
ofir
pele
and
michael
werman
2009
fast
and
robust
earth
mover
distances
in
2009
ieee
12th
international
conference
on
computer
vision
ieee
460
467
21
alex
rosenblat
karen
ec
levy
solon
barocas
and
tim
hwang
2017
discriminating
tastes
uber
customer
ratings
as
vehicles
for
workplace
discrimination
policy
internet
2017
256
279
22
ashudeep
singh
and
thorsten
joachims
2018
fairness
of
exposure
in
rankings
arxiv
preprint
arxiv
1802.07281
2018
23
latanya
sweeney
2013
discrimination
in
online
ad
delivery
corr
abs
1301.6822
2013
http://arxiv.org/abs/1301.6822
521