information
retrieval
journal
2021
24
85
113
https://doi.org/10.1007/s10791-020-09386-w
evaluation
metrics
measuring
bias
search
engine
results
gizem
gezici1
aldo
lipani2
yucel
saygin1
emine
yilmaz2
received
february
2020
accepted
december
2020
published
online
27
january
2021
author
exclusive
licence
springer
nature
part
springer
nature
2021
abstract
search
engines
decide
see
given
search
query
since
many
people
exposed
information
search
engines
fair
expect
search
engines
neutral
however
search
engine
results
necessarily
cover
viewpoints
search
query
topic
can
biased
towards
specific
view
since
search
engine
results
returned
based
relevance
calculated
using
many
features
sophisticated
algorithms
search
neutrality
necessarily
focal
point
therefore
important
evaluate
search
engine
results
respect
bias
work
propose
novel
web
search
bias
evaluation
measures
take
account
rank
relevance
also
propose
framework
evaluate
web
search
bias
using
proposed
measures
test
framework
two
popular
search
engines
based
57
controversial
query
topics
abortion
medical
marijuana
gay
marriage
measure
stance
bias
support
well
ideological
bias
conservative
liberal
observe
stance
necessarily
correlate
ideological
leaning
positive
stance
abortion
indicates
liberal
leaning
positive
stance
cuba
embargo
indicates
conservative
leaning
experiments
show
neither
search
engines
suffers
stance
bias
however
search
engines
suffer
ideological
bias
favouring
one
ideological
leaning
significant
perspective
polarisation
society
keywords
bias
evaluation
fair
ranking
search
bias
web
search
introduction
search
engines
become
indispensable
part
lives
reported
smart
sights
2018
46.8
world
population
accessed
internet
2017
2021
number
expected
reach
53.7
according
internetlivestats
2018
currently
average
3.5
billion
google
searches
done
per
day
statistics
indicate
search
engines
replaced
traditional
broadcast
media
become
major
source
information
gizem
gezici
gizemgezici@sabanciuniv.edu
department
computer
science
engineering
sabanci
university
istanbul
turkey
department
computer
science
university
college
london
london
uk
123
86
information
retrieval
journal
2021
24
85
113
gatekeepers
web
many
people
diaz
2008
information
seekers
search
web
also
influenced
search
engine
result
pages
serps
pertaining
wide
range
areas
work
entertainment
religion
politics
instance
course
elections
known
people
issue
repeated
queries
web
political
candidates
events
democratic
debate
donald
trump
climate
change
kul
shrestha
et
al
2018
serps
returned
response
queries
may
influence
voting
decisions
claimed
epstein
robertson
2015
report
manipulated
search
rankings
can
change
voting
preferences
undecided
individuals
least
20
although
search
engines
widely
used
seeking
information
majority
online
users
tend
believe
provide
neutral
results
serving
facilitators
accessing
information
web
goldman
2008
however
counter
examples
belief
well
recent
dispute
president
donald
trump
google
example
mr
trump
accused
google
displaying
negative
news
name
searched
google
responded
saying
users
type
queries
google
search
bar
goal
make
sure
receive
relevant
answers
matter
seconds
search
used
set
political
agenda
don
bias
results
toward
political
ideology
ginger
david
2018
work
hope
shed
light
debate
specifically
concentrating
queries
regarding
donald
trump
conducting
depth
analysis
search
answers
broad
set
controversial
topics
based
concrete
evaluation
measures
bias
defined
respect
balance
representativeness
web
documents
retrieved
database
given
query
mowshowitz
kawaguchi
2002a
user
issues
query
search
engine
documents
different
sources
gathered
ranked
displayed
user
assume
user
searches
2016
presidential
election
top-n
ranked
results
displayed
search
scenario
retrieved
results
may
favor
political
perspectives
others
thereby
fail
provide
impartial
knowledge
given
query
claimed
mr
trump
though
without
scientific
support
hence
potential
undue
emphasis
specific
perspectives
viewpoints
retrieved
results
lead
bias
kulshrestha
et
al
2018
respect
definition
bias
presented
scenario
unbalanced
representation
skewed
slanted
distribution
viewpoints
serp
political
searches
towards
query
topic
consider
serp
biased
given
search
query
bias
especially
important
query
topic
controversial
opposing
views
case
becomes
critical
search
engines
supposed
return
results
balanced
representation
different
perspectives
implies
favour
one
specific
perspective
another
otherwise
may
dramatically
affect
public
case
elections
leading
polarisation
society
controversial
issues
hand
returning
unbalanced
representation
distinct
viewpoints
sufficient
claim
search
engine
ranking
algorithm
biased
one
reason
skewed
serp
due
corpus
documents
indexed
returned
given
topic
come
slanted
distribution
meaning
ranking
algorithm
returns
biased
result
set
due
biased
corpus
differentiate
algorithmic
vs
corpus
bias
one
needs
investigate
source
bias
addition
skewed
list
analysis
top-n
search
results
however
existence
bias
regardless
corpus
algorithmic
bias
still
conflict
expectation
ir
system
fair
accountable
transparent
culpepper
et
al
2018
furthermore
reported
people
susceptible
bias
unaware
bargh
et
al
2001
epstein
et
al
2017
showed
alerting
users
bias
can
effective
suppressing
search
engine
manipulation
effect
seme
thus
search
engines
least
inform
users
bias
decrease
possible
seme
123
information
retrieval
journal
2021
24
85
113
87
making
accountable
thereby
alleviating
negative
effects
bias
serving
facilitators
generally
claim
work
aim
serve
purpose
proposing
search
bias
evaluation
framework
taking
account
rank
relevance1
serps
contributions
work
can
summarised
follows
propose
new
generalisable
search
bias
evaluation
framework
measure
bias
serps
quantifying
two
different
types
bias
content
stance
bias
ideological
bias
present
three
novel
fairness-aware
measures
bias
suffer
limita
tions
previously
presented
bias
measures
based
common
information
retrieval
ir
utility-based
evaluation
measures
precision
cut-off
rank
biased
preci
sion
rbp
discounted
cumulative
gain
cut-off
dcg
explained
sect
3.2
detail
apply
proposed
framework
measure
stance
ideological
bias
political
searches
searches
related
wide
range
controversial
topics
including
limited
education
health
entertainment
religion
politics
google
bing
news
search
results
also
utilise
framework
compare
relative
bias
queries
various
controversial
issues
two
popular
search
engines
google
bing
news
search
like
note
distinguish
stance
ideological
leaning
serps
stance
serp
query
topic
favor
topic
whereas
ideological
leaning
serp
stands
specific
ideological
group
conservatives
liberals
supports
corresponding
topic
hence
stance
serp
directly
imply
ideological
leaning
example
given
two
controversial
queries
abortion
cuba
embargo
serp
positive
stance
topic
abortion
indicating
liberal
leaning
positive
stance
topic
cuba
embargo
indicates
conservative
leaning
therefore
looking
stance
serps
controversial
issues
enough
even
misleading
determining
ideological
bias
demonstrate
proposed
framework
can
used
quantify
bias
serps
search
engines
case
bing
google
response
queries
related
controversial
topics
analysis
mainly
two-fold
first
evaluate
stance
bias
serps
use
evaluation
proxy
quantify
ideological
bias
asserted
serps
search
engines
work
via
proposed
framework
aim
answer
following
research
ques
tions
rq1
pro-against
stance
space
search
engines
return
biased
serps
towards
con
troversial
topics
rq2
search
engines
show
significantly
different
magnitude
stance
bias
towards
controversial
topics
rq3
conservative-liberal
ideology
space
search
engines
return
biased
serps
biases
significantly
different
towards
controversial
topics
address
research
questions
controversial
topics
representing
broad
range
issues
serps
google
bing
content
analysis
analysing
textual
content
retrieved
documents
order
answer
rq1
measure
degree
deviation
ranked
serps
ideal
distribution
different
stances
equally
referring
notion
relevance
defined
literature
system
relevance
topical
relevance
relevance
predicted
system
123
88
information
retrieval
journal
2021
24
85
113
likely
appear
detect
bias
results
unbalanced
representation
distinct
perspectives
label
documents
stances
crowd-sourcing
use
labels
stance
bias
evaluation
paper
focus
particular
kind
bias
statistical
parity
generally
known
equality
outcome
given
population
divided
groups
groups
output
system
equally
represented
contrast
popular
measure
generally
known
equality
opportunity
given
population
divided
groups
groups
output
represented
based
proportion
population
namely
base
rates
choosing
equality
outcome
mainly
two
reasons
first
context
controversial
topics
corresponding
debate
questions
queries
certain
answers
based
scientific
facts
second
identification
stance
full
ranking
list
fair
representative
set
indexed
documents
expensive
get
annotated
crowd-sourcing
thus
choice
ideal
ranking
makes
experiments
feasible
address
rq2
compare
stance
bias
serps
two
search
engines
see
show
similar
level
bias
corresponding
controversial
topics
rq3
naturally
answered
assigning
ideological
leaning
label
query
topic
conservative
liberal
depending
ideology
favors
proposition
query
interpret
document
stance
labels
conservative-to-liberal
ideology2
space
transform
stance
labels
ideological
leanings
according
assigned
leaning
labels
corresponding
topics
note
conservative-to-liberal
ideology
space
stand
political
parties
context
accept
ideology
labels
conservative
liberal
viewpoint
towards
given
controversial
topic
similarly
fulfilled
lahoti
et
al
2018
three
popular
controversial
topics
gun
control
abortion
obamacare
twitter
domain
instance
topic
abortion
query
abortion
legal
since
mostly
liberals
support
proposition
query
liberal
leaning
assigned
abortion
stance
labels
retrieved
documents
towards
query
transformed
ideological
leanings
follows
document
pro
stance
means
supports
asserted
proposition
ideological
leaning
liberal
stance
leaning
conservative
bias
evaluation
framework
concentrate
top-10
serps
coming
news
sources
investigate
two
major
search
engines
bing
google
terms
bias
deliberately
use
news
serps
experiments
since
often
exhibit
specific
view
towards
topic
alam
downey
2014
recent
studies
sarcona
2019
99firms
2019
show
average
70
clicks
first
page
results
thus
focus
top-10
results
show
existence
bias
experiments
show
statistically
significant
difference
stance
bias
magnitude
measured
across
two
search
engines
meaning
favour
one
specific
stance
however
stress
stance
bias
results
need
taken
grain
salt
demonstrated
abortion
cuba
embargo
query
examples
polarisation
society
mostly
ideological
leanings
second
phase
experiments
show
statistically
significant
difference
ideological
bias
search
engines
favour
one
ideological
leaning
remainder
paper
structured
follows
sect
give
related
work
search
bias
evaluation
framework
proposed
sect
sect
detail
experimental
setup
present
results
discuss
results
sect
sect
present
limitations
work
conclude
sect
referring
notion
ideology
perceived
crowd
workers
123
information
retrieval
journal
2021
24
85
113
89
background
related
work
recent
years
bias
analysis
serps
search
engines
attracted
lot
interest
baeza
yates
2016
mowshowitz
kawaguchi
2002b
noble
2018
pan
et
al
2007
tavani
2012
due
concerns
search
engines
may
manipulate
search
results
influencing
users
main
reason
behind
concerns
search
engines
become
fundamental
source
information
dutton
et
al
2013
surveys
pew
2014
reuters
2018
found
people
obtain
news
search
engines
social
media
users
reported
higher
trust
search
engines
accuracy
information
newman
et
al
2018
2019
elisa
shearer
2018
many
internet-using
us
adults
even
use
search
engines
fact-check
information
dutton
et
al
2017
figure
growing
usage
search
engines
trust
might
undesirable
effects
public
methods
measure
effects
following
review
research
areas
related
first
automatic
stance
detection
fair
ranking
evaluation
lastly
search
bias
quantification
2.1
opinion
mining
sentiment
analysis
form
opinion
mining
related
work
contrastive
opinion
modeling
com
proposed
fang
et
al
2012
com
given
political
text
collection
task
present
opinions
distinct
perspectives
given
query
topic
quantify
differences
unsupervised
topic
model
com
applied
debate
records
headline
news
differently
keyword
analysis
differentiate
opinions
using
topic
modelling
compute
different
ir
metrics
content
news
articles
evaluate
compare
bias
serps
two
search
engines
aktolga
allan
2013
consider
sentiment
towards
controversial
topics
propose
different
diversification
methods
based
topic
sentiment
main
aim
diversify
retrieved
results
search
engine
according
various
sentiment
biases
blog
posts
rather
measure
bias
serps
news
search
engines
work
demartini
siersdorfer
2010
exploit
automatic
lexicon-based
text
classification
approaches
support
vector
machines
sentiwordnet
respectively
extract
sentiment
value
textual
content
serps
response
controversial
topics
unlike
us
demar
tini
siersdorfer
2010
use
sentiment
information
compare
opinions
retrieved
results
three
commercial
search
engines
without
measuring
bias
paper
propose
new
bias
evaluation
framework
robust
bias
measures
systematically
measure
bias
serps
chelaru
et
al
2012
focus
queries
rather
serps
inves
tigate
opinionated
queries
issued
search
engines
computing
sentiment
suggested
queries
controversial
topics
follow-up
work
chelaru
et
al
2013
authors
use
different
classifiers
detect
sentiment
expressed
queries
extend
previous
experiments
two
different
use
cases
instead
queries
work
analyses
serps
news
domain
therefore
need
identify
stance
news
articles
automatically
obtaining
article
stances
beyond
scope
work
thus
use
crowd-sourcing
2.2
evaluating
fairness
ranking
fairness
evaluation
ranked
results
attracted
attention
recent
years
yang
stoy
anovich
2017
propose
three
bias
measures
namely
normalized
discounted
difference
rnd
normalized
discounted
kullback-leibler
divergence
rkl
normalized
dis
123
90
information
retrieval
journal
2021
24
85
113
counted
ratio
rrd
related
normalized
discounted
cumulative
gain
ndcg
use
logarithmic
discounting
regularization
inspired
ndcg
also
stated
original
paper
researchers
use
metrics
check
exists
systematic
discrimination
group
individuals
two
differ
ent
groups
protected
g1
unprotected
group
g2
ranking
words
researchers
quantify
relative
representation
g1
protected
group
whose
members
share
characteristic
race
gender
used
discrimination
ranked
output
definitions
three
proposed
measures
can
rewritten
follows
g1
dg1
log2
10
20
general
definition
evaluation
measure
given
ranked
list
docu
ments
serp
whereas
g1
specifically
protected
group
g1
definition
normalisation
constant
ranked
list
retrieved
serp
size
ranked
list
number
documents
ranked
list
note
deliberately
incremented
10
compute
set-based
fairness
discrete
values
top-10
top-20
etc
instead
usually
done
ir
proposed
measures
show
correct
behaviour
bigger
sample
sizes
purpose
computing
set-based
fairness
express
fair
higher
positions
ranked
list
important
top-10
vs
top-100
rewritten
formula
dg1
defines
distance
function
expected
probability
retrieve
document
belonging
g1
overall
population
observed
probability
rank
measure
systematic
bias
probabilities
turn
equal
pg1
ri
g1
computed
g1
cut-off
value
three
proposed
measures
formula
number
documents
considered
cut-off
value
ri
defined
document
retrieved
rank
note
ri
returns
label
associated
document
ri
specifying
group
g1
g2
based
ri
g1
refers
conditional
statement
returns
document
ri
member
g1
otherwise
original
paper
dg1
defined
rnd
rkl
rrd
dg1
pg1
pg1
rnd
pg1
dg1
pg1
log
pg1
pg1
pg1
log
rkl
pg1
pg1
pg1
dg1
rrd
pg1
pg1
measures
although
inspired
ir
evaluation
measures
particularly
context
content
bias
search
results
suffer
following
limitations
rnd
measure
focuses
protected
group
g1
compute
steps
given
equal
desired
proportion
two
groups
50
50
distance
function
rnd
denoted
dg1
always
give
value
0.5
first
retrieved
document
will
always
case
matter
group
document
belongs
pro
case
caused
dg1
rnd
123
information
retrieval
journal
2021
24
85
113
91
use
absolute
value
eq
case
holds
10
measure
bias
top-10
results
fact
avoided
original
paper
yang
stoyanovich
2017
computing
steps
10
top-10
top-20
etc
rather
steps
usually
done
ir
gives
meaningful
results
evaluation
framework
rkl
measure
differentiate
biases
equal
magnitude
opposite
directions
given
equal
desired
proportion
two
groups
50
50
differentiate
bias
towards
conservative
liberal
case
also
ir
settings
easy
interpret
computed
values
kl-divergence
denoted
dg1
rkl
compared
measures
since
measures
based
standard
utility
based
ir
measures
furthermore
kl-divergence
tends
generate
larger
distances
small
datasets
thus
compute
larger
bias
values
case
10
documents
situation
may
become
even
problematic
measure
bias
less
number
documents
top-3
top-5
fine-grained
analysis
original
paper
disadvantage
alleviated
computing
rkl
values
also
discrete
points
steps
10
instead
rrd
measure
treat
protected
unprotected
groups
g1
g2
symmet
rically
stated
original
paper
applicable
framework
proposed
measures
treat
g1
g2
equal
since
two
protected
groups
pro
stance
bias
conservative
liberal
ideological
bias
measure
bias
search
settings
moreover
rrd
applicable
special
conditions
g1
minority
group
underlying
population
also
declared
authors
constraints
measures
scope
search
bias
evaluation
measures
focus
differences
relative
representation
g1
dis
tributions
therefore
general
point
view
probably
samples
necessary
measures
show
expected
behavior
work
properly
original
paper
experiments
fulfilled
three
different
datasets
one
synthetic
includes
1000
samples
two
real
datasets
include
1000
7000
samples
evaluate
bias
measures
10
samples
query
wise
evaluation
probably
measures
mainly
devised
purpose
measuring
bias
ranked
outputs
instead
search
engine
results
none
datasets
contain
search
results
either
measures
difficult
use
practice
since
rely
normalization
term
computed
stochastically
highest
possible
value
corresponding
bias
measure
given
number
documents
protected
group
size
g1
paper
rely
standard
statistical
tests
since
easier
interpret
provide
confidence
intervals
successfully
used
investigate
inequalities
search
systems
previously
chen
et
al
2018
measures
consider
relevance
fundamental
aspect
evaluating
bias
search
engines
example
case
searching
controversial
topic
first
retrieved
document
news
belonging
g1
content
relevant
searched
topic
measures
still
consider
document
positive
g1
however
document
absolutely
effect
providing
unbiased
representation
controversial
topic
user
metrics
devised
particularly
evaluating
bias
ranked
outputs
instead
serps
although
proposed
measures
yang
stoyanovich
2017
valuable
context
measuring
bias
ranked
outputs
individuals
ranked
individuals
members
protected
group
g1
measures
aforemen
123
92
information
retrieval
journal
2021
24
85
113
tioned
limitations
limitations
particularly
visible
content
bias
evaluation
web
documents
ranked
search
engines
typical
ir
setting
paper
address
limitations
proposing
family
fairness-aware
measures
main
purpose
evaluating
content
bias
serps
based
standard
utility-based
ir
evaluation
measures
zehlike
et
al
2017
based
yang
stoyanovich
2017
work
propose
algorithm
test
statistical
significance
fair
ranking
beutel
et
al
2019
propose
pairwise
fairness
measure
recommender
systems
however
authors
unlike
us
measure
fair
ness
personalized
recommendations
consider
relevance
work
unpersonalized
information
retrieval
setting
consider
relevance
kallus
zhou
2019
investigate
fairness
predictive
risk
scores
bipartite
ranking
task
main
goal
rank
positively
labelled
examples
negative
ones
however
measures
bias
based
area
roc
curve
auc
agnostic
rank
position
document
retrieved
2.3
quantifying
search
engine
biases
although
search
engine
algorithms
transparent
available
external
researchers
algorithm
auditing
techniques
provide
effective
means
systematically
evaluating
results
controlled
environment
sandvig
et
al
2014
prior
works
leverage
lda-variant
unsupervised
methods
crowd-sourcing
analyse
bias
content
url
analysis
indexical
bias
saez-trumper
et
al
2013
propose
unsupervised
methods
characterise
different
types
biases
online
news
media
social
media
communities
also
analysing
political
perspectives
news
sources
yigit-sert
et
al
2016
investigate
media
bias
analysing
user
comments
along
content
online
news
articles
identify
latent
aspects
two
highly
polarising
topics
turkish
political
arena
kulshrestha
et
al
2017
quantify
bias
social
media
measuring
bias
author
tweet
kulshrestha
et
al
2018
bias
web
search
quantified
url
analysis
google
political
domain
without
serp
content
analysis
work
consider
google
bing
serps
news
sources
ny-times
bbc
news
order
quantify
bias
content
analysis
addition
unsupervised
approaches
crowd-sourcing
widely
used
mechanism
analyse
bias
content
crowd-sourcing
common
approach
labelling
tasks
different
research
areas
image
video
annotation
krishna
et
al
2017
vondrick
et
al
2013
object
detection
su
et
al
2012
named
entity
recognition
lawson
et
al
2010
finin
et
al
2010
sentiment
analysis
räbiger
et
al
2018
relevance
evaluation
alonso
et
al
2008
alonso
mizzaro
2012
yuen
et
al
2011
provide
detailed
survey
crowd-sourcing
applications
yuen
et
al
2011
suggest
crowd-sourcing
can
also
used
gathering
opinions
crowd
mellebeek
et
al
2010
use
crowd-sourcing
classify
spanish
consumer
comments
show
non-expert
amazon
mechanical
turk
mturk
annotations
viable
cost-effective
alternative
expert
ones
work
use
crowd-sourcing
collecting
opinions
public
consumer
products
controversial
topics
apart
content
bias
another
research
area
namely
indexical
bias
indexi
cal
bias
refers
bias
displayed
selection
items
rather
content
retrieved
documents
namely
content
bias
mowshowitz
kawaguchi
2002b
mow
showitz
kawaguchi
2002a
mowshowitz
kawaguchi
2005
quantify
instead
123
information
retrieval
journal
2021
24
85
113
93
indexical
bias
using
precision
recall
measures
moreover
researchers
approximate
ideal
norm
distribution
produced
collection
search
engines
measure
bias
yet
may
fair
bias
evaluation
procedure
since
ideal
unbiased
whereas
serps
search
engines
may
actually
contain
bias
similarly
chen
yang
2006
use
method
order
quantify
indexical
content
bias
ever
content
analysis
performed
representing
serps
weighted
vector
different
html
tags
without
in-depth
analysis
textual
content
work
evaluate
content
bias
analysing
textual
contents
google
bing
serps
generate
ideal
relying
serps
search
engines
order
measure
bias
fair
way
addition
categorisation
content
indexical
bias
analysis
prior
methods
used
auditing
algorithms
quantify
bias
can
also
divided
three
main
categories
audience-based
content-based
rater-based
audience-based
measures
focus
identifying
political
perspectives
media
outlets
web
pages
utilising
interests
ideologies
political
affiliations
users
likes
shares
facebook
bakshy
et
al
2015
based
premise
readers
follow
news
sources
closest
ideological
point
view
mullainathan
shleifer
2005
lahoti
et
al
2018
model
problem
ideological
leaning
social
media
users
media
sources
liberal-conservative
ideology
space
twitter
constrained
non-negative
matrix
factorisation
problem
content-based
measures
exploit
linguistic
features
textual
content
gentzkow
shapiro
2010
extract
frequent
phrases
different
political
partisans
democrats
republicans
congress
reports
researchers
come
metric
media
slant
index
measure
us
newspapers
political
leaning
finally
rater-based
methods
also
exploit
textual
content
can
evaluated
content-based
methods
unlike
content-based
rater-based
methods
use
ratings
people
sentiment
partisan
ideological
leaning
content
instead
analysing
textual
content
linguisti
cally
rater-based
methods
generally
leverage
crowd-sourcing
collect
labels
content
analysis
instance
budak
et
al
2016
quantify
bias
partisanship
us
news
outlets
newspapers
political
blogs
15
selected
queries
related
wide
range
controversial
issues
democrats
republicans
argue
researchers
use
mturk
crowd-sourcing
platform
obtain
topic
political
slant
labels
positive
towards
democrats
republicans
articles
similarly
epstein
robertson
2017
use
crowd-sourcing
score
individual
search
results
diakopoulos
et
al
2018
make
use
mturk
platform
rater-based
approach
get
labels
google
serp
websites
focusing
content
apply
audience-based
approach
utilising
prior
work
bakshy
et
al
2015
specifically
quantifying
partisan
bias
work
follows
rater-based
approach
making
use
mturk
platform
crowd-sourcing
analyse
web
search
bias
stances
ideological
leanings
news
articles
instead
partisan
bias
textual
contents
serps
endeavors
audit
partisan
bias
web
search
diakopoulos
et
al
2018
present
four
case
studies
google
search
results
quantify
partisan
bias
first
page
collect
serps
issuing
complete
candidate
names
2016
us
presidential
election
queries
utilise
crowd-sourcing
obtain
sentiment
scores
serps
found
google
presented
higher
proportion
negative
articles
republican
candidates
democratic
ones
similarly
epstein
robertson
2017
present
case
study
election
use
browser
extension
collect
google
yahoo
search
data
election-related
queries
use
crowd-sourcing
score
serps
researchers
also
found
left-leaning
bias
google
biased
yahoo
follow-up
work
found
small
significant
ranking
bias
standard
serps
due
personalisation
robertson
et
al
2018a
similarly
researchers
audit
google
search
123
94
information
retrieval
journal
2021
24
85
113
donald
trump
presidential
inauguration
dynamic
set
political
queries
using
auto
complete
suggestions
robertson
et
al
2018b
hu
et
al
2019
conduct
algorithm
audit
construct
specific
lexicon
partisan
cues
measuring
political
partisanship
google
search
snippets
relative
corresponding
web
pages
define
corresponding
difference
bias
particular
use
case
without
making
robust
search
bias
evaluation
serps
user
perspective
work
introduce
novel
fairness-aware
ir
measures
involve
rank
information
evaluate
content
bias
use
crowd
sourcing
obtain
labels
news
serps
returned
towards
queries
related
wide
range
controversial
topics
instead
political
ones
robust
bias
evaluation
measures
main
aim
audit
ideological
bias
web
search
rather
solely
partisan
bias
apart
partisan
bias
recent
studies
investigated
different
types
bias
various
purposes
chen
et
al
2018
investigate
gender
bias
various
resume
search
engines
platforms
help
recruiters
search
suitable
candidates
use
statistical
tests
examine
two
types
indirect
discrimination
individual
group
fairness
similarly
another
research
study
authors
investigate
gender
stereotypes
analyzing
gender
distribution
image
search
results
retrieved
bing
four
different
regions
otterbacher
et
al
2017
researchers
use
query
person
queries
related
68
character
traits
intelligent
person
results
show
photos
women
often
retrieved
emotional
similar
traits
whereas
rational
related
traits
represented
photos
men
follow-up
work
researchers
conduct
controlled
experiment
via
crowd-sourcing
participants
three
different
countries
detect
bias
image
search
results
otterbacher
et
al
2018
demographic
information
along
measures
sexism
analysed
together
results
confirm
sexist
people
less
likely
detect
report
gender
biases
search
results
raji
buolamwini
2019
examine
impact
publicly
naming
biased
performance
results
commercial
ai
products
face
recognition
directly
challenging
companies
change
products
geyik
et
al
2019
present
fairness-aware
ranking
framework
quantify
bias
respect
protected
attributes
improve
fairness
individuals
without
affecting
business
metrics
authors
extended
metrics
proposed
yang
stoyanovich
2017
specified
limitations
sect
2.2
evaluated
procedure
using
simulations
application
linkedin
talent
search
vincent
et
al
2019
measure
dependency
search
engines
user-created
content
respond
queries
using
google
search
wikipedia
articles
another
work
researchers
propose
novel
metric
involves
users
attention
auditing
group
fairness
ranked
lists
sapiezynski
et
al
2019
gao
shah
2019
propose
framework
effectively
efficiently
estimate
solution
space
fairness
ir
modelled
optimisation
problem
fairness
constraint
researchers
work
top-k
diversity
fairness
ranking
terms
statistical
parity
disparate
impact
fairness
propose
entropy-based
metrics
measure
topical
diversity
bias
presented
serps
google
using
clustering
instead
labelled
dataset
group
information
gao
shah
2020
unlike
approach
goal
quantify
search
bias
serps
rather
topical
diversity
use
crowd-labelled
dataset
thereby
evaluate
bias
user
perspective
stance
ideological
leanings
documents
context
focus
proposing
new
search
bias
evaluation
procedure
ranked
lists
quantify
bias
news
serps
proposed
robust
fairness-aware
ir
measures
also
compare
relative
bias
two
search
engines
incorporating
relevance
ranking
information
procedure
without
tracking
source
bias
discussed
123
information
retrieval
journal
2021
24
85
113
95
sect
procedure
can
used
source
bias
analysis
well
leave
future
work
search
engine
bias
evaluation
framework
section
describe
search
bias
evaluation
framework
present
measures
bias
proposed
protocol
identify
search
bias
3.1
preliminaries
first
aim
detect
bias
respect
distribution
stances
expressed
contents
serps
let
set
search
engines
set
queries
controversial
topics
query
issued
search
engine
search
engine
returns
serp
define
stance
i-th
retrieved
document
ri
respect
ri
stance
can
following
values
pro
neutral
not-relevant
document
stance
respect
topic
can
pro
document
favour
controversial
topic
document
describes
pro
aspects
topic
neutral
document
support
help
either
side
controversial
topic
document
provides
impartial
fair
description
pro
cons
topic
document
controversial
topic
document
describes
cons
aspects
topic
not-relevant
document
not-relevant
respect
controversial
topic
analyses
deliberately
use
recent
controversial
topics
us
real
debatable
ones
rather
topics
possibly
exposed
false
media
balance
occurs
media
present
opposing
viewpoints
equal
evidence
supports
flat
earth
debate
grimes
2016
stokes
2019
topic
set
contains
abortion
illegal
immigration
gay
marriage
similar
controversial
topics
comprise
opposing
points
view
since
complicated
concepts
concerning
identity
religion
political
ide
ological
leaning
actual
points
search
engines
likely
provide
biased
results
noble
2018
influence
people
dramatically
second
aim
detect
bias
respect
distribution
ideological
leanings
expressed
contents
serps
associating
query
belonging
controversial
topic
one
current
ideological
leaning
combining
stances
ri
associated
ideological
leaning
can
measure
ideological
bias
content
given
serp
topic
belongs
specific
ideology
document
retrieved
topic
pro
stance
consider
document
biased
towards
ideology
define
ideological
leaning
ideological
leaning
can
following
values
conservative
liberal
neither
topic
ideological
leaning
can
conservative
topic
part
conservative
policies
conservatives
favour
topic
123
96
information
retrieval
journal
2021
24
85
113
table
symbols
functions
labels
used
throughout
paper
symbols
set
search
engines
search
engine
set
queries
query
ranked
list
given
serp
list
retrieved
documents
ri
document
retrieved
rank
size
number
documents
ranked
list
number
documents
considered
cut-off
functions
ri
returns
label
associated
ri
evaluation
measure
serps
labels
pro
stance
neutral
stance
stance
not-relevant
stance
conservative
ideological
leaning
liberal
ideological
leaning
neither
ideological
leanings
liberal
topic
part
liberal
policies
liberals
favour
topic
neither
neither
policies
either
favour
topic
reference
table
shows
summary
symbols
functions
labels
used
paper
3.2
measures
bias
based
aforementioned
definition
provided
sect
bias
can
quantified
mea
suring
degree
deviation
distribution
documents
ideal
one
give
broad
definition
ideal
list
poses
problems
scope
work
controversial
topics
can
mention
existence
bias
ranked
list
retrieved
search
engine
presented
information
significantly
deviates
true
likelihoods
white
2013
justified
sect
scope
work
focus
equality
output
thus
accept
true
likelihoods
different
views
equal
rather
computing
corresponding
base
rates
therefore
using
proposed
definition
reversely
can
assume
ideal
list
one
minimises
difference
two
opposing
views
indicate
context
stances
formally
measure
stance
bias
serp
follows
123
information
retrieval
journal
2021
24
85
113
97
function
measures
likelihood
satisfying
information
need
user
view
view
note
ideological
bias
measured
way
transforming
stances
documents
ideological
leanings
will
explained
sect
4.2
defining
eq
define
mean
bias
mb
search
engine
mb
unbiased
search
engine
produce
mean
bias
limitation
mb
search
engine
biased
towards
view
one
topic
bias
towards
view
another
topic
two
contributions
will
cancel
order
avoid
limitation
also
define
mean
absolute
bias
mab
consists
taking
absolute
value
bias
formally
defined
follows
mab
unbiased
search
engine
produces
mean
absolute
bias
although
measure
defined
eq
solves
limitation
mb
mab
says
nothing
towards
view
search
engine
biased
making
two
measures
bias
complementary
ir
likelihood
satisfying
information
need
users
measured
via
retrieval
evaluation
measures
among
measures
selected
utility-based
evaluation
measures
class
evaluation
measures
quantify
terms
worth
user
normally
computed
sum
information
gain
summed
relevant
documents
retrieved
ir
evaluation
measures
used
following
experiments
rbp
dcg
view
formalised
eq
however
differently
previous
definition
ri
possible
outcomes
g1
g2
document
ri
can
return
label
associated
stance
hence
pro
documents
relevant
topic
taken
account
since
ri
returns
neutral
not-relevant
otherwise
substituting
eq
eq
obtain
first
measure
bias
βp
ri
ri
main
limitation
measure
bias
weak
concept
ranking
first
documents
contribute
equally
bias
score
next
two
evaluation
measures
overcome
issue
defining
discount
functions
rbp
weights
every
document
based
coefficients
normalised
geometric
series
value
parameter
rbp
similarly
done
reformulate
rbp
measure
bias
follows
rbp
pi
ri
substituting
eq
eq
obtain
βrbp
pi
ri
ri
123
98
information
retrieval
journal
2021
24
85
113
dcg
instead
weights
document
based
logarithmic
discount
function
similarly
done
rbp
reformulate
dcg
measure
bias
follows
dcg
ri
log
substituting
eq
eq
obtain
βdcg
ri
ri
log
since
evaluating
web-users
dcg
set
10
rbp
set
0.8
last
formulation
eq
although
looks
similar
rnd
measure
suffer
four
limitations
introduced
sect
2.2
particular
presented
measures
bias
focus
one
group
use
binary
score
associated
document
stance
ideological
leaning
similar
way
measures
used
ir
considering
relevance
also
like
ir
can
computed
rank
exclude
non-relevant
documents
measurement
bias
framework
provides
various
user
models
associated
ir
evaluation
measures
dcg
rbp
3.3
quantifying
bias
using
measures
bias
defined
previous
section
quantify
bias
two
search
engines
bing
google
using
news
versions
search
engines
compare
thereof
following
describe
step
proposed
procedure
used
quantify
bias
serps
dataset
construction
gathered
serps
search
engines
queries
controversial
topic
retrieved
document
obtain
stance
document
respect
topic
ideological
leaning
query
belonging
controversial
topic
done
automatically
via
classification
however
dataset
training
decided
gather
labels
via
crowd-sourcing
bias
evaluation
compute
bias
measures
every
serp
three
ir-based
measures
bias
rbp
dcg
aggregate
results
using
two
measures
bias
mb
mab
statistical
analysis
identify
whether
bias
measured
byproduct
ran
domness
compute
one-sample
t-test
null
hypothesis
difference
exists
true
mean
equal
zero
hypothesis
rejected
hence
significant
difference
claim
evaluated
search
engine
biased
compare
difference
bias
measured
across
two
search
engines
using
two-tailed
paired
t-test
null
hypothesis
difference
two
true
means
equal
zero
hypothesis
rejected
hence
significant
difference
claim
difference
bias
two
search
engines
experimental
setup
section
provide
description
experimental
setup
based
proposed
method
defined
sect
3.3
123
information
retrieval
journal
2021
24
85
113
99
4.1
material
obtained
controversial
topics
procon
org
2018
procon
org
non-profit
charitable
organisation
provides
online
resource
search
controversial
topics
procon
org
selects
topics
controversial
important
many
us
citizens
also
taking
readers
suggestions
account
collected
74
controversial
topics
topic
questions
website
applied
three
filters
topics
practical
reasons
without
deliberately
selecting
topics
first
filter
selects
polar
questions
also
known
yes-no
questions
different
sides
analysis
filter
decreased
topic
set
size
74
70
second
filter
removes
topics
contain
up-to-date
information
topic
pages
provided
procon
org
since
recent
controversial
topics
return
up-to-date
results
second
filter
number
topics
became
64
lastly
third
filter
includes
topics
search
engines
return
results
corresponding
topic
questions
otherwise
comparison
analysis
possible
last
filter
final
topic
set
became
size
57
table
contains
full
list
controversial
topic
titles
questions
used
study
used
topic
questions
57
topics
crawling
example
topic
question
topic
title
abortion
abortion
legal
topic
questions
reflect
main
debate
corresponding
controversial
topics
used
including
upper-cased
characters
without
removing
punctuation
etc
querying
search
engines
collected
news
search
results
incognito
mode
avoid
personalisation
effect
thus
retrieved
serps
specific
anyone
presumably
general
us
users
submitted
topic
question
us
news
search
engines
google
bing
using
us
proxy
since
used
news
versions
two
search
engines
sponsoring
results
may
affect
analysis
appear
news
search
results
firstly
crawled
urls
retrieved
results
topic
question
minimise
time
lags
search
engines
since
serp
topic
may
vary
time
subsequently
extracted
textual
contents
top-10
documents
using
crawled
urls
way
time
span
serps
google
bing
controversial
topic
whole
corpus
became
min
average
moreover
starting
crawling
process
firstly
made
experiments
small
set
topics
different
topic
set
provided
paper
news
search
well
default
search
observe
significant
changes
especially
top-10
documents
news
search
even
10
15
min
time
lags
indicates
news
search
less
dynamic
default
search
believe
min
time
lags
drastically
affect
search
results
4.2
crowd-sourcing
campaigns
end-to-end
process
obtaining
stances
ideological
leanings
shown
flow
chart
fig
emphasised
dotted
parts
flow-chart
show
steps
document
stance
classification
dsc
topic
ideological
leaning
classification
tilc
dsc
process
inputs
unlabelled
top-10
search
results
crawled
data
collection
procedure
described
sect
4.1
outputs
stance
labels
documents
via
crowd-sourcing
respect
topic
questions
used
retrieve
displayed
flow-chart
tilc
process
uses
crowd-sourcing
output
ideological
leanings
123
100
information
retrieval
journal
2021
24
85
113
table
controversial
topics
topics
marked
red
dots
conservative
blue
liberal
abortion
abortion
alternative
energy
vs
animal
testing
legal
fossil
fuels
can
animals
used
alternative
energy
scientific
commercial
effectively
replace
fossil
testing
fuels
banned
books
bill
clinton
bill
born
gay
origins
parents
adults
clinton
good
president
sexual
orientation
able
ban
books
sexual
orientation
schools
libraries
determined
birth
cell
phones
radiation
climate
change
human
college
education
worth
cell
phone
radiation
safe
activity
primarily
college
education
responsible
global
worth
climate
change
concealed
handguns
corporal
punishment
corporate
tax
rate
jobs
adults
corporal
lowering
federal
right
carry
concealed
punishment
used
corporate
income
tax
rate
handgun
k-12
schools
create
jobs
cuba
embargo
daylight
savings
time
drinking
age
lower
united
states
maintain
united
states
drinking
age
embargo
cuba
keep
daylight
saving
lowered
21
time
younger
age
drone
strikes
overseas
drug
use
sports
electoral
college
united
states
performance
enhancing
united
states
use
continue
use
drone
drugs
steroids
electoral
college
strikes
abroad
accepted
sports
presidential
elections
euthanasia
assisted
vaping
e-cigarettes
felon
voting
felons
suicide
euthanasia
vaping
e-cigarettes
completed
physician-assisted
safe
sentence
incarceration
suicide
legal
probation
parole
allowed
vote
fighting
hockey
gay
marriage
gay
gold
standard
fighting
allowed
marriage
legal
united
states
return
hockey
gold
standard
golf
sport
golf
illegal
immigration
israeli-palestinian
sport
government
allow
two-state
solution
immigrants
two-state
solution
israel
illegally
become
us
palestine
citizens
acceptable
solution
israeli-palestinian
conflict
lowering
voting
age
medical
marijuana
milk
healthy
16
voting
age
marijuana
medical
drinking
milk
healthy
lowered
16
option
humans
minimum
wage
national
anthem
protest
net
neutrality
net
federal
minimum
wage
refusing
stand
neutrality
restored
increased
national
anthem
appropriate
form
protest
obamacare
obamacare
obesity
disease
olympics
olympic
patient
protection
obesity
disease
games
overall
benefit
affordable
care
act
host
countries
obamacare
good
cities
america
123
information
retrieval
journal
2021
24
85
113
101
table
continued
penny
keep
police
body
cameras
prescription
drug
ads
penny
stay
circulation
police
officers
prescription
drugs
wear
body
cameras
advertised
directly
consumers
prostitution
legalize
right
health
care
ronald
reagan
ronald
prostitution
americans
reagan
good
president
legal
right
entitled
health
care
sanctuary
cities
school
uniforms
school
vouchers
school
sanctuary
cities
receive
students
wear
vouchers
good
idea
federal
funding
school
uniforms
social
media
social
social
security
standardized
tests
networking
sites
good
privatization
use
standardized
tests
society
social
security
improving
education
privatized
america
student
loan
debt
tablets
vs
textbooks
teacher
tenure
student
loan
debt
tablets
replace
teachers
get
tenure
easier
discharge
textbooks
k-12
schools
bankruptcy
god
pledge
universal
basic
income
vaccines
kids
words
universal
basic
income
vaccines
required
god
us
pledge
good
idea
children
allegiance
vegetarianism
video
games
violence
voting
machines
people
become
vegetarian
violent
video
games
electronic
voting
machines
contribute
youth
improve
voting
violence
process
fig
flow-chart
crowd-sourcing
campaigns
topic
questions
accepted
stance
labels
documents
acquired
dsc
process
transformed
ideological
leaning
labels
based
assigned
ideology
corresponding
topic
questions
steps
obtaining
document
labels
stance
ideological
leaning
detection
described
123
102
information
retrieval
journal
2021
24
85
113
label
stance
document
respect
topic
questions
used
crowd
sourcing
selected
mturk
crowd-sourcing
platform
platform
obtain
high
quality
crowd-labels
task
properties
set
follows
since
topics
mostly
related
us
selected
crowd-workers
us
moreover
tried
find
qualified
experienced
workers
setting
following
thresholds
human
intelligence
task
hit
approval
rate
percentage
greater
95
number
hits
approved
greater
1000
worker
set
wage
0.15
time
allowed
30
minutes
per
hit
document
judged
three
crowd-workers
classify
stance
document
asked
crowd-workers
label
given
controversial
topic
question
stance
document
pro
neutral
not-relevant
link
working
task
assigned
instructions
given
worker
three
groups
general
specific
initially
workers
provided
overview
stance
detection
task
steps
task
listed
read
topic
question
open
news
article
link
etc
finally
rules
tips
displayed
last
part
contained
definitions
pro
neutral
stance
given
sect
3.1
additionally
included
clue
workers
saying
title
article
may
give
general
idea
stance
however
sufficient
determine
overall
viewpoint
request
workers
read
also
rest
article
apart
end
page
put
warning
informed
workers
answers
known
us
may
reject
hits
single
self-contained
task
worker
based
evaluation
following
page
hit
shown
worker
topic
question
query
link
news
article
whose
stance
will
determined
repeating
reminding
main
question
stance
detection
task
order
obtain
reliable
annotations
first
annotated
randomly
chosen
set
doc
uments
later
used
check
quality
crowd-labels
specified
warning
workers
expert
labels
rejected
low
quality
annotations
requested
new
labels
documents
iterative
process
continued
obtained
docu
ment
labels
end
iterative
process
sake
label
reliability
computed
two
agreement
scores
approved
labels
document
stance
detection
reported
table
reported
inter-rater
agreement
scores
percent
agreements
corresponding
annotators
looked
pairwise
agreement
put
agreement
otherwise
computed
mean
fractions
reported
kappa
score
document
stance
classification
considered
fair
agreement
previously
researchers
reported
kappa
score
inter-rater
agreement
experts
0.385
instead
crowd-workers
task
document
stance
classification
serps
towards
different
query
set
includes
controversial
topics
well
popular
products
claiming
mturk
workers
difficulty
task
alam
downey
2014
although
task
seems
challenging
queries
controversial
issues
reported
kappa
score
mturk
workers
comparable
expert
agreement
score
believe
sufficient
due
subjective
nature
difficulty
task
distribution
accepted
stance
labels
search
results
search
engine
displayed
fig
one
may
argue
query
controversial
topic
issued
news
search
engine
serp
mostly
contain
controversial
articles
support
one
dominant
viewpoint
towards
given
topic
hence
informational
pages
articles
adequately
discussing
different
viewpoints
topic
documents
neutral
stance
never
get
chance
included
analysis
however
distribution
fig
refutes
argument
showing
majority
labels
search
engines
actually
neutral
123
information
retrieval
journal
2021
24
85
113
103
fig
percentages
document
stance
labels
annotated
crowd-workers
identify
ideological
leaning
topic
used
crowd-sourcing
dis
played
fig
asked
crowd-workers
classify
topic
conservative
liberal
neither
get
high
quality
annotations
also
topic
ideology
detection
worker
properties
set
stance
detection
selected
crowd-workers
us
wage
per
hit
set
0.1
time
allowed
min
similarly
stance
detection
informational
page
gave
overview
listed
steps
lastly
provided
rules
tips
task
last
part
contained
ideological
leaning
definitions
given
sect
3.1
additionally
requested
workers
evaluate
ide
ological
leaning
given
topic
based
current
ideological
climate
warned
related
rejection
hits
next
page
workers
shown
hit
topic
question
query
one
main
debates
corresponding
topic
asked
worker
following
ideological
group
answer
favourably
question
topics
assigned
conservative
liberal
leanings
decided
based
judgment
five
annotators
majority-voting
leanings
topics
shown
table
two
agreement
scores
computed
judgments
ideological
leaning
detection
also
reported
table
map
stance
pro-to-against
conservative-to-liberal
applied
simple
transformation
documents
transformation
needed
may
documents
pro
stance
example
towards
abortion
cuba
embargo
though
documents
stance
different
ideological
leanings
since
pro
stance
abortion
implies
liberal
leaning
whereas
pro
stance
cuba
embargo
implies
conservative
leaning
topics
case
cuba
embargo
can
directly
interpret
pro-to-against
stance
labels
search
results
conservative
to-liberal
ideological
leaning
labels
topics
case
abortion
liberal-to-conservative
hand
topics
vaccines
kids
crowded
label
resulted
neither
conservative-to-liberal
liberal-to-conservative
transformation
meaningful
therefore
eliminated
analysis
note
within
budget
constraints
crowd-sourcing
protocol
designed
obtain
crowd-labels
high-quality
labelling
expert
random
sample
documents
applying
iterative
process
majority
voting
labels
123
104
information
retrieval
journal
2021
24
85
113
table
crowd-workers
campaign
inter-rater
fleiss-kappa
agreement
document
stance
0.4968
0.3500
topic
ideological
leaning
0.5281
0.3478
table
performance
10
rbp
dcg
10
search
engines
p-values
two-tailed
paired
t-test
computed
engine
0.8509
0.7708
3.9114
engine
engine
0.7404
0.6886
3.4773
p-value
0.001
0.001
0.01
table
stance
bias
search
10
rbp
dcg
10
engines
p-values
two-tailed
paired
t-test
computed
mb
engine
0.0281
0.0197
0.1069
engine
engine
0.0175
0.0271
0.1142
p-value
0.05
0.05
0.05
mab
engine
0.2596
0.2738
1.3380
engine
0.2246
0.2266
1.0789
p-value
0.05
0.05
0.05
table
ideological
bias
10
rbp
dcg
10
search
engines
p-values
two-tailed
paired
t-test
computed
mb
engine
0.1368
0.1247
0.6290
engine
engine
0.1289
0.1386
0.6591
p-value
0.05
0.05
0.05
mab
engine
0.2579
0.2894
1.3989
engine
0.2184
0.2158
1.0456
p-value
0.05
0.05
0.05
4.3
results
table
present
performance
two
search
engines
measured
topics
document
considered
relevant
classified
pro
neutral
difference
evaluation
measures
statistically
significant
table
present
stance
bias
search
engines
note
three
measures
bias
10
rbp
dcg
10
lower
value
better
means
lower
bias
scope
work
opposed
corresponding
classic
ir
measures
mb
mab
scores
positive
three
ir
evaluation
measures
also
differences
two
search
engines
mb
mab
measures
statistically
significant
shown
two-tailed
pair
t-test
measures
table
show
ideological
bias
similarly
table
lower
better
since
use
measures
bias
table
similar
table
unlike
table
mb
scores
negative
mab
scores
positive
three
ir
evaluation
measures
two-tailed
paired
t-test
computed
mbs
compare
difference
bias
engine
engine
statistically
123
information
retrieval
journal
2021
24
85
113
105
3.5
2.5
1.5
0.5
0.5
1.5
2.5
3.5
pro
fig
dc
10
dc
10
measured
stances
black
points
engine
yellow
points
engine
3.5
2.5
liberal
1.5
0.5
0.5
1.5
2.5
3.5
conserva
ve
fig
dc
10
dc
10
measured
ideological
leanings
black
points
engine
yellow
points
engine
123
106
information
retrieval
journal
2021
24
85
113
engine
engine
fig
dc
10
measured
stances
positive
negative
engine
engine
fig
dc
10
measured
leanings
positive
negative
123
information
retrieval
journal
2021
24
85
113
107
significant
nonetheless
two-tailed
test
mabs
statistically
significant
measure
10
statistically
significant
measures
rbp
dcg
10
fig
show
topic-wise
serps
distribute
pro-against
stance
space
measure
dcg
10
x-axis
pro
stance
score
dc
10
y-axis
stance
score
dc
10
point
corresponds
overall
serp
score
topic
black
points
serps
retrieved
engine
yellow
points
retrieved
engine
fig
compare
overall
stance
bias
score
dc
10
difference
pro
stance
scores
serps
topic
measured
two
search
engines
x-axis
engine
y-axis
engine
points
positive
coordinates
denote
topics
whose
serps
overall
biased
towards
pro
stance
negative
coordinates
stance
figures
similar
figs
instead
measuring
stance
bias
measure
ideological
bias
former
case
therefore
fig
displays
overall
serps
topics
distribute
conservative-liberal
ideological
space
measure
dcg
10
similarly
fig
compare
overall
ideological
bias
score
dc
10
difference
conservative
liberal
leaning
scores
serps
points
positive
coordinates
stand
topics
biased
towards
conservative
leaning
negative
coordinates
liberal
discussion
investigating
existence
bias
serps
initially
compared
retrieval
performances
two
search
engines
table
observe
performance
two
search
engines
high
engine
better
engine
difference
statistically
significant
verified
across
three
ir
evaluation
measures
next
verify
search
engines
return
biased
results
terms
document
stances
rq1
investigate
engines
suffer
level
bias
rq2
difference
engines
statistically
significant
table
mb
scores
positive
regarding
rq1
engines
seem
biased
towards
pro
stance
applied
one-sample
t-test
mb
scores
check
existence
stance
bias
true
mean
different
zero
mentioned
sect
3.3
however
biases
statistically
significant
means
expectation
may
result
noise
systematic
stance
bias
preference
one
stance
respect
based
mab
scores
can
observe
engines
suffer
absolute
bias
however
difference
two
engines
shown
non-significant
two-tailed
t-test
results
show
search
engines
biased
towards
specific
stance
returning
results
since
statistically
significant
difference
ideal
distribution
nonetheless
engines
exists
absolute
bias
can
interpreted
expected
bias
topic
question
empirical
findings
imply
search
engines
biased
topics
towards
pro
stance
others
towards
stance
results
displayed
fig
figure
refers
values
used
compute
mab
score
dcg
10
column
shows
difference
pro
stances
engines
topics
uniformly
distributed
note
topic
can
located
up-right
area
plot
sum
coordinates
bounded
maximum
possible
dcg
10
score
moreover
observe
topics
distributed
123
108
information
retrieval
journal
2021
24
85
113
similarly
across
engines
also
confirmed
fig
can
observe
stance
bias
scores
dc
10
differences
dcg
10
scores
pro
stance
dcg
10
scores
stance
topics
somehow
balanced
up-right
quadrant
low-left
quadrant
moreover
two
quadrants
area
agreement
stance
two
engines
two
quadrants
contain
topics
engines
disagree
can
conclude
engines
agree
majority
cases
lastly
investigate
search
engines
biased
ideology
space
rq3
looking
mb
scores
table
observe
search
engines
seem
biased
towards
ideological
leaning
liberal
mb
scores
negative
unlike
stance
bias
one
sample
t-test
mb
scores
show
expectations
statistically
significant
different
confidence
values
p-value
0.005
across
three
ir
measures
engine
whereas
confidence
value
10
engine
p-value
0.05
rbp
dcg
10
results
indicate
search
engines
biased
towards
leaning
liberal
comparing
two
search
engines
mb
scores
observe
differences
statistically
significant
means
observed
difference
may
result
random
noise
based
mab
since
mab
scores
positive
can
also
observe
engines
suffer
absolute
bias
however
contrast
observed
stance
bias
time
difference
expected
ideological
bias
two
search
engines
rbp
dcg
10
difference
engines
statistically
significant
finding
different
user
models
evaluation
measures
model
suggest
perceived
bias
users
may
change
based
behaviour
user
always
inspects
first
10
results
modelled
10
may
perceive
ideological
bias
engine
engine
less
systematic
user
just
inspects
top
results
may
perceive
engine
biased
engine
moreover
comparing
finding
performance
engines
can
observe
better
performing
engine
biased
worse
performing
one
comparing
fig
fig
observe
fig
points
look
less
uniformly
distributed
fig
topics
mostly
liberal
side
moreover
engine
fewer
points
conservative
side
engine
comparing
fig
fig
observe
engines
fig
biased
towards
liberal
side
respect
observed
fig
also
observe
engines
mostly
agree
points
placed
up-right
low-left
quadrants
conclusion
find
important
point
scope
work
find
source
bias
discussed
introduction
bias
may
result
input
data
may
contain
biases
search
algorithm
contains
sophisticated
features
specifically
chosen
algorithms
although
designed
effective
satisfying
information
needs
may
produce
systematic
biases
nonetheless
look
problem
user
perspective
matter
bias
comes
results
biased
described
findings
seem
consistent
prior
works
epstein
robertson
2017
diakopoulos
et
al
2018
exists
liberal
left-leaning
partisan
bias
serps
even
unpersonalised
search
settings
robertson
et
al
2018a
limitations
work
potential
limitations
stated
introduction
focus
particular
kind
bias
known
statistical
parity
generally
known
equality
outcome
123
information
retrieval
journal
2021
24
85
113
109
instead
equality
opportunity
uses
query-specific
base
rates
context
controversial
topics
document
labels
obtained
via
crowd-sourcing
bias
measure
requiring
equal
representation
stances
instead
query-specific
base
rates
made
experiments
feasible
firstly
query
questions
list
certain
answers
based
scientific
facts
subjective
queries
investigating
equality
opportunity
queries
can
categorized
subjective
objective
top
evaluation
framework
objective
queries
expert
labels
can
obtained
used
base
rates
search
results
can
evaluated
taking
account
base
rates
please
note
evaluation
framework
better
applied
controversial
queries
public
perspective
mainly
goal
balanced
serps
instead
skewed
results
believe
queries
handled
different
framework
since
queries
intrinsically
controversial
holocaust
real
one
correct
answer
without
need
discussion
besides
identification
stance
full
ranking
list
currently
expensive
get
annotated
via
crowd-sourcing
tackle
issue
machine
learning
model
can
help
us
automate
process
obtaining
stance
labels
another
potential
limitation
queries
may
real
user
queries
nonetheless
extracted
queries
directly
topic
pages
procon
org
2018
along
topics
deliberately
change
queries
avoid
interference
bias
side
results
work
make
domain-specific
selection
topics
apply
filtering
subjective
objective
rather
accepted
controversial
topics
general
public
perspective
main
scope
work
apart
crowd-workers
personal
biases
may
affect
labelling
process
reason
tried
mitigate
biases
asking
workers
annotate
stances
rather
ideologies
make
judgment
objective
ii
aggregating
final
judgment
coming
multiple
workers
additionally
analysis
refers
specific
point
time
data
collected
enable
reproducibility
easier
comparison
results
point
future
made
dataset
publicly
available
lastly
note
bias
analysis
can
used
indicator
potentially
biased
ranking
algorithms
enough
order
track
source
bias
scope
work
investigate
source
bias
may
come
data
input
bias
ranking
mechanism
algorithmic
bias
corresponding
search
engines
despite
potential
limitations
believe
work
good
attempt
evaluate
bias
search
results
new
bias
measures
dataset
crawled
specifically
search
bias
evaluation
since
bias
analysis
complex
deliberately
limited
scope
focused
bias
analysis
recent
controversial
topics
news
search
nonetheless
limitations
lead
us
numerous
interesting
future
directions
conclusion
future
work
work
introduced
new
bias
evaluation
measures
generalisable
evaluation
framework
address
issue
web
search
bias
news
search
results
applied
proposed
framework
measure
stance
ideological
bias
serps
bing
google
well
compare
relative
bias
towards
controversial
topics
initial
results
show
search
engines
seem
unbiased
considering
document
stances
ideologically
biased
considering
document
ideological
leanings
work
intended
analyse
serps
without
effect
personalisation
thus
results
highlight
123
110
information
retrieval
journal
2021
24
85
113
search
biases
exist
even
though
personalization
effect
minimized
search
engines
can
empower
users
accountable
scope
work
investigate
source
bias
left
future
work
therefore
results
can
seen
potential
indicator
experiments
gathered
document
stances
via
crowd-sourcing
thus
obvious
future
work
direction
use
automatic
stance
detection
methods
instead
crowd-sourcing
obtain
document
labels
thereby
evaluating
bias
whole
corpus
retrieved
serps
track
source
bias
moreover
investigating
workers
bias
follow-up
work
interesting
since
difficult
remove
biases
practice
work
focus
equality
outcome
using
another
bias
measure
equality
opportunity
takes
account
corresponding
group
proportions
query-specific
base
rates
population
alternative
follow-up
work
plan
categorize
queries
subjective
objective
modify
ideal
ranking
definition
specifically
objective
queries
based
corpus
distributions
bias
analysis
objective
queries
particularly
ones
related
critical
domains
health
search
can
investigated
top
evaluation
framework
believe
interesting
follow-up
work
furthermore
plan
study
effect
localization
personalization
much
stances
ideological
leanings
varied
across
users
echo
chamber
effect
serps
incorporate
study
bias
evaluation
framework
future
acknowledgements
thank
reviewers
comments
work
funded
epsrc
fellowship
titled
task
based
information
retrieval
grant
reference
number
ep
p024289
visiting
researcher
programme
alan
turing
institute
compliance
ethical
standards
ethical
standard
author
emine
yilmaz
previously
worked
research
consultant
microsoft
research
currently
research
consultant
amazon
research
references
2018
internetlivestats
http://www.internetlivestats.com/.
retrieved
2018
10
06
2018
procon
org
procon
org
pros
cons
controversial
issues
https://www.procon.org/.
retrieved
2018
07
31
2018
search
engine
statistics
2018
https://www.smartinsights.com/search-engine-marketing/search-
engine-statistics
retrieved
2018
10
06
99firms
2019
search
engine
statistics
https://99firms.com/blog/search-engine-statistics/#gref.
retrieved
2019
09
06
aktolga
allan
2013
sentiment
diversification
different
biases
proceedings
36th
international
acm
sigir
conference
research
development
information
retrieval
pp
593
602
acm
alam
downey
2014
analyzing
content
emphasis
web
search
engines
proceedings
37th
international
acm
sigir
conference
research
development
information
retrieval
pp
1083
1086
acm
alonso
mizzaro
2012
using
crowdsourcing
trec
relevance
assessment
information
processing
management
48
1053
1066
alonso
rose
stewart
2008
crowdsourcing
relevance
evaluation
sigir
forum
42
15
baeza-yates
2016
data
algorithmic
bias
web
proceedings
8th
acm
conference
web
science
pp
acm
bakshy
messing
adamic
2015
exposure
ideologically
diverse
news
opinion
facebook
science
348
1130
1132
123
information
retrieval
journal
2021
24
85
113
111
bargh
gollwitzer
lee-chai
barndollar
trötschel
2001
automated
will
nonconscious
activation
pursuit
behavioral
goals
journal
personality
social
psychology
81
1014
beutel
chen
doshi
qian
wei
wu
heldt
zhao
hong
chi
et
al
2019
fairness
recommendation
ranking
pairwise
comparisons
arxiv
1903.00780
budak
goel
rao
2016
fair
balanced
quantifying
media
bias
crowdsourced
content
analysis
public
opinion
quarterly
80
250
271
chelaru
altingovde
siersdorfer
2012
analyzing
polarity
opinionated
queries
european
conference
information
retrieval
pp
463
467
springer
chelaru
altingovde
siersdorfer
nejdl
2013
analyzing
detecting
exploiting
senti
ment
web
queries
acm
transactions
web
tweb
chen
yang
2006
position
paper
study
web
search
engine
bias
assessment
iw3c2
www
chen
ma
hannák
wilson
2018
investigating
impact
gender
rank
resume
search
engines
proceedings
2018
chi
conference
human
factors
computing
systems
pp
14
culpepper
diaz
smucker
2018
research
frontiers
information
retrieval
report
third
strategic
workshop
information
retrieval
lorne
swirl
2018
acm
sigir
forum
vol
52
pp
46
47
acm
new
york
ny
usa
demartini
siersdorfer
2010
dear
search
engine
opinion
sentiment
analysis
semantic
enrichment
web
search
results
proceedings
3rd
international
semantic
search
workshop
acm
diakopoulos
trielli
stark
mussenden
2018
vote
search
informs
choice
candidate
digital
dominance
power
google
amazon
facebook
apple
moore
tambini
eds
22
diaz
2008
google
goggles
sociopolitical
bias
search
engine
design
web
search
pp
11
34
springer
dutton
reisdorf
dubois
blank
2017
search
politics
uses
impacts
search
britain
france
germany
italy
poland
spain
united
states
dutton
blank
groselj
2013
cultures
internet
internet
britain
oxford
internet
survey
2013
report
oxford
oxford
internet
institute
elisa
shearer
2018
news
use
across
social
media
platforms
2018
https://www.journalism.org/
2018
09
10
news-use-across-social-media-platforms-2018
epstein
robertson
2017
method
detecting
bias
search
rankings
evidence
systematic
bias
related
2016
presidential
election
technical
report
white
paper
wp-17-02
epstein
robertson
2015
search
engine
manipulation
effect
seme
possible
impact
outcomes
elections
proceedings
national
academy
sciences
112
e4512
e4521
epstein
robertson
lazer
wilson
2017
suppressing
search
engine
manipulation
effect
seme
proceedings
acm
human
computer
interaction
42
fang
si
somasundaram
yu
2012
mining
contrastive
opinions
political
texts
using
cross-perspective
topic
model
proceedings
fifth
acm
international
conference
web
search
data
mining
pp
63
72
acm
finin
murnane
karandikar
keller
martineau
dredze
2010
annotating
named
enti
ties
twitter
data
crowdsourcing
proceedings
naacl
hlt
2010
workshop
creating
speech
language
data
amazon
mechanical
turk
pp
80
88
association
computational
linguistics
gao
shah
2019
fair
can
go
detecting
boundaries
fairness
optimization
information
retrieval
proceedings
2019
acm
sigir
international
conference
theory
information
retrieval
pp
229
236
gao
shah
2020
toward
creating
fairer
ranking
search
engine
results
information
processing
management
57
102138
gentzkow
shapiro
2010
drives
media
slant
evidence
us
daily
newspapers
econometrica
78
35
71
geyik
ambler
kenthapadi
2019
fairness-aware
ranking
search
recommendation
systems
application
linkedin
talent
search
proceedings
25th
acm
sigkdd
international
conference
knowledge
discovery
data
mining
pp
2221
2231
ginger
david
2018
google
responds
trump
says
political
motive
search
results
https://www.reuters.com/article/us-usa-trump-tech-alphabet/google-responds-to-trump-says-
no-political-motive-in-search-results-iduskcn1ld1qp
retrieved
2018
10
06
123
112
information
retrieval
journal
2021
24
85
113
goldman
2008
search
engine
bias
demise
search
engine
utopianism
web
search
pp
121
133
springer
grimes
2016
impartial
journalism
laudable
false
balance
dangerous
https://www.
theguardian
com
science
blog
2016
nov
08
impartial-journalism-is-laudable-but-false-balance-is
dangerous
retrieved
2019
08
15
hu
jiang
robertson
wilson
2019
auditing
partisanship
google
search
snippets
world
wide
web
conference
pp
693
704
institute
2014
personal
news
cycle
americans
choose
get
news
reston
american
press
institute
kallus
zhou
2019
fairness
risk
scores
beyond
classification
bipartite
ranking
xauc
metric
arxiv
1902.05826
krishna
zhu
groth
johnson
hata
kravitz
et
al
2017
visual
genome
connecting
language
vision
using
crowdsourced
dense
image
annotations
international
journal
computer
vision
123
32
73
kulshrestha
eslami
messias
zafar
ghosh
gummadi
karahalios
2017
quantifying
search
bias
investigating
sources
bias
political
searches
social
media
proceedings
2017
acm
conference
computer
supported
cooperative
work
social
computing
pp
417
432
acm
kulshrestha
eslami
messias
zafar
ghosh
gummadi
et
al
2018
search
bias
quantification
investigating
political
bias
social
media
web
search
information
retrieval
journal
22
188
227
lahoti
garimella
gionis
2018
joint
non-negative
matrix
factorization
learning
ideological
leaning
twitter
proceedings
eleventh
acm
international
conference
web
search
data
mining
pp
351
359
lawson
eustice
perkowitz
yetisgen-yildiz
2010
annotating
large
email
datasets
named
entity
recognition
mechanical
turk
proceedings
naacl
hlt
2010
workshop
creating
speech
language
data
amazon
mechanical
turk
pp
71
79
association
computational
linguistics
mellebeek
benavent
grivolla
codina
costa-jussa
banchs
2010
opinion
mining
spanish
customer
comments
non-expert
annotations
mechanical
turk
proceedings
naacl
hlt
2010
workshop
creating
speech
language
data
amazon
mechanical
turk
pp
114
121
association
computational
linguistics
mowshowitz
kawaguchi
2002a
assessing
bias
search
engines
information
processing
management
38
141
156
mowshowitz
kawaguchi
2002b
bias
web
communications
acm
45
56
60
mowshowitz
kawaguchi
2005
measuring
search
engine
bias
information
processing
man
agement
41
1193
1205
mullainathan
shleifer
2005
market
news
american
economic
review
95
1031
1053
newman
fletcher
kalogeropoulos
nielsen
2019
reuters
institute
digital
news
report
2019
vol
2019
reuters
institute
study
journalism
newman
fletcher
kalogeropoulos
levy
nielsen
2018
reuters
institute
digital
news
report
2018
vol
2018
reuters
institute
study
journalism
noble
2018
algorithms
oppression
search
engines
reinforce
racism
new
york
nyu
press
otterbacher
bates
clough
2017
competent
men
warm
women
gender
stereotypes
backlash
image
search
results
proceedings
2017
chi
conference
human
factors
computing
systems
pp
6620
6631
otterbacher
checco
demartini
clough
2018
investigating
user
perception
gender
bias
image
search
role
sexism
41st
international
acm
sigir
conference
research
development
information
retrieval
pp
933
936
pan
hembrooke
joachims
lorigo
gay
granka
2007
google
trust
users
decisions
rank
position
relevance
journal
computer-mediated
communication
12
801
823
räbiger
gezici
saygın
spiliopoulou
2018
predicting
worker
disagreement
effective
crowd
labeling
2018
ieee
5th
international
conference
data
science
advanced
analytics
dsaa
pp
179
188
ieee
raji
buolamwini
2019
actionable
auditing
investigating
impact
publicly
naming
biased
performance
results
commercial
ai
products
proceedings
2019
aaai
acm
conference
ai
ethics
society
pp
429
435
robertson
lazer
wilson
2018b
auditing
personalization
composition
politically
related
search
engine
results
pages
proceedings
2018
world
wide
web
conference
pp
955
965
123
information
retrieval
journal
2021
24
85
113
113
robertson
jiang
joseph
friedland
lazer
wilson
2018a
auditing
partisan
audience
bias
within
google
search
proceedings
acm
human
computer
interaction
148
saez-trumper
castillo
lalmas
2013
social
media
news
communities
gatekeeping
cover
age
statement
bias
proceedings
22nd
acm
international
conference
information
knowledge
management
pp
1679
1684
acm
sandvig
hamilton
karahalios
langbort
2014
auditing
algorithms
research
methods
detecting
discrimination
internet
platforms
data
discrimination
converting
critical
concerns
productive
inquiry
22
sapiezynski
zeng
robertson
mislove
wilson
2019
quantifying
impact
user
attentionon
fair
group
representation
ranked
lists
companion
proceedings
2019
world
wide
web
conference
pp
553
562
sarcona
2019
organic
search
click
rates
numbers
never
lie
https://www.zerolimitweb.
com
organic-vs-ppc-2019-ctr-results-best-practices
retrieved
2019
09
06
stokes
2019
false
media
balance
https://www.newphilosopher.com/articles/false-media-balance/.
retrieved
2019
09
15
su
deng
fei-fei
2012
crowdsourcing
annotations
visual
object
detection
workshops
twenty-sixth
aaai
conference
artificial
intelligence
tavani
2012
search
engines
ethics
vincent
johnson
sheehan
hecht
2019
measuring
importance
user-generated
content
search
engines
proceedings
international
aaai
conference
web
social
media
13
505
516
vondrick
patterson
ramanan
2013
efficiently
scaling
crowdsourced
video
annotation
international
journal
computer
vision
101
184
204
white
2013
beliefs
biases
web
search
proceedings
36th
international
acm
sigir
conference
research
development
information
retrieval
pp
12
acm
yang
stoyanovich
2017
measuring
fairness
ranked
outputs
proceedings
29th
interna
tional
conference
scientific
statistical
database
management
22
acm
yigit-sert
altingovde
ulusoy
2016
towards
detecting
media
bias
utilizing
user
comments
yuen
king
leung
2011
survey
crowdsourcing
systems
2011
ieee
third
inter
national
conference
privacy
security
risk
trust
2011
ieee
third
international
conference
social
computing
pp
766
773
ieee
zehlike
bonchi
castillo
hajian
megahed
baeza-yates
2017
fa
ir
fair
top
ranking
algorithm
proceedings
2017
acm
conference
information
knowledge
management
pp
1569
1578
acm
publisher
note
springer
nature
remains
neutral
regard
jurisdictional
claims
published
maps
institutional
affiliations
123