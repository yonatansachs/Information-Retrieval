session
3a
bia
fair
sigir
20
juli
25
30
2020
virtual
event
china
control
fair
bia
dynam
learning-to-rank
marco
morik
ashudeep
singh
m.morik@tu-berlin.d
ashudeep@cs.cornell.edu
technisch
univerität
berlin
cornel
univers
berlin
germani
ithaca
ny
jessica
hong
thorsten
joachim
jwh296@cornell.edu
tj@cs.cornell.edu
cornel
univers
cornel
univers
ithaca
ny
ithaca
ny
abstract
introduct
rank
primari
interfac
mani
onlin
consid
problem
dynam
learning-to-rank
ltr
platform
match
user
item
news
product
music
video
rank
function
dynam
adapt
base
feedback
two-sid
market
user
draw
util
user
provid
dynam
ltr
problem
ubiquit
rank
rank
also
determin
util
ex
onlin
system
news-fe
rank
adapt
number
posur
revenu
item
provid
publish
seller
like
articl
receiv
onlin
store
adapt
number
artist
studio
alreadi
note
myopic
optimiz
posit
review
product
movie-recommend
system
ing
util
user
done
virtual
learning-to-rank
adapt
watch
movi
system
algorithm
can
unfair
item
provid
therefor
learn
predict
dynam
intertwin
past
present
learning-to-rank
approach
explicitli
enforc
merit
feedback
influenc
futur
rank
specif
form
onlin
base
fair
guarante
group
item
articl
learn
partial-inform
feedback
17
publish
track
artist
particular
pro
dynam
ltr
system
widespread
use
unqu
pose
learn
algorithm
ensur
notion
amort
group
tionabl
use
least
two
issu
requir
care
fair
simultan
learn
rank
function
design
consider
first
rank
system
induc
bia
implicit
feedback
data
algorithm
take
form
control
rank
present
particular
item
rank
highli
integr
unbias
estim
fair
util
dy
like
collect
addit
feedback
turn
can
namic
adapt
data
becom
avail
addit
influenc
futur
rank
promot
mislead
rich-get-rich
rigor
theoret
foundat
converg
guarante
dynam
31
32
39
second
rank
system
arbit
find
empir
algorithm
highli
practic
robust
much
exposur
item
receiv
exposur
directli
influenc
opinion
ideolog
orient
present
news
cc
concept
articl
econom
gain
revenu
product
sale
stream
inform
system
learn
rank
ing
provid
item
rais
fair
consider
exposur
alloc
base
merit
keyword
item
14
41
will
show
follow
naiv
dynam
ltr
method
oblivi
issu
can
lead
econom
rank
learning-to-rank
fair
bia
select
bia
exposur
dispar
unfair
polar
acm
refer
format
paper
present
first
dynam
ltr
algorithm
call
marco
morik
ashudeep
singh
jessica
hong
thorsten
joachim
2020
fairco
overcom
rich-get-rich
dynam
enforc
control
fair
bia
dynam
learning-to-rank
proceed
ing
configur
allocation-of-exposur
scheme
unlik
exist
43rd
intern
acm
sigir
confer
research
develop
inform
retriev
sigir
20
juli
25
30
2020
virtual
event
china
fair
ltr
algorithm
14
41
42
47
fairco
explicitli
address
acm
new
york
ny
usa
10
page
https://doi.org/10.1145/3397271.3401100
dynam
natur
learn
problem
system
unbi
ase
fair
even
though
relev
merit
item
equal
contribut
still
learn
core
approach
lie
merit-bas
work
conduct
cornel
univers
exposure-alloc
criterion
amort
learn
permiss
make
digit
hard
copi
part
work
person
process
14
41
view
enforc
merit-bas
ex
classroom
use
grant
without
fee
provid
copi
made
distribut
posur
criterion
control
problem
deriv
p-control
profit
commerci
advantag
copi
bear
notic
full
citat
optim
fair
exposur
well
qualiti
first
page
copyright
compon
work
own
other
author
must
honor
abstract
credit
permit
copi
otherwis
rank
crucial
compon
control
abil
republish
post
server
redistribut
list
requir
prior
specif
permiss
estim
merit
relev
accur
even
though
feed
fee
request
permiss
permissions@acm.org
back
reveal
increment
system
oper
sigir
20
juli
25
30
2020
virtual
event
china
2020
copyright
held
owner
author
public
right
licens
acm
feedback
bias
rank
shown
process
31
acm
isbn
978
4503
8016
20
07
15.00
effect
fairco
includ
new
unbias
cardin
relev
https://doi.org/10.1145/3397271.3401100
429
session
3a
bia
fair
sigir
20
juli
25
30
2020
virtual
event
china
estim
oppos
exist
ordin
method
32
revers
remain
49
user
left-lean
like
can
use
unbias
merit
estim
fair
articl
left
rank
articl
sole
true
averag
rank
criterion
relev
put
item
right
posit
10
item
addit
theoret
justif
fairco
provid
left
posit
11
20
mean
platform
give
empir
result
synthet
news-fe
data
real-world
articl
left
vastli
less
exposur
right
argu
movi
recommend
data
find
fairco
effect
can
consid
unfair
sinc
two
group
receiv
enforc
fair
provid
good
rank
perform
fur
disproportion
differ
outcom
despit
similar
merit
thermor
fairco
effici
robust
easi
implement
relev
differ
averag
relev
lead
much
larger
differ
exposur
group
motiv
argu
two
defici
name
bia
unfair
consid
follow
illustr
exampl
dynam
ltr
prob
ness
just
undesir
lem
onlin
news-aggreg
platform
want
present
rank
undesir
consequ
exampl
bias
estim
lead
ing
top
news
articl
front
page
extern
poor
rank
qualiti
unfair
like
alien
left
mechan
identifi
set
20
20
articl
lean
user
exampl
drive
platform
begin
day
left
learn
problem
encourag
polar
rank
20
articl
front
page
user
start
come
furthermor
note
two
defici
specif
platform
platform
use
follow
naiv
algorithm
news
exampl
naiv
algorithm
lead
anal
learn
rank
ogou
problem
mani
domain
exampl
consid
rank
system
job
applic
rich-get-rich
dynam
exposur
alloc
may
perpetu
even
amplifi
exist
algorithm
naiv
dynam
ltr
algorithm
unfair
dispar
male
femal
applic
sim
initi
counter
ilarli
consid
onlin
marketplac
product
differ
foreach
user
seller
group
rank
rich-get-rich
dynam
present
rank
argsort
random
tiebreak
unfair
exposur
alloc
can
encourag
monopoli
drive
increment
articl
read
user
seller
market
exampl
illustr
follow
two
desiderata
less
naiv
dynam
ltr
algorithm
fulfil
execut
algorithm
begin
day
platform
unbiased
algorithm
bias
subject
start
present
20
articl
random
order
first
rich-get-rich
dynam
user
may
observ
user
read
articl
posit
fair
algorithm
enforc
fair
alloc
expo
increment
counter
articl
next
sure
base
merit
relev
user
articl
now
get
rank
first
counter
updat
base
second
user
read
cycl
continu
two
desiderata
mind
paper
develop
alterna
subsequ
user
unfortun
naiv
algorithm
least
tive
naiv
algorithm
particular
introduc
two
defici
make
suboptim
unsuit
mani
dynam
learning-to-rank
set
section
section
formal
rank
applic
amort
notion
merit-bas
fair
account
fact
first
defici
lie
choic
estim
merit
unknown
begin
learn
process
averag
relev
articl
name
fraction
user
learn
throughout
section
address
bia
want
read
articl
unfortun
even
infinit
problem
provid
estim
elimin
present
bia
amount
user
feedback
counter
consist
global
person
rank
polici
final
section
estim
averag
relev
31
32
39
particular
item
propos
control-bas
algorithm
design
optim
happen
get
read
earli
iter
get
rank
rank
qualiti
dynam
enforc
fair
highli
user
find
thu
opportun
provid
posit
feedback
perpetu
relat
work
rich-get-rich
dynam
feedback
count
record
rank
algorithm
wide
recogn
potenti
articl
reflect
mani
user
actual
want
societ
impact
form
core
mani
onlin
system
read
articl
includ
search
engin
recommend
system
news
feed
second
defici
naiv
algorithm
lie
rank
onlin
vote
control
rich-get-rich
phenomena
rec
polici
creat
sourc
unfair
even
true
averag
ommend
rank
studi
perspect
relev
articl
accur
known
14
41
consid
optim
util
explor
well
ensur
follow
omnisci
variant
naiv
algorithm
rank
ing
fair
system
40
48
sever
advers
articl
true
averag
relev
true
fraction
consequ
naiv
rank
system
19
polit
polar
user
want
read
articl
can
rank
izat
11
misinform
45
unfair
alloc
exposur
42
unfair
let
us
assum
two
group
articl
right
bias
judgment
phenomena
matthew
left
10
item
articl
polit
right
effect
23
view
rank
problem
two-sid
market
left-lean
sourc
51
user
right-lean
want
user
item
deriv
util
rank
system
read
articl
group
right
articl
group
left
bring
novel
perspect
tackl
problem
41
430
session
3a
bia
fair
sigir
20
juli
25
30
2020
virtual
event
china
work
take
inspir
work
develop
method
inform
want
learn
singl
global
rank
mitig
bia
unfair
dynam
set
like
introductori
news
exampl
machin
learn
method
underli
rank
algorithm
present
rank
σt
system
receiv
feedback
grow
concern
around
question
vector
ct
user
non-neg
valu
ct
everi
machin
learn
algorithm
can
unfair
especi
given
simplest
case
click
click
numer
real-world
applic
10
sever
will
use
word
click
placehold
throughout
paper
definit
propos
fair
binari
classif
set
simplic
feedback
may
take
mani
form
well
recent
domain
rank
recommenda
binari
exampl
video
stream
servic
tion
inform
retriev
13
14
16
41
definit
feedback
may
percentag
user
watch
video
fair
rank
span
one
pure
base
composit
feedback
ct
receiv
dynam
ltr
algorithm
top-k
16
relevance-bas
definit
fair
now
updat
rank
polici
produc
polici
πt
exposur
41
amort
attent
equiti
14
will
discuss
use
next
time
step
definit
greater
detail
section
work
also
re
late
recent
interest
studi
impact
fair
πt
σ1
c1
σt
ct
learn
algorithm
appli
dynam
set
21
35
43
instanc
dynam
ltr
algorithm
naiv
algorithm
inform
retriev
long-stand
interest
alreadi
outlin
section
mere
comput
ct
produc
learn
rank
bias
click
data
alreadi
argu
new
rank
polici
global
rank
independ
bia
log
click
data
occur
feedback
incom
plete
bias
present
numer
approach
base
prefer
25
30
click
model
18
random
ize
intervent
36
exist
recent
new
approach
4.1
partial
bias
feedback
de-bias
feedback
data
use
techniqu
causal
infer
key
challeng
dynam
ltr
lie
fact
feedback
miss
data
analysi
propos
provabl
elimin
se
ct
provid
meaning
feedback
item
user
lection
bias
32
follow
approach
paper
extend
examin
follow
larg
bodi
work
click
model
18
dynam
rank
set
propos
new
unbias
model
censor
process
specif
binari
vector
regress
object
section
et
indic
item
examin
user
model
learn
dynam
rank
set
relat
con
relationship
ct
rt
follow
vention
learning-to-rank
algorithm
lambdarank
lamb
et
damart
ranknet
softrank
etc
15
44
howev
implement
ct
fair
constraint
base
merit
need
explicitli
estim
otherwis
relev
user
measur
merit
score
esti
come
back
run
exampl
news
rank
rt
contain
mate
method
don
necessarili
mean
full
inform
articl
user
interest
set
also
close
relat
onlin
learn
rank
top-k
read
ct
reveal
inform
articl
rank
feedback
observ
top-k
item
examin
user
et
analog
job
henc
explor
intervent
necessari
ensur
conver
placement
applic
rt
indic
candid
whether
genc
26
34
37
49
algorithm
design
respect
qualifi
receiv
interview
call
ct
reveal
click-model
assumpt
49
learn
presenc
inform
candid
examin
employ
document
featur
34
key
differ
method
second
challeng
lie
fact
examin
vector
consid
explor
explicit
intervent
et
observ
impli
feedback
valu
ct
mere
exploit
user-driven
explor
howev
explicit
explo
ambigu
may
either
indic
lack
examin
ration
also
incorpor
algorithm
improv
et
neg
feedback
rt
converg
rate
method
problemat
et
uniformli
random
item
get
examin
strongli
bias
rank
σt
present
dynam
learning-to-rank
user
current
iter
specif
user
like
begin
formal
defin
dynam
ltr
problem
given
look
item
high
rank
one
lower
set
item
need
rank
respons
incom
31
model
posit
bia
probabl
distribut
request
time
step
request
examin
vector
rt
et
σt
rt
arriv
rank
system
request
consist
featur
click
model
can
brought
form
18
sim
vector
describ
user
inform
need
queri
user
pliciti
paper
mere
use
position-bas
model
pbm
profil
user
vector
true
relev
rate
rt
20
assum
margin
probabl
examin
pt
item
collect
featur
vector
visibl
item
depend
rank
rank
system
true
relev
rate
rt
hidden
base
present
rank
despit
simplic
found
inform
rank
polici
πt
produc
rank
pbm
can
captur
main
effect
posit
bia
accur
enough
σt
present
user
note
polici
may
ignor
reliabl
practic
32
46
431
session
3a
bia
fair
sigir
20
juli
25
30
2020
virtual
event
china
4.2
evalu
rank
perform
candid
discuss
section
estim
pt
take
measur
qualiti
rank
polici
util
group-bas
approach
fair
aggreg
exposur
group
user
virtual
rank
metric
use
inform
retriev
de
gm
fine
util
rank
function
relev
individu
item
case
item-bas
relev
exp
pt
repres
articl
user
like
read
candid
qualifi
interview
commonli
use
util
measur
group
can
legal
protect
group
gender
race
dcg
29
reflect
structur
item
sold
particular
seller
dcg
simpli
put
item
group
individu
fair
log2
rank
order
formul
fair
criteria
relat
exposur
merit
defin
merit
item
expect
averag
rele
ndcg
normal
dcg
optim
rank
vanc
aggreg
group
distribut
request
rank
polici
evalu
expect
util
merit
section
will
discuss
get
unbias
estim
4.3
optim
rank
perform
merit
use
bias
feedback
data
ct
definit
hand
can
address
type
di
user-fac
goal
dynam
ltr
converg
polici
pariti
identifi
section
specif
extend
dispar
argmaxπ
maxim
util
even
solv
treatment
criterion
41
dynam
rank
problem
problem
estim
despit
lack
knowledg
use
amort
notion
fair
14
particular
maxim
problem
comput
challeng
sinc
two
group
dispar
space
rank
polici
exponenti
even
learn
just
singl
global
rank
fortun
easi
show
38
íτ
exp
íτ
exp
sorting-bas
polici
dτe
10
merit
merit
argsort
measur
far
amort
exposur
time
step
fulfil
exposure-bas
fair
dispar
express
far
averag
time
step
group
item
got
exposur
proport
relev
dispar
zero
greater
violat
fair
note
optim
virtual
commonli
use
ir
dcg
alloc
strategi
beyond
proportion
implement
problem
lie
estim
expect
relev
well
use
altern
definit
dispar
41
item
condit
learn
singl
global
exposur
can
also
alloc
base
fair
criteria
rank
simplifi
estim
expect
averag
exampl
dispar
impact
specif
exposur
alloc
relev
item
global
rank
impli
41
consid
feedback
ct
click
purchas
can
deriv
via
vote
measur
impact
argsort
imp
ct
11
section
will
use
techniqu
causal
infer
missing-data
analysi
design
unbias
consist
estim
keep
follow
dispar
close
zero
control
requir
access
observ
feedback
exposur
alloc
make
impact
proport
relev
ct
íτ
imp
íτ
imp
fair
dynam
ltr
dτ
12
merit
merit
sort
global
rank
may
provid
optim
util
user
introductori
exampl
alreadi
refer
impact-bas
fair
dispar
sec
illustr
rank
can
unfair
grow
bodi
tion
will
deriv
control
drive
exposur
literatur
address
unfair
rank
now
impact
dispar
zero
extend
merit-bas
fair
14
41
dynam
ltr
set
key
scarc
resourc
rank
polici
alloc
among
unbias
estim
item
exposur
base
model
introduc
pre
abl
implement
rank
polici
equat
viou
section
defin
exposur
item
mar
fair
dispar
equat
10
12
need
accu
ginal
probabl
examin
pt
et
σt
rt
rate
estim
posit
bia
pt
expect
condit
probabl
user
will
see
thu
op
relev
expect
averag
relev
portun
read
articl
buy
product
interview
consid
estim
problem
follow
432
session
3a
bia
fair
sigir
20
juli
25
30
2020
virtual
event
china
6.1
estim
posit
bia
use
unobserv
true
relev
r1
rτ
learn
model
pt
part
dynam
ltr
problem
position-bia
model
mere
input
dynam
ltr
ee
algorithm
fortun
sever
techniqu
estim
posit
bia
model
alreadi
exist
literatur
22
32
46
õõ
ct
agnost
use
simplest
case
ct
2r
et
σt
examin
probabl
pt
depend
rank
pt
et
item
analog
position-bas
click
model
20
fix
probabl
rank
shown
32
46
rt
rt
2r
pt
position-bas
probabl
can
estim
explicit
pt
implicit
swap
intervent
furthermor
shown
22
contextu
featur
user
queri
can
rt
rt
incorpor
neural-network
base
propens
model
allow
ing
captur
certain
user
may
explor
rank
queri
propens
model
rt
learn
can
appli
predict
pt
new
queri
rank
σt
6.2
estim
condit
relev
key
challeng
estim
equat
lie
line
formul
expect
term
margin
exposur
inabl
directli
observ
true
relev
rt
instead
probabl
et
σt
decompos
expect
data
partial
bias
feedback
ct
object
addit
note
et
σt
overcom
problem
take
approach
inspir
32
therefor
equal
pt
exposur
model
line
sub
extend
dynam
rank
set
key
idea
correct
stitut
ct
et
rt
simplifi
express
sinc
select
bia
relev
label
observ
et
rt
whenev
user
expos
item
note
ct
use
techniqu
survey
sampl
causal
infer
propens
pt
expos
item
now
cancel
27
28
howev
unlik
ordin
estim
propos
32
long
bound
away
zero
mean
item
need
cardin
relev
estim
sinc
fair
dispar
probabl
found
user
case
user
cardin
natur
therefor
propos
follow
cardin
natur
explor
low
enough
rank
activ
inter
relev
estim
vention
can
use
stochast
promot
item
order
key
idea
behind
estim
lie
train
object
ensur
non-zero
examin
propens
26
note
un
use
ct
expect
equival
least-squar
biased
hold
sequenc
r1
σ1
xt
rt
σt
object
access
rt
start
deriv
let
consid
matter
complex
depend
rank
σt
estim
access
relev
label
r1
rτ
previou
time
step
straightforward
beyond
proof
unbiased
possibl
use
stan
solut
solv
follow
least-squar
object
dard
concentr
inequ
show
converg
given
regress
model
neural
network
size
train
sequenc
increas
thu
un
paramet
model
der
standard
condit
capac
uniform
converg
possibl
show
converg
minim
least-squar
regressor
size
train
sequenc
rt
13
increas
will
use
regress
object
learn
neural
network
ranker
section
8.2
minimum
object
least-squar
regress
estim
sinc
r1
rτ
avail
de
6.3
estim
averag
relev
fine
asymptot
equival
object
mere
use
condit
relev
use
rank
polici
bias
feedback
c1
cτ
new
object
correct
po
equat
defin
merit
equat
sition
bia
use
invers
propens
score
ip
weight
27
28
fair
dispar
averag
relev
need
posit
bia
p1
pτ
take
role
missing
serv
rank
criterion
global
rank
model
equat
margin
deriv
argu
follow
direct
way
get
ct
ct
2r
14
unbias
estim
pt
denot
regress
estim
defin
minimum
object
reg
regress
object
14
unbias
ct
ip
15
mean
expect
equal
regress
object
pt
433
session
3a
bia
fair
sigir
20
juli
25
30
2020
virtual
event
china
follow
show
estim
unbias
long
now
posit
state
fairco
rank
polici
propens
bound
away
zero
fairco
στ
argsort
errτ
17
1õ
et
rt
ee
ip
et
σt
pt
exposure-bas
dispar
τe
use
error
et
term
refer
polici
fairco
exp
impact-bas
rt
dispar
τi
use
refer
fairco
imp
pt
like
polici
section
4.3
fairco
sort-bas
polici
howev
sort
criterion
combin
relev
1õ
rt
error
term
repres
fair
violat
idea
behind
fairco
error
term
push
item
underexpos
group
upward
rank
paramet
can
chosen
posit
constant
choic
follow
experi
will
use
estim
whenev
lead
asymptot
converg
shown
theorem
direct
estim
need
fair
dispar
exposur
fair
suitabl
choic
can
influenc
global
rank
criterion
finite-sampl
behavior
fairco
higher
can
lead
oscil
behavior
smaller
make
converg
dynam
control
fair
smoother
slower
explor
role
experi
given
formal
dynam
ltr
problem
defini
find
keep
fix
0.01
work
well
across
tion
fair
deriv
estim
relev
experi
anoth
key
qualiti
fairco
agnost
paramet
now
posit
tackl
problem
choic
error
metric
conjectur
can
easili
rank
enforc
fair
condit
view
adapt
type
fair
dispar
furthermor
control
problem
sinc
need
robust
uncertainti
easi
implement
effici
make
well
suit
practic
applic
estim
begin
learn
illustr
theoret
properti
fairco
now
ana
process
specif
propos
control
abl
make
lyze
converg
case
exposure-bas
fair
initi
uncertainti
estim
converg
learn
process
disentangl
converg
estim
merit
follow
pairwis
definit
amort
fair
converg
fairco
consid
time
point
τ0
merit
section
quantifi
much
fair
class
alreadi
close
merit
can
thu
focu
violat
use
follow
overal
dispar
metric
question
whether
fairco
can
drive
zero
start
unfair
may
persist
time
τ0
make
prob
lem
well-pos
need
assum
exposur
avail
dτ
dτ
16
overabund
otherwis
may
unavoid
give
group
exposur
deserv
even
put
metric
can
instanti
dispar
dτe
bottom
rank
suffici
condit
exclud
equat
10
exposure-bas
fair
dτi
equa
case
consid
problem
follow
true
tion
12
impact-bas
fair
sinc
optim
fair
achiev
pair
group
rank
entir
time
point
seek
minim
end
now
deriv
method
call
fairco
exp
exp
18
take
form
proport
control
p-control
merit
merit
12
p-control
wide
use
control-loop
mechan
intuit
condit
state
rank
ahead
reduc
appli
feedback
correct
term
proport
dispar
underexpos
past
can
now
error
applic
error
correspond
violat
state
follow
theorem
amort
fair
dispar
equat
10
12
specif
set
disjoint
group
gm
theorem
7.1
set
disjoint
group
gm
error
term
control
item
defin
fix
target
merit
merit
fulfil
18
relev
model
exposur
model
pt
errτ
max
pt
pmax
valu
run
fairco
exp
gi
time
τ0
will
alway
ensur
overal
dispar
respect
error
term
errτ
zero
group
alreadi
target
merit
converg
zero
rate
τ1
matter
unfair
exposur
τ10
τt
exp
τ0
maximum
exposur
impact
merit
item
group
error
term
grow
increas
dispar
note
dispar
error
term
use
es
proof
theorem
includ
full
version
timat
merit
equat
15
converg
merit
paper
arxiv
note
theorem
hold
time
sampl
size
increas
avoid
divis
zero
merit
point
τ0
even
estim
merit
chang
substanti
τ0
can
set
minimum
constant
estim
merit
converg
true
merit
434
session
3a
bia
fair
sigir
20
juli
25
30
2020
virtual
event
china
fairco
exp
will
ensur
amort
dispar
converg
news
experi
learn
global
rank
compar
zero
well
follow
method
naiv
rank
sum
observ
feedback
ct
empir
evalu
d-ultr
glob
dynam
ltr
sort
via
unbias
esti
addit
theoret
justif
approach
also
mate
ip
eq
15
conduct
empir
evaluation1
first
present
experi
fairco
imp
fair
control
eq
17
impact
fair
semi-synthet
news
dataset
investig
differ
aspect
propos
method
control
condit
0.750
0.20
avg
cumul
ndcg
evalu
method
real-world
movi
prefer
data
naiv
impact
unfair
extern
valid
0.725
0.15
d-ultr
glob
0.700
0.10
fairco
imp
8.1
robust
analysi
news
data
abl
evalu
method
varieti
specif
de
0.675
0.05
sign
test
set
creat
follow
simul
environ
0.650
0.00
1000
2000
3000
1000
2000
3000
ment
articl
ad
font
media
bia
dataset2
simul
user
user
dynam
rank
problem
set
news
articl
belong
two
group
left
right
left-lean
right-lean
news
figur
converg
ndcg
left
unfair
right
articl
number
user
increas
100
trial
trial
sampl
set
30
news
articl
articl
dataset
contain
polar
valu
rescal
8.1
can
fairco
reduc
unfair
maintain
good
rank
interv
user
polar
simul
ing
qualiti
key
question
evalu
fairco
user
polar
drawn
mixtur
two
normal
figur
show
ndcg
unfair
converg
naiv
distribut
clip
ultr
glob
fairco
imp
plot
show
naiv
achiev
ut
clip
pneд
0.5
0.2
pneд
0.5
0.2
19
lowest
ndcg
unfair
remain
high
pneд
probabl
user
left-lean
mean
0.5
number
user
interact
increas
d-ultr
glob
achiev
use
pneд
0.5
unless
specifi
addit
user
best
ndcg
predict
theori
unfair
open
paramet
0.05
0.55
indic
breadth
margin
better
naiv
fairco
manag
sub
interest
outsid
polar
base
polar
user
stantial
reduc
unfair
come
small
decreas
ut
item
true
relev
drawn
bernoulli
ndcg
compar
d-ultr
glob
distribut
follow
question
will
provid
insight
result
evalu
compon
fairco
explor
ut
rt
bernoulli
exp
robust
model
user
behavior
use
position-bas
click
0.3
averag
model
pbm
18
margin
probabl
user
ut
examin
articl
depend
posit
choos
0.2
naiv
exposur
drop-off
analog
gain
function
dcg
ip
0.1
pt
20
log2
rank
σt
0.0
500
1000
1500
2000
2500
3000
remaind
simul
follow
dynam
rank
user
setup
time
step
user
ut
arriv
system
algorithm
present
unperson
rank
σt
user
figur
error
relev
estim
number
provid
feedback
ct
accord
pt
rt
algorithm
user
increas
30
10
trial
observ
ct
rt
investig
group-fair
group
item
accord
polar
item
polar
belong
8.1
unbias
estim
converg
true
relev
left-lean
group
left
item
polar
first
compon
fairco
evalu
unbias
ip
belong
right-lean
group
right
estim
ip
equat
15
figur
show
absolut
measur
rank
qualiti
averag
cumul
ndcg
differ
estim
global
relev
true
global
íτ
dcg
user
time
measur
relev
ip
estim
use
naiv
error
naiv
stagnat
around
0.25
estim
error
exposur
unfair
via
impact
unfair
via
de
ip
approach
zero
number
user
increas
fine
equat
16
verifi
ip
elimin
effect
posit
bia
learn
implement
avail
https://github.com/marcomorik/dynamic-fairness.
accur
estim
true
expect
relev
news
https://www.adfontesmedia.com/interactive-media-bias-chart/
articl
can
use
fair
rank
criteria
435
session
3a
bia
fair
sigir
20
juli
25
30
2020
virtual
event
china
0.2
naiv
see
solut
unfair
increas
method
impact
unfair
d-ultr
glob
start
enforc
fair
expens
ndcg
fairco
imp
experi
found
evid
linprog
baselin
su
0.1
perior
fairco
howev
linprog
substanti
expens
comput
make
fairco
prefer
practic
0.0
50
100
150
200
250
300
350
400
number
right-lean
user
begin
naiv
impact
unfair
0.75
0.3
d-ultr
glob
figur
effect
block
right-lean
user
ndcg
0.2
fairco
imp
unfair
impact
50
trial
3000
user
0.70
0.1
0.65
8.1
fairco
overcom
rich-get-rich
dynam
il
0.0
0.2
0.4
0.2
0.4
lustrat
exampl
section
argu
naiv
rank
item
proport
left-lean
item
proport
left-lean
item
highli
sensit
initi
condit
item
get
first
click
lead
rich-get-rich
dynam
now
test
figur
ndcg
left
unfair
right
vari
pro
whether
fairco
overcom
problem
particular
adver
portion
left
20
trial
3000
user
sarial
modifi
user
distribut
first
user
right-lean
pneд
follow
left-lean
user
pneд
8.1
fairco
effect
differ
group
size
experi
continu
balanc
user
distribut
pneд
0.5
ment
vari
asymmetri
polar
within
set
30
news
figur
show
unfair
3000
user
interact
ex
articl
rang
left
left
15
news
articl
pect
naiv
sensit
head-start
right
group
size
run
20
trial
3000
user
figur
show
lean
articl
get
d-ultr
glob
fare
better
un
regardless
group
ratio
fairco
reduc
unfair
fair
remain
constant
high
independ
initi
user
whole
rang
maintain
ndcg
contrast
distribut
sinc
unbias
estim
ip
correct
naiv
d-ultr
glob
suffer
high
unfair
present
bia
estim
still
converg
true
rel
evanc
fairco
inherit
robust
initi
condit
sinc
use
ip
estim
activ
control
unfair
0.4
naiv
impact
unfair
make
method
achiev
low
unfair
across
0.8
d-ultr
glob
whole
rang
ndcg
fairco
imp
0.2
0.74
0.7
linprog
impact
unfair
0.15
0.72
fairco
imp
0.0
0.2
0.4
0.6
0.8
0.2
0.4
0.6
0.8
ndcg
0.10
proport
left-lean
user
proport
left-lean
user
0.70
0.05
0.68
figur
ndcg
left
unfair
right
vari
0.00
user
distribut
20
trial
3000
user
10
10
10
10
10
10
10
10
10
10
10
100
101
102
8.1
fairco
effect
differ
user
distribut
final
figur
compar
lp
baselin
p-control
examin
robust
vari
user
distribut
control
term
ndcg
left
unfair
right
differ
polar
distribut
user
vari
pneд
equat
19
valu
15
trial
3000
user
run
20
trial
3000
user
figur
observ
naiv
d-ultr
glob
suffer
high
unfair
8.1
effect
fairco
compar
expens
larg
imbal
minor
major
group
linear-program
baselin
baselin
adapt
linear
fairco
abl
control
unfair
set
program
method
41
dynam
ltr
set
minim
amort
fair
dispar
consid
8.2
evalu
real-world
prefer
data
work
method
use
current
relev
dispar
evalu
method
real-world
prefer
data
adopt
estim
solv
linear
program
problem
whose
solut
ml-20m
dataset
24
select
five
product
compani
stochast
rank
polici
satisfi
fair
constraint
movi
dataset
mgm
warner
bro
para
expect
detail
method
describ
mount
20th
centuri
fox
columbia
product
compani
full
version
paper
arxiv
figur
show
ndcg
form
group
aim
ensur
fair
exposur
impact
unfair
3000
user
averag
15
trial
exclud
movi
rate
divers
user
linprog
fairco
differ
valu
hyperparamet
popul
set
300
rate
movi
produc
method
reduc
d-ultr
glob
can
tion
compani
select
100
movi
highest
standard
436
session
3a
bia
fair
sigir
20
juli
25
30
2020
virtual
event
china
0.9
0.4
avg
cumul
ndcg
deviat
rate
across
user
user
select
104
exposur
unfair
naiv
user
rate
number
chosen
movi
0.3
d-ultr
glob
leav
us
partial
fill
rate
matrix
104
user
0.8
0.2
d-ultr
100
movi
avoid
miss
data
eas
evalu
use
fairco
exp
off-the-shelf
matrix
factor
algorithm3
fill
miss
0.1
entri
normal
rate
appli
sigmoid
function
center
rate
slope
10
serv
0.7
2000
4000
6000
0.0
2000
4000
6000
relev
probabl
higher
star
rate
correspond
user
user
higher
likelihood
posit
feedback
final
trial
obtain
binari
relev
matrix
draw
bernoulli
sampl
figur
ndcg
left
exposur
unfair
right
user
movi
pair
probabl
use
movi
data
number
user
interact
increas
10
user
embed
matrix
factor
model
user
trial
featur
0.9
0.20
avg
cumul
ndcg
follow
experi
use
fairco
learn
sequenc
naiv
impact
unfair
rank
polici
πt
person
base
goal
0.15
d-ultr
glob
maxim
ndcg
provid
fair
exposur
0.8
0.10
d-ultr
product
compani
user
interact
simul
analog
fairco
imp
previou
experi
time
step
sampl
user
0.05
rank
algorithm
present
rank
100
movi
0.7
0.00
user
follow
position-bas
model
equat
20
2000
4000
6000
2000
4000
6000
user
user
reveal
ct
accordingli
condit
relev
model
reg
use
fairco
figur
ndcg
left
impact
unfair
right
d-ultr
use
one
hidden-lay
neural
network
consist
movi
data
number
user
interact
increas
10
50
input
node
fulli
connect
64
node
hidden
layer
trial
relu
activ
connect
100
output
node
sigmoid
output
predict
probabl
relev
movi
sinc
train
network
less
100
observ
access
partial
feedback
ct
track
perform
unreli
use
global
ranker
d-ultr
glob
first
100
skylin
predict
theori
appear
converg
user
train
network
100
user
updat
asymptot
network
everi
10
user
previous
collect
feedback
8.2
can
fairco
reduc
unfair
figur
show
fairco
exp
c1
cτ
use
unbias
regress
object
can
effect
control
exposur
unfair
unlik
meth
eq
14
adam
optim
33
od
activ
consid
fair
similarli
figur
show
fairco
imp
effect
control
impact
unfair
ex
1.0
avg
cumul
ndcg
pect
improv
fair
come
reduct
ndcg
naiv
d-ultr
reduct
small
0.9
d-ultr
glob
skylin
0.20
0.20
exposur
unfair
0.8
d-ultr
impact
unfair
0.15
0.15
fairco
imp
0.7
0.10
0.10
fairco
exp
1000
2000
3000
4000
5000
6000
user
0.05
0.05
0.00
0.00
figur
compar
ndcg
person
non
2000
4000
6000
2000
4000
6000
user
user
person
rank
movi
data
10
trial
8.2
person
via
unbias
object
improv
ndcg
figur
10
unfair
exposur
left
unfair
first
evalu
whether
train
person
model
use
impact
right
person
control
optim
de-bias
reg
regress
estim
improv
rank
perfor
either
exposur
impact
10
trial
manc
non-person
model
figur
show
rank
reg
d-ultr
provid
substanti
higher
ndcg
8.2
differ
exposur
impact
fair
figur
10
unbias
global
rank
d-ultr
glob
naiv
rank
evalu
algorithm
optim
exposur
fair
per
get
upper
bound
perform
person
form
term
impact
fair
vice
versa
plot
show
model
also
train
skylin
model
use
practic
un
two
criteria
achiev
differ
goal
sub
observ
true
relev
rt
least-squar
object
stantial
differ
fact
optim
fair
impact
can
eq
13
even
though
unbias
regress
estim
reg
even
increas
unfair
exposur
illustr
choic
criterion
need
ground
requir
appli
surpris
librari
http://surpriselib.com/)
svd
bias
fals
50
cation
437
session
3a
bia
fair
sigir
20
juli
25
30
2020
virtual
event
china
conclus
20
nick
craswel
onno
zoeter
michael
taylor
bill
ramsey
2008
experi
mental
comparison
click
position-bia
model
wsdm
identifi
bias
feedback
uncontrol
exposur
alloca
21
daniel
ensign
sorel
friedler
scott
nevil
carlo
scheidegg
suresh
tion
can
lead
unfair
undesir
behavior
dynam
venkatasubramanian
2018
runaway
feedback
loop
predict
polic
confer
fair
account
transpar
ltr
address
problem
propos
fairco
abl
22
zhichong
fang
agarw
joachim
2019
intervent
harvest
adapt
enforc
amort
merit-bas
fair
constraint
context-depend
examination-bia
estim
sigir
even
though
underli
relev
still
learn
23
fabrizio
germano
vicenç
gómez
gaël
le
men
2019
few-get
richer
surpris
consequ
popularity-bas
rank
arxiv
preprint
algorithm
robust
present
bia
thu
exhibit
arxiv
1902.02580
2019
rich-get-rich
dynam
final
fairco
easi
implement
24
maxwel
harper
joseph
konstan
2015
movielen
dataset
histori
context
acm
tii
2015
comput
effici
make
well
suit
practic
25
herbrich
graepel
obermay
2000
larg
margin
rank
boundari
applic
ordin
regress
advanc
larg
margin
classifi
26
katja
hofmann
shimon
whiteson
maarten
de
rijk
2013
balanc
ex
plorat
exploit
listwis
pairwis
onlin
learn
rank
acknowledg
inform
retriev
inform
retriev
2013
research
support
part
nsf
award
iis-1901168
27
daniel
horvitz
donovan
thompson
1952
gener
sampl
without
replac
finit
univers
journal
american
statist
gift
workday
content
repres
opinion
associ
1952
author
necessarili
share
endors
28
guido
imben
donald
rubin
2015
causal
infer
statist
social
respect
employ
sponsor
biomed
scienc
cambridg
univers
press
29
kalervo
järvelin
jaana
kekäläinen
2002
cumul
gain-bas
evalu
ir
techniqu
toi
2002
refer
30
joachim
2002
optim
search
engin
use
clickthrough
data
acm
himan
abdollahpouri
gedimina
adomaviciu
robin
burk
ido
guy
dietmar
sigkdd
confer
knowledg
discoveri
data
mine
kdd
133
142
jannach
toshihiro
kamishima
jan
krasnodebski
luiz
pizzato
2019
beyond
31
joachim
granka
bing
pan
hembrook
radlinski
gay
2007
person
research
direct
multistakehold
recommend
arxiv
evalu
accuraci
implicit
feedback
click
queri
reformula
preprint
arxiv
1905.01986
2019
tion
web
search
acm
toi
2007
himan
abdollahpouri
robin
burk
bamshad
mobash
2017
control
32
joachim
swaminathan
schnabel
2017
unbias
learning-to-rank
popular
bia
learning-to-rank
recommend
acm
recsi
bias
feedback
wsdm
lada
adam
bernardo
huberman
2000
power-law
distribut
33
diederik
kingma
jimmi
ba
2014
adam
method
stochast
opti
world
wide
web
scienc
2000
mizat
arxiv
preprint
arxiv
1412.6980
2014
agarw
takatsu
zaitsev
joachim
2019
gener
framework
34
shuai
li
tor
lattimor
csaba
szepesvári
2018
onlin
learn
rank
counterfactu
learning-to-rank
sigir
featur
arxiv
preprint
arxiv
1810.02567
2018
agarw
zaitsev
xuanhui
wang
cheng
li
najork
joachim
35
lydia
liu
sarah
dean
esther
rolf
max
simchowitz
moritz
hardt
2018
2019
estim
posit
bia
without
intrus
intervent
wsdm
delay
impact
fair
machin
learn
icml
qingyao
ai
kepe
bi
cheng
luo
jiafeng
guo
bruce
croft
2018
unbi
36
radlinski
joachim
2006
minim
invas
random
col
ase
learn
rank
unbias
propens
estim
sigir
lect
unbias
prefer
clickthrough
log
aaai
1406
1412
michael
ekstrand
sebastian
kohlmeier
asia
biega
fernando
diaz
2019
trec
37
radlinski
kleinberg
joachim
2008
learn
divers
rank
fair
rank
track
https://fair-trec.github.io/
onlin
access
08
14
2019
multi-arm
bandit
icml
ricardo
baeza-y
2018
bia
web
commun
acm
2018
38
stephen
robertson
1977
probabl
rank
principl
ir
journal
solon
baroca
moritz
hardt
arvind
narayanan
2018
fair
machin
document
1977
learn
2018
39
salganik
sheridan
dodd
watt
2006
experiment
studi
10
solon
baroca
andrew
selbst
2016
big
data
dispar
impact
calif
inequ
unpredict
artifici
cultur
market
scienc
2006
rev
2016
40
tobia
schnabel
adith
swaminathan
ashudeep
singh
navin
chandak
11
michael
beam
2014
autom
news
person
news
recom
thorsten
joachim
2016
recommend
treatment
debias
learn
mender
system
design
choic
impact
news
recept
commun
research
evalu
icml
2014
41
ashudeep
singh
thorsten
joachim
2018
fair
exposur
rank
12
wayn
bequett
2003
process
control
model
design
simul
prentic
acm
sigkdd
hall
profession
42
ashudeep
singh
thorsten
joachim
2019
polici
learn
fair
13
alex
beutel
jilin
chen
tulse
doshi
hai
qian
li
wei
yi
wu
lukasz
heldt
rank
neurip
zhe
zhao
lichan
hong
ed
chi
cristo
goodrow
2019
fair
43
behzad
tabibian
vicenç
gómez
abir
de
bernhard
schölkopf
recommend
rank
pairwis
comparison
acm
sigkdd
manuel
gomez
rodriguez
2019
consequenti
rank
algorithm
14
asia
biega
krishna
gummadi
gerhard
weikum
2018
equiti
attent
long-term
welfar
arxiv
preprint
arxiv
1905.05305
2019
amort
individu
fair
rank
sigir
44
michael
taylor
john
guiver
stephen
robertson
tom
minka
2008
softrank
15
christoph
jc
burg
2010
ranknet
lambdarank
lambdamart
optim
non-smooth
rank
metric
wsdm
acm
overview
learn
2010
45
soroush
vosoughi
deb
roy
sinan
aral
2018
spread
true
fals
16
elisa
celi
damian
straszak
nisheeth
vishnoi
2017
rank
news
onlin
scienc
2018
fair
constraint
arxiv
preprint
arxiv
1704.06840
2017
46
xuanhui
wang
nadav
golbandi
michael
benderski
donald
metzler
marc
17
nicolò
cesa-bianchi
gábor
lugosi
2006
predict
learn
game
najork
2018
posit
bia
estim
unbias
learn
rank
person
cambridg
univers
press
search
wsdm
acm
18
aleksandr
chuklin
ilya
markov
maarten
de
rijk
2015
click
model
47
himank
yadav
zhengxiao
du
thorsten
joachim
2019
fair
learning-to
web
search
synthesi
lectur
inform
concept
retriev
servic
rank
implicit
feedback
arxiv
cs
lg
1911.08054
2015
48
hongzhi
yin
bin
cui
jing
li
junji
yao
chen
chen
2012
challeng
19
giovanni
luca
ciampaglia
azadeh
nematzadeh
filippo
menczer
alessandro
long
tail
recommend
vldb
2012
flammini
2018
algorithm
popular
bia
hinder
promot
qualiti
49
masrour
zoghi
toma
tuni
mohammad
ghavamzadeh
branislav
kveton
scientif
report
2018
csaba
szepesvari
zheng
wen
2017
onlin
learn
rank
stochast
click
model
icml
438