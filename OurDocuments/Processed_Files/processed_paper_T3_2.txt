tutorial
fairness
rankings
recommenders
evaggelia
pitoura
pitoura@cs.uoi.gr
university
ioannina
ioannina
greece
georgia
koutrika
georgia@athenarc.gr
athena
research
center
athens
greece
among
others
recent
studies
report
social
media
become
main
source
online
news
2.4
billion
internet
users
nearly
64.5
receive
breaking
news
social
media
instead
traditional
sources
22
thus
great
extent
systems
play
central
role
shaping
experiences
influencing
perception
world
many
reports
questioning
output
systems
instance
known
study
search
results
showed
evidence
stereotype
exaggeration
images
returned
people
search
professional
careers
16
abstract
growing
complexity
available
online
information
search
engines
via
rankings
recommender
systems
come
rescue
providing
suggestions
users
items
potential
interest
movies
products
news
articles
even
potential
friends
results
suggestions
aim
covering
user
information
needs
play
important
role
guiding
users
decisions
forming
opinions
however
technology
used
responsibly
may
lead
discrimination
amplify
potential
biases
original
data
restrict
transparency
strengthen
unfairness
example
consider
scenarios
models
based
biased
data
produce
results
abet
violence
decrease
diversity
adverse
impact
economic
policies
potential
benefits
rankings
recommenders
well-accepted
understood
importance
using
systems
fair
manner
recently
attracted
attention
tutorial
cover
recent
advancements
highlight
future
research
directions
increasingly
relevant
research
area
fairness
rankings
recommenders
tutorial
pay
special
attention
concept
fairness
rankings
recommender
systems
fairness
typically
mean
lack
discrimination
correct
assume
insights
achieved
via
computations
data
unbiased
simply
data
collected
automatically
processing
performed
algorithmically
bias
may
come
algorithm
reflecting
example
commercial
preferences
designers
even
actual
data
example
survey
contains
biased
questions
specific
population
misrepresented
input
data
tutorial
review
number
definitions
fairness
aim
addressing
discrimination
bias
amplification
ensure
fair
treatment
organize
definitions
around
notions
individual
group
fairness
also
present
methods
achieving
fairness
rankings
recommendations
taking
cross-type
view
distinguishing
pre-processing
in-processing
post-processing
approaches
conclude
discussion
new
research
directions
arise
introduction
currently
algorithmic
systems
driven
large
amounts
data
increasingly
used
aspects
society
systems
offer
enormous
opportunities
accelerate
scientific
discovery
domains
including
personalized
medicine
smart
weather
forecasting
automate
tasks
help
improving
life
personal
assistants
recommendations
potential
transforming
society
open
government
name
just
benefits
often
systems
used
assist
even
replace
human
decision
making
diverse
domains
examples
include
software
systems
used
school
admissions
housing
pricing
goods
credit
score
estimation
job
applicant
selection
sentencing
decisions
courts
surveillance
prominent
case
compas
software
used
courts
us
assist
bail
sentencing
decisions
risk
assessment
algorithm
predicts
future
crime
ubiquitous
use
systems
may
create
possible
threats
economic
loss
social
stigmatization
even
loss
liberty
instance
known
study
propublica
found
compas
false
positive
rate
african
american
defendants
namely
people
labelled
high-risk
re-offend
nearly
twice
high
white
defendants
11
another
wellknown
study
shows
names
used
predominantly
men
women
colour
much
likely
generate
ads
related
arrest
records
34
data-driven
systems
also
employed
search
recommendation
engines
social
media
tools
news
outlets
tutorial
objectives
tutorial
aims
presenting
toolkit
definitions
models
methods
used
ensuring
fairness
rankings
recommendations
objectives
three-fold
provide
solid
framework
novel
quickly
evolving
impactful
domain
highlight
challenges
research
paths
researchers
practitioners
work
problems
intersection
recommender
systems
databases
show
fairness
challenges
manifest
areas
cloud
computation
job
scheduling
transfer
findings
existing
works
areas
purpose
organize
tutorial
along
following
main
axes
motivation
background
need
fair
rankings
recommendations
ii
modeling
fairness
rankings
recommendations
iii
ensuring
fair
rankings
recommendations
iv
fairness
computations
algorithms
systems
open
research
challenges
motivation
background
fairness
emerged
important
category
research
machine
learning
systems
many
application
areas
extending
concept
rankings
recommendations
tricky
first
essential
tension
goals
fairness
personalization
inherent
idea
personalization
2019
copyright
held
owner
author
published
proceedings
23rd
international
conference
extending
database
technology
edbt
march
30
april
2020
isbn
978
89318
083
openproceedings
org
distribution
paper
permitted
terms
creative
commons
license
cc-by-nc-nd
4.0
series
issn
2367
2005
kostas
stefanidis
konstantinos.stefanidis@tuni.fi
tampere
university
tampere
finland
651
10.5441
002
edbt
2020.86
best
items
one
user
may
different
another
however
contexts
equity
across
rankings
recommendation
outcomes
desirable
goal
furthermore
fairness
multi-sided
concept
impacts
multiple
groups
individuals
must
considered
tutorial
start
presenting
motivating
examples
need
fair
rankings
recommendations
several
domains
including
justice
ads
image
search
others
highlight
possible
causes
unfairness
biased
incomplete
data
algorithmic
inefficiencies
point
potential
harms
filter
bubbles
polarization
loss
opportunity
discrimination
consider
number
different
dimensions
based
classify
existing
models
approaches
firstly
distinguish
multiple
viewpoints
fairness
can
recommendation
systems
namely
fairness
recommended
items
31
fairness
users
19
38
fairness
groups
users
24
29
fairness
item
providers
recommendation
platform
25
furthermore
distinguish
existing
methods
achieving
fairness
rankings
recommendations
pre-processing
31
in-processing
13
post-processing
approaches
15
suggested
data
items
31
users
19
38
group
users
27
29
item
providers
finally
investigate
notion
fairness
sequential
multi-round
recommenders
25
33
goal
ensure
fairness
number
interactions
users
system
also
discuss
fairness
case
link
recommendations
networks
related
concepts
homogeneity
echo
chambers
polarity
12
part
tutorial
concludes
discourse
related
concepts
relationship
fairness
diversity
recommendation
independence
transparency
15
feedback
loops
ensuring
fairness
section
present
methods
achieving
fairness
rankings
recommendations
first
discuss
trade-offs
among
fairness
personalization
accuracy
taking
cross-type
view
approaches
can
distinguished
pre-processing
in-processing
post-processing
pre-processing
approaches
target
transforming
data
underlying
bias
discrimination
removed
in-processing
approaches
target
modifying
existing
introducing
new
algorithms
result
fair
rankings
recommendations
removing
bias
post-processing
approaches
treat
algorithms
producing
rankings
recommendations
black
boxes
without
changing
inner
workings
ensure
fairness
modify
output
algorithm
modeling
fairness
fairness
general
term
coming
single
definition
model
tricky
start
part
tutorial
reviewing
definitions
fairness
general
ask
nondiscrimination
users
items
based
values
one
sensitive
protected
attributes
gender
race
organize
definitions
respect
notions
individual
fairness
treating
similar
individuals
similarly
10
18
group
fairness
treating
different
groups
equally
nondiscrimination
sensitive
groups
35
present
number
widely
used
models
definitions
fairness
23
36
including
5.1
recommenders
first
study
fairness
systems
produce
recommendations
individuals
comprise
majority
existing
recommender
systems
start
presenting
pre-processing
approaches
work
modifying
input
recommender
example
appropriate
sampling
adding
data
input
31
performing
database
repair
28
focus
approaches
designing
fairness-aware
algorithms
recommendation
algorithms
produce
fair
recommendations
will
present
algorithms
fairness-aware
matrix
factorization
38
multi-armed
bandits
13
21
deep
learning
recommenders
44
instance
show
fairness
respect
consumers
item
providers
important
variants
well-known
sparse
linear
method
slim
can
used
negotiate
trade-off
fairness
accuracy
improve
balance
user
item
neighborhoods
alternatively
can
augment
learning
objective
matrix
factorization
adding
smoothed
variation
fairness
metric
38
another
example
present
methods
mitigate
bias
increase
fairness
incorporating
randomness
variational
autoencoders
recommenders
finally
present
post-processing
approaches
modify
output
recommenders
ensure
fairness
15
moving
individuals
groups
group
recommendations
attracted
significant
research
efforts
importance
benefiting
group
users
however
maximizing
satisfaction
group
member
minimizing
unfairness
challenging
20
study
different
fair-aware
algorithms
group
recommenders
20
27
29
32
demographic
statistical
parity
35
stating
proportion
part
protected
class
gender
take
positive
outcome
equal
rates
conditional
statistical
parity
36
defines
statistical
parity
given
set
legitimate
factors
equalized
odds
stating
protected
unprotected
groups
equal
rates
true
positives
false
positives
fairness
awareness
10
stating
two
similar
individuals
receive
similar
outcome
counterfactual
fairness
18
stating
decision
individual
fair
actual
world
counterfactual
world
individual
belongs
different
demographic
group
calibration-based
fairness
26
stating
group
receives
predicted
probability
least
fraction
members
belong
predicted
class
next
review
models
fairness
extended
case
ranked
outputs
including
attention-based
probability-based
approaches
well
approaches
based
pair-wise
comparisons
37
look
definitions
algorithmic
fairness
fair
ranking
adopted
recommender
systems
31
39
given
fairness
multi-sided
concept
extend
taxonomy
umbrella
recommender
systems
considering
fairness
can
refer
652
5.2
potential
benefits
fairness
well-accepted
nowadays
still
need
study
actual
impact
fairnessenhancing
algorithms
example
extensive
user
studies
needed
evaluate
level
acceptance
fairness-enhanced
results
users
long
term
effect
results
perceptions
preferences
extensive
studies
exploit
feedback
loops
also
performed
line
work
investigate
deeper
connections
concepts
fairness
explainability
personalization
moreover
will
advantageous
study
comparatively
notions
equality
ensures
equal
treatment
equity
ensures
treatment
based
needs
operationalizing
equity
difficult
task
often
depends
domain
study
rankings
order
guarantee
fair
rankings
in-processing
approaches
work
result
generation
procedures
allow
systematic
control
degree
unfairness
output
exploiting
learning
techniques
satisfying
statistical
parity
preserving
relevance
37
43
work
30
formulates
fairness
constraints
rankings
targeting
relevance
maximization
terms
exposure
allocation
learning-based
in-processing
approach
also
used
41
reduce
discrimination
inequality
opportunity
rankings
method
learns
ranking
function
additional
objective
reduces
disparate
exposure
recent
learning
rank
approach
deltr
looks
average
probability
items
protected
group
ranked
top
position
42
post-processing
approach
40
aims
satisfying
statistical
tests
representativeness
ranking
items
certain
order
ensure
ratio
protected
individuals
appear
within
prefix
ranking
namely
top-k
must
given
proportion
attention
received
items
different
positions
ranking
also
items
ranked
first
positions
exposed
much
attention
lower
ones
tackles
problem
ranking
presented
query
result
items
first
positions
similar
relevance
happens
decision
made
items
top-ranked
solution
situation
called
amortized
fairness
considers
position
index
proxy
level
attention
item
exposed
output
prediction
algorithm
corresponds
item
relevance
accumulated
attention
across
series
rankings
proportional
accumulated
relevance
indicating
long
term
ranking
fairness
tutorial
information
motivation
target
audience
tutorial
topic
lies
core
conference
interests
tutorial
aims
researchers
students
well
professionals
developers
searching
ranking
recommender
systems
general
data
management
community
researchers
students
will
get
good
introduction
topic
get
inspired
challenging
research
problems
furthermore
professionals
developers
will
learn
appropriate
fairness-aware
techniques
promote
fairness
systems
materials
will
used
tutorial
will
publicly
available
prerequisites
tutorial
carefully
structured
accommodate
attendees
unfamiliar
topic
experienced
participants
providing
required
background
knowledge
shared
terminology
common
understanding
basic
fairness-related
concepts
intended
duration
aiming
90
minute
tutorial
link
tutorial
resources
https://sites.google.com/view/fair-ranking-recommend
open
issues
research
directions
section
present
critical
comparison
existing
work
ensuring
fair
rankings
recommendations
lessons
learnt
areas
furthermore
discuss
open
issues
new
research
directions
arise
first
present
fairness
concepts
studied
different
areas
computer
science
fairness
often
ubiquitous
property
computations
algorithms
systems
beyond
recommender
systems
instance
federated
stream
processing
systems
open
challenge
ensure
global
fairness
processing
quality
experienced
queries
14
systems
processing
big
data
hadoop
spark
massively
parallel
databases
need
run
workloads
behalf
multiple
tenants
simultaneously
abundant
disk-based
storage
systems
usually
complemented
smaller
much
faster
cache
cache
allocation
strategies
required
speed
overall
workload
fair
tenant
17
highlight
number
possible
research
directions
start
observation
even
exist
several
definitions
models
representing
fairness
coming
different
research
perspectives
definitions
models
many
times
somewhat
incomparable
hindering
consistent
understanding
treatment
compiling
existing
definitions
produce
new
ones
evaluating
suitability
different
domains
applications
appears
open
topic
research
fairness
recommendations
multi-sided
achieving
fairness
parties
involved
also
topic
needs
investigated
presenters
evaggelia
pitoura
prof
univ
ioannina
greece
also
leads
distributed
management
data
laboratory
received
phd
degree
purdue
univ
usa
research
interests
area
data
management
systems
recent
emphasis
social
networks
responsible
data
management
publications
include
150
articles
international
journals
including
tods
tkde
pvldb
conferences
including
sigmod
icde
www
highly-cited
book
mobile
computing
research
funded
ec
national
sources
served
serves
editorial
board
acm
tods
vldbj
tkde
dapd
group
leader
senior
pc
member
co-chair
many
international
conferences
including
pc
chair
edbt
2016
icde
2012
20
years
experience
teaching
prior
tutorials
temporal
graphs
ebiss
17
social
graphs
bigdat
15
data
graphs
summersoc
14
personalization
icde
10
mobile
computing
icde
03
pervasive
computing
icde
00
georgia
koutrika
research
director
athena
research
center
greece
15
years
experience
multiple
roles
hp
labs
ibm
almaden
stanford
building
innovative
solutions
recommendations
data
analytics
exploration
work
incorporated
commercial
products
described
granted
patents
18
patent
applications
us
worldwide
published
80
papers
top-tier
conferences
journals
acm
distinguished
speaker
associate
editor
tkde
pvldb
served
653
serves
pc
member
co-chair
many
conferences
including
demo
pc
chair
acm
sigmod
2018
general
chair
acm
sigmod
2016
prior
tutorials
recommender
systems
sigmod
18
edbt
18
icde
15
personalization
icde
10
icde
07
vldb
05
22
martin
2018
social
media
changed
consume
news
forbes
2018
https://www.forbes.com/sites/nicolemartin1/2018/11/
30
how-social-media-has-changed-how-we-consume-news
18ae4c093c3c
23
ninareh
mehrabi
fred
morstatter
nripsuta
saxena
kristina
lerman
aram
galstyan
2019
survey
bias
fairness
machine
learning
corr
abs
1908.09635
2019
24
eirini
ntoutsi
kostas
stefanidis
kjetil
nørvåg
hans-peter
kriegel
2012
fast
group
recommendations
applying
user
clustering
er
126
140
25
gourab
patro
abhijnan
chakraborty
niloy
ganguly
krishna
gummadi
2020
incremental
fairness
two-sided
market
platforms
smoothly
updating
recommendations
aaai
26
geoff
pleiss
manish
raghavan
felix
wu
jon
kleinberg
kilian
weinberger
2017
fairness
calibration
advances
neural
information
processing
systems
30
guyon
luxburg
bengio
wallach
fergus
vishwanathan
garnett
eds
curran
associates
inc
5680
5689
27
dimitris
sacharidis
2019
top-n
group
recommendations
fairness
sac
1663
1670
28
babak
salimi
luke
rodriguez
bill
howe
dan
suciu
2019
interventional
fairness
causal
database
repair
algorithmic
fairness
sigmod
793
810
29
dimitris
serbos
shuyao
qi
nikos
mamoulis
evaggelia
pitoura
panayiotis
tsaparas
2017
fairness
package-to-group
recommendations
www
371
379
30
ashudeep
singh
thorsten
joachims
2018
fairness
exposure
rankings
kdd
2219
2228
31
harald
steck
2018
calibrated
recommendations
recsys
154
162
32
maria
stratigi
haridimos
kondylakis
kostas
stefanidis
2018
fairgrecs
fair
group
recommendations
exploiting
personal
health
information
dexa
147
155
33
maria
stratigi
jyrki
nummenmaa
evaggelia
pitoura
kostas
stefanidis
2020
fair
sequential
group
recommendations
sac
34
latanya
sweeney
2013
discrimination
online
ad
delivery
commun
acm
56
2013
44
54
35
virginia
tsintzou
evaggelia
pitoura
panayiotis
tsaparas
2019
bias
disparity
recommendation
systems
rmse
36
sahil
verma
julia
rubin
2018
fairness
definitions
explained
fairware
37
ke
yang
julia
stoyanovich
2017
measuring
fairness
ranked
outputs
ssdm
22
22
38
sirui
yao
bert
huang
2017
beyond
parity
fairness
objectives
collaborative
filtering
nips
2921
2930
39
sirui
yao
bert
huang
2017
new
fairness
metrics
recommendation
embrace
differences
fat
ml
2017
40
meike
zehlike
francesco
bonchi
carlos
castillo
sara
hajian
mohamed
megahed
ricardo
baeza-yates
2017
fa
ir
fair
top-k
ranking
algorithm
cikm
1569
1578
41
meike
zehlike
carlos
castillo
2018
reducing
disparate
exposure
ranking
learning
rank
approach
corr
abs
1805.08716
2018
42
meike
zehlike
gina-theresa
diehn
carlos
castillo
2020
reducing
disparate
exposure
ranking
learning
rank
approach
www
43
richard
zemel
yu
wu
kevin
swersky
toniann
pitassi
cynthia
dwork
2013
learning
fair
representations
icml
325
333
44
ziwei
zhu
xia
hu
james
caverlee
2018
fairness-aware
tensor-based
recommendation
cikm
1153
1162
kostas
stefanidis
assoc
professor
data
science
tampere
university
finland
got
phd
personalized
data
management
univ
ioannina
greece
research
interests
lie
intersection
databases
information
retrieval
data
mining
web
include
personalization
recommender
systems
large-scale
entity
resolution
information
integration
publications
include
80
papers
peer-reviewed
conferences
journals
including
sigmod
icde
acm
tods
book
entity
resolution
web
data
years
experience
teaching
prior
tutorials
recommender
systems
mumia
training
school
14
personalization
icde
10
entity
resolution
icde
17
eswc
16
www
14
cikm
13
references
sihem
amer-yahia
senjuti
basu
roy
ashish
chawla
gautam
das
cong
yu
2009
group
recommendation
semantics
efficiency
pvldb
2009
754
765
pranjal
awasthi
matthäus
kleindessner
jamie
morgenstern
2019
effectiveness
equalized
odds
fair
classification
imperfect
group
information
corr
abs
1906.03284
2019
richard
berk
hoda
heidari
shahin
jabbari
matthew
joseph
michael
kearns
jamie
morgenstern
seth
neel
aaron
roth
2017
convex
framework
fair
regression
corr
abs
1706.02409
2017
alex
beutel
jilin
chen
tulsee
doshi
hai
qian
li
wei
yi
wu
lukasz
heldt
zhe
zhao
lichan
hong
ed
chi
cristos
goodrow
2019
fairness
recommendation
ranking
pairwise
comparisons
kdd
2212
2220
asia
biega
krishna
gummadi
gerhard
weikum
2018
equity
attention
amortizing
individual
fairness
rankings
sigir
405
414
rodrigo
borges
kostas
stefanidis
2019
enhancing
long
term
fairness
recommendations
variational
autoencoders
medes
95
102
robin
burke
2017
multisided
fairness
recommendation
corr
abs
1707.00093
2017
robin
burke
nasim
sonboli
aldo
ordonez-gauger
2018
balanced
neighborhoods
multi-sided
fairness
recommendation
fat
202
214
elisa
celis
amit
deshpande
tarun
kathuria
nisheeth
vishnoi
2016
fair
diverse
corr
abs
1610.07183
2016
10
cynthia
dwork
moritz
hardt
toniann
pitassi
omer
reingold
richard
zemel
2012
fairness
awareness
innovations
theoretical
computer
science
214
226
11
angwin
et
al
2016
machine
bias
propublica
2016
https://www.propublica.
org
article
machine-bias-risk-assessments-in-criminal-sentencing
12
kiran
garimella
gianmarco
de
francisci
morales
aristides
gionis
michael
mathioudakis
2018
reducing
controversy
connecting
opposing
views
ijcai
5249
5253
13
matthew
joseph
michael
kearns
jamie
morgenstern
aaron
roth
2016
fairness
learning
classic
contextual
bandits
nips
325
333
14
evangelia
kalyvianaki
marco
fiscato
theodoros
salonidis
peter
pietzuch
2016
themis
fairness
federated
stream
processing
overload
sigmod
541
553
15
toshihiro
kamishima
shotaro
akaho
hideki
asoh
jun
sakuma
2018
recommendation
independence
fat
187
201
16
matthew
kay
cynthia
matuszek
sean
munson
2015
unequal
representation
gender
stereotypes
image
search
results
occupations
chi
3819
3828
17
mayuresh
kunjir
brandon
fain
kamesh
munagala
shivnath
babu
2017
robus
fair
cache
allocation
data-parallel
workloads
sigmod
219
234
18
matt
kusner
joshua
loftus
chris
russell
ricardo
silva
2017
counterfactual
fairness
nips
4066
4076
19
jurek
leonhardt
avishek
anand
megha
khosla
2018
user
fairness
recommender
systems
www
101
102
20
xiao
lin
min
zhang
yongfeng
zhang
zhaoquan
gu
yiqun
liu
shaoping
ma
2017
fairness-aware
group
recommendation
pareto-efficiency
recsys
107
115
21
yang
liu
goran
radanovic
christos
dimitrakakis
debmalya
mandal
david
parkes
2017
calibrated
fairness
bandits
corr
abs
1707.01875
2017
654