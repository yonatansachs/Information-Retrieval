information
retrieval
journal
2021
24
85
113
https://doi.org/10.1007/s10791-020-09386-w
evaluation
metrics
for
measuring
bias
in
search
engine
results
gizem
gezici1
aldo
lipani2
yucel
saygin1
emine
yilmaz2
received
february
2020
accepted
december
2020
published
online
27
january
2021
the
author
under
exclusive
licence
to
springer
nature
part
of
springer
nature
2021
abstract
search
engines
decide
what
we
see
for
given
search
query
since
many
people
are
exposed
to
information
through
search
engines
it
is
fair
to
expect
that
search
engines
are
neutral
however
search
engine
results
do
not
necessarily
cover
all
the
viewpoints
of
search
query
topic
and
they
can
be
biased
towards
specific
view
since
search
engine
results
are
returned
based
on
relevance
which
is
calculated
using
many
features
and
sophisticated
algorithms
where
search
neutrality
is
not
necessarily
the
focal
point
therefore
it
is
important
to
evaluate
the
search
engine
results
with
respect
to
bias
in
this
work
we
propose
novel
web
search
bias
evaluation
measures
which
take
into
account
the
rank
and
relevance
we
also
propose
framework
to
evaluate
web
search
bias
using
the
proposed
measures
and
test
our
framework
on
two
popular
search
engines
based
on
57
controversial
query
topics
such
as
abortion
medical
marijuana
and
gay
marriage
we
measure
the
stance
bias
in
support
or
against
as
well
as
the
ideological
bias
conservative
or
liberal
we
observe
that
the
stance
does
not
necessarily
correlate
with
the
ideological
leaning
positive
stance
on
abortion
indicates
liberal
leaning
but
positive
stance
on
cuba
embargo
indicates
conservative
leaning
our
experiments
show
that
neither
of
the
search
engines
suffers
from
stance
bias
however
both
search
engines
suffer
from
ideological
bias
both
favouring
one
ideological
leaning
to
the
other
which
is
more
significant
from
the
perspective
of
polarisation
in
our
society
keywords
bias
evaluation
fair
ranking
search
bias
web
search
introduction
search
engines
have
become
an
indispensable
part
of
our
lives
as
reported
by
smart
sights
2018
46.8
of
the
world
population
accessed
the
internet
in
2017
and
by
2021
the
number
is
expected
to
reach
53.7
according
to
internetlivestats
2018
currently
on
average
3.5
billion
google
searches
are
done
per
day
these
statistics
indicate
that
search
engines
replaced
traditional
broadcast
media
and
have
become
major
source
of
information
gizem
gezici
gizemgezici@sabanciuniv.edu
department
of
computer
science
and
engineering
sabanci
university
istanbul
turkey
department
of
computer
science
university
college
london
london
uk
123
86
information
retrieval
journal
2021
24
85
113
gatekeepers
to
the
web
for
many
people
diaz
2008
as
information
seekers
search
the
web
more
they
are
also
more
influenced
by
search
engine
result
pages
serps
pertaining
to
wide
range
of
areas
work
entertainment
religion
and
politics
for
instance
in
the
course
of
elections
it
is
known
that
people
issue
repeated
queries
on
the
web
about
political
candidates
and
events
such
as
democratic
debate
donald
trump
climate
change
kul
shrestha
et
al
2018
serps
returned
in
response
to
these
queries
may
influence
the
voting
decisions
as
claimed
by
epstein
and
robertson
2015
who
report
that
manipulated
search
rankings
can
change
the
voting
preferences
of
undecided
individuals
at
least
by
20
although
search
engines
are
widely
used
for
seeking
information
the
majority
of
online
users
tend
to
believe
that
they
provide
neutral
results
serving
only
as
facilitators
in
accessing
information
on
the
web
goldman
2008
however
there
are
counter
examples
to
that
belief
as
well
recent
dispute
between
the
president
donald
trump
and
google
is
such
an
example
where
mr
trump
accused
google
of
displaying
only
negative
news
about
him
when
his
name
is
searched
to
which
google
responded
by
saying
when
users
type
queries
into
the
google
search
bar
our
goal
is
to
make
sure
they
receive
the
most
relevant
answers
in
matter
of
seconds
and
search
is
not
used
to
set
political
agenda
and
we
don
bias
our
results
toward
any
political
ideology
ginger
and
david
2018
in
this
work
we
hope
to
shed
some
light
on
that
debate
by
not
specifically
concentrating
on
queries
regarding
donald
trump
but
by
conducting
an
in
depth
analysis
of
search
answers
to
broad
set
of
controversial
topics
based
on
concrete
evaluation
measures
bias
is
defined
with
respect
to
balance
in
representativeness
of
web
documents
retrieved
from
database
for
given
query
mowshowitz
and
kawaguchi
2002a
when
user
issues
query
to
search
engine
documents
from
different
sources
are
gathered
ranked
and
displayed
to
the
user
assume
that
user
searches
for
2016
presidential
election
and
the
top-n
ranked
results
are
displayed
in
such
search
scenario
the
retrieved
results
may
favor
some
political
perspectives
over
others
and
thereby
fail
to
provide
impartial
knowledge
for
the
given
query
as
claimed
by
mr
trump
though
without
any
scientific
support
hence
the
potential
undue
emphasis
of
specific
perspectives
or
viewpoints
in
the
retrieved
results
lead
to
bias
kulshrestha
et
al
2018
with
respect
to
the
definition
of
bias
and
the
presented
scenario
if
there
is
an
unbalanced
representation
skewed
or
slanted
distribution
of
the
viewpoints
in
serp
not
only
in
political
searches
towards
the
query
topic
then
we
consider
this
serp
as
biased
for
the
given
search
query
bias
is
especially
important
if
the
query
topic
is
controversial
having
opposing
views
in
which
case
it
becomes
more
critical
that
search
engines
are
supposed
to
return
results
with
balanced
representation
of
different
perspectives
which
implies
that
they
do
not
favour
one
specific
perspective
over
another
otherwise
this
may
dramatically
affect
public
as
in
the
case
of
elections
leading
to
polarisation
in
society
for
controversial
issues
on
the
other
hand
returning
an
unbalanced
representation
of
distinct
viewpoints
is
not
sufficient
to
claim
that
the
search
engine
ranking
algorithm
is
biased
one
reason
for
skewed
serp
could
be
due
to
the
corpus
itself
if
documents
indexed
and
returned
for
given
topic
come
from
slanted
distribution
meaning
that
the
ranking
algorithm
returns
biased
result
set
due
to
biased
corpus
to
differentiate
the
algorithmic
vs
corpus
bias
one
needs
to
investigate
the
source
of
bias
in
addition
to
the
skewed
list
analysis
of
the
top-n
search
results
however
the
existence
of
bias
regardless
of
being
corpus
or
algorithmic
bias
would
still
conflict
with
the
expectation
that
an
ir
system
should
be
fair
accountable
and
transparent
culpepper
et
al
2018
furthermore
it
was
reported
that
people
are
more
susceptible
to
bias
when
they
are
unaware
of
it
bargh
et
al
2001
and
epstein
et
al
2017
showed
that
alerting
users
about
bias
can
be
effective
in
suppressing
search
engine
manipulation
effect
seme
thus
search
engines
should
at
least
inform
their
users
about
the
bias
and
decrease
the
possible
seme
123
information
retrieval
journal
2021
24
85
113
87
by
making
themselves
more
accountable
thereby
alleviating
the
negative
effects
of
bias
and
serving
only
as
facilitators
as
they
generally
claim
to
be
in
this
work
we
aim
to
serve
that
purpose
by
proposing
search
bias
evaluation
framework
taking
into
account
the
rank
and
relevance1
of
the
serps
our
contributions
in
this
work
can
be
summarised
as
follows
we
propose
new
generalisable
search
bias
evaluation
framework
to
measure
bias
in
serps
by
quantifying
two
different
types
of
bias
on
content
which
are
stance
bias
and
ideological
bias
we
present
three
novel
fairness-aware
measures
of
bias
that
do
not
suffer
from
the
limita
tions
of
the
previously
presented
bias
measures
based
on
common
information
retrieval
ir
utility-based
evaluation
measures
precision
at
cut-off
rank
biased
preci
sion
rbp
and
discounted
cumulative
gain
at
cut-off
dcg
which
are
explained
in
sect
3.2
in
detail
we
apply
the
proposed
framework
to
measure
the
stance
and
ideological
bias
not
only
in
political
searches
but
searches
related
to
wide
range
of
controversial
topics
including
but
not
limited
to
education
health
entertainment
religion
and
politics
on
google
and
bing
news
search
results
we
also
utilise
our
framework
to
compare
the
relative
bias
for
queries
from
various
controversial
issues
on
two
popular
search
engines
google
and
bing
news
search
we
would
like
to
note
that
we
distinguish
the
stance
and
ideological
leaning
in
serps
the
stance
in
serp
for
query
topic
could
be
in
favor
or
against
the
topic
whereas
the
ideological
leaning
in
serp
stands
for
the
specific
ideological
group
as
conservatives
or
liberals
that
supports
the
corresponding
topic
hence
the
stance
in
serp
does
not
directly
imply
the
ideological
leaning
for
example
given
two
controversial
queries
abortion
and
cuba
embargo
serp
could
have
positive
stance
for
the
topic
of
abortion
indicating
liberal
leaning
while
positive
stance
for
the
topic
of
cuba
embargo
indicates
conservative
leaning
therefore
looking
at
the
stance
of
the
serps
for
controversial
issues
is
not
enough
and
could
even
be
misleading
in
determining
the
ideological
bias
we
demonstrate
how
the
proposed
framework
can
be
used
to
quantify
bias
in
the
serps
of
search
engines
in
this
case
bing
and
google
in
response
to
queries
related
to
controversial
topics
our
analysis
is
mainly
two-fold
where
we
first
evaluate
stance
bias
in
serps
and
then
use
this
evaluation
as
proxy
to
quantify
ideological
bias
asserted
in
the
serps
of
the
search
engines
in
this
work
via
the
proposed
framework
we
aim
to
answer
the
following
research
ques
tions
rq1
on
pro-against
stance
space
do
search
engines
return
biased
serps
towards
con
troversial
topics
rq2
do
search
engines
show
significantly
different
magnitude
of
stance
bias
from
each
other
towards
controversial
topics
rq3
on
conservative-liberal
ideology
space
do
search
engines
return
biased
serps
and
if
so
are
these
biases
significantly
different
from
each
other
towards
controversial
topics
we
address
these
research
questions
for
controversial
topics
representing
broad
range
of
issues
in
serps
of
google
and
bing
through
content
analysis
analysing
the
textual
content
of
the
retrieved
documents
in
order
to
answer
rq1
we
measure
the
degree
of
deviation
of
the
ranked
serps
from
an
ideal
distribution
where
different
stances
are
equally
we
are
referring
to
the
notion
of
relevance
defined
in
the
literature
as
system
relevance
or
topical
relevance
which
is
the
relevance
predicted
by
the
system
123
88
information
retrieval
journal
2021
24
85
113
likely
to
appear
to
detect
bias
which
results
from
the
unbalanced
representation
of
distinct
perspectives
we
label
the
documents
stances
with
crowd-sourcing
and
use
these
labels
for
stance
bias
evaluation
in
this
paper
we
focus
on
particular
kind
of
bias
statistical
parity
or
more
generally
known
as
equality
of
outcome
given
population
divided
into
groups
the
groups
in
the
output
of
the
system
should
be
equally
represented
this
is
in
contrast
with
the
other
popular
measure
generally
known
as
equality
of
opportunity
given
population
divided
into
groups
the
groups
in
the
output
should
be
represented
based
on
their
proportion
in
the
population
namely
base
rates
for
choosing
the
equality
of
outcome
we
have
mainly
two
reasons
first
in
the
context
of
the
controversial
topics
not
all
of
the
corresponding
debate
questions
queries
have
certain
answers
based
on
scientific
facts
second
the
identification
of
the
stance
for
the
full
ranking
list
which
is
fair
representative
set
of
the
indexed
documents
is
too
expensive
to
get
annotated
through
crowd-sourcing
thus
this
choice
of
ideal
ranking
makes
the
experiments
feasible
to
address
rq2
we
compare
the
stance
bias
in
the
serps
of
the
two
search
engines
to
see
if
they
show
similar
level
of
bias
for
the
corresponding
controversial
topics
rq3
is
naturally
answered
by
assigning
an
ideological
leaning
label
to
each
query
topic
as
conservative
or
liberal
depending
on
which
ideology
favors
the
proposition
in
the
query
we
further
interpret
the
document
stance
labels
in
conservative-to-liberal
ideology2
space
and
transform
these
stance
labels
into
ideological
leanings
according
to
the
assigned
leaning
labels
of
the
corresponding
topics
we
note
that
conservative-to-liberal
ideology
space
does
not
only
stand
for
political
parties
in
this
context
we
accept
these
ideology
labels
as
having
more
conservative
liberal
viewpoint
towards
given
controversial
topic
as
similarly
fulfilled
by
lahoti
et
al
2018
for
three
popular
controversial
topics
of
gun
control
abortion
and
obamacare
in
twitter
domain
for
instance
the
topic
of
abortion
has
the
query
of
should
abortion
be
legal
since
mostly
liberals
support
the
proposition
in
this
query
liberal
leaning
is
assigned
to
abortion
the
stance
labels
of
the
retrieved
documents
towards
the
query
are
transformed
into
ideological
leanings
as
follows
if
document
has
the
pro
stance
which
means
that
it
supports
the
asserted
proposition
then
its
ideological
leaning
is
liberal
if
it
has
the
against
stance
its
leaning
is
conservative
in
our
bias
evaluation
framework
we
concentrate
on
the
top-10
serps
coming
from
the
news
sources
to
investigate
two
major
search
engines
bing
and
google
in
terms
of
bias
we
deliberately
use
news
serps
for
our
experiments
since
they
often
exhibit
specific
view
towards
topic
alam
and
downey
2014
recent
studies
sarcona
2019
99firms
2019
show
that
on
average
more
than
70
of
all
the
clicks
are
in
the
first
page
results
thus
we
only
focus
on
the
top-10
results
to
show
the
existence
of
bias
experiments
show
that
there
is
no
statistically
significant
difference
of
stance
bias
in
magnitude
measured
across
the
two
search
engines
meaning
that
they
do
not
favour
one
specific
stance
over
other
however
we
should
stress
that
stance
bias
results
need
to
be
taken
with
grain
of
salt
as
demonstrated
through
the
abortion
and
cuba
embargo
query
examples
polarisation
of
the
society
is
mostly
on
ideological
leanings
and
our
second
phase
of
experiments
show
that
there
is
statistically
significant
difference
of
ideological
bias
where
both
search
engines
favour
one
ideological
leaning
over
other
the
remainder
of
the
paper
is
structured
as
follows
in
sect
we
give
the
related
work
and
the
search
bias
evaluation
framework
is
proposed
in
sect
in
sect
we
detail
the
experimental
setup
and
present
the
results
then
we
discuss
the
results
in
sect
in
sect
we
present
the
limitations
of
this
work
and
we
conclude
in
sect
we
are
referring
to
the
notion
of
ideology
perceived
by
the
crowd
workers
123
information
retrieval
journal
2021
24
85
113
89
background
and
related
work
in
recent
years
bias
analysis
in
serps
of
search
engines
has
attracted
lot
of
interest
baeza
yates
2016
mowshowitz
and
kawaguchi
2002b
noble
2018
pan
et
al
2007
tavani
2012
due
to
the
concerns
that
search
engines
may
manipulate
the
search
results
influencing
users
the
main
reason
behind
these
concerns
is
that
search
engines
have
become
the
fundamental
source
of
information
dutton
et
al
2013
and
surveys
from
pew
2014
and
reuters
2018
found
that
more
people
obtain
their
news
from
search
engines
than
social
media
the
users
reported
higher
trust
on
search
engines
for
the
accuracy
of
information
newman
et
al
2018
2019
elisa
shearer
2018
and
many
internet-using
us
adults
even
use
search
engines
to
fact-check
information
dutton
et
al
2017
to
figure
out
how
this
growing
usage
of
search
engines
and
trust
in
them
might
have
undesirable
effects
on
public
and
what
could
be
the
methods
to
measure
those
effects
in
the
following
we
review
the
research
areas
related
first
to
automatic
stance
detection
then
to
fair
ranking
evaluation
and
lastly
to
search
bias
quantification
2.1
opinion
mining
and
sentiment
analysis
form
of
opinion
mining
related
to
our
work
is
contrastive
opinion
modeling
com
proposed
by
fang
et
al
2012
in
com
given
political
text
collection
the
task
is
to
present
the
opinions
of
the
distinct
perspectives
on
given
query
topic
and
to
quantify
their
differences
with
an
unsupervised
topic
model
com
is
applied
on
debate
records
and
headline
news
differently
from
keyword
analysis
to
differentiate
opinions
using
topic
modelling
we
compute
different
ir
metrics
from
the
content
of
the
news
articles
to
evaluate
and
compare
the
bias
in
the
serps
of
two
search
engines
aktolga
and
allan
2013
consider
the
sentiment
towards
controversial
topics
and
propose
different
diversification
methods
based
on
the
topic
sentiment
their
main
aim
is
to
diversify
the
retrieved
results
of
search
engine
according
to
various
sentiment
biases
in
blog
posts
rather
than
measure
bias
in
the
serps
of
news
search
engines
as
we
do
in
this
work
demartini
and
siersdorfer
2010
exploit
automatic
and
lexicon-based
text
classification
approaches
support
vector
machines
and
sentiwordnet
respectively
to
extract
sentiment
value
from
the
textual
content
of
serps
in
response
to
controversial
topics
unlike
us
demar
tini
and
siersdorfer
2010
only
use
this
sentiment
information
to
compare
opinions
in
the
retrieved
results
of
three
commercial
search
engines
without
measuring
bias
in
this
paper
we
propose
new
bias
evaluation
framework
with
robust
bias
measures
to
systematically
measure
bias
in
serps
chelaru
et
al
2012
focus
on
queries
rather
than
serps
and
inves
tigate
if
the
opinionated
queries
are
issued
to
search
engines
by
computing
the
sentiment
of
suggested
queries
for
controversial
topics
in
follow-up
work
chelaru
et
al
2013
authors
use
different
classifiers
to
detect
the
sentiment
expressed
in
queries
and
extend
the
previous
experiments
with
two
different
use
cases
instead
of
queries
our
work
analyses
the
serps
in
news
domain
therefore
we
need
to
identify
the
stance
of
the
news
articles
automatically
obtaining
article
stances
is
beyond
the
scope
of
this
work
thus
we
use
crowd-sourcing
2.2
evaluating
fairness
in
ranking
fairness
evaluation
in
ranked
results
has
attracted
attention
in
recent
years
yang
and
stoy
anovich
2017
propose
three
bias
measures
namely
normalized
discounted
difference
rnd
normalized
discounted
kullback-leibler
divergence
rkl
and
normalized
dis
123
90
information
retrieval
journal
2021
24
85
113
counted
ratio
rrd
that
are
related
to
normalized
discounted
cumulative
gain
ndcg
through
the
use
of
logarithmic
discounting
for
regularization
which
is
inspired
from
ndcg
as
also
stated
in
the
original
paper
researchers
use
these
metrics
to
check
if
there
exists
systematic
discrimination
against
group
of
individuals
when
there
are
only
two
differ
ent
groups
as
protected
g1
and
an
unprotected
group
g2
in
ranking
in
other
words
researchers
quantify
the
relative
representation
of
g1
the
protected
group
whose
members
share
characteristic
such
as
race
or
gender
that
cannot
be
used
for
discrimination
in
ranked
output
the
definitions
of
these
three
proposed
measures
can
be
rewritten
as
follows
g1
dg1
log2
10
20
where
is
general
definition
of
an
evaluation
measure
for
given
ranked
list
of
docu
ments
serp
whereas
g1
is
specifically
for
the
protected
group
of
g1
in
this
definition
is
normalisation
constant
is
the
ranked
list
of
the
retrieved
serp
and
is
the
size
of
this
ranked
list
number
of
documents
in
the
ranked
list
note
that
is
deliberately
incremented
by
10
to
compute
set-based
fairness
at
discrete
values
as
top-10
top-20
etc
instead
of
as
usually
done
in
ir
for
the
proposed
measures
to
show
the
correct
behaviour
with
bigger
sample
sizes
the
purpose
of
computing
the
set-based
fairness
to
express
that
being
fair
at
higher
positions
of
the
ranked
list
is
more
important
top-10
vs
top-100
in
the
rewritten
formula
dg1
defines
distance
function
between
the
expected
probability
to
retrieve
document
belonging
to
g1
in
the
overall
population
and
its
observed
probability
at
rank
to
measure
the
systematic
bias
these
probabilities
turn
out
to
be
equal
to
pg1
ri
g1
when
computed
over
g1
at
cut-off
value
and
for
the
three
proposed
measures
as
below
in
this
formula
is
the
number
of
documents
considered
in
as
cut-off
value
and
ri
is
defined
as
the
document
in
retrieved
at
rank
note
that
ri
returns
the
label
associated
to
the
document
ri
specifying
its
group
as
g1
or
g2
based
on
this
ri
g1
refers
to
conditional
statement
which
returns
if
the
document
ri
is
the
member
of
g1
and
otherwise
in
the
original
paper
dg1
is
defined
for
rnd
rkl
and
rrd
as
dg1
pg1
pg1
for
rnd
pg1
dg1
pg1
log
pg1
pg1
pg1
log
for
rkl
pg1
pg1
pg1
dg1
for
rrd
pg1
pg1
these
measures
although
inspired
by
ir
evaluation
measures
particularly
in
the
context
of
content
bias
in
search
results
suffer
from
the
following
limitations
rnd
measure
focuses
on
on
the
protected
group
g1
if
we
were
to
compute
at
steps
of
with
the
given
equal
desired
proportion
of
the
two
groups
as
50
50
then
the
distance
function
of
rnd
denoted
as
dg1
would
always
give
value
of
0.5
for
the
first
retrieved
document
where
this
will
always
be
the
case
no
matter
which
group
this
document
belongs
to
pro
or
against
in
our
case
this
is
caused
by
dg1
of
rnd
123
information
retrieval
journal
2021
24
85
113
91
through
the
use
of
its
absolute
value
in
eq
in
our
case
this
holds
when
and
10
where
we
measure
bias
in
the
top-10
results
this
is
in
fact
avoided
in
the
original
paper
yang
and
stoyanovich
2017
by
computing
at
steps
of
10
as
top-10
top-20
etc
rather
than
steps
of
as
it
is
usually
done
in
ir
which
gives
more
meaningful
results
in
our
evaluation
framework
rkl
measure
cannot
differentiate
between
biases
of
equal
magnitude
but
in
opposite
directions
with
the
given
equal
desired
proportion
of
the
two
groups
as
50
50
it
cannot
differentiate
bias
towards
conservative
or
liberal
in
our
case
also
in
ir
settings
it
is
not
as
easy
to
interpret
the
computed
values
from
the
kl-divergence
denoted
as
dg1
for
rkl
compared
to
our
measures
since
our
measures
are
based
on
the
standard
utility
based
ir
measures
furthermore
kl-divergence
tends
to
generate
larger
distances
for
small
datasets
thus
it
could
compute
larger
bias
values
in
the
case
of
only
10
documents
and
this
situation
may
become
even
more
problematic
if
we
measure
bias
for
less
number
of
documents
top-3
top-5
for
more
fine-grained
analysis
in
the
original
paper
this
disadvantage
is
alleviated
by
computing
the
rkl
values
also
at
discrete
points
of
steps
10
instead
of
rrd
measure
does
not
treat
the
protected
and
unprotected
groups
g1
and
g2
symmet
rically
as
stated
in
the
original
paper
which
is
not
applicable
to
our
framework
our
proposed
measures
treat
g1
and
g2
equal
since
we
have
two
protected
groups
pro
and
against
for
stance
bias
conservative
and
liberal
for
ideological
bias
to
measure
bias
in
search
settings
moreover
rrd
is
only
applicable
in
special
conditions
when
g1
is
the
minority
group
in
the
underlying
population
as
also
declared
by
the
authors
while
we
do
not
have
such
constraints
for
our
measures
in
the
scope
of
search
bias
evaluation
these
measures
focus
on
differences
in
the
relative
representation
of
g1
between
dis
tributions
therefore
from
general
point
of
view
most
probably
more
samples
are
necessary
for
these
measures
to
show
the
expected
behavior
and
work
properly
in
the
original
paper
experiments
are
fulfilled
with
three
different
datasets
one
is
synthetic
which
includes
1000
samples
and
two
are
real
datasets
which
include
1000
and
7000
samples
to
evaluate
bias
with
these
measures
while
we
have
only
10
samples
for
query
wise
evaluation
this
is
probably
because
these
measures
were
mainly
devised
for
the
purpose
of
measuring
bias
in
ranked
outputs
instead
of
search
engine
results
none
of
these
datasets
contain
search
results
either
these
measures
are
difficult
to
use
in
practice
since
they
rely
on
normalization
term
that
is
computed
stochastically
as
the
highest
possible
value
of
the
corresponding
bias
measure
for
the
given
number
of
documents
and
protected
group
size
g1
in
this
paper
we
rely
on
standard
statistical
tests
since
they
are
easier
to
interpret
provide
confidence
intervals
and
have
been
successfully
used
to
investigate
inequalities
in
search
systems
previously
by
chen
et
al
2018
these
measures
do
not
consider
relevance
which
is
fundamental
aspect
when
evaluating
bias
in
search
engines
for
example
as
in
our
case
when
searching
for
controversial
topic
if
the
first
retrieved
document
is
about
news
belonging
to
g1
but
its
content
is
not
relevant
to
the
searched
topic
then
these
measures
would
still
consider
this
document
as
positive
for
g1
however
this
document
has
absolutely
no
effect
on
providing
an
unbiased
representation
of
the
controversial
topic
to
the
user
this
is
because
these
metrics
were
devised
particularly
for
evaluating
bias
in
the
ranked
outputs
instead
of
serps
although
the
proposed
measures
by
yang
and
stoyanovich
2017
are
valuable
in
the
context
of
measuring
bias
in
ranked
outputs
where
the
individuals
are
being
ranked
and
some
of
these
individuals
are
the
members
of
the
protected
group
g1
these
measures
have
the
aforemen
123
92
information
retrieval
journal
2021
24
85
113
tioned
limitations
these
limitations
are
particularly
visible
for
content
bias
evaluation
where
the
web
documents
are
being
ranked
by
search
engines
in
typical
ir
setting
in
this
paper
we
address
these
limitations
by
proposing
family
of
fairness-aware
measures
with
the
main
purpose
of
evaluating
content
bias
in
serps
based
on
standard
utility-based
ir
evaluation
measures
zehlike
et
al
2017
based
on
yang
and
stoyanovich
2017
work
propose
an
algorithm
to
test
the
statistical
significance
of
fair
ranking
beutel
et
al
2019
propose
pairwise
fairness
measure
for
recommender
systems
however
the
authors
unlike
us
measure
fair
ness
on
personalized
recommendations
and
do
not
consider
relevance
while
we
work
in
an
unpersonalized
information
retrieval
setting
and
we
do
consider
relevance
kallus
and
zhou
2019
investigate
the
fairness
of
predictive
risk
scores
as
bipartite
ranking
task
where
the
main
goal
is
to
rank
positively
labelled
examples
above
negative
ones
however
their
measures
of
bias
based
on
the
area
under
the
roc
curve
auc
are
agnostic
from
the
rank
position
at
which
document
has
been
retrieved
2.3
quantifying
search
engine
biases
although
the
search
engine
algorithms
are
not
transparent
and
available
to
external
researchers
algorithm
auditing
techniques
provide
an
effective
means
for
systematically
evaluating
the
results
in
controlled
environment
sandvig
et
al
2014
prior
works
leverage
lda-variant
unsupervised
methods
and
crowd-sourcing
to
analyse
bias
in
content
or
url
analysis
for
indexical
bias
saez-trumper
et
al
2013
propose
unsupervised
methods
to
characterise
different
types
of
biases
in
online
news
media
and
in
their
social
media
communities
by
also
analysing
political
perspectives
of
the
news
sources
yigit-sert
et
al
2016
investigate
media
bias
by
analysing
the
user
comments
along
with
the
content
of
the
online
news
articles
to
identify
the
latent
aspects
of
two
highly
polarising
topics
in
the
turkish
political
arena
kulshrestha
et
al
2017
quantify
bias
in
social
media
by
measuring
the
bias
of
the
author
of
tweet
while
in
kulshrestha
et
al
2018
bias
in
web
search
is
quantified
through
url
analysis
for
google
in
political
domain
without
any
serp
content
analysis
in
our
work
we
consider
the
google
and
bing
serps
from
news
sources
such
as
ny-times
and
bbc
news
in
order
to
quantify
bias
through
content
analysis
in
addition
to
the
unsupervised
approaches
crowd-sourcing
is
widely
used
mechanism
to
analyse
bias
in
content
crowd-sourcing
is
common
approach
for
labelling
tasks
in
different
research
areas
such
as
image
video
annotation
krishna
et
al
2017
vondrick
et
al
2013
object
detection
su
et
al
2012
named
entity
recognition
lawson
et
al
2010
finin
et
al
2010
sentiment
analysis
räbiger
et
al
2018
and
relevance
evaluation
alonso
et
al
2008
alonso
and
mizzaro
2012
yuen
et
al
2011
provide
detailed
survey
of
crowd-sourcing
applications
as
yuen
et
al
2011
suggest
crowd-sourcing
can
also
be
used
for
gathering
opinions
from
the
crowd
mellebeek
et
al
2010
use
crowd-sourcing
to
classify
spanish
consumer
comments
and
show
that
non-expert
amazon
mechanical
turk
mturk
annotations
are
viable
and
cost-effective
alternative
to
expert
ones
in
this
work
we
use
crowd-sourcing
for
collecting
opinions
of
the
public
not
about
consumer
products
but
controversial
topics
apart
from
the
content
bias
there
is
another
research
area
namely
indexical
bias
indexi
cal
bias
refers
to
the
bias
which
is
displayed
in
the
selection
of
items
rather
than
in
the
content
of
retrieved
documents
namely
content
bias
mowshowitz
and
kawaguchi
2002b
mow
showitz
and
kawaguchi
2002a
mowshowitz
and
kawaguchi
2005
quantify
instead
only
123
information
retrieval
journal
2021
24
85
113
93
indexical
bias
by
using
precision
and
recall
measures
moreover
the
researchers
approximate
the
ideal
norm
by
the
distribution
produced
by
collection
of
search
engines
to
measure
bias
yet
this
may
not
be
fair
bias
evaluation
procedure
since
the
ideal
itself
should
be
unbiased
whereas
the
serps
of
search
engines
may
actually
contain
bias
similarly
chen
and
yang
2006
use
the
same
method
in
order
to
quantify
indexical
and
content
bias
how
ever
content
analysis
was
performed
by
representing
the
serps
with
weighted
vector
with
different
html
tags
without
an
in-depth
analysis
of
the
textual
content
in
this
work
we
evaluate
content
bias
by
analysing
the
textual
contents
of
the
google
and
bing
serps
and
we
do
not
generate
the
ideal
relying
on
the
serps
of
other
search
engines
in
order
to
measure
bias
in
more
fair
way
in
addition
to
the
categorisation
of
the
content
and
indexical
bias
analysis
prior
methods
used
in
auditing
algorithms
to
quantify
bias
can
also
be
divided
into
three
main
categories
as
audience-based
content-based
and
rater-based
audience-based
measures
focus
on
identifying
the
political
perspectives
of
media
outlets
and
web
pages
by
utilising
the
interests
ideologies
or
political
affiliations
of
its
users
likes
and
shares
on
facebook
bakshy
et
al
2015
based
on
the
premise
that
readers
follow
the
news
sources
that
are
closest
to
their
ideological
point
of
view
mullainathan
and
shleifer
2005
lahoti
et
al
2018
model
the
problem
of
ideological
leaning
of
social
media
users
and
media
sources
in
the
liberal-conservative
ideology
space
on
twitter
as
constrained
non-negative
matrix
factorisation
problem
content-based
measures
exploit
linguistic
features
in
textual
content
gentzkow
and
shapiro
2010
extract
frequent
phrases
of
the
different
political
partisans
democrats
republicans
from
the
congress
reports
then
the
researchers
come
with
the
metric
of
media
slant
index
to
measure
us
newspapers
political
leaning
finally
rater-based
methods
also
exploit
textual
content
and
can
be
evaluated
under
the
content-based
methods
unlike
the
content-based
the
rater-based
methods
use
ratings
of
people
for
the
sentiment
partisan
or
ideological
leaning
of
content
instead
of
analysing
the
textual
content
linguisti
cally
rater-based
methods
generally
leverage
crowd-sourcing
to
collect
the
labels
for
the
content
analysis
for
instance
budak
et
al
2016
quantify
bias
partisanship
in
us
news
outlets
newspapers
and
political
blogs
for
15
selected
queries
related
to
wide
range
of
controversial
issues
about
which
democrats
and
republicans
argue
the
researchers
use
mturk
as
crowd-sourcing
platform
to
obtain
the
topic
and
political
slant
labels
being
positive
towards
democrats
or
republicans
of
the
articles
similarly
epstein
and
robertson
2017
use
crowd-sourcing
to
score
individual
search
results
and
diakopoulos
et
al
2018
make
use
of
the
mturk
platform
rater-based
approach
to
get
labels
for
the
google
serp
websites
by
focusing
on
the
content
and
apply
an
audience-based
approach
through
utilising
the
prior
work
of
bakshy
et
al
2015
specifically
for
quantifying
partisan
bias
our
work
follows
rater-based
approach
by
making
use
of
the
mturk
platform
for
crowd-sourcing
to
analyse
web
search
bias
through
stances
and
ideological
leanings
of
the
news
articles
instead
of
partisan
bias
in
the
textual
contents
of
the
serps
there
have
been
endeavors
to
audit
partisan
bias
on
web
search
diakopoulos
et
al
2018
present
four
case
studies
on
google
search
results
and
to
quantify
partisan
bias
in
the
first
page
they
collect
serps
by
issuing
complete
candidate
names
of
the
2016
us
presidential
election
as
queries
and
utilise
crowd-sourcing
to
obtain
the
sentiment
scores
of
the
serps
they
found
that
google
presented
higher
proportion
of
negative
articles
for
republican
candidates
than
the
democratic
ones
similarly
epstein
and
robertson
2017
present
case
study
for
the
election
and
use
browser
extension
to
collect
google
and
yahoo
search
data
for
the
election-related
queries
then
use
crowd-sourcing
to
score
the
serps
the
researchers
also
found
left-leaning
bias
and
google
was
more
biased
than
yahoo
in
their
follow-up
work
they
found
small
but
significant
ranking
bias
in
the
standard
serps
but
not
due
to
personalisation
robertson
et
al
2018a
similarly
researchers
audit
google
search
after
123
94
information
retrieval
journal
2021
24
85
113
donald
trump
presidential
inauguration
with
dynamic
set
of
political
queries
using
auto
complete
suggestions
robertson
et
al
2018b
hu
et
al
2019
conduct
an
algorithm
audit
and
construct
specific
lexicon
of
partisan
cues
for
measuring
political
partisanship
of
google
search
snippets
relative
to
the
corresponding
web
pages
they
define
the
corresponding
difference
as
bias
for
this
particular
use
case
without
making
robust
search
bias
evaluation
of
serps
from
the
user
perspective
in
this
work
we
introduce
novel
fairness-aware
ir
measures
which
involve
rank
information
to
evaluate
content
bias
for
this
we
use
crowd
sourcing
to
obtain
labels
of
the
news
serps
returned
towards
the
queries
related
to
wide
range
of
controversial
topics
instead
of
only
political
ones
with
our
robust
bias
evaluation
measures
our
main
aim
is
to
audit
ideological
bias
in
web
search
rather
than
solely
partisan
bias
apart
from
partisan
bias
recent
studies
have
investigated
different
types
of
bias
for
various
purposes
chen
et
al
2018
investigate
gender
bias
in
the
various
resume
search
engines
which
are
platforms
that
help
recruiters
to
search
for
suitable
candidates
and
use
statistical
tests
to
examine
two
types
of
indirect
discrimination
individual
and
group
fairness
similarly
in
another
research
study
authors
investigate
gender
stereotypes
by
analyzing
the
gender
distribution
in
image
search
results
retrieved
by
bing
in
four
different
regions
otterbacher
et
al
2017
researchers
use
the
query
of
person
and
the
queries
related
to
68
character
traits
such
as
intelligent
person
and
the
results
show
that
photos
of
women
are
more
often
retrieved
for
emotional
and
similar
traits
whereas
rational
and
related
traits
are
represented
by
photos
of
men
in
follow-up
work
researchers
conduct
controlled
experiment
via
crowd-sourcing
with
participants
from
three
different
countries
to
detect
bias
in
image
search
results
otterbacher
et
al
2018
demographic
information
along
with
measures
of
sexism
are
analysed
together
and
the
results
confirm
that
sexist
people
are
less
likely
to
detect
and
report
gender
biases
in
the
search
results
raji
and
buolamwini
2019
examine
the
impact
of
publicly
naming
biased
performance
results
of
commercial
ai
products
in
face
recognition
for
directly
challenging
companies
to
change
their
products
geyik
et
al
2019
present
fairness-aware
ranking
framework
to
quantify
bias
with
respect
to
protected
attributes
and
improve
the
fairness
for
individuals
without
affecting
the
business
metrics
the
authors
extended
the
metrics
proposed
by
yang
and
stoyanovich
2017
of
which
we
specified
the
limitations
in
sect
2.2
and
evaluated
their
procedure
using
simulations
with
application
to
linkedin
talent
search
vincent
et
al
2019
measure
the
dependency
of
search
engines
on
user-created
content
to
respond
to
queries
using
google
search
and
wikipedia
articles
in
another
work
researchers
propose
novel
metric
that
involves
users
and
their
attention
for
auditing
group
fairness
in
ranked
lists
sapiezynski
et
al
2019
gao
and
shah
2019
propose
framework
that
effectively
and
efficiently
estimate
the
solution
space
where
fairness
in
ir
is
modelled
as
an
optimisation
problem
with
fairness
constraint
same
researchers
work
on
top-k
diversity
fairness
ranking
in
terms
of
statistical
parity
and
disparate
impact
fairness
and
propose
entropy-based
metrics
to
measure
the
topical
diversity
bias
presented
in
serps
of
google
using
clustering
instead
of
labelled
dataset
with
group
information
gao
and
shah
2020
unlike
to
their
approach
our
goal
is
to
quantify
search
bias
in
serps
rather
than
topical
diversity
for
this
we
use
crowd-labelled
dataset
thereby
to
evaluate
bias
from
the
user
perspective
with
stance
and
ideological
leanings
of
the
documents
in
this
context
we
focus
on
proposing
new
search
bias
evaluation
procedure
in
ranked
lists
to
quantify
bias
in
the
news
serps
with
the
proposed
robust
fairness-aware
ir
measures
we
also
compare
the
relative
bias
of
the
two
search
engines
through
incorporating
relevance
and
ranking
information
into
the
procedure
without
tracking
the
source
of
bias
as
discussed
123
information
retrieval
journal
2021
24
85
113
95
in
sect
our
procedure
can
be
used
for
the
source
of
bias
analysis
as
well
which
we
leave
as
future
work
search
engine
bias
evaluation
framework
in
this
section
we
describe
our
search
bias
evaluation
framework
then
we
present
the
measures
of
bias
and
the
proposed
protocol
to
identify
search
bias
3.1
preliminaries
our
first
aim
is
to
detect
bias
with
respect
to
the
distribution
of
stances
expressed
in
the
contents
of
the
serps
let
be
the
set
of
search
engines
and
be
the
set
of
queries
about
controversial
topics
when
query
is
issued
to
search
engine
the
search
engine
returns
serp
we
define
the
stance
of
the
i-th
retrieved
document
ri
with
respect
to
as
ri
stance
can
have
the
following
values
pro
neutral
against
not-relevant
document
stance
with
respect
to
topic
can
be
pro
when
the
document
is
in
favour
of
the
controversial
topic
the
document
describes
more
the
pro
aspects
of
the
topic
neutral
when
the
document
does
not
support
or
help
either
side
of
the
controversial
topic
the
document
provides
an
impartial
fair
description
about
the
pro
and
cons
of
the
topic
against
when
the
document
is
against
the
controversial
topic
the
document
describes
more
the
cons
aspects
of
the
topic
not-relevant
when
the
document
is
not-relevant
with
respect
to
the
controversial
topic
for
our
analyses
we
deliberately
use
recent
controversial
topics
in
us
that
are
the
real
debatable
ones
rather
than
the
topics
being
possibly
exposed
to
false
media
balance
which
occurs
when
the
media
present
opposing
viewpoints
as
being
more
equal
than
the
evidence
supports
flat
earth
debate
grimes
2016
stokes
2019
our
topic
set
contains
abortion
illegal
immigration
gay
marriage
and
similar
controversial
topics
which
comprise
opposing
points
of
view
since
complicated
concepts
concerning
the
identity
religion
political
or
ide
ological
leaning
are
the
actual
points
where
search
engines
are
more
likely
to
provide
biased
results
noble
2018
and
influence
people
dramatically
our
second
aim
is
to
detect
bias
with
respect
to
the
distribution
of
ideological
leanings
expressed
in
the
contents
of
the
serps
we
do
this
by
associating
each
query
belonging
to
controversial
topic
to
one
current
ideological
leaning
then
combining
the
stances
for
each
ri
and
the
associated
ideological
leaning
of
we
can
measure
the
ideological
bias
of
the
content
of
given
serp
if
topic
belongs
to
specific
ideology
and
document
retrieved
for
this
topic
has
pro
stance
we
consider
this
document
to
be
biased
towards
this
ideology
we
define
the
ideological
leaning
of
as
an
ideological
leaning
can
have
the
following
values
conservative
liberal
both
or
neither
topic
ideological
leaning
can
be
conservative
when
the
topic
is
part
of
the
conservative
policies
the
conservatives
are
in
favour
of
the
topic
123
96
information
retrieval
journal
2021
24
85
113
table
symbols
functions
and
labels
used
throughout
the
paper
symbols
set
of
search
engines
search
engine
set
of
queries
query
ranked
list
of
the
given
serp
list
of
retrieved
documents
ri
the
document
in
retrieved
at
rank
size
of
number
of
documents
in
the
ranked
list
number
of
documents
considered
in
cut-off
functions
ri
returns
the
label
associated
to
ri
an
evaluation
measure
for
serps
labels
pro
stance
neutral
stance
against
stance
not-relevant
stance
conservative
ideological
leaning
liberal
ideological
leaning
both
or
neither
ideological
leanings
liberal
when
the
topic
is
part
of
the
liberal
policies
the
liberals
are
in
favour
of
the
topic
both
or
neither
when
both
or
neither
policies
are
either
in
favour
or
against
the
topic
for
reference
table
shows
summary
of
all
the
symbols
functions
and
labels
used
in
this
paper
3.2
measures
of
bias
based
on
the
aforementioned
definition
provided
in
sect
bias
can
be
quantified
by
mea
suring
the
degree
of
deviation
of
the
distribution
of
documents
from
the
ideal
one
to
give
broad
definition
of
an
ideal
list
poses
problems
but
in
the
scope
of
this
work
for
controversial
topics
we
can
mention
the
existence
of
bias
in
ranked
list
retrieved
by
search
engine
if
the
presented
information
significantly
deviates
from
true
likelihoods
white
2013
as
justified
in
sect
in
the
scope
of
this
work
we
focus
on
equality
of
output
thus
we
accept
the
true
likelihoods
of
different
views
as
equal
rather
than
computing
them
from
the
corresponding
base
rates
therefore
using
the
proposed
definition
reversely
we
can
assume
that
the
ideal
list
is
the
one
that
minimises
the
difference
between
two
opposing
views
which
we
indicate
here
as
and
in
the
context
of
stances
formally
we
measure
the
stance
bias
in
serp
as
follows
123
information
retrieval
journal
2021
24
85
113
97
where
is
function
that
measures
the
likelihood
of
in
satisfying
the
information
need
of
the
user
about
the
view
and
the
view
we
note
that
ideological
bias
is
measured
in
the
same
way
by
transforming
the
stances
of
the
documents
into
ideological
leanings
which
will
be
explained
in
sect
4.2
before
defining
from
eq
we
define
the
mean
bias
mb
of
search
engine
as
mb
an
unbiased
search
engine
would
produce
mean
bias
of
limitation
of
mb
is
that
if
search
engine
is
biased
towards
the
view
on
one
topic
and
bias
towards
the
view
on
another
topic
these
two
contributions
will
cancel
each
other
out
in
order
to
avoid
this
limitation
we
also
define
the
mean
absolute
bias
mab
which
consists
in
taking
the
absolute
value
of
the
bias
for
each
formally
this
is
defined
as
follows
mab
an
unbiased
search
engine
produces
mean
absolute
bias
of
although
this
measure
defined
in
eq
solves
the
limitation
of
mb
mab
says
nothing
about
towards
which
view
the
search
engine
is
biased
making
these
two
measures
of
bias
complementary
in
ir
the
likelihood
of
in
satisfying
the
information
need
of
users
is
measured
via
retrieval
evaluation
measures
among
these
measures
we
selected
utility-based
evaluation
measures
this
class
of
evaluation
measures
quantify
in
terms
of
its
worth
to
the
user
and
are
normally
computed
as
sum
of
the
information
gain
summed
over
the
relevant
documents
retrieved
by
the
ir
evaluation
measures
used
in
the
following
experiments
are
rbp
and
dcg
for
the
view
is
formalised
as
in
eq
however
differently
from
the
previous
definition
of
ri
where
the
only
possible
outcomes
are
g1
and
g2
for
the
document
ri
here
can
return
any
of
the
label
associated
to
stance
and
hence
only
pro
and
against
documents
that
are
relevant
to
the
topic
are
taken
into
account
since
ri
returns
neutral
and
not-relevant
when
otherwise
substituting
eq
to
eq
we
obtain
the
first
measure
of
bias
βp
ri
ri
the
main
limitation
of
this
measure
of
bias
is
that
it
has
weak
concept
of
ranking
the
first
documents
contribute
equally
to
the
bias
score
the
next
two
evaluation
measures
overcome
this
issue
by
defining
discount
functions
rbp
weights
every
document
based
on
the
coefficients
of
normalised
geometric
series
with
value
where
is
parameter
of
rbp
similarly
to
what
is
done
for
we
reformulate
rbp
to
measure
bias
as
follows
rbp
pi
ri
substituting
eq
to
eq
we
obtain
βrbp
pi
ri
ri
123
98
information
retrieval
journal
2021
24
85
113
dcg
instead
weights
each
document
based
on
logarithmic
discount
function
similarly
to
what
is
done
for
and
rbp
we
reformulate
dcg
to
measure
bias
as
follows
dcg
ri
log
substituting
eq
to
eq
we
obtain
βdcg
ri
ri
log
since
we
are
evaluating
web-users
for
and
dcg
we
set
10
and
for
rbp
we
set
0.8
this
last
formulation
eq
although
it
looks
similar
to
the
rnd
measure
it
does
not
suffer
from
the
four
limitations
introduced
in
sect
2.2
in
particular
all
these
presented
measures
of
bias
do
not
focus
on
one
group
use
binary
score
associated
to
the
document
stance
or
ideological
leaning
similar
to
the
way
these
measures
are
used
in
ir
when
considering
relevance
also
like
in
ir
can
be
computed
at
each
rank
exclude
non-relevant
documents
from
the
measurement
of
bias
and
the
framework
provides
various
user
models
associated
to
the
ir
evaluation
measures
dcg
and
rbp
3.3
quantifying
bias
using
the
measures
of
bias
defined
in
the
previous
section
we
quantify
the
bias
of
the
two
search
engines
bing
and
google
using
the
news
versions
of
these
search
engines
then
we
compare
them
thereof
following
we
describe
each
step
of
the
proposed
procedure
used
to
quantify
bias
in
serps
dataset
construction
after
having
gathered
all
the
serps
for
both
search
engines
and
all
queries
for
each
controversial
topic
for
each
retrieved
document
we
obtain
the
stance
of
the
document
with
respect
to
the
topic
and
the
ideological
leaning
of
the
query
belonging
to
controversial
topic
both
could
be
done
automatically
via
classification
however
because
there
is
no
dataset
for
training
we
decided
to
gather
these
labels
via
crowd-sourcing
bias
evaluation
we
compute
the
bias
measures
for
every
serp
with
all
three
ir-based
measures
of
bias
rbp
and
dcg
we
then
aggregate
the
results
using
the
two
measures
of
bias
mb
and
mab
statistical
analysis
to
identify
whether
the
bias
measured
is
not
byproduct
of
ran
domness
we
compute
one-sample
t-test
the
null
hypothesis
is
that
no
difference
exists
and
that
the
true
mean
is
equal
to
zero
if
this
hypothesis
is
rejected
hence
there
is
significant
difference
and
we
claim
that
the
evaluated
search
engine
is
biased
then
we
compare
the
difference
in
bias
measured
across
the
two
search
engines
using
two-tailed
paired
t-test
the
null
hypothesis
is
that
the
difference
between
the
two
true
means
is
equal
to
zero
if
this
hypothesis
is
rejected
hence
there
is
significant
difference
we
claim
that
there
is
difference
in
bias
between
the
two
search
engines
experimental
setup
in
this
section
we
provide
description
of
our
experimental
setup
based
on
the
proposed
method
as
defined
in
sect
3.3
123
information
retrieval
journal
2021
24
85
113
99
4.1
material
we
obtained
all
the
controversial
topics
from
procon
org
2018
procon
org
is
non-profit
charitable
organisation
that
provides
an
online
resource
for
search
on
controversial
topics
procon
org
selects
the
topics
that
are
controversial
and
important
to
many
us
citizens
by
also
taking
the
readers
suggestions
into
account
we
collected
all
74
controversial
topics
with
their
topic
questions
from
the
website
then
we
applied
three
filters
on
these
topics
for
practical
reasons
without
deliberately
selecting
any
topics
the
first
filter
selects
only
the
polar
questions
also
known
as
yes-no
questions
because
they
have
no
different
sides
for
the
analysis
this
filter
decreased
the
topic
set
size
from
74
to
70
the
second
filter
removes
the
topics
that
do
not
contain
up-to-date
information
in
their
topic
pages
provided
by
procon
org
since
they
are
not
recent
controversial
topics
and
would
not
return
up-to-date
results
with
the
second
filter
the
number
of
topics
became
64
lastly
the
third
filter
only
includes
the
topics
if
both
search
engines
return
results
for
the
corresponding
topic
questions
otherwise
the
comparison
analysis
would
not
be
possible
after
the
last
filter
the
final
topic
set
became
the
size
of
57
table
contains
the
full
list
of
controversial
topic
titles
with
questions
used
in
this
study
we
used
the
topic
questions
of
these
57
topics
for
crawling
for
example
the
topic
question
of
the
topic
title
abortion
is
should
abortion
be
legal
the
topic
questions
reflect
the
main
debate
on
the
corresponding
controversial
topics
and
we
used
them
as
they
are
including
upper-cased
characters
without
removing
punctuation
etc
for
querying
the
search
engines
we
collected
the
news
search
results
in
incognito
mode
to
avoid
any
personalisation
effect
thus
the
retrieved
serps
are
not
specific
to
anyone
but
presumably
general
to
us
users
we
submitted
each
topic
question
to
us
news
search
engines
of
google
and
bing
using
us
proxy
since
we
used
the
news
versions
of
the
two
search
engines
sponsoring
results
which
may
affect
our
analysis
did
not
appear
in
the
news
search
results
at
all
then
we
firstly
crawled
the
urls
of
the
retrieved
results
for
the
same
topic
question
to
minimise
the
time
lags
between
the
search
engines
since
the
serp
of
the
same
topic
may
vary
over
time
subsequently
we
extracted
the
textual
contents
of
the
top-10
documents
using
the
crawled
urls
by
this
way
the
time
span
between
the
serps
of
google
and
bing
for
each
controversial
topic
whole
corpus
became
min
on
average
moreover
before
starting
the
crawling
process
we
firstly
made
some
experiments
with
small
set
of
topics
different
from
the
topic
set
provided
in
the
paper
in
the
news
search
as
well
as
default
search
and
did
not
observe
significant
changes
especially
in
the
top-10
documents
of
the
news
search
even
in
10
15
min
time
lags
this
indicates
that
the
news
search
is
less
dynamic
than
default
search
and
we
believe
that
the
min
of
time
lags
would
not
drastically
affect
the
search
results
4.2
crowd-sourcing
campaigns
the
end-to-end
process
of
obtaining
stances
and
ideological
leanings
is
shown
in
the
flow
chart
in
fig
the
emphasised
dotted
parts
of
the
flow-chart
show
the
steps
of
the
document
stance
classification
dsc
and
topic
ideological
leaning
classification
tilc
the
dsc
process
inputs
unlabelled
top-10
search
results
crawled
by
the
data
collection
procedure
described
in
sect
4.1
and
outputs
the
stance
labels
of
all
these
documents
via
crowd-sourcing
with
respect
to
the
topic
questions
used
to
retrieve
them
as
displayed
in
the
flow-chart
the
tilc
process
uses
crowd-sourcing
to
output
the
ideological
leanings
of
123
100
information
retrieval
journal
2021
24
85
113
table
all
controversial
topics
topics
marked
with
red
dots
are
conservative
and
blue
for
liberal
abortion
should
abortion
alternative
energy
vs
animal
testing
should
be
legal
fossil
fuels
can
animals
be
used
for
alternative
energy
scientific
or
commercial
effectively
replace
fossil
testing
fuels
banned
books
should
bill
clinton
was
bill
born
gay
origins
of
parents
or
other
adults
be
clinton
good
president
sexual
orientation
is
able
to
ban
books
from
sexual
orientation
schools
and
libraries
determined
at
birth
cell
phones
radiation
is
climate
change
is
human
college
education
worth
cell
phone
radiation
safe
activity
primarily
it
is
college
education
responsible
for
global
worth
it
climate
change
concealed
handguns
corporal
punishment
corporate
tax
rate
jobs
should
adults
have
the
should
corporal
does
lowering
the
federal
right
to
carry
concealed
punishment
be
used
in
corporate
income
tax
rate
handgun
k-12
schools
create
jobs
cuba
embargo
should
the
daylight
savings
time
drinking
age
lower
it
united
states
maintain
its
should
the
united
states
should
the
drinking
age
embargo
against
cuba
keep
daylight
saving
be
lowered
from
21
to
time
younger
age
drone
strikes
overseas
drug
use
in
sports
should
electoral
college
should
should
the
united
states
performance
enhancing
the
united
states
use
the
continue
its
use
of
drone
drugs
such
as
steroids
electoral
college
in
strikes
abroad
be
accepted
in
sports
presidential
elections
euthanasia
assisted
vaping
e-cigarettes
is
felon
voting
should
felons
suicide
should
euthanasia
vaping
with
e-cigarettes
who
have
completed
their
or
physician-assisted
safe
sentence
incarceration
suicide
be
legal
probation
and
parole
be
allowed
to
vote
fighting
in
hockey
should
gay
marriage
should
gay
gold
standard
should
the
fighting
be
allowed
in
marriage
be
legal
united
states
return
to
hockey
gold
standard
golf
is
it
sport
is
golf
illegal
immigration
should
israeli-palestinian
sport
the
government
allow
two-state
solution
is
immigrants
who
are
here
two-state
solution
israel
illegally
to
become
us
and
palestine
an
citizens
acceptable
solution
to
the
israeli-palestinian
conflict
lowering
the
voting
age
to
medical
marijuana
should
milk
is
it
healthy
is
16
should
the
voting
age
marijuana
be
medical
drinking
milk
healthy
for
be
lowered
to
16
option
humans
minimum
wage
should
the
national
anthem
protest
is
net
neutrality
should
net
federal
minimum
wage
be
refusing
to
stand
for
the
neutrality
be
restored
increased
national
anthem
an
appropriate
form
of
protest
obamacare
obamacare
is
obesity
disease
is
olympics
are
the
olympic
the
patient
protection
and
obesity
disease
games
an
overall
benefit
affordable
care
act
for
their
host
countries
obamacare
good
for
and
cities
america
123
information
retrieval
journal
2021
24
85
113
101
table
continued
penny
keep
it
should
the
police
body
cameras
prescription
drug
ads
penny
stay
in
circulation
should
police
officers
should
prescription
drugs
wear
body
cameras
be
advertised
directly
to
consumers
prostitution
legalize
it
right
to
health
care
ronald
reagan
was
ronald
should
prostitution
be
should
all
americans
have
reagan
good
president
legal
the
right
be
entitled
to
health
care
sanctuary
cities
should
school
uniforms
should
school
vouchers
are
school
sanctuary
cities
receive
students
have
to
wear
vouchers
good
idea
federal
funding
school
uniforms
social
media
are
social
social
security
standardized
tests
is
the
networking
sites
good
for
privatization
should
use
of
standardized
tests
our
society
social
security
be
improving
education
in
privatized
america
student
loan
debt
should
tablets
vs
textbooks
teacher
tenure
should
student
loan
debt
be
should
tablets
replace
teachers
get
tenure
easier
to
discharge
in
textbooks
in
k-12
schools
bankruptcy
under
god
in
the
pledge
universal
basic
income
is
vaccines
for
kids
should
should
the
words
under
universal
basic
income
any
vaccines
be
required
god
be
in
the
us
pledge
good
idea
for
children
of
allegiance
vegetarianism
should
video
games
and
violence
voting
machines
do
people
become
vegetarian
do
violent
video
games
electronic
voting
machines
contribute
to
youth
improve
the
voting
violence
process
fig
flow-chart
of
the
crowd-sourcing
campaigns
all
topic
questions
then
the
accepted
stance
labels
of
all
documents
acquired
from
the
dsc
process
are
transformed
into
ideological
leaning
labels
based
on
the
assigned
ideology
of
their
corresponding
topic
questions
the
steps
of
obtaining
document
labels
in
stance
and
ideological
leaning
detection
are
described
below
123
102
information
retrieval
journal
2021
24
85
113
to
label
the
stance
of
each
document
with
respect
to
the
topic
questions
we
used
crowd
sourcing
we
selected
mturk
as
crowd-sourcing
platform
in
this
platform
to
obtain
high
quality
crowd-labels
task
properties
were
set
as
follows
since
the
topics
are
mostly
related
to
us
we
selected
crowd-workers
only
from
us
moreover
we
tried
to
find
qualified
and
experienced
workers
by
setting
the
following
thresholds
human
intelligence
task
hit
approval
rate
percentage
should
be
greater
than
95
and
number
of
hits
approved
should
be
greater
than
1000
for
each
worker
we
set
the
wage
as
0.15
and
time
allowed
was
30
minutes
per
hit
each
document
was
judged
by
three
crowd-workers
to
classify
the
stance
of
document
we
asked
crowd-workers
to
label
given
controversial
topic
question
the
stance
of
document
in
pro
neutral
against
not-relevant
or
link
not
working
before
the
task
was
assigned
instructions
were
given
to
worker
in
three
groups
from
general
to
specific
initially
workers
were
provided
an
overview
of
the
stance
detection
task
then
steps
of
the
task
were
listed
read
the
topic
question
open
the
news
article
link
etc
and
finally
rules
and
tips
were
displayed
this
last
part
contained
definitions
of
having
pro
neutral
or
against
stance
as
given
in
sect
3.1
above
additionally
we
included
clue
for
workers
saying
that
title
of
the
article
may
give
you
general
idea
about
the
stance
however
it
is
not
sufficient
to
determine
its
overall
viewpoint
and
then
request
workers
to
read
also
the
rest
of
the
article
apart
from
these
at
the
end
of
the
page
we
put
warning
and
informed
the
workers
that
some
of
the
answers
were
known
to
us
and
we
may
reject
their
hits
single
self-contained
task
for
worker
based
on
evaluation
then
in
the
following
page
hit
was
shown
to
the
worker
with
topic
question
query
link
to
the
news
article
whose
stance
will
be
determined
by
repeating
reminding
the
main
question
of
the
stance
detection
task
in
order
to
obtain
reliable
annotations
we
first
annotated
randomly
chosen
set
of
doc
uments
later
used
to
check
the
quality
of
crowd-labels
as
specified
in
the
warning
to
the
workers
with
these
expert
labels
we
rejected
low
quality
annotations
and
requested
new
labels
for
those
documents
this
iterative
process
continued
until
we
obtained
all
the
docu
ment
labels
at
the
end
of
this
iterative
process
for
the
sake
of
label
reliability
we
computed
two
agreement
scores
on
the
approved
labels
for
document
stance
detection
reported
in
table
the
reported
inter-rater
agreement
scores
are
the
percent
agreements
between
the
corresponding
annotators
we
looked
at
pairwise
agreement
put
if
there
is
an
agreement
and
otherwise
then
we
computed
the
mean
for
the
fractions
reported
kappa
score
for
document
stance
classification
is
considered
fair
agreement
previously
researchers
reported
kappa
score
of
the
inter-rater
agreement
between
experts
0.385
instead
of
crowd-workers
for
the
same
task
document
stance
classification
in
serps
towards
different
query
set
which
includes
controversial
topics
as
well
as
popular
products
by
claiming
mturk
workers
had
difficulty
with
the
task
alam
and
downey
2014
although
our
task
seems
to
be
more
challenging
the
queries
are
only
about
controversial
issues
our
reported
kappa
score
for
mturk
workers
is
comparable
to
their
expert
agreement
score
which
we
believe
to
be
sufficient
due
to
the
subjective
nature
and
difficulty
of
the
task
the
distribution
of
the
accepted
stance
labels
for
the
search
results
of
each
search
engine
is
displayed
in
fig
one
may
argue
that
for
query
about
controversial
topic
issued
to
news
search
engine
its
serp
would
mostly
contain
controversial
articles
that
support
one
dominant
viewpoint
towards
given
topic
hence
informational
pages
or
articles
adequately
discussing
different
viewpoints
of
the
topic
documents
that
have
neutral
stance
would
never
get
chance
to
be
included
in
the
analysis
however
the
distribution
in
fig
refutes
this
argument
by
showing
that
the
majority
of
the
labels
for
both
search
engines
is
actually
neutral
123
information
retrieval
journal
2021
24
85
113
103
fig
percentages
of
the
document
stance
labels
annotated
by
crowd-workers
to
identify
the
ideological
leaning
of
each
topic
we
again
used
crowd-sourcing
as
dis
played
in
fig
we
asked
the
crowd-workers
to
classify
each
topic
as
conservative
liberal
or
both
or
neither
to
get
high
quality
annotations
also
for
topic
ideology
detection
worker
properties
were
set
as
the
same
with
the
stance
detection
we
again
selected
crowd-workers
only
from
us
the
wage
per
hit
was
set
as
0.1
and
the
time
allowed
was
min
similarly
to
the
stance
detection
in
the
informational
page
we
gave
an
overview
listed
the
steps
and
lastly
provided
the
rules
tips
for
this
task
last
part
contained
the
ideological
leaning
definitions
as
given
in
sect
3.1
additionally
we
requested
the
workers
to
evaluate
the
ide
ological
leaning
of
given
topic
based
on
the
current
ideological
climate
and
warned
them
related
to
the
rejection
of
their
hits
as
before
in
the
next
page
the
workers
were
shown
hit
with
topic
question
query
one
of
the
main
debates
of
the
corresponding
topic
and
asked
the
worker
the
following
which
ideological
group
would
answer
favourably
to
this
question
the
topics
assigned
to
conservative
or
liberal
leanings
have
been
decided
based
on
the
judgment
of
five
annotators
with
majority-voting
the
leanings
of
the
topics
are
shown
in
table
two
agreement
scores
computed
on
the
judgments
for
ideological
leaning
detection
are
also
reported
in
table
to
map
the
stance
from
the
pro-to-against
to
the
conservative-to-liberal
we
applied
simple
transformation
to
the
documents
this
transformation
is
needed
because
there
may
be
documents
which
have
pro
stance
for
example
towards
abortion
and
cuba
embargo
though
these
documents
have
the
same
stance
they
have
different
ideological
leanings
since
having
pro
stance
on
abortion
implies
liberal
leaning
whereas
pro
stance
on
cuba
embargo
implies
conservative
leaning
for
some
topics
as
in
the
case
of
cuba
embargo
we
can
directly
interpret
the
pro-to-against
stance
labels
of
search
results
as
conservative
to-liberal
ideological
leaning
labels
while
for
other
topics
as
in
the
case
of
the
abortion
as
liberal-to-conservative
on
the
other
hand
for
those
topics
such
as
vaccines
for
kids
which
crowded
label
resulted
in
both
or
neither
the
conservative-to-liberal
or
liberal-to-conservative
transformation
was
not
meaningful
and
therefore
eliminated
by
our
analysis
we
note
that
within
budget
constraints
the
crowd-sourcing
protocol
was
designed
to
obtain
crowd-labels
with
high-quality
by
labelling
expert
the
random
sample
of
documents
applying
iterative
process
and
majority
voting
on
these
labels
123
104
information
retrieval
journal
2021
24
85
113
table
crowd-workers
campaign
inter-rater
fleiss-kappa
agreement
document
stance
0.4968
0.3500
topic
ideological
leaning
0.5281
0.3478
table
performance
of
the
10
rbp
dcg
10
search
engines
p-values
of
two-tailed
paired
t-test
computed
engine
0.8509
0.7708
3.9114
between
engine
and
engine
0.7404
0.6886
3.4773
p-value
0.001
0.001
0.01
table
stance
bias
of
the
search
10
rbp
dcg
10
engines
p-values
of
two-tailed
paired
t-test
computed
between
mb
engine
0.0281
0.0197
0.1069
engine
and
engine
0.0175
0.0271
0.1142
p-value
0.05
0.05
0.05
mab
engine
0.2596
0.2738
1.3380
engine
0.2246
0.2266
1.0789
p-value
0.05
0.05
0.05
table
ideological
bias
of
the
10
rbp
dcg
10
search
engines
p-values
of
two-tailed
paired
t-test
computed
mb
engine
0.1368
0.1247
0.6290
between
engine
and
engine
0.1289
0.1386
0.6591
p-value
0.05
0.05
0.05
mab
engine
0.2579
0.2894
1.3989
engine
0.2184
0.2158
1.0456
p-value
0.05
0.05
0.05
4.3
results
in
table
we
present
the
performance
of
the
two
search
engines
this
is
measured
over
all
the
topics
document
is
considered
relevant
when
classified
as
pro
against
or
neutral
the
difference
for
all
evaluation
measures
is
statistically
significant
in
table
we
present
the
stance
bias
of
the
search
engines
note
that
for
all
the
three
measures
of
bias
10
rbp
and
dcg
10
lower
value
is
better
which
means
lower
bias
in
the
scope
of
this
work
as
opposed
to
their
corresponding
classic
ir
measures
all
mb
and
mab
scores
are
positive
for
all
three
ir
evaluation
measures
also
the
differences
between
the
two
search
engines
for
both
mb
and
mab
measures
are
statistically
not
significant
and
it
is
shown
with
the
two-tailed
pair
t-test
on
these
measures
in
table
we
show
the
ideological
bias
similarly
to
table
lower
is
better
since
we
use
the
same
measures
of
bias
this
table
is
similar
to
table
unlike
the
table
all
mb
scores
are
negative
while
all
mab
scores
are
positive
for
all
three
ir
evaluation
measures
the
two-tailed
paired
t-test
computed
on
mbs
to
compare
the
difference
in
bias
between
engine
and
engine
this
is
statistically
not
123
information
retrieval
journal
2021
24
85
113
105
3.5
2.5
against
1.5
0.5
0.5
1.5
2.5
3.5
pro
fig
dc
10
against
dc
10
measured
on
stances
black
points
for
engine
and
yellow
points
for
engine
3.5
2.5
liberal
1.5
0.5
0.5
1.5
2.5
3.5
conserva
ve
fig
dc
10
against
dc
10
measured
on
ideological
leanings
black
points
for
engine
and
yellow
points
for
engine
123
106
information
retrieval
journal
2021
24
85
113
engine
engine
fig
dc
10
measured
on
stances
where
positive
is
and
negative
is
engine
engine
fig
dc
10
measured
on
leanings
where
positive
is
and
negative
is
123
information
retrieval
journal
2021
24
85
113
107
significant
nonetheless
the
two-tailed
test
on
mabs
is
statistically
not
significant
for
the
measure
10
but
it
is
statistically
significant
for
the
measures
rbp
and
dcg
10
in
fig
we
show
how
the
topic-wise
serps
distribute
over
the
pro-against
stance
space
for
the
measure
dcg
10
the
x-axis
is
the
pro
stance
score
dc
10
and
the
y-axis
is
the
against
stance
score
dc
10
each
point
corresponds
to
the
overall
serp
score
of
topic
black
points
are
those
serps
retrieved
by
engine
and
yellow
points
are
those
retrieved
by
engine
in
fig
we
compare
the
overall
stance
bias
score
dc
10
difference
between
the
pro
and
against
stance
scores
of
serps
for
each
topic
measured
on
the
two
search
engines
the
x-axis
is
engine
and
the
y-axis
is
engine
the
points
in
positive
coordinates
denote
the
topics
whose
serps
are
overall
biased
towards
the
pro
stance
negative
coordinates
are
for
the
against
stance
figures
and
are
similar
to
figs
and
but
instead
of
measuring
the
stance
bias
we
measure
the
ideological
bias
in
the
former
case
therefore
fig
displays
how
the
overall
serps
of
topics
distribute
over
the
conservative-liberal
ideological
space
for
the
measure
dcg
10
similarly
in
fig
we
compare
the
overall
ideological
bias
score
dc
10
difference
between
the
conservative
and
liberal
leaning
scores
of
the
serps
where
the
points
in
positive
coordinates
stand
for
the
topics
that
are
biased
towards
the
conservative
leaning
negative
coordinates
are
for
the
liberal
discussion
before
investigating
the
existence
of
bias
in
serps
we
initially
compared
the
retrieval
performances
of
two
search
engines
in
table
we
observe
that
the
performance
of
the
two
search
engines
is
high
but
engine
is
better
than
engine
their
difference
is
statistically
significant
this
is
verified
across
all
three
ir
evaluation
measures
next
we
verify
if
the
search
engines
return
biased
results
in
terms
of
document
stances
rq1
and
if
so
we
further
investigate
if
the
engines
suffer
from
the
same
level
of
bias
rq2
that
the
difference
between
the
engines
are
not
statistically
significant
in
table
all
mb
scores
are
positive
and
regarding
the
rq1
the
engines
seem
to
be
biased
towards
the
pro
stance
we
applied
the
one-sample
t-test
on
mb
scores
to
check
the
existence
of
stance
bias
if
the
true
mean
is
different
from
zero
as
mentioned
in
sect
3.3
however
these
biases
are
statistically
not
significant
which
means
that
this
expectation
may
be
the
result
of
noise
there
is
not
systematic
stance
bias
preference
of
one
stance
with
respect
to
the
other
based
on
mab
scores
we
can
observe
that
both
engines
suffer
from
an
absolute
bias
however
the
difference
between
the
two
engines
is
shown
to
be
non-significant
with
the
two-tailed
t-test
these
results
show
that
both
search
engines
are
not
biased
towards
specific
stance
in
returning
results
since
there
is
no
statistically
significant
difference
from
the
ideal
distribution
nonetheless
for
both
engines
there
exists
an
absolute
bias
which
can
be
interpreted
as
the
expected
bias
for
topic
question
these
empirical
findings
imply
that
the
search
engines
are
biased
for
some
topics
towards
the
pro
stance
and
for
others
towards
the
against
stance
the
results
are
displayed
in
fig
this
figure
refers
to
the
values
used
to
compute
the
mab
score
of
the
dcg
10
column
it
shows
that
the
difference
between
the
pro
and
against
stances
of
both
engines
for
topics
is
uniformly
distributed
to
note
that
no
topic
can
be
located
on
the
up-right
area
of
the
plot
because
the
sum
of
their
coordinates
is
bounded
by
the
maximum
possible
dcg
10
score
moreover
we
observe
that
topics
are
distributed
123
108
information
retrieval
journal
2021
24
85
113
similarly
across
the
engines
this
is
also
confirmed
by
fig
where
we
can
observe
that
the
stance
bias
scores
dc
10
the
differences
between
dcg
10
scores
for
the
pro
stance
and
dcg
10
scores
for
the
against
stance
of
topics
are
somehow
balanced
between
the
up-right
quadrant
and
the
low-left
quadrant
moreover
these
two
quadrants
are
the
area
of
agreement
in
stance
between
the
two
engines
the
other
two
quadrants
contain
those
topics
where
the
engines
disagree
here
we
can
conclude
that
the
engines
agree
with
each
other
in
the
majority
of
cases
lastly
we
investigate
if
the
search
engines
are
biased
in
the
ideology
space
rq3
looking
at
mb
scores
in
table
we
observe
that
both
search
engines
seem
to
be
biased
towards
the
same
ideological
leaning
liberal
all
mb
scores
are
negative
unlike
the
stance
bias
one
sample
t-test
on
mb
scores
show
that
these
expectations
are
statistically
significant
with
different
confidence
values
p-value
0.005
across
all
three
ir
measures
for
engine
whereas
the
same
confidence
value
on
10
for
engine
and
p-value
0.05
on
rbp
and
dcg
10
these
results
indicate
that
both
search
engines
are
biased
towards
the
same
leaning
which
is
liberal
comparing
the
two
search
engines
on
mb
scores
we
observe
that
their
differences
are
statistically
not
significant
which
means
that
the
observed
difference
may
be
the
result
of
random
noise
based
on
mab
since
all
mab
scores
are
positive
we
can
also
observe
that
both
engines
suffer
from
an
absolute
bias
however
in
contrast
with
what
observed
for
the
stance
bias
this
time
there
is
difference
in
expected
ideological
bias
between
the
two
search
engines
for
rbp
and
dcg
10
the
difference
between
the
engines
is
statistically
significant
this
finding
and
the
different
user
models
that
these
evaluation
measures
model
suggest
that
the
perceived
bias
by
the
users
may
change
based
on
their
behaviour
user
that
always
inspects
the
first
10
results
as
modelled
by
10
may
perceive
the
same
ideological
bias
between
engine
and
engine
while
less
systematic
user
which
just
inspects
the
top
results
may
perceive
that
engine
is
more
biased
than
engine
moreover
comparing
this
finding
with
the
performance
of
the
engines
we
can
observe
that
the
better
performing
engine
is
more
biased
than
the
worse
performing
one
comparing
fig
with
fig
we
observe
that
in
fig
the
points
look
less
uniformly
distributed
than
in
fig
topics
are
mostly
on
the
liberal
side
moreover
engine
has
fewer
points
on
the
conservative
side
than
engine
comparing
fig
with
fig
we
observe
that
the
engines
in
fig
are
more
biased
towards
the
liberal
side
with
respect
to
what
observed
in
fig
also
we
observe
that
the
engines
mostly
agree
most
of
the
points
are
placed
on
the
up-right
and
low-left
quadrants
in
conclusion
we
find
important
to
point
out
that
it
is
not
in
the
scope
of
this
work
to
find
the
source
of
bias
as
discussed
in
the
introduction
bias
may
be
result
of
the
input
data
which
may
contain
biases
or
the
search
algorithm
which
contains
sophisticated
features
and
specifically
chosen
algorithms
that
although
designed
to
be
effective
in
satisfying
information
needs
may
produce
systematic
biases
nonetheless
we
look
at
the
problem
from
the
user
perspective
and
no
matter
where
the
bias
comes
from
the
results
are
biased
as
described
our
findings
seem
to
be
consistent
with
prior
works
epstein
and
robertson
2017
diakopoulos
et
al
2018
that
there
exists
liberal
left-leaning
partisan
bias
in
serps
even
in
unpersonalised
search
settings
robertson
et
al
2018a
limitations
this
work
has
potential
limitations
as
stated
in
the
introduction
we
focus
on
particular
kind
of
bias
known
as
statistical
parity
or
more
generally
known
as
equality
of
outcome
123
information
retrieval
journal
2021
24
85
113
109
instead
of
equality
of
opportunity
which
uses
query-specific
base
rates
in
the
context
of
the
controversial
topics
where
the
document
labels
were
obtained
via
crowd-sourcing
this
bias
measure
requiring
equal
representation
of
stances
instead
of
query-specific
base
rates
made
our
experiments
feasible
this
is
firstly
because
not
all
of
the
query
questions
in
our
list
have
certain
answers
based
on
scientific
facts
some
of
them
are
subjective
queries
in
investigating
the
equality
of
opportunity
queries
can
be
further
categorized
as
subjective
and
objective
on
top
of
our
evaluation
framework
for
the
objective
queries
expert
labels
can
be
obtained
and
used
as
base
rates
then
search
results
can
be
evaluated
by
taking
into
account
these
base
rates
please
note
that
our
evaluation
framework
could
better
be
applied
to
the
controversial
queries
from
the
public
perspective
mainly
where
the
goal
is
to
have
balanced
serps
instead
of
skewed
results
we
believe
that
some
queries
should
be
handled
with
different
framework
since
those
queries
are
not
intrinsically
controversial
such
as
is
holocaust
real
there
is
only
one
correct
answer
without
the
need
of
discussion
besides
the
identification
of
the
stance
for
the
full
ranking
list
is
currently
too
expensive
to
get
annotated
via
crowd-sourcing
to
tackle
this
issue
machine
learning
model
can
help
us
to
automate
the
process
of
obtaining
the
stance
labels
another
potential
limitation
is
that
some
queries
may
not
be
real
user
queries
nonetheless
we
extracted
the
queries
directly
from
their
topic
pages
of
the
procon
org
2018
along
with
the
topics
we
deliberately
did
not
change
the
queries
to
avoid
any
interference
bias
from
our
side
on
the
results
in
this
work
we
did
not
make
domain-specific
selection
of
the
topics
or
apply
any
filtering
as
subjective
objective
rather
we
accepted
them
as
controversial
topics
from
the
general
public
perspective
which
is
the
main
scope
of
this
work
apart
from
these
crowd-workers
own
personal
biases
may
affect
the
labelling
process
for
this
reason
we
tried
to
mitigate
these
biases
by
asking
the
workers
to
annotate
stances
rather
than
ideologies
to
make
their
judgment
more
objective
and
ii
aggregating
the
final
judgment
coming
from
multiple
workers
additionally
our
analysis
refers
to
specific
point
in
time
where
the
data
was
collected
to
enable
reproducibility
and
an
easier
comparison
of
these
results
at
some
point
in
the
future
we
made
our
dataset
publicly
available
lastly
we
note
that
this
bias
analysis
can
only
be
used
as
an
indicator
of
potentially
biased
ranking
algorithms
because
it
is
not
enough
in
order
to
track
the
source
of
bias
in
the
scope
of
this
work
we
did
not
investigate
the
source
of
bias
that
may
come
from
the
data
input
bias
or
from
the
ranking
mechanism
algorithmic
bias
of
the
corresponding
search
engines
despite
these
potential
limitations
we
believe
that
our
work
is
good
attempt
to
evaluate
bias
in
search
results
with
new
bias
measures
and
dataset
crawled
specifically
for
the
search
bias
evaluation
since
the
bias
analysis
is
very
complex
we
deliberately
limited
our
scope
and
only
focused
on
the
bias
analysis
of
recent
controversial
topics
in
news
search
nonetheless
all
these
limitations
lead
us
to
numerous
interesting
future
directions
conclusion
and
future
work
in
this
work
we
introduced
new
bias
evaluation
measures
and
generalisable
evaluation
framework
to
address
the
issue
of
web
search
bias
in
news
search
results
we
applied
the
proposed
framework
to
measure
stance
and
ideological
bias
in
the
serps
of
bing
and
google
as
well
as
compare
their
relative
bias
towards
controversial
topics
our
initial
results
show
that
both
search
engines
seem
to
be
unbiased
when
considering
the
document
stances
and
ideologically
biased
when
considering
the
document
ideological
leanings
in
this
work
we
intended
to
analyse
serps
without
the
effect
of
personalisation
thus
these
results
highlight
123
110
information
retrieval
journal
2021
24
85
113
that
search
biases
exist
even
though
the
personalization
effect
is
minimized
and
that
search
engines
can
empower
users
by
being
more
accountable
in
the
scope
of
this
work
we
did
not
investigate
the
source
of
bias
which
we
left
as
future
work
therefore
the
results
can
be
seen
as
potential
indicator
in
our
experiments
we
gathered
document
stances
via
crowd-sourcing
thus
the
obvious
future
work
in
this
direction
is
to
use
automatic
stance
detection
methods
instead
of
crowd-sourcing
to
obtain
the
document
labels
thereby
evaluating
bias
in
the
whole
corpus
of
retrieved
serps
to
track
the
source
of
bias
moreover
investigating
the
workers
bias
in
follow-up
work
would
be
interesting
since
it
is
very
difficult
to
remove
all
biases
in
practice
in
this
work
we
focus
on
equality
of
outcome
but
using
another
bias
measure
equality
of
opportunity
which
takes
into
account
the
corresponding
group
proportions
query-specific
base
rates
in
the
population
would
be
an
alternative
follow-up
work
we
plan
to
categorize
queries
as
subjective
and
objective
then
modify
the
ideal
ranking
definition
specifically
for
the
objective
queries
based
on
the
corpus
distributions
the
bias
analysis
for
the
objective
queries
particularly
the
ones
related
to
the
critical
domains
such
as
health
search
can
be
investigated
further
on
top
of
our
evaluation
framework
which
we
believe
to
be
an
interesting
follow-up
work
furthermore
we
plan
to
study
the
effect
of
localization
and
personalization
how
much
the
stances
and
ideological
leanings
varied
across
users
or
the
echo
chamber
effect
on
serps
then
incorporate
that
study
into
our
bias
evaluation
framework
in
the
future
acknowledgements
we
thank
the
reviewers
for
their
comments
this
work
has
been
funded
by
the
epsrc
fellowship
titled
task
based
information
retrieval
grant
reference
number
ep
p024289
and
the
visiting
researcher
programme
of
the
alan
turing
institute
compliance
with
ethical
standards
ethical
standard
author
emine
yilmaz
previously
worked
as
research
consultant
for
microsoft
research
and
she
is
currently
research
consultant
for
amazon
research
references
2018
internetlivestats
http://www.internetlivestats.com/.
retrieved
2018
10
06
2018
procon
org
procon
org
pros
and
cons
of
controversial
issues
https://www.procon.org/.
retrieved
2018
07
31
2018
search
engine
statistics
2018
https://www.smartinsights.com/search-engine-marketing/search-
engine-statistics
retrieved
2018
10
06
99firms
2019
search
engine
statistics
https://99firms.com/blog/search-engine-statistics/#gref.
retrieved
2019
09
06
aktolga
allan
2013
sentiment
diversification
with
different
biases
proceedings
of
the
36th
international
acm
sigir
conference
on
research
and
development
in
information
retrieval
pp
593
602
acm
alam
downey
2014
analyzing
the
content
emphasis
of
web
search
engines
in
proceedings
of
the
37th
international
acm
sigir
conference
on
research
and
development
in
information
retrieval
pp
1083
1086
acm
alonso
mizzaro
2012
using
crowdsourcing
for
trec
relevance
assessment
information
processing
management
48
1053
1066
alonso
rose
stewart
2008
crowdsourcing
for
relevance
evaluation
sigir
forum
42
15
baeza-yates
2016
data
and
algorithmic
bias
in
the
web
proceedings
of
the
8th
acm
conference
on
web
science
pp
acm
bakshy
messing
adamic
2015
exposure
to
ideologically
diverse
news
and
opinion
on
facebook
science
348
1130
1132
123
information
retrieval
journal
2021
24
85
113
111
bargh
gollwitzer
lee-chai
barndollar
trötschel
2001
the
automated
will
nonconscious
activation
and
pursuit
of
behavioral
goals
journal
of
personality
and
social
psychology
81
1014
beutel
chen
doshi
qian
wei
wu
heldt
zhao
hong
chi
et
al
2019
fairness
in
recommendation
ranking
through
pairwise
comparisons
arxiv
1903.00780
budak
goel
rao
2016
fair
and
balanced
quantifying
media
bias
through
crowdsourced
content
analysis
public
opinion
quarterly
80
250
271
chelaru
altingovde
siersdorfer
2012
analyzing
the
polarity
of
opinionated
queries
in
european
conference
on
information
retrieval
pp
463
467
springer
chelaru
altingovde
siersdorfer
nejdl
2013
analyzing
detecting
and
exploiting
senti
ment
in
web
queries
acm
transactions
on
the
web
tweb
chen
yang
2006
position
paper
study
of
web
search
engine
bias
and
its
assessment
iw3c2
www
chen
ma
hannák
wilson
2018
investigating
the
impact
of
gender
on
rank
in
resume
search
engines
in
proceedings
of
the
2018
chi
conference
on
human
factors
in
computing
systems
pp
14
culpepper
diaz
smucker
2018
research
frontiers
in
information
retrieval
report
from
the
third
strategic
workshop
on
information
retrieval
in
lorne
swirl
2018
acm
sigir
forum
vol
52
pp
46
47
acm
new
york
ny
usa
demartini
siersdorfer
2010
dear
search
engine
what
your
opinion
about
sentiment
analysis
for
semantic
enrichment
of
web
search
results
in
proceedings
of
the
3rd
international
semantic
search
workshop
acm
diakopoulos
trielli
stark
mussenden
2018
vote
for
how
search
informs
our
choice
of
candidate
digital
dominance
the
power
of
google
amazon
facebook
and
apple
moore
and
tambini
eds
22
diaz
2008
through
the
google
goggles
sociopolitical
bias
in
search
engine
design
web
search
pp
11
34
springer
dutton
reisdorf
dubois
blank
2017
search
and
politics
the
uses
and
impacts
of
search
in
britain
france
germany
italy
poland
spain
and
the
united
states
dutton
blank
groselj
2013
cultures
of
the
internet
the
internet
in
britain
oxford
internet
survey
2013
report
oxford
oxford
internet
institute
elisa
shearer
2018
news
use
across
social
media
platforms
2018
https://www.journalism.org/
2018
09
10
news-use-across-social-media-platforms-2018
epstein
robertson
2017
method
for
detecting
bias
in
search
rankings
with
evidence
of
systematic
bias
related
to
the
2016
presidential
election
technical
report
white
paper
no
wp-17-02
epstein
robertson
2015
the
search
engine
manipulation
effect
seme
and
its
possible
impact
on
the
outcomes
of
elections
proceedings
of
the
national
academy
of
sciences
112
e4512
e4521
epstein
robertson
lazer
wilson
2017
suppressing
the
search
engine
manipulation
effect
seme
proceedings
of
the
acm
human
computer
interaction
42
fang
si
somasundaram
yu
2012
mining
contrastive
opinions
on
political
texts
using
cross-perspective
topic
model
in
proceedings
of
the
fifth
acm
international
conference
on
web
search
and
data
mining
pp
63
72
acm
finin
murnane
karandikar
keller
martineau
dredze
2010
annotating
named
enti
ties
in
twitter
data
with
crowdsourcing
in
proceedings
of
the
naacl
hlt
2010
workshop
on
creating
speech
and
language
data
with
amazon
mechanical
turk
pp
80
88
association
for
computational
linguistics
gao
shah
2019
how
fair
can
we
go
detecting
the
boundaries
of
fairness
optimization
in
information
retrieval
in
proceedings
of
the
2019
acm
sigir
international
conference
on
theory
of
information
retrieval
pp
229
236
gao
shah
2020
toward
creating
fairer
ranking
in
search
engine
results
information
processing
management
57
102138
gentzkow
shapiro
2010
what
drives
media
slant
evidence
from
us
daily
newspapers
econometrica
78
35
71
geyik
ambler
kenthapadi
2019
fairness-aware
ranking
in
search
recommendation
systems
with
application
to
linkedin
talent
search
in
proceedings
of
the
25th
acm
sigkdd
international
conference
on
knowledge
discovery
data
mining
pp
2221
2231
ginger
david
2018
google
responds
to
trump
says
no
political
motive
in
search
results
https://www.reuters.com/article/us-usa-trump-tech-alphabet/google-responds-to-trump-says-
no-political-motive-in-search-results-iduskcn1ld1qp
retrieved
2018
10
06
123
112
information
retrieval
journal
2021
24
85
113
goldman
2008
search
engine
bias
and
the
demise
of
search
engine
utopianism
web
search
pp
121
133
springer
grimes
2016
impartial
journalism
is
laudable
but
false
balance
is
dangerous
https://www.
theguardian
com
science
blog
2016
nov
08
impartial-journalism-is-laudable-but-false-balance-is
dangerous
retrieved
2019
08
15
hu
jiang
robertson
wilson
2019
auditing
the
partisanship
of
google
search
snippets
the
world
wide
web
conference
pp
693
704
institute
2014
the
personal
news
cycle
how
americans
choose
to
get
their
news
reston
american
press
institute
kallus
zhou
2019
the
fairness
of
risk
scores
beyond
classification
bipartite
ranking
and
the
xauc
metric
arxiv
1902.05826
krishna
zhu
groth
johnson
hata
kravitz
et
al
2017
visual
genome
connecting
language
and
vision
using
crowdsourced
dense
image
annotations
international
journal
of
computer
vision
123
32
73
kulshrestha
eslami
messias
zafar
ghosh
gummadi
karahalios
2017
quantifying
search
bias
investigating
sources
of
bias
for
political
searches
in
social
media
in
proceedings
of
the
2017
acm
conference
on
computer
supported
cooperative
work
and
social
computing
pp
417
432
acm
kulshrestha
eslami
messias
zafar
ghosh
gummadi
et
al
2018
search
bias
quantification
investigating
political
bias
in
social
media
and
web
search
information
retrieval
journal
22
188
227
lahoti
garimella
gionis
2018
joint
non-negative
matrix
factorization
for
learning
ideological
leaning
on
twitter
in
proceedings
of
the
eleventh
acm
international
conference
on
web
search
and
data
mining
pp
351
359
lawson
eustice
perkowitz
yetisgen-yildiz
2010
annotating
large
email
datasets
for
named
entity
recognition
with
mechanical
turk
in
proceedings
of
the
naacl
hlt
2010
workshop
on
creating
speech
and
language
data
with
amazon
mechanical
turk
pp
71
79
association
for
computational
linguistics
mellebeek
benavent
grivolla
codina
costa-jussa
banchs
2010
opinion
mining
of
spanish
customer
comments
with
non-expert
annotations
on
mechanical
turk
in
proceedings
of
the
naacl
hlt
2010
workshop
on
creating
speech
and
language
data
with
amazon
mechanical
turk
pp
114
121
association
for
computational
linguistics
mowshowitz
kawaguchi
2002a
assessing
bias
in
search
engines
information
processing
management
38
141
156
mowshowitz
kawaguchi
2002b
bias
on
the
web
communications
of
the
acm
45
56
60
mowshowitz
kawaguchi
2005
measuring
search
engine
bias
information
processing
man
agement
41
1193
1205
mullainathan
shleifer
2005
the
market
for
news
american
economic
review
95
1031
1053
newman
fletcher
kalogeropoulos
nielsen
2019
reuters
institute
digital
news
report
2019
vol
2019
reuters
institute
for
the
study
of
journalism
newman
fletcher
kalogeropoulos
levy
nielsen
2018
reuters
institute
digital
news
report
2018
vol
2018
reuters
institute
for
the
study
of
journalism
noble
2018
algorithms
of
oppression
how
search
engines
reinforce
racism
new
york
nyu
press
otterbacher
bates
clough
2017
competent
men
and
warm
women
gender
stereotypes
and
backlash
in
image
search
results
in
proceedings
of
the
2017
chi
conference
on
human
factors
in
computing
systems
pp
6620
6631
otterbacher
checco
demartini
clough
2018
investigating
user
perception
of
gender
bias
in
image
search
the
role
of
sexism
in
the
41st
international
acm
sigir
conference
on
research
development
in
information
retrieval
pp
933
936
pan
hembrooke
joachims
lorigo
gay
granka
2007
in
google
we
trust
users
decisions
on
rank
position
and
relevance
journal
of
computer-mediated
communication
12
801
823
räbiger
gezici
saygın
spiliopoulou
2018
predicting
worker
disagreement
for
more
effective
crowd
labeling
in
2018
ieee
5th
international
conference
on
data
science
and
advanced
analytics
dsaa
pp
179
188
ieee
raji
buolamwini
2019
actionable
auditing
investigating
the
impact
of
publicly
naming
biased
performance
results
of
commercial
ai
products
in
proceedings
of
the
2019
aaai
acm
conference
on
ai
ethics
and
society
pp
429
435
robertson
lazer
wilson
2018b
auditing
the
personalization
and
composition
of
politically
related
search
engine
results
pages
in
proceedings
of
the
2018
world
wide
web
conference
pp
955
965
123
information
retrieval
journal
2021
24
85
113
113
robertson
jiang
joseph
friedland
lazer
wilson
2018a
auditing
partisan
audience
bias
within
google
search
proceedings
of
the
acm
on
human
computer
interaction
148
saez-trumper
castillo
lalmas
2013
social
media
news
communities
gatekeeping
cover
age
and
statement
bias
in
proceedings
of
the
22nd
acm
international
conference
on
information
knowledge
management
pp
1679
1684
acm
sandvig
hamilton
karahalios
langbort
2014
auditing
algorithms
research
methods
for
detecting
discrimination
on
internet
platforms
data
and
discrimination
converting
critical
concerns
into
productive
inquiry
22
sapiezynski
zeng
robertson
mislove
wilson
2019
quantifying
the
impact
of
user
attentionon
fair
group
representation
in
ranked
lists
in
companion
proceedings
of
the
2019
world
wide
web
conference
pp
553
562
sarcona
2019
organic
search
click
through
rates
the
numbers
never
lie
https://www.zerolimitweb.
com
organic-vs-ppc-2019-ctr-results-best-practices
retrieved
2019
09
06
stokes
2019
false
media
balance
https://www.newphilosopher.com/articles/false-media-balance/.
retrieved
2019
09
15
su
deng
fei-fei
2012
crowdsourcing
annotations
for
visual
object
detection
in
workshops
at
the
twenty-sixth
aaai
conference
on
artificial
intelligence
tavani
2012
search
engines
and
ethics
vincent
johnson
sheehan
hecht
2019
measuring
the
importance
of
user-generated
content
to
search
engines
proceedings
of
the
international
aaai
conference
on
web
and
social
media
13
505
516
vondrick
patterson
ramanan
2013
efficiently
scaling
up
crowdsourced
video
annotation
international
journal
of
computer
vision
101
184
204
white
2013
beliefs
and
biases
in
web
search
in
proceedings
of
the
36th
international
acm
sigir
conference
on
research
and
development
in
information
retrieval
pp
12
acm
yang
stoyanovich
2017
measuring
fairness
in
ranked
outputs
in
proceedings
of
the
29th
interna
tional
conference
on
scientific
and
statistical
database
management
22
acm
yigit-sert
altingovde
ulusoy
2016
towards
detecting
media
bias
by
utilizing
user
comments
yuen
king
leung
2011
survey
of
crowdsourcing
systems
in
2011
ieee
third
inter
national
conference
on
privacy
security
risk
and
trust
and
2011
ieee
third
international
conference
on
social
computing
pp
766
773
ieee
zehlike
bonchi
castillo
hajian
megahed
baeza-yates
2017
fa
ir
fair
top
ranking
algorithm
in
proceedings
of
the
2017
acm
on
conference
on
information
and
knowledge
management
pp
1569
1578
acm
publisher
note
springer
nature
remains
neutral
with
regard
to
jurisdictional
claims
in
published
maps
and
institutional
affiliations
123