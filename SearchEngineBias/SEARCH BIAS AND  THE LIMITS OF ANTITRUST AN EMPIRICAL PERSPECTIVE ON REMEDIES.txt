SEARCH BIAS AND
THE LIMITS OF ANTITRUST:
AN EMPIRICAL PERSPECTIVE ON REMEDIES
David A. Hyman and David J. Franklyn∗
ABSTRACT: As Google has moved from providing “ten blue links” to “universal
search,” controversy has erupted over whether Google is favoring its own specialized
search results over competing specialized results offered by other entities. Google’s
competitors have complained about “search bias,” and demanded that antitrust enforcers should ensure “search neutrality.” Both the U.S. Federal Trade Commission
(FTC) and the European Commission have considered these complaints. The FTC
closed its investigation without taking any action, but the European Commission issued
a formal statement of objections to Google in April 2015. This study empirically examines the impact of potential design remedies on search bias, including prominent
links to rival specialized search services (“architectural remedies”) and clearer labeling
of Google’s specialized search results (“labeling remedies”). This study finds that
architectural remedies have much greater impact than labeling remedies. User awareness of labeling is low, and even labels far more explicit than those currently employed
do not have much impact. Consumers have sticky expectations about how search results are presented, and their click-through behavior tracks those expectations irrespective of how the search results are labeled. However, major architectural changes can
have a substantial impact on click-through rates. These findings suggest that the impact
of architectural remedies will depend greatly on their design features, while labeling
remedies are unlikely to have a significant impact. We explore the implications of these
findings for other issues at the interface of Internet and intellectual property (IP) law.
CITATION: David A. Hyman and David J. Franklyn, Search Bias and the Limits of
Antitrust: An Empirical Perspective on Remedies, 55 Jurimetrics J. 339–380 (2015).

∗David A. Hyman is H. Ross and Helen Workman Chair in Law, University of Illinois
College of Law; Academic Affiliate, McCarthy Institute and Center for the Empirical Study of
Trademark Law. David J. Franklyn is Professor of Law; Executive Director, McCarthy Institute
for Intellectual Property and Technology Law and Director, Center for the Empirical Study of
Trademark Law at the University of San Francisco School of Law.
Financial support for this project was received from the McCarthy Institute, the University of
San Francisco, and the University of Illinois. The McCarthy Institute has received unrestricted and
restricted grants from various sources, including Microsoft and various law firms. After completing this article, Hyman and Franklyn were retained by Fairsearch to conduct an empirical
study of the impact of Google’s proposed commitments to the European Commission. We describe our findings from that study in a forthcoming article. We appreciate the helpful comments
we received from Professors Ben Edelman and Eric Goldman, and from several anonymous
referees.

SPRING 2015

Electronic copy available at: https://ssrn.com/abstract=2260942

339

Hyman & Franklyn
Google dominates online search in the United States, and its every move
sends ripples through the online economy. As Google shifted from providing
“ten blue links” to “universal search,” controversy has erupted over whether
Google is favoring its own specialized search results over competing specialized results offered by other entities.1 Each time that Google has added new
specialized search functionality (e.g., Google Maps, Google Flight Search
(GFS), Google Places, and Google Shopping), entities that were already
providing such specialized services (e.g., Mapquest, Kayak, Yelp, and
Nextag), have complained bitterly about “search bias,” and demanded that
antitrust enforcers take steps to ensure “search neutrality.” Competitors claim
that Google is leveraging its market power over search in ways that give an
unfair advantage to its specialized search products. Google’s competitors
claim that this unfair advantage makes it harder for them to succeed, even
when they are offering a superior product.2 Microsoft has challenged Google
Shopping on similar grounds, suggesting that its users are being “Scroogled,”
and promoting Bing as an unbiased search engine.3 These complaints have
attracted attention from Congress, antitrust enforcers, and numerous academic
commentators.
The U.S. Federal Trade Commission (FTC) investigated search bias as
part of its multiyear investigation of Google, but it closed the investigation in
January 2013 without taking any action.4 The European Commission identified
the way “Google displays links to its own specialised search services” as the
first of four “competition concerns” it had with Google’s business practices.5
In response, Google made a series of settlement proposals to the European
Commission, each requiring more prominent presentation of vertical search
rivals (“architectural remedies) and clearer labeling (“labeling remedies”).6

1. See Marina Lao, “Neutral” Search as a Basis for Antitrust Action?, HARV. J. L. & TECH.
(July 2013), at 10, http://jolt.law.harvard.edu/antitrust/articles/Lao.pdf (“Prior to 2005 . . . [t]he
role of general search engines . . . was simply to generate a list of the most useful websites—the
‘ten blue links’—in response to search queries. All three major search engines have since redesigned their products and evolved into integrated information portals, apparently in response to
user desires. Among the changes was the introduction of “universal search” for certain types of
queries. Universal search involves integrating the search engine’s maps, images, videos, or other
information it has created or compiled into its search results, and prominently displaying that
proprietary content ahead of the blue links.”).
2. See infra Part I.B.
3. See SCROOGLED! SHOPPING, http://web.archive.org/web/20140714100959/http://www.
scroogled.com/Shopping/ (accessed by searching for Scroogled! on the Internet Archive index)
(last visited July 14, 2014). See also Danny Sullivan, Bing Attacks Google Shopping With
“Scroogled” Campaign, Forgets It’s Guilty of Same Problems, SEARCH ENGINE LAND (Nov. 28,
2012, 3:55 PM), http://searchengineland.com/microsoft-attacks-google-with-scroogled-campaignforgets-its-guilty-of-same-thing-140856. In early 2015, Microsoft took down the Scroogled website, and the URL (www.scroogled.com) now redirects to a website entitled, “Why Microsoft.”
Barb Darrow, Microsoft Quietly Buries Scroogled Site, GIGAOM (Jan. 13, 2015, 6:52 AM),
https://gigaom.com/2015/01/13/microsoft-quietly-buries-scroogled-site/
4. See infra Part I.C.1.
5. See infra Part I.C.2.
6. Id.

340

55 JURIMETRICS

Electronic copy available at: https://ssrn.com/abstract=2260942

Search Bias and the Limits of Antitrust
The parties were unable to come to terms, and the European Commission
issued a formal Statement of Objections to Google in April 2015.7
Of course, Google’s business practices have prompted legal push back in
other areas. As we have explored elsewhere, Google’s sale of trademarks as
keywords prompted a decade of litigation worldwide.8 Other disputes have
arisen, or are likely to arise, at the interface of Internet, intellectual property
(IP), and antitrust law.9 Many of these disputes implicate the way in which
search results are organized and presented, or the way in which those results
are labeled, or both.
Antitrust law has provided the battlefield for most of these disputes. However, commentators’ analytical firepower has been almost entirely trained on
the issue of whether or not the antitrust laws have been violated. The issue of
remedies has largely escaped attention—even though the lengthy debate over
substantive competition law issues is unlikely to go anywhere useful if an
effective remedy cannot be crafted.
To help inform the remedies issue, we empirically examine the significance of search output architecture and labeling on consumer knowledge and
behavior. Building on our previous work, this study modifies the architecture
and labeling of the Google Shopping region of the search results page (SRP),
and evaluates how these changes affect click-through behavior in online surveys/simulations.10 This study also examines awareness of existing labels,
recall of labels encountered during the surveys/simulations, and knowledge of
which regions of the SRP are paid. We take no position on the merits of the
search bias/neutrality issue, but our findings cast light on the larger context in
which search results are presented by search engines and processed/interpreted
by users. Our findings have obvious implications for the ongoing litigation
brought by the European Commission against Google, and for other issues
involving the content and display of search results.
In brief, we find that the architecture of the SRP (i.e., the way in which
search results are graphically arranged on the page) is far more important than
any labels that might appear on that page. User awareness of labeling is low,
and even labels far more explicit than those currently employed do not dramatically improve consumer awareness of whether content is paid or unpaid.
Stated differently, consumer knowledge and behavior appears to be the result
7. See infra notes 34–48.
8. David J. Franklyn & David A. Hyman, Trademarks as Search Engine Keywords: Much
Ado About Something?, 26 HARVARD J.L. & TECH. 481, 483, 485 (2013) [hereinafter Franklyn &
Hyman, Trademarks as Keywords]; David A. Hyman & David J. Franklyn, Trademarks as Search
Engine Keywords: Who, What, When?, 92 TEX. L. REV. 2117, 2118 (2014).
9. For example, Google Books gave rise to litigation brought by the Authors Guild alleging
copyright infringement—resulting in a nine-year litigation odyssey. Claire Cain Miller & Julie
Bosman, Siding With Google, Judge Says Book Search Does Not Infringe Copyright, N.Y. TIMES,
Nov. 15, 2013, at B7, available at http://www.nytimes.com/2013/11/15/business/media/judgesides-with-google-on-book-scanning-suit.html.
10. We refer to our study as a survey/simulation because it encompasses elements of both.
Respondents run a series of simulated searches, and are surveyed on where they would click if
they were interested in looking and buying certain products. We also survey respondents on their
ability to recall certain labels.

SPRING 2015

Electronic copy available at: https://ssrn.com/abstract=2260942

341

Hyman & Franklyn
of sticky expectations about how search results are displayed, irrespective of
how the results are labeled. These findings indicate the impact of architectural
remedies (if any) will depend greatly on how they are designed, while labeling
remedies (if any) are unlikely to have a significant impact. Regulators and
judges should take account of these findings in considering the utility of ordering a remedy in the first instance—as well as the likely effect of whatever
remedies they might ultimately order.
Part I provides background on the dispute over search bias. Part II describes the methodology and results from the two surveys/simulations we
conducted in the United States. Part III discusses various issues raised by our
findings.

I. BACKGROUND ON SEARCH BIAS
A. Evolution of Google’s Search Output
Originally, Google presented only unpaid search results that took the form
of links to webpages created and maintained by other individuals and entities.11 The specific uniform resource locators (URLs) that appeared were dictated by Google’s PageRank algorithm.12 Over time, Google has made several
important changes to this model.
The first major change was the introduction of paid ads in 2000.13 These
ads originally appeared only in the right-hand column of the SRP, but an increasing share of the SRP has become monetized. Ads now routinely appear in
a colored box on top of the center column of the search output page, as well as
in the right column of the search output page.14
Beginning in 2007, Google moved from a “ten blue links” model to “universal search.”15 Instead of trying to simply provide links to other websites,
Google began attempting to answer users’ questions directly—and in some
instances, imbedding the results of one or more “vertical searches” provided
directly by Google.16 Vertical search options include Google Maps, GFS,
Google Local (previously known as Google Places), and Google Shopping.
Google’s critics complain that it “hard codes” the appearance of these vertical

11. JOHN BATTELLE, THE SEARCH: HOW GOOGLE AND ITS RIVALS REWROTE THE RULES OF
BUSINESS AND TRANSFORMED OUR CULTURE (2005).
12. Id. We refer to PageRank based search as “algorithmic search” throughout.
13. Id.
14. The labeling of Google’s ads has evolved over time as well. At the outset, ads were
labeled “Sponsored Links.” Id. After Google created ad space in the shaded box in the center
column, it relabeled the paid content in the center and right columns “Ads.” Google occasionally
places ads at the bottom of the SRP as well. As noted below, there is variation among search
engines in the design of their SRP and the labeling of paid content over time.
15. Marissa Mayer, Universal Search: The Best Answer Is Still the Best Answer, GOOGLE
OFFICIAL BLOG (May 16, 2007), http://googleblog.blogspot.com/2007/05/universal-search-bestanswer-is-still.html. See also Danny Sullivan, Google Launches “Universal Search” & Blended
Results, Search Engine Land (May 16, 2007, 2:33 PM), http://searchengineland.com/google-20google-universal-search-11232.
16. Sullivan, supra note 15.

342

55 JURIMETRICS

Electronic copy available at: https://ssrn.com/abstract=2260942

Search Bias and the Limits of Antitrust
searches to ensure they appear near the top of the algorithmic search results, if
not above them.17
Google Shopping demonstrates the evolution of vertical search and its
display on the Google SRP. The earliest incarnation was “Froogle,” which was
introduced in December 2002 as a price comparison service.18 Froogle obtained its content by indexing product data from vendor websites. Vendors did
not pay to have their content listed in Froogle. In 2007, Froogle was rebranded
as “Google Product Search.”19 It continued to operate as a price comparison
service that did not require payment from vendors.20 In 2010, Google launched
“Product Listing Ads,” which showed images of products within the colored
ad box in the center column of the SRP—and still did not require payment
from vendors.21 Finally, in May 2012, Google launched “Google Shopping.”22
The Google Shopping region includes images of the specified products, and
vendors must now pay to be included. Google Shopping generally appears in
the center column, above unpaid search results, and below any paid ads that
appear in the colored/shaded box on top of the center column of the SRP.

B. Complaints from Competitors
The dispute over search bias/neutrality originated in complaints from
Google’s competitors that they were being disadvantaged by changes in their
algorithmic search ranking and placement, as well as by claims that Google
was systematically disfavoring sites that competed with its own vertical search
products. Several of these companies formed “Fairsearch,” which has aggressively lobbied for the FTC and European Commission to bring an antitrust
action against Google.23 Hearings before the Senate Antitrust Committee in
2011 provided a platform for complaints by representatives of Yelp and Nex17. Benjamin Edelman, Hard-Coding Bias in Google “Algorithmic” Search Results
(November 15, 2010), http://www.benedelman.org/hardcoding/; Benjamin Edelman & Benjamin
Lockwood, Measuring Bias in “Organic” Web Search app. 1 (Jan. 19, 2011), http://www.
benedelman.org/searchbias/appendix1.html (Appendix 1: Others’ Concerns about Search Engine
Bias); see also Marissa Mayer, Presentation at Seattle Conference on Scalability: Scaling Google
for Every User, in GOOGLE TECH TALKS, YOUTUBE (June 23, 2007), http://www.youtube.com/
watch?v=LT1UFZSbcxE#t=44m50s (“[When] we roll[ed] out Google Finance, we did put the
Google link first. It seems only fair right, we do all the work for the search page and all these other
things, so we do put it first. . . . That has actually been our policy, since then, because of Finance.
So for Google Maps again, it’s the first link.”).
18. Danny Sullivan, Goodbye Froogle, Hello Google Product Search!, SEARCH ENGINE
LAND (Apr. 18, 2007, 8:21 PM), at http://searchengineland.com/goodbye-froogle-hello-googleproduct-search-11001.
19. Id.
20. Elinor Mills, Google Takes the Pun Out of Shopping, CNET NEWS (Apr. 18, 2007, 4:00
PM), http://news.cnet.com/2100-1038_3-6177393.html.
21. Danny Sullivan, Google Product Listing Ads Available to All Advertisers, SEARCH
ENGINE LAND (Nov. 11, 2010, 3:09 PM), http://searchengineland.com/google-product-adsavailable-to-all-advertisers-55498.
22. Danny Sullivan, Google Product Search to Become Google Shopping, Use Pay-To-Play
Model, SEARCH ENGINE LAND (May 31, 2012, 12:00 PM), http://searchengineland.com/googleproduct-search-to-become-google-shopping-use-pay-to-play-model-122959.
23. FAIRSEARCH, http://www.fairsearch.org (last visited May 7, 2013).

SPRING 2015

Electronic copy available at: https://ssrn.com/abstract=2260942

343

Hyman & Franklyn
tag.24 The former Assistant Attorney General for Antitrust (Tom Barnett),
representing Expedia, testified at length about the problem of search bias.25 In
response, the former head of the FTC’s Bureau of Competition (Susan
Creighton), who was representing Google, testified that Google’s practices did
not raise antitrust concerns.26

C. Antitrust Investigations of Search Bias
1. FTC
The FTC launched a formal investigation of Google’s advertising and
search practices in 2011.27 The investigation was closed in 2013 with a settlement that did not address the issue of search bias. The FTC’s press release
made it clear that the agency found little merit in the claims regarding search
bias and dismissed the argument that Google’s practices raised antitrust concerns.
The FTC conducted an extensive investigation into allegations that
Google had manipulated its search algorithms to harm vertical websites and
unfairly promote its own competing vertical properties, a practice commonly
known as “search bias.” In particular, the FTC evaluated Google’s introduction of “Universal Search”—a product that prominently displays targeted
Google properties in response to specific categories of searches, such as
shopping and local—to determine whether Google used that product to reduce or eliminate a nascent competitive threat. Similarly, the investigation
focused on the allegation that Google altered its search algorithms to demote
certain vertical websites in an effort to reduce or eliminate a nascent competitive threat. According to the Commission statement, however, the FTC concluded that the introduction of Universal Search, as well as additional
changes made to Google’s search algorithms—even those that may have had
the effect of harming individual competitors—could be plausibly justified as
innovations that improved Google’s product and the experience of its users. It
28
therefore has chosen to close the investigation.

24. The Power of Google: Serving Consumers or Threatening Competition?: Hearing Before
the Subcomm. on Antitrust, Competition Policy and Consumer Rights of the S. Comm. on the
Judiciary, 112th Cong. 35–36 (2011), available at http://www.gpo.gov/fdsys/pkg/CHRG112shrg71471/pdf/CHRG-112shrg71471.pdf.
25. Id. at 33.
26. Id. at 38–39.
27. Jessica Guynn & Jim Puzzanghera, FTC Launches Investigation of Google, L.A. TIMES
(June 25, 2011), http://articles.latimes.com/2011/jun/25/business/la-fi-google-ftc-20110625; see
also Thomas Catan & Amir Efrati, Feds to Launch Probe of Google, WALL ST. J. (June 24, 2011),
http://online.wsj.com/article/SB10001424052702303339904576403603764717680.html.
28. Press Release, Fed. Trade Comm’n, Google Agrees to Change Its Business Practices to
Resolve FTC Competition Concerns In the Markets for Devices Like Smart Phones, Games and
Tablets, and in Online Search (Jan. 3, 2013), available at http://www.ftc.gov/opa/2013/01/
google.shtm; see also Statement of the Federal Trade Commission Regarding Google’s Search
Practices: In the Matter of Google Inc., FTC File Number 111-0163, FED. TRADE COMM’N (Jan.
3, 2013), available at https://www.ftc.gov/system/files/documents/public_statements/295971/
130103googlesearchstmtofcomm.pdf.

344

55 JURIMETRICS

Electronic copy available at: https://ssrn.com/abstract=2260942

Search Bias and the Limits of Antitrust
The settlement did include a separate “Letter of Commitment,” in which
Google promised to provide a mechanism whereby website owners could opt
out of having their content appear on Google’s vertical search options, including Google Shopping, G+ Local, GFS, Google Hotels, and Google Advisor.29
Google’s critics were quite vocal about their unhappiness that the FTC
settlement did not address search bias.30 The issue was rekindled in 2015,
when a portion of a 2012 FTC staff report on the case was inadvertently disclosed to the Wall Street Journal.31 The report showed that the FTC’s Bureau
of Competition concluded that Google had, in fact, targeted its rivals in vertical search, by adopting “a strategy of demoting or refusing to display, links
to certain vertical websites in highly commercial categories.”32 Although the
inadvertent disclosure attracted considerable public attention, there has been
no indication the FTC or DOJ is planning to revisit the issue of search bias.33

2. European Commission Investigation
In February 2010, several companies filed complaints with the European
Commission claiming “that Google downgraded their sites in its [algorithmic]
search results to weaken potential competitors for advertising.”34 On November 30, 2010, the European Commission announced a formal probe to
“investigate whether Google has abused a dominant market position in online
search by allegedly lowering the ranking of unpaid search results . . . by ac29. Letter from David Drummond, Senior Vice President of Corporate Dev. & Chief Legal
Officer, Google Inc., to Hon. Job Leibowitz, Chairman, Fed. Trade Comm’n (Dec. 27, 2012),
available at https://www.ftc.gov/system/files/documents/closing_letters/google-inc./130103google
letterchairmanleibowitz.pdf.
30. See, e.g., Google Wins an Antitrust Battle, Editorial, N.Y. TIMES, Jan. 6, 2013, at SR10,
available at http://www.nytimes.com/2013/01/06/opinion/sunday/google-wins-an-antitrust-battle.
html; Pamela Jones Harbour, Op-Ed., The Emperor of All Identities, N.Y. TIMES, Dec. 19, 2012, at
A35, available at http://www.nytimes.com/2012/12/19/opinion/why-google-has-too-much-powerover-your-private-life.html; Edward Wyatt, Critics of Google Antitrust Ruling Fault the Focus,
N.Y. TIMES, Jan. 7, 2013, at B1, available at http://www.nytimes.com/2013/01/07/technology/
googles-rivals-say-ftc-antitrust-ruling-missed-the-point.html; John Cassidy, Why the Feds Should
Have Been Tougher on Google, NEW YORKER (Jan. 8, 2013), http://www.newyorker.com/online/
blogs/johncassidy/2013/01/why-the-feds-should-have-been-tougher-on-google.html; FairSearch
Panel “Lessons from the Google-FTC Settlement”, FAIRSEARCH.ORG (Apr. 12, 2013), http://
www.fairsearch.org/general/video-fairsearch-panel-lessons-from-the-google-ftc-settlement/; The
FTC’s Missed Opportunity on Google, BLOOMBERG (Jan. 3, 2013, 1:05 PM), http://www.
bloomberg.com/news/2013-01-03/the-ftc-s-missed-opportunity-on-google.html.
31. See, e.g., Brody Mullins et al., Inside the U.S. Antitrust Probe of Google, WALL ST. J.
(Mar. 19, 2015, 7:38 PM), http://www.wsj.com/articles/inside-the-u-s-antitrust-probe-of-google1426793274.
32. Id. (internal quotation marks omitted).
33. See, e.g., Rebecca R. Ruiz & Conor Dougherty, Take Google to Court, Staff Report
Urged FTC, N.Y. TIMES, Mar. 20, 2015, at B1 available at http://www.nytimes.com/2015/03/
20/technology/take-google-to-court-staff-report-urged-ftc.html?_r=0.
34. James Kanter & Eric Pfanner, Google Faces Antitrust Inquiry in Europe, N.Y. TIMES,
Dec. 1, 2010, at B1, available at http://www.nytimes.com/2010/12/01/technology/01google.html;
Richard Waters & Niki Tait, Google Faces Brussels Antitrust Scrutiny, FINANCIAL TIMES (Feb.
24, 2010, 3:42 PM), http://www.ft.com/cms/s/2/46018520-20da-11df-b920-00144feab49a.html.

SPRING 2015

Electronic copy available at: https://ssrn.com/abstract=2260942

345

Hyman & Franklyn
cording preferential placement to the results of its own vertical search services
in order to shut out competing services.”35 While the European Commission
conducted its investigation, there were additional complaints from other companies.36 As part of its investigation, the European Commission explicitly
identified search bias as an antitrust concern:
Google prominently displays links to its own specialised search services
within its web search results and does not inform users of this favourable
treatment. Due to the favourable treatment of Google’s own services, consumers are more likely to not make use of potentially more relevant competing services. First, users are not aware of the promotion of Google’s offer
within the search results. Second, competitors’ results that are potentially
more relevant are less visible and even sometimes not directly visible to users—they are more difficult for the user to find, for instance because the user
has to scroll down the screen to see them or has to go to a subsequent search
results web page.
The Commission is concerned that this practice unduly diverts traffic
away from Google’s competitors in specialised search towards Google’s own
specialised search services. It therefore reduces the ability of consumers to
find a potentially more relevant choice of specialised search services. Since
Google is an important source of traffic for competing specialised search services, this may reduce competitors’ incentives to innovate in specialised
37
search.

In April 2013, Google proposed to settle the E.C. investigation into search
bias with a remedy blending architectural and labeling remedies.38 Google
proposed to:
(i) - label promoted links to its own specialised search services so that users
can distinguish them from natural web search results,
- clearly separate these promoted links from other web search results by
clear graphical features (such as a frame), and
35. Press Release, European Comm’n, Antitrust: Commission Probes Allegations of
Antitrust Violations by Google (Nov. 30, 2010), available at http://europa.eu/rapid/press-release_
IP-10-1624_en.htm.
36. See Alex Barker, Antitrust Chief Holds Aces in Google Case, FINANCIAL TIMES (Jan. 10,
2013, 7:44 AM), http://www.ft.com/cms/s/0/42a827b2-5b24-11e2-8d06-00144feab49a.html; Foo
Yun Chee, EU Sees Google Competition Deal After August, REUTERS (Feb. 22, 2013),
http://www.reuters.com/article/2013/02/22/us-eu-google-idUSBRE91L0EJ20130222;
Greg
Sterling, Europeans Taking Sweet Time in Resolving Antitrust Case With Google, SEARCH ENGINE
LAND, (Feb. 25, 2013, 10:26 AM) http://searchengineland.com/europeans-taking-sweet-time-inresolving-antitrust-issues-with-google-149603; Aoife White, Google Antitrust Scrutiny Mounts in
Europe, BLOOMBERG (May 7, 2012, 4:00 PM), http://www.bloomberg.com/news/2012-05-07/
google-antitrust-scrutiny-mounts-in-europe.html.
37. Memorandum, European Comm’n, Commission Seeks Feedback on Commitments
Offered by Google to Address Competition Concerns—Questions and Answers (Apr. 25, 2013),
available at http://europa.eu/rapid/press-release_MEMO-13-383_en.htm.
38. James Kanter, In Europe, New Protest Over Google, N.Y. TIMES, Apr. 9, 2013, at B1,
available at http://www.nytimes.com/2013/04/09/technology/09iht-google09.html (noting that the
European Commission was “receiving proposals this week from Google to clear up concerns
about its search practices, and that he [Mr. Alumnia, the E.C. head of antitrust) hoped they would
make it easier for Internet users to identify when Google was promoting its own services rather
than those of competitors who might offer better results”).

346

55 JURIMETRICS

Electronic copy available at: https://ssrn.com/abstract=2260942

Search Bias and the Limits of Antitrust
- display links to three rival specialised search services close to its own
services, in a place that is clearly visible to users,
(ii) - offer all websites the option to opt-out from the use of all their content
in Google’s specialised search services, while ensuring that any opt-out does
not unduly affect the ranking of those web sites in Google’s general web
search results,
- offer all specialised search web sites that focus on product search or local search the option to mark certain categories of information in such a way
39
that such information is not indexed or used by Google.

The European Commission solicited feedback on whether it should make
Google’s Commitments legally binding as part of a broader settlement of the
issues raised in the investigation. Critics made it clear they were unsatisfied
with the remedy proposed by Google.40 The European Commission subsequently rejected the proposed settlement and requested further concessions
from Google.41 Google subsequently made two additional settlement offers, in
September 2013 and February 2014.42 Although the head of the European
Commission’s antitrust authority (the Directorate-General for Competition or
DG-Comp) indicated he would accept the February 2014 Commitments,43 the
settlement collapsed in September 2014 and the European Commission demanded further concessions from Google.44 A new head of DG-Comp took
over in November 2014.45

39. Press Release, European Comm’n, Antitrust: Commission Seeks Feedback on
Commitments Offered by Google to Address Competition Concerns (Apr. 25, 2013), available at
http://europa.eu/rapid/press-release_IP-13-371_en.htm.
40. See, e.g., James Kanter, Rivals Are Invited to Review Google Antitrust Settlement, N.Y.
TIMES, Apr. 26, 2013, at B3, available at http://www.nytimes.com/2013/04/26/technology/26ihtgoogle26.html; Responses to Google’s Proposed Remedies to the European Commission, FAIR
SEARCH.ORG EUROPE, http://www.fairsearcheurope.eu/responses-to-googles-proposal-to-theeuropean-commission/ (last visited Mar. 10, 2015).
41. James Kanter & Claire Cain Miller, In European Antitrust Fight, Google Needs to
Appease Competitors, N.Y. TIMES, July 18, 2013, at B1, available at http://www.nytimes.
com/2013/07/18/technology/europe-wants-more-concessions-from-google.html?_r=0; Foo Yun
Chee, EU Demands More Concessions from Google to Settle Case, REUTERS (July 17, 2013),
http://www.reuters.com/article/2013/07/17/us-eu-google-idUSBRE96G0FK20130717.
42. Foo Yun Chee, Google Offers New Concessions to Avoid Fine in EU Case, REUTERS
(Sept. 9, 2013, 6:19 AM), http://www.reuters.com/article/2013/09/09/us-eu-google-idUSBRE9880
D620130909; Aoife White, Google Publishes Concessions Deal to Settle EU Antitrust Probe,
BLOOMBERG (Feb. 14, 2014, 10:59 AM), http://www.bloomberg.com/news/2014-02-14/googlepublishes-concessions-deal-to-settle-eu-antitrust-probe.html.
43. Press Release, European Comm’n, Antitrust: Commission Obtains from Google
Comparable Display of Specialized Search Rivals (Feb. 5, 2014), available at http://europa.eu/
rapid/press-release_IP-14-116_en.htm?locale=en. See also Nick Summers, Google Finally Settles
Its Antitrust Case in the EU with Commitment to Promoting Rival Services, TNW (Feb. 5, 2014,
1:33 PM), http://thenextweb.com/eu/2014/02/05/google-finally-settles-antitrust-case-eu-commitmentpromoting-rival-services/.
44. Tom Fairless, EU Asks More of Google: European Union Antitrust Authorities Seek
Fresh Concessions From Internet Giant in Ongoing Probe, WALL ST. J. (Sept. 8, 2014, 12:49
PM), http://www.wsj.com/articles/eu-asks-more-of-google-1410180167.
45. Tom Fairless, Google Must Improve Search Settlement or Face Charges, EU’s Almunia
Says: Antitrust Chief Says Investigation Hasn’t Been Swayed by Political Pressure, WALL ST. J.,

SPRING 2015

Electronic copy available at: https://ssrn.com/abstract=2260942

347

Hyman & Franklyn
On April 15, 2015, the European Commission issued a formal Statement
of Objections (SO) to Google.46 The SO reflects the preliminary conclusion of
the Commission’s investigation:
Google gives systematic favourable treatment to its comparison shopping
product (currently called “Google Shopping”) in its general search results
pages, e.g. by showing Google Shopping more prominently on the screen. It
may therefore artificially divert traffic from rival comparison shopping services and hinder their ability to compete on the market. . . . The Commission’s preliminary view is that to remedy such conduct, Google should treat
47
its own comparison shopping service and those of rivals in the same way.

Google has ten weeks to respond to the SO, and may then seek a formal hearing.48

D. Previous Research
We divide our summary of previous research on search bias into pure
legal scholarship and empirical work.

1. Legal Scholarship
There are numerous academic articles on the issue of search
bias/neutrality.49 Critics have claimed that Google’s dominance in algorithmic
search has allowed it to foreclose opportunities for competitors and suggested
that antitrust law provides a way to address such conduct.50 Others have suggested that the United States should create a federal search commission,51 or
called for further government investigation of the frequency and severity of

(Sept. 23, 2014, 8:27 AM), http://www.wsj.com/articles/google-must-improve-search-settlementor-face-charges-eus-almunia-says-1411462097.
46. Press Release, European Commission, Antitrust: Commission Sends Statement of
Objections to Google on Comparison Shopping Service (Apr. 15, 2015), http://europa.eu/rapid/
press-release_IP-15-4780_en.htm.
47. Id.
48. Id.
49. See, e.g., Benjamin G. Edelman & Joshua D. Wright, Debate on Antitrust Scrutiny of
Google, 2 J.L. 445 (2012).
50. Kristine Laudadio Devine, Preserving Competition in Multi-Sided Innovative Markets:
How Do You Solve a Problem Like Google?, 10 N.C. J.L. & TECH. 59, 104 (2008); Benjamin
Edelman, Bias in Search Results?: Diagnosis and Response, 7 INDIAN J.L. & TECH. 16, 26 (2011);
George N. Bauer, Note, Why Internet-Based Monopolies Have an Inherent “Get-Out-of-Jail-FreeCard”, 76 BROOK. L. REV. 731, 764 (2011); Joshua G. Hazan, Note, Stop Being Evil: A Proposal
for Unbiased Google Search, 111 MICH. L. REV. 789, 801 (2013); see also Eric Clemons, What an
Antitrust Case Against Google Might Look Like, TECHCRUNCH (Mar. 1, 2009), http://
techcrunch.com/2009/03/01/what-an-antitrust-case-against-google-might-look-like/.
51. See Oren Bracha & Frank Pasquale, Federal Search Commission? Access, Fairness and
Accountability in the Law of Search, 93 CORNELL L. REV. 1149, 1206–09 (2008); see also Frank
Pasquale, Dominant Search Engines: An Essential Cultural & Political Facility, in THE NEXT
DIGITAL DECADE: ESSAYS ON THE FUTURE OF THE INTERNET 401 (Berin Szoka & Adam Marcus
eds., 2010).

348

55 JURIMETRICS

Electronic copy available at: https://ssrn.com/abstract=2260942

Search Bias and the Limits of Antitrust
search bias.52 Most antitrust scholars have been skeptical of such claims; they
have raised serious questions about the definition and frequency of search bias,
the extent to which antitrust provides a useful remedy to the problem, to the
extent it actually exists, and whether search bias is simply a form of vertical
integration that has pro-competitive benefits.53 IP and Internet scholars have
argued that search is inherently dynamic and attempts to impose a “search
neutrality” framework would not work well.54 First Amendment scholars have
argued that search (and the host of subjective judgments that inform search
results) constitutes speech, and are accordingly constitutionally protected.55
The issue of a remedy has attracted relatively little attention. Critics of the
FTC and European Commission investigations have argued that search bias is
a nonproblem—and even if it is a problem, any remedy will end up making
consumers worse off. Enthusiasts of the investigations have claimed an effective remedy must either confine Google to its existing search markets, or force
it to provide equal access to favored positions on the SRP—without devoting
much attention to how precisely either of those things might be done—let
alone quantifying the actual impact of doing so.

2. Empirical Research on Search Bias and Remedies
There is relatively little empirical research on search bias, and we could
not locate any empirical research on the issue of remedies for search bias.56
52. Eric K. Clemons, Does Google Deliberately Engage in Deceptive Practices? Maybe and
Maybe Not, HUFFINGTON POST TECH (Sept. 19, 2011, 12:29 PM), http://www.huffingtonpost.
com/eric-k-clemons/does-google-deliberately-_b_969895.html.
53. Robert H. Bork & J. Gregory Sidak, What Does the Chicago School Teach About
Internet Search and the Antitrust Treatment of Google?, 8 J. COMPETITION L. & ECON. 663, 663
(2012); Daniel A. Crane, Search Neutrality and Referral Dominance, 8 J. COMPETITION L. &
ECON. 459, 459 (2012); Daniel A. Crane, Search Neutrality as an Antitrust Principle, 19 GEO.
MASON L. REV. 1199, 1199 (2012); Lao, supra note 1; Marina Lao, Search, Essential Facilities,
and the Antitrust Duty to Deal, 11 NW. J. TECH. AND INTELL. PROP. 275, 276 (2013) [hereinafter
Lao, Search, Essential Facilities, and the Antitrust Duty to Deal]; Geoffrey A. Manne & Joshua
D. Wright, Google and the Limits of Antitrust: The Case Against the Case Against Google, 34
HARV. J.L. & PUB. POL’Y 171, 173 (2011); Geoffrey A. Manne & Joshua D. Wright, If Search
Neutrality is the Answer, What’s the Question?, 2012 COLUM. BUS. L. REV. 151, 151 (2012). See
generally Marvin Ammori & Luke Pelican, Competitors’ Proposed Remedies for Search Bias:
Search “Neutrality” and Other Proposals, 15 J. INTERNET L. 1 (2012) (discussing the weaknesses
of competitors’ proposed remedies targeting search bias).
54. Eric Goldman, Revisiting Search Engine Bias, 38 WM. MITCHELL L. REV. 96, 107
(2011); Eric Goldman, Search Engine Bias and the Demise of Search Engine Utopianism, 8 YALE
J.L. & TECH. 188, 188 (2006); James Grimmelman, Some Skepticism About Search Neutrality, in
THE NEXT DIGITAL DECADE: ESSAYS ON THE FUTURE OF THE INTERNET 435, 238 (Berin Szoka &
Adam Marcus eds., 2010).
55. EUGENE VOLOKH & DONALD M. FALK, FIRST AMENDMENT PROTECTION FOR SEARCH
ENGINE SEARCH RESULTS 1, 3 (Apr. 20, 2012), available at http://www.volokh.com/wpcontent/uploads/2012/05/SearchEngineFirstAmendment.pdf. Others have been unpersuaded by
this argument. See Hillary Greene, Information Product Redesign as Commercial Expression:
Antitrust Treatment of Speech and Innovation, B.U.L. REV. 1, 3–5 (forthcoming 2015).
56. Although we have been unable to locate any empirical studies on the issue of remedies
for search bias, there is an extensive literature on the effectiveness of disclosure remedies. This
literature has obvious implications for the (routinely proposed) remedy of prominently labeling
search results to more clearly indicate their provenance. In general, this literature finds that disclo-

SPRING 2015

Electronic copy available at: https://ssrn.com/abstract=2260942

349

Hyman & Franklyn
Part of the difficulty is determining what is meant by “search bias.” What
actually counts as “neutral search?” Is it bias for a search engine to have any
preference whatsoever for links that it has some connection with (i.e., for
“affiliated links”)? In the limiting case, is it bias for a search engine to “hard
code” the appearance of affiliated links at the top of the algorithmic results? If
it turns out that all search engines give some preference to affiliated links, does
that indicate that all search engines are biased, or that no search engines are
biased? Should search engines that proclaim they provide objective results be
held to a different standard than search engines that do not make such promises?
There are also daunting philosophical questions lurking in the definition
of search bias. Consider one obvious difficulty. Suppose that when Google
launched its original search engine in 1998, it included the full panoply of
vertical searches and preferences for affiliated links that it deployed over the
subsequent seventeen years. Would that initial decision by Google result in
search bias? On what theory? If not, why should the fact that Google subsequently added those vertical searches and preferences for affiliated links give
rise to a phenomenon that some people have collectively decided to call
“search bias?” Stated differently, to what extent is the timing and sequencing
of innovation doing the work of creating the controversy? Luckily (for the
reader), such metaphysical questions are beyond the scope of this article. Instead, they are raised to flag some of the complexities that underlie the facile
label of “search bias.”
Putting the metaphysical questions aside, we identified three studies that
offer an empirical perspective on the issue of search bias. In the first study,
Edelman and Lockwood picked thirty-two search terms that they expected to
have a high degree of references to affiliated links, and ran them through five
search engines (Google, Bing, Yahoo, AOL, and Ask).57 They analyzed the
top algorithmic link, the first three algorithmic links, and the first page of
algorithmic links.58 Across all search engines, they found that 19% of links
refer to a search engine’s affiliated links.59 Focusing on the first algorithmic
link, they find that Google refers to its affiliated links about twice as often as
Yahoo and Bing refer to Google content in this position.60 However, they also
find that Yahoo refers to its affiliated links more often than Google if one
considers the entirety of the first page.61 Edelman and Lockwood conclude that
sure remedies are entirely ineffective—except when they are counterproductive. We refer interested readers to a first-rate review and synthesis of this literature. See generally OMRI BENSHAHAR & CARL E. SCHNEIDER, MORE THAN YOU WANTED TO KNOW: THE FAILURE OF MANDATED
DISCLOSURE (2014) (discussing the failures of the mandated disclosure). See also Omri BenShahar & Carl E. Schneider, The Failure of Mandated Disclosure, 159 U. PA. L. REV. 647, 679–
729 (2011).
57. Benjamin Edelman & Benjamin Lockwood, Measuring Bias in “Organic” Web Search
(Jan. 19, 2011), http://www.benedelman.org/searchbias/.
58. Id.
59. Id. Edelman and Lockwood refer to this “own content” bias.
60. Id.
61. Id.

350

55 JURIMETRICS

Electronic copy available at: https://ssrn.com/abstract=2260942

Search Bias and the Limits of Antitrust
their findings indicate that Google intentionally places its affiliated links first,
which they treat as prima facie evidence of search bias.62
Wright replicated Edelman and Lockwood’s study using three search
engines (Bing, Google and Blekko), and noted significant changes in the
search engine environment in the year between the two studies.63 However, in
addition to the thirty-two search terms selected by Edelman and Lockwood, he
also studied a random sample of 1,000 Google search queries.64 Wright argued
that the first page (and not the first link) is the appropriate scope for evaluating
search bias and found that Google’s ranking of its affiliated links differed in
only 8% of queries.65 Wright also found that Bing had a higher bias toward
affiliated links than Google.66
Wright also found that search engines did not refer to affiliated links in an
overwhelming majority of queries.67 Google referred to affiliated links in the
first position, when other search engines did not, in only 6.7% of queries,
while Bing did so more than twice as often.68 When considering the entire first
page, the bias for affiliated links was similar for Google and Bing.69
Why did Wright obtain such different results than Edelman and Lockwood? Some of the difference is likely attributable to the passage of a year and
the accompanying evolution in search. Some of the difference may also be
attributable to differences in study design (e.g., analyzing the first link versus
the first page of search output). But, the largest difference is almost certainly
attributable to the sample used by Edelman and Lockwood versus Wright.
Edelman and Lockwood studied thirty-two search terms selected because they
were likely to trigger affiliated links. Wright tested the same thirty-two search
terms, but his primary dataset was a random sample of 1,000 actual searches.
Each approach has strengths and weaknesses. Edelman and Lockwood are
like Willie Sutton—they are looking for evidence of search bias where it is
most likely to occur. The strength of this approach is that if researchers do not
find evidence of search bias where it is most likely to occur, they can be confident it is not occurring at all. Conversely, the nonrandom nature of the search
terms means that even if Edelman and Lockwood had been able to find evidence of search bias, they would have been unable to draw any conclusion
about the actual prevalence of search bias as experienced by the average user.
What about Wright’s random sample of 1,000 searches? Because a large
number of searches are idiosyncratic, a random sample will include many
searches made by only a few users. Although a random sample better captures
the experience of the average search engine user, the prevalence of idiosyn62. Id.
63. Joshua D. Wright, Defining and Measuring Search Bias: Some Preliminary Evidence
(George Mason Law & Economics Research Paper No. 12-14, 2011), available at http://ssrn.com/
abstract=2004649.
64. Id.
65. Id.
66 . Id.
67. Id.
68. Id.
69. Id.

SPRING 2015

Electronic copy available at: https://ssrn.com/abstract=2260942

351

Hyman & Franklyn
cratic searches means that even a significant degree of search bias can go undetected.
In 2013, Edelman and Lai released a new study, analyzing the impact of
GFS on click-through rates (CTRs) to online travel agencies and airlines.70
Beginning in December 2011, GFS was hard coded to appear above the top
algorithmic link in response to specific qualifying searches (e.g., “flights to
Orlando”). The GFS listings presented information on air carriers, flights, and
price quotes in an interactive box that allowed users to check fares on various
dates and filter the results.
Using a large dataset aggregated from actual search engine usage by a
panel of users, Edelman and Lai studied the impact of GFS on CTRs to 23
popular travel sites, composed of 17 online travel agencies and 6 large U.S.
airlines.71 They found that the introduction of GFS reduced uncontrolled CTRs
on nonpaid algorithmic links for these 23 sites from 5.5% to 3.5% (a drop of
36%), while CTRs on paid links for these 23 sites increased from 3% to 6.4%
(an increase of 113%).72 When they performed a regression analysis including
appropriate controls, they found that the introduction of GFS increased CTRs
on paid links for these 23 sites from 6.1% to 11.3% (an 85% increase) and
decreased CTRs on unpaid links for these 23 sites from 6.2% to 2.2% (a 65%
decrease).73 Further analysis indicated that GFS had a larger impact on the
sites that received the most traffic from the search terms.
These three studies help cast light on the frequency of search bias—but
they say little or nothing about possible remedies, and the trade-offs of using
architectural versus labeling remedies. We now turn to those issues.

II. METHODOLOGY AND FINDINGS
A. Overview
We conducted two interactive online surveys/simulations during February
2013 and March 2013. The authors were responsible for designing and
analyzing the surveys/simulations. A private firm administered the surveys/
simulations.74 Appendix A summarizes basic demographic information about
participants. A broad cross-section of the population was obtained.
Both surveys/simulations asked approximately forty substantive questions, followed by eight demographic questions. The survey/simulation began
by asking respondents to turn off any ad blocker they were using, and then
asked a series of questions about their use of ad blocking software, their preferred search engine, and whether they could recall seeing various labels used
by search engines to identify paid content. Respondents were randomly as70. Benjamin Edelman & Zhenyu Lai, Design of Search Engine Services: Channel
Interdependence in Search Engine Results (Harvard Bus. Sch. NOM Unit, Working Paper No. 13087, 2015), available at http://ssrn.com/abstract=2251294 (formerly titled Exclusive Preferential
Placement as Search Diversion: Evidence from Flight Search, Apr. 28, 2013).
71. Id. at 13, 52.
72. Id. at 16.
73. Id. at 4.
74. SURV. SAMPLING INT’L, www.surveysampling.com (last visited Mar. 22, 2015).

352

55 JURIMETRICS

Electronic copy available at: https://ssrn.com/abstract=2260942

Search Bias and the Limits of Antitrust
signed to one of two search scenarios (i.e., either “Nikon camera” or “London
Fog”) and directed to a website displaying a virtual Google search environment.75 Each participant was asked to run a Google search using their assigned
search term and click on the link they would have selected if they were interested in obtaining information on the specified product. Respondents were
then asked to rerun the same simulated search and click on the link they would
have selected if they were interested in purchasing the specified product. The
results captured the specific link that respondents clicked in response to these
questions, and mapped the clicked links to specific regions of the SRP.
A picture of the SRP that respondents were shown for Nikon camera and
London Fog in the 2nd Survey/Simulation are shown below, as Figure 1 and
Figure 2, respectively.76
Figure 1. Nikon Camera SRP, 2nd Survey/Simulation

75. We used Google because it is the most popular search engine and has been the target of
investigations of search bias by both the FTC and the European Commission. The virtual Google
search environment looked exactly like a Google SRP, except we omitted the left-side column in
the search output page. This was to ensure sufficient space was available to display the entirety of
the center and right-side columns. However, in this paper, we consistently refer to columns as they
would appear in a normal Google search (i.e., the center column and the right-side column). We
refer to the website as a “virtual Google search environment” because the SRP was identical to an
actual Google SRP, apart from our manipulation of labeling and architecture.
76. As noted above, and as Figures 1 and 2 reflect, we deliberately omitted the left-side
column in the search output page. Although Figures 1 and 2 are truncated in length, respondents
were actually shown a full page of search results, and could scroll up and down.

SPRING 2015

Electronic copy available at: https://ssrn.com/abstract=2260942

353

Hyman & Franklyn
Figure 2. London Fog SRP, 2nd Survey/Simulation

The images for the 1st survey/simulation were identical, except the Google
Shopping Region was on the right side of the SRP.
In both Figures 1 and 2, the Google Shopping region appears immediately
below the colored region in the center column. The main difference between
the two images is that the image for Nikon camera (Figure 1) has three paid
ads in the Google Shopping region v. one paid ad in the London Fog Google
Shopping region (Figure 2).
We then explored the impact of architectural and labeling remedies on
click-through rates. Respondents repeatedly reran the same search, and were
presented with a series of five (1st survey/simulation) or seven (2nd survey/simulation) variations of the SRP. Within each survey/simulation, SRP
variations were presented in random order to reduce the impact of any order
effect. In each instance, respondents were asked to click on the link they
would have chosen if they were interested in purchasing the product in question.
We focused on the Google Shopping region, which has been the source of
multiple complaints about search bias. Indeed, as noted previously, the European Commission’s SO focused exclusively on Google Shopping. As evident
in Figures 1 and 2, the Google Shopping region is labeled “Shop for [nikon
camera or london fog] on Google” at the left upper margin of the Shopping
region. There is a separate “Sponsored” label at the upper right-hand margin of
the Shopping region. We refer to the label at the left upper margin of the

354

55 JURIMETRICS

Electronic copy available at: https://ssrn.com/abstract=2260942

Search Bias and the Limits of Antitrust
Shopping region as the “Google-native label” in the balance of this article.77
For the first variation, the Google-native labels were changed to “Paid Ads for
nikon camera by Google Comparison ShoppingTM” and “Paid Ads for london
fog by Google Comparison ShoppingTM.” Our goal was to make it clear that
the contents represented paid content. This variation is referred to as the
“Google-tweaked label.” Figure 3 shows the SRP, with an enlarged view of
the Google-tweaked label. The only change made was to the Google Shopping
label; otherwise Figure 3 is identical to Figure 1.
Figure 3. Nikon Camera SRP with
Google-Tweaked Shopping Label (Enlarged Label)

77. As noted above, Google used the term “Sponsored” to indicate paid content in the top
center and right-side columns, but it switched to “Ads” in November 2010. Barry Schwartz,
Google Does Away with “Sponsored Links” Label, Now Ads Are Labeled “Ads,” SEARCH ENGINE
LAND (Nov. 5, 2010, 3:06 PM), http://searchengineland.com/google-does-away-with-sponsoredlinks-label-now-ads-are-labeled-ads-54956. When Google launched Google Shopping in May
2012, it brought back the label “Sponsored” in the upper right-hand corner of the Shopping region,
along with the label “Shop for [what you searched for] on Google” in the upper left-hand corner of
the Shopping region. Jim Yu, Google Shopping—The Balance Between Old and New, SEARCH
ENGINE LAND (Aug. 9, 2012, 12:20 PM), http://searchengineland.com/google-shopping-–-thebalance-between-old-new-129011. It kept using “Ads” for non-Shopping paid content in the topcenter and right-side columns. Id. In effect, this means that since May 2012, Google has been
simultaneously using two different labels (“Ads” and “Sponsored”) to indicate paid content.

SPRING 2015

Electronic copy available at: https://ssrn.com/abstract=2260942

355

Hyman & Franklyn
The next variation was a “fanciful control” that had the same content and
appearance as Google Shopping, but was labeled to make it clear that it was
not a Google-affiliated entity (i.e., “Paid Ads for nikon camera by Netcompare
ShoppingTM”). Figure 4 shows the SRP, with an enlarged view of the Netcompare label. The only change made was to the label; otherwise Figure 4 is identical to Figures 1 and 3. Below, this variation is referred to as the
“Netcompare” label.
Figure 4. Nikon Camera SRP with
Netcompare Shopping Label (Enlarged Label)

We also evaluated the impact of page architecture by showing respondents
images with both the Netcompare and Google Shopping regions. Figure 5
shows the SRP, with an enlarged view of the two Shopping regions (in this
instance, the Shopping regions bear the Google-native and Netcompare labels,
with the Google-native labeled region on top). We also flipped the order of the
Shopping regions (i.e., putting the Netcompare Shopping region on top).
Finally, we experimented with the labels.78 To avoid excessive variation, the
78. We tested the Google-native label and the Google-tweaked label against the full Netcompare label for London Fog, and the Google-native label and the Google-tweaked label against a
shortened version of the Netcompare label for Nikon camera.

356

55 JURIMETRICS

Electronic copy available at: https://ssrn.com/abstract=2260942

Search Bias and the Limits of Antitrust
same content (i.e., pictures of five specific cameras and links to each) appeared in both the Netcompare and Google Shopping regions, but the cameras
were displayed in a different order in different images.
Figure 5. Nikon Camera SRP with both Google-Tweaked
and Netcompare Shopping Regions (Enlarged Label)

As noted previously, Google Shopping was in the right-hand column in
the 1st survey/simulation and the center column in the 2nd survey/simulation,
functioning as an additional architectural variation. Finally, in the 2nd survey/simulation, respondents saw an image with the Google Shopping region
removed entirely.

SPRING 2015

Electronic copy available at: https://ssrn.com/abstract=2260942

357

Hyman & Franklyn
Table 1 summarizes the variations we tested. Check marks indicate the
number of variations tested for each survey/simulation.
Table 1. Images Shown To Survey/Simulation Respondents
Shopping Labels Tested
Google Native
Google “Tweaked”
Netcompare
Google Native + Netcompare
Google “Tweaked” + Netcompare
No Google Shopping region
Total Image Variations Tested

Survey/Simulation
1st
2nd
√
√
√
√
√
√
√
√√
√√
√√
√
6
8

Google native = “Shop for nikon camera on google” or “Shop for london fog on Google.” Google
“tweaked” = “Paid ads for nikon camera by Google Comparison ShoppingTm” and “Paid ads for
london fog by Google Comparison ShoppingTm.” Netcompare = “Paid ads for nikon camera by
Netcompare ShoppingTm” and “Paid ads for london fog by Netcompare ShoppingTm.” “√” = image
shown to respondents. “√√” = 2 images shown to respondents -- Google Shopping on top v.
Netcompare on top, when both Shopping regions are shown. “√” for Google Native + Netcompare
= Google Shopping on top when both are shown.

After respondents viewed all the SRP variations listed in Table 1, they were
shown an image of an SRP with each section labeled, and asked to identify
which sections contained paid content. Respondents saw three SRPs, differing
in the labeling of the Shopping region (i.e., we tested the Google-native,
Google-tweaked, and Netcompare labels). We then asked respondents whether
they recalled seeing certain labels during the course of the survey/simulation.
The final set of questions requested demographic information.

B. Findings
1. Ad-Blocker Usage and Baseline Label Knowledge
Table 1 provides some basic statistics on completion rates and the significance of ad-blocker software. Both surveys/simulations had an unusually high
initial drop-out rate. More than half of those who were invited to participate
and clicked through declined to proceed after they were told they would need
to disable their ad-blocker software.79 The firm we used to administer the
survey/simulation indicated that its usual drop-out rate is approximately 25–
33%. It is unclear how many of those who dropped out did so because they use
ad blocker and did not wish to turn it off, or do not use ad blocker but were put
off by a survey/simulation that requested them to disable something on their
computer.80
79. We excluded respondents who would not turn off ad-blocker software from our survey
because we believed the software might interfere with the rendering of the Google Shopping
region for some (but not all) respondents.
80. In subsequent research, we found similar drop-out rates even when we did not require
respondents to turn off ad blocker.

358

55 JURIMETRICS

Electronic copy available at: https://ssrn.com/abstract=2260942

Search Bias and the Limits of Antitrust
Table 2. Completion Rates
Survey/Simulation

1st

2nd

Feb. 2013

Mar. 2013

Respondents that initiated survey/simulation

4,491

3,325

Quit after learning they had to disable ad blocker

2,470

1,895

770

605

Completed

1,251

825

Usable (t>5 minutes, and all questions completed)

1,098

747

Use ad-blocker software (% of usable)
Completion rate
Usable completion rate

23%
62%
54%

21%
58%
52%

Date fielded

Initiated but did not complete

Basic statistics on those who initiated and completed surveys/simulations conducted during February and March 2013. Respondents that “quit after learning they had to disable ad blocker” did
not submit responses to any questions. In two instances, the survey/simulation results reported a
single stray answer; those respondents were treated as “quit after learning they had to disable Ad
blocker.” “Completed” means respondents clicked through to the end , even if they did not answer
each question. “Usable” is limited to those who answered all questions, and took at least five
minutes to complete. Mean (median) completion time for usable surveys/simulations was 14
minutes (12 minutes). Completion rate = Completed/(Initiated but did not complete + Completed).
Usable completion rate = Usable/(Initiated but did not complete + Completed).

Regardless, as Table 2 indicates, roughly 22% of those who completed the
survey/simulation use ad-blocker software. We consider this figure to be a
plausible lower-bound estimate of the percentage of the general population
employing ad-blocker software.81
We excluded respondents who did not take at least five minutes to complete the survey/simulation on the grounds they were probably not taking the
questions seriously. However, our results are not materially affected by
whether we include or exclude such individuals. Once we exclude those who
did not answer a single question and those with nonusable results (because
they did not answer all questions or completed the survey/simulation too
quickly), the completion rate was 54% in the 1st survey/simulation and 52% in
the 2nd survey/simulation. If everyone that completed the survey/simulation is
included, regardless of how long they took and regardless of whether they
answered each question, the response rate rises to 62% in the 1st survey/simulation and 58% in the 2nd survey/simulation.

81. We think this is a lower-bound estimate because we assumed those who opted out of the
surveys after being asked to turn off their ad-blocker software were at least as likely to use ad
blocker as those who ultimately participated in the surveys.

SPRING 2015

Electronic copy available at: https://ssrn.com/abstract=2260942

359

Hyman & Franklyn
Table 3 presents respondents’ self-reported preferred search engine and
their degree of familiarity with how search results are organized and labeled.
Table 3. Search Engine Preferences and Familiarity with Output
Survey/simulation
Preferred Search Engine
Bing
Google
Yahoo
Other

1st

2nd

10%
72%
14%
5%

9%
76%
12%
3%

Familiarity with Search Results Organization/Labeling
Extremely familiar
16%
Very familiar
25%
Moderately familiar
33%
Slightly familiar
15%
Not at all familiar
11%

14%
25%
33%
16%
12%

Basic statistics on preferred search engine and familiarity with search results, organization, and
labeling for those who participated in 1st and 2nd surveys/simulations (conducted during February and March 2013), limited to those with usable responses.

As expected, Google is the clear favorite, with Yahoo and Bing a distant second and third respectively. We found a broad range of self-reported familiarity
with the organization and labeling of search engine results, with 72–74% of
respondents indicating they were moderately, very, or extremely familiar.
Interestingly, more sophisticated users are more likely to use ad blocking
software. Although Table 2 shows an overall ad-blocker usage rate of 22%,
when we analyzed usage by self-reported familiarity with the organization and
labeling of search results, we found only 11% of respondents who selfreported they were “not at all familiar” with the way search results are organized and labeled used ad blocker, compared to 33% of respondents who selfreported that they were “extremely familiar.”
To what extent do respondents actually notice labels? Respondents were
asked whether they had seen six specific labels in the past month or two of
Internet usage. Table 4 presents the results. The labels that were actually in use
during this period are set in boldface.

360

55 JURIMETRICS

Electronic copy available at: https://ssrn.com/abstract=2260942

Search Bias and the Limits of Antitrust
Table 4. Label Recollection
Label
Ads
Commercial Ads
Sponsored Results
Sponsored Links
Shop for [what you searched for] on [Name of Search Engine]
Products on [Name of Search Engine] Shopping
I have not noticed any labels.

% Recall
40%
26%
39%
48%
26%
19%
19%

Recollection of labels seen in the last month or two before the survey/simulation date, for both
1st and 2nd survey/simulation combined, and for those with usable survey/simulation responses.
Labels in actual use during the period in question are bolded. Respondents could select more than
one label, so results sum to more than 100%.

Confirming our earlier work on this subject, Table 4 indicates that respondents
pay little attention to the labels being used by search engines to indicate paid
content.82 The single most popular response, chosen by 48% of all respondents, was a label that had not been in use since November 2010 (i.e., “Sponsored Links”).83 Only 40% of respondents chose the label currently used by
Google to mark non-Shopping paid content (“Ads”) and far fewer chose the
labels currently used by Google Shopping and Yahoo Shopping (26% and
19% respectively).84 Thirty-nine percent of people chose a label used only by
Yahoo (“Sponsored Results”), even though only 13% of respondents identified
Yahoo as their preferred search engine.85 Almost 20% of respondents admitted
they had not noticed any labels. Finally, 26% of respondents reported seeing a
label that has never been used (“Commercial Ads”).

2. Baseline Click-Through Behavior
To assess the impact of architecture and labeling on behavior, it is necessary to set a baseline. Table 5 presents the results when we asked respondents
to click on a link if they were seeking to obtain information (“looking”) or
purchase the specified product (“buying”), and it computes the difference
when Google Shopping is located in the center column versus the right column
of the SRP. For ease of analysis, Table 5 and subsequent tables combine the
results for Nikon camera and London Fog, although we note below when we
observe material differences.
82. See Franklyn & Hyman, Trademarks as Keywords, supra note 8, at 484.
83. As noted above, Google brought back the term “Sponsored” in May 2012 for use in
labeling the Google Shopping region. Thus, the word “Sponsored” was not used at all from November 2010 to May 2012. Since May 2012, it has not been used with the word “Links.” See
supra note 77 and accompanying text. And, it is one of two labels on the Google Shopping region.
We discuss the implications of our findings with regard to “Sponsored Links” below.
84. Google uses “Shop for [what you searched for] on Google” to label the Google Shopping
region. Yahoo uses “Products on Yahoo Shopping” to label the Yahoo Shopping region.
85. It is possible that survey participants were responding to the use of the word “Sponsored,” which was used by Google to designate paid content (“Sponsored Links”) before November 2010, and then used since May 2012 to designate the Google Shopping region.

SPRING 2015

Electronic copy available at: https://ssrn.com/abstract=2260942

361

Hyman & Franklyn
Table 5. Click-Through by SRP Region: Looking versus Buying
Search Behavior
Google Shopping
Location

Looking

Buying

Center

Right

Center

Right

Algorithmic Links

58%

65%

47%

55%

Non-Shopping Paid Ads

33%

28%

39%

37%

Google Shopping

7%

4%

13%

7%

Other Links

2%

2%

1%

2%

Difference (Center – Right)
Looking
∆
Algorithmic Links

-7%

Non-Shopping Paid Ads

5%

Google Shopping

3%

Other Links

0%

t-stat
(p-value)
-3.22
(0.00)
2.20
(0.03)
2.62
(0.01)
0.35
(0.73)

Buying
∆
-7%
2%
6%
-1%

t-stat
(p value)
-3.03
(0.00)
0.89
(0.38)
4.41
(0.00)
1.56
(0.12)

Percentage of click-through for identified regions of the SRP in the 1st and 2nd surveys/simulations, in response to questions on location that respondents would click on if they
were interested in obtaining information about the specified product (Nikon camera or London
Fog) or buying the specified product. Limited to usable surveys. Non-Shopping Paid = region of
the SRP marked as Ads, whether located in the colored box on top of the center column or on the
right-side column of search results.

As Table 5 indicates, respondents were most likely to click on algorithmic
links, whether the question was about looking or buying, and whether Google
Shopping was located in the center column or in the right column of the SRP.
However, CTRs on Google Shopping were much higher when it was placed in
the center column of the SRP, whether the question was about looking or
buying.86 Although the absolute frequency of clicks on Google Shopping was
modest, the percentages for “buying” were almost double those for “looking.”87 The differences in CTRs when Google Shopping is in the center column versus the right column are statistically significant for algorithmic links

86. For those who were looking, 58% clicked on algorithmic links when Google Shopping
was in the center column versus 65% when Google Shopping was in the right column. For those
who were buying, 47% clicked on algorithmic links when Google Shopping was in the center
column versus 55% when Google Shopping was in the right column.
87. For those who were looking, 7% clicked on Google Shopping when it was in the center
column versus 4% when it was in the right column. For those who were buying, 13% clicked on
Google Shopping when it was in the center column versus 7% when it was in the right column.

362

55 JURIMETRICS

Electronic copy available at: https://ssrn.com/abstract=2260942

Search Bias and the Limits of Antitrust
and Google Shopping, and for Non-Shopping Paid Ads for looking (but not
buying).88
In unreported analysis, we do observe some statistically significant differences in the click-through patterns for Non-Shopping Paid Ads and algorithmic links for respondents who saw the Nikon SRP versus the London Fog
SRP. In both the 1st and 2nd survey/simulation, we find a substantially higher
CTR on Non-Shopping Paid Ads (and a reduction in CTR on algorithmic
links) for Nikon camera, compared to the CTRs for London Fog.89 We suspect
this is because the colored paid ads region in the center column of the Nikon
camera SRP (Figure 1) has three links, while the same region in the London
Fog SRP (Figure 2) only has one link.90

3. Effect of Labeling and Architecture on Click-Through
We first present results for the images that had a single Shopping region
(whether Google or Netcompare Shopping). Table 6 presents the results for
four different scenarios: (1) Google-native label, (2) Google-tweaked label, (3)
Netcompare, and (4) no Shopping region whatsoever.

88. When we compare click-through rates (CTRs) for information versus buying in the 1st
and 2nd surveys, we find the differences (decreases for algorithmic links, and increases for nonShopping paid ads, and Google Shopping) are statistically significant at a level of p <0.01.
89. In the 1st survey, for Nikon camera, the CTR for Non-Shopping Paid Ads (looking) was
36%, versus 46% for buying. For London Fog, the corresponding figures were 20% and 27%. In
the 2nd Survey, for Nikon camera, the CTR for Non-Shopping Paid Ads (looking) was again 36%,
versus 46% for buying. For London Fog, the corresponding figures were 27% and 31%. All of
these differences were statistically significant at a level of p < 0.01.
90. Cf. supra Figures 1 and 2. When we examine CTRs on a per-link basis, we find roughly
comparable click-through frequency for the first paid ad in the center colored region of the SRP
for both Nikon camera and London Fog. Thus, the higher CTR for Nikon camera compared to
London Fog is likely attributable to the presence of the 2nd and 3rd links in the center colored
region of the SRP for Nikon camera.

SPRING 2015

Electronic copy available at: https://ssrn.com/abstract=2260942

363

Hyman & Franklyn
Table 6. Click-Through Rates—Single Shopping Region
Variation

1

2

3

4

Shopping Label

Google

Google

Netcompare

None

Label Version

Native

Tweaked

1st Survey/Simulation - Google Shopping in right column
Algorithmic

55%

57%

55%

-

Non-Shopping Paid Ads
Google
Shopping
Netcompare

37%

33%

34%

-

7%

10%

-

-

-

-

11%

-

Other

2%

1%

1%

-

2nd Survey/Simulation - Google Shopping in center column
Algorithmic

47%

48%

46%

58%

Non-Shopping Paid Ads
Google
Shopping
Netcompare

39%

36%

40%

41%

13%

15%

-

1%

-

-

13%

-

Other

1%

1%

1%

1%

Percentage of click-through for identified regions of the SRP when respondents were asked where
they would click if they were interested in buying the specified product (Nikon camera or London
Fog). Limited to usable surveys/simulations. Non-Shopping Paid Ads = region of the SRP marked
as ads, whether located in the colored box on top of the center column or on the right side column
of search results. Shopping label refers to whether the Shopping region bears label of Googlenative, Google-tweaked, Netcompare, or is missing entirely (2nd survey/simulation only). Label
version refers to whether the Google label is native or tweaked, as defined above. The 1st
survey/simulation had 1,098 usable responses. The 2nd survey/simulation had 747 usable
responses. All percentages are relative to those figures.

Table 6 reveals several significant findings. First, modifying the Google
Shopping label to make it crystal clear that this region includes paid content
does not materially affect click-through frequency.91 Second, changing the
label to a fanciful control (Netcompare) does not materially affect the CTR.92
Third, the CTR on the Shopping region is substantially higher when it is in the
center column of the SRP, compared to when it is in the right column of the
SRP.93 Finally, when Google Shopping is absent, most of those who would
have otherwise clicked on Google Shopping instead click on an algorithmic

91. In the 1st survey, the CTR for Google-native was 7% and the CTR for Google-tweaked
was 10%. In the 2nd survey, the CTR for Google-native was 13% and the CTR for Googletweaked was 15%. These differences are not statistically significant.
92. In the 1st survey, the CTR for Netcompare was 11%. In the 2nd survey, the CTR was
13%. These figures are similar to those for both the Google-native and Google-tweaked labels, and
the difference is not statistically significant.
93. When the Shopping region was in the center column, the CTR ranged from 13–15%.
When it was in the right column, the CTR ranged from 7-11%. The differences between CTRs on
the Shopping region in the 1st survey versus the 2nd survey were statistically significant for
Google native and Google Shopping but not for Netcompare.

364

55 JURIMETRICS

Electronic copy available at: https://ssrn.com/abstract=2260942

Search Bias and the Limits of Antitrust
link.94 Taken together, these findings suggest that consumer decision making
(and CTRs) are driven more by the architecture and layout of the SRP (i.e., the
location of the shopping region) than by the way in which specific regions of
the SRP are labeled.
To probe this issue further, we also tested SRPs with both the Google
Shopping and Netcompare Shopping regions—and alternated which Shopping
region was on top and which label was used to indicate the Google Shopping
region. Table 7 presents CTRs for the Shopping regions under each of these
scenarios.95
Table 7. Click-Through Rates—Dual Shopping Regions
Variation

1

Google Label Version
Region on top?

Shopping

Shopping

2

3

Native
Google

Netcompare

4
Tweaked

Google

1st Survey/Simulation - Google Shopping on Right Side
Google
12%
10%
Netcompare
4%
4%
2nd Survey/Simulation – Google Shopping in Center
Google
20%
10%
14%
Netcompare
7%
13%
7%

Netcompare

5%
9%

5%
17%

Percentage of click-through for identified regions of the SRP when respondents were asked where
they would click if they were interested in buying the specified product (Nikon camera or London
Fog). Limited to usable surveys/simulations. Two Shopping regions appear in each tested image.
“Region on top” refers to which Shopping region label (i.e., Google-native, Google-tweaked, or
Netcompare) is on top when two Shopping regions are displayed. Non-Shopping Paid = region of
the SRP marked as Ads, whether located in the colored box on top of the center column or on the
right side column of search results. The 1st survey/simulation had 1,098 usable responses. The
2nd survey/simulation had 747 usable responses. All percentages are relative to those figures.

94. In the 2nd survey/simulation, averaging across all labeling variations, when the Shopping
region is present, roughly 47% of respondents clicked on an algorithmic link, 38% clicked on a
Non-Shopping paid link, and 14% clicked on a Shopping link. When the Shopping region was
removed, those 14% had to go somewhere—and almost 80% of them clicked on an algorithmic
link. The 80% figure is calculated as follows: first, compare the CTR on algorithmic links when
Google Shopping is absent versus present (58% - 47% = 11%). Then, divide that by the CTR on
Google Shopping when it is present (14%). 11%/14% = 78.6%.
We did not test CTRs on a SRP without Google Shopping as part of the 1st survey/
simulation. However, if we assume the same algorithmic CTR as in the 2nd survey/simulation,
that would mean that roughly 43% of those who previously clicked on Google Shopping ((58% 55%)/7%) would click on an algorithmic link if Google Shopping did not appear on the SRP.
95. In the interest of simplicity, Table 7 omits CTRs on the other regions of the SRP. In the
1st survey/simulation, with Google Shopping on the right side, algorithmic links accounted for
55% of clicks and Non-Shopping Paid Ads accounted for 30% of clicks across all tested variations. In the 2nd survey/simulation, with Google Shopping in the center, algorithmic links accounted for 37–42% of clicks and Non-Shopping Paid Ads accounted for 35–38% of clicks,
depending on the tested variation.

SPRING 2015

Electronic copy available at: https://ssrn.com/abstract=2260942

365

Hyman & Franklyn
Table 7 confirms and extends the findings in Table 6 that architecture
dominates labeling. In the 1st survey/simulation (where Shopping is on the
right side of the SRP), the top Shopping region gets 9–12% of click-through
(mean = 10%), and the bottom Shopping region gets 4–5% of click-through
(mean = 4%). In the 2nd survey/simulation (where the Shopping region is in
the center column of the SRP), the top Shopping region gets 13–20% of clickthroughs (mean = 16%), and the bottom Shopping region gets 5–10% of clickthroughs (mean = 7%). These patterns hold, irrespective of labeling.96 Stated
differently, across our entire sample, the top Shopping region gets roughly 2.4
times as many clicks as the bottom Shopping region, independent of the location of the Shopping region on the SRP, and independent of how each Shopping region is labeled.

4. Label Effectiveness
How effective are the labels on the SRP at communicating information?
Our previous research indicated that consumers paid little attention to labels
on search output.97 Table 4 makes it clear that respondents’ recollection of
labels currently in use is poor. But, this does not mean that “better” labels will
be equally ineffective, nor should one assume that respondents are unable to
differentiate between paid and unpaid content because they cannot properly
recall labels that are currently in use. Accordingly, the study tested whether
respondents were able to identify which sections of the search page were paid
or unpaid. We presented respondents with a version of Figure 1 or Figure 2, in
which four regions of the SRP (right-side ads, center ads, Google Shopping,
and Algorithmic links) were labeled with superimposed letters.98 For each
region, respondents were asked whether the specified region contained unpaid
algorithmic content, paid content, unpaid content selected for them by
Google’s special marketing team (a fanciful control that we invented), or don’t
know/not sure.
Table 8 presents the results for the three regions containing paid content
(i.e., right-side ads, center ads, and Google Shopping). To simplify the
presentation, Table 8 only provides percentages for those who correctly indicated the content was paid.99

96. In the 2nd survey, where we have paired Google native/Google tweaked and Google
native/Netcompare, with Google native on top and bottom in each, we find a statistically significant increase in CTRs from being on top, irrespective of labeling. We find no statistically
significant impact on the CTR on algorithmic and Non-Shopping Paid Ads.
97. See Franklyn & Hyman, Trademarks as Keywords, supra note 8, at 484.
98. We tested both the Google-native and the Google-tweaked labels. Examples of the
images that were shown are available from the authors on request.
99. Thus, Table 8 does not provide a breakdown of the percentages for those who believed a
region containing paid content was instead (i) unpaid links selected by Google’s Special Marketing Team (our fanciful control); (ii) algorithmic content; or (iii) selected “don’t know/not sure.”
Across both surveys, roughly 19% of respondents selected the fanciful control (Google’s Special
Marketing Team), 16% selected algorithmic content, and 13% selected don’t know/not sure.

366

55 JURIMETRICS

Electronic copy available at: https://ssrn.com/abstract=2260942

Search Bias and the Limits of Antitrust
Table 8: Correctly Identified Paid Regions of SRP?
Shopping Label
Type
Link

NonShopping
Paid Ads

Shopping

of

Location
(Column)

1st

Google-Native
51%

GoogleTweaked
54%

2nd

49%

54%

1st

56%

54%

2nd

54%

56%

Right

1st

47%

55%

Center

2nd

31%

36%

Right

Center

Survey/Simulation

Percentage that correctly answered whether the specified region of the SRP in the 1st and 2nd
surveys/simulations was paid versus unpaid, with Shopping region labeled with either Googlenative or Google-tweaked labels. The 1st survey/simulation had 1,098 usable responses. The 2nd
survey/simulation had 747 usable responses. All percentages are relative to those figures.

As Table 8 indicates, respondents struggled to identify paid content. Averaging across both surveys/simulations and all paid regions, only 48% of respondents correctly identified whether a paid region was, in fact, paid. When
looking at cumulative performance the results were even worse, with only 13–
20% of respondents correctly identifying all three paid regions.100
Respondents did worse with Google Shopping than they did with the
center and right side Ads, but they did better with Google Shopping when it
was in the right column than when it was in the center column.101 This finding
likely reflects the impact of consumer expectations regarding architecture,
with respondents assuming that the right-hand column of the SRP contains
paid content. Tweaking the Google Shopping label to make it obvious that it
included paid content increased the number of respondents that responded
correctly, but the figures are still unimpressive.102

100. If we limit ourselves to analyzing the SRP with the Google-native label for Google
Shopping, there are three regions in each of the 1st and 2nd surveys that include only paid content.
Only 20% of respondents correctly identified all three paid regions in the 1st survey, and only
13% of respondents did so in the 2nd survey. We discuss the extent to which demographic and
other factors predict better performance in identifying paid regions of the SRP in Part II.B.6, infra.
101. For Google Shopping, the percentage of correct responses (averaging Google native
and Google Shopping) was 51% when it was located in the right column and 34% when it was
located in the center column. For Ads, the corresponding results were 52% (right column) and
55% (center column).
102. As Table 8 reflects when Google Shopping was in the right column of the SRP, tweaking the label increased the percentage of correct responses from 47% to 55%. When Google
Shopping was in the center column, tweaking the label increases the percentage of correct responses from 31% to 36%. Although these increases are statistically significant, the level of overall performance is still modest.

SPRING 2015

Electronic copy available at: https://ssrn.com/abstract=2260942

367

Hyman & Franklyn
Finally, respondents were asked whether they could recall labels they seen
over the course of these survey/simulation. We provided respondents with
twelve separate labels: nine of which they had seen and three of which they
had not.103 Table 9 presents the responses to this question, combining both
surveys. Labels that were actually seen are bolded, as are the correct answers.
Table 9. Recollection of Labels
Label

Yes

No

Not sure

Shop for xx on Google

62%

21%

16%

Shop for xx on Netcompare Shopping™

33%

53%

14%

Ads

67%

21%

11%

Sponsored

54%

31%

15%

Google Comparison Shopping™

41%

43%

16%

Paid Ads

35%

47%

18%

Netcompare Shopping™

30%

54%

16%

Sponsored Links

64%

23%

13%

Commercial Ads

19%

58%

22%

Sponsored Results

48%

34%

18%

Shop for xx

72%

16%

12%

Paid ads for xx

26%

55%

19%

Table 9 provides additional evidence that respondents were not paying attention to labels. Despite repeated exposure, five of the eight labels that were
used were not noticed by a majority of respondents. And, a sizeable number of
respondents believed they had seen two labels that were not actually used (i.e.,
Sponsored Links and Sponsored Results).104 Averaged across all labels, only
48% of respondents remembered seeing a label that was used—while 44% of
respondents remembered seeing labels that were not used. However, compared
to Table 4, we observe across-the-board improvements in recall (i.e., increases
in the percentage of respondents that recalled seeing a label that was presented, and decreases in the percentage of respondents that recalled seeing a
label that was not presented). It remains to be seen how transient this improvement will turn out to be.

103. For purposes of this question, we treated partial labels (e.g., “Google Comparison
Shopping”) as a correct response.
104. Interestingly, more respondents thought they had seen a label that wasn’t used (“Sponsored Link”) than one that was used (“Sponsored”), even though both labels contained the word
“Sponsored.”

368

55 JURIMETRICS

Electronic copy available at: https://ssrn.com/abstract=2260942

Search Bias and the Limits of Antitrust

5. Search Strategies
Search bias might not matter as much if respondents do not use search
engines to locate products and services for purchase. Accordingly, we asked
respondents how they would search for the product they had been randomly
assigned as part of the survey/simulation. Table 10 provides the combined
results from both surveys/simulations and confirms our expectation that most
respondents do, in fact rely on search engines to locate products for purchase.
Table 10. Shopping Behavior by Search Preference
Preferred Search Engine
Preferred search strategy

Bing

Google

Yahoo

All

Google search
Search with preferred search
engine

15%

74%

17%

56%

42%

-

34%

12%

10%

10%

18%

11%

Amazon

27%

13%

20%

15%

eBay

3%

2%

7%

3%

Facebook

0%

0%

1%

0%

Other

3%

1%

4%

2%

Go to

Tm

owner website

Although we asked about “Other” preferred search strategies, we did not explicitly ask about specialized search engines, bookmarked sites, typing in
known URLs, web display advertising, mobile apps, and links from other
websites. It is possible that the percentages in Table 10 would be different if
some of these alternatives had been explicitly listed.
Even if users rely on search engines to identify products for purchase,
architecture and labeling might not affect CTRs if users ignore or pay little
attention to particular regions of the SRP. Accordingly, we asked respondents
whether they completely ignored or paid less attention to links in particular
regions of the SRP. Table 11 presents the results of this analysis. Because
respondents could select more than one response, the percentages in Table 11
sum to more than 100%.

SPRING 2015

Electronic copy available at: https://ssrn.com/abstract=2260942

369

Hyman & Franklyn
Table 11. Which Regions Do Respondents Ignore/Discount?
Completely ignore/pay much less
attention to:

1st
Survey/Simulation

2nd
Survey/Simulation

Algorithmic Links

6%

7%

Center Ads

35%

38%

Google Shopping

38%

22%

Right Ads

59%

62%

Treat all equally

29%

28%

Percentage of usable survey/simulation responses that reported completely ignoring
or paying much less attention to specified regions of SRP. Because respondents
could select more than one answer, the figures sum to more than 100%.

Table 11 indicates that most respondents paid more attention to algorithmic
links than to paid content, and an appreciable number ignored or discounted all
ads. Ad content in the right-hand column is particularly prone to be discounted
by respondents. Of course, we are unable to quantify the impact of selfreported willingness to ignore or pay less attention to particular regions of the
SRP on actual CTRs.

6. Regression Analysis
We conducted a Poisson regression to evaluate the extent to which various
factors predicted better (or worse) performance in identifying paid content.
Details of the regression are in Appendix B. We found that gender, race, education, age, and self-reported awareness of search results organization and
labeling correlate with the ability to correctly identify paid regions of the SRP,
and with recollection of labels encountered during the survey/simulation.
Marital status, the presence of children in the household, and region of residency had no discernable effect on the ability to correctly identify paid regions
or on label recollection.
To make these findings more accessible, we used the coefficients derived
from our regression analysis to estimate the extent to which individuals with
certain demographic attributes would know whether the three paid regions in a
typical SRP were paid (i.e., the issue addressed in Table 8). Consumer protection law requires that paid content be clearly and conspicuously labeled.105 Are
users aware whether links in a particular region of the SRP are paid content?
105. See generally FED. TRADE COMM’N, .COM DISCLOSURES: HOW TO MAKE EFFECTIVE
DISCLOSURES IN DIGITAL ADVERTISING, (2000), available at https://www.ftc.gov/system/files/
documents/plain-language/bus41-dot-com-disclosures-information-about-online-advertising.pdf (pertaining to clear and conspicuous disclosures in online advertising); Letter from Mary K. Engle,
Assoc. Dir. for Adver. Practices, Fed. Trade Comm’n (June 24, 2013), available at http://
www.ftc.gov/os/2013/06/130625searchenginegeneralletter.pdf (pertaining to the 2002 Search
Engine Letter issued by the FTC, advising search engines to distinguish advertising from natural
search results); Letter from Heather Hippsley, Acting Assoc. Dir., Div. of Adver. Practices, Fed.
Trade Comm’n, to Gary Ruskin, Exec. Dir., Commercial Alert (June 27, 2002), available at http://
www.ftc.gov/os/closings/staff/commercialalertletter.shtm (responding to a complaint requesting

370

55 JURIMETRICS

Electronic copy available at: https://ssrn.com/abstract=2260942

Search Bias and the Limits of Antitrust
We used four distinct scenarios: (1) white male, (2) white female, (3)
nonwhite male, and (4) nonwhite female. For each of these four scenarios, we
present two variations:
•
•

The individual has a masters or other graduate degree, and self-reports
that they are moderately familiar with the way search results are organized and labeled.
The individual has a high school degree or less, and self-reports that
they are unfamiliar with the way search results are organized and labeled.

Figure 6 provides the results of this analysis for all eight scenarios, presented
in terms of the percentage of correct answers for the three paid regions on the
SRP.
Figure 6. Frequency of Correct Responses on Which Regions Are Paid

As Figure 6 makes clear, there are substantial differences in the degree of
knowledge about which portions of the SRP are paid. Education and selfreported familiarity with the way in which search results are organized and
labeled have a particularly large impact. However, we also found material
differences along racial and gender grounds, with nonwhite males having the
lowest level of performance and white females having the highest level of
performance in identifying paid regions of the SRP. Figure 6 makes it clear
that even the most knowledgeable and sophisticated users are wrong about
which regions are paid at least 1/3rd of the time—and the least knowledgeable
and least sophisticated users are wrong at least 2/3rds of the time.

investigation of various search engines for ambiguous paid placement and paid inclusion programs).

SPRING 2015

Electronic copy available at: https://ssrn.com/abstract=2260942

371

Hyman & Franklyn

III. DISCUSSION
A. Google Shopping and the Logic of Vertical Integration
At one time, a Google search returned a pristine set of algorithmic links.
But, over time, Google has dramatically altered the appearance and substantive
content of the SRP. In part, the change is the result of adding vertical search
functions that are displayed above the algorithmic content. And, in part, the
change is the result of expanding the share of real estate devoted to paid content on the SRP. Google Shopping sits at the intersection of these two developments, so it provides an ideal foundation for our study of the impact of
architecture and labeling on consumer perceptions and behavior.
Strikingly, although Google Shopping occupies prime real estate (just
above the algorithmic links) and has visually rich content, at most 13% of
respondents clicked on it—with a much lower CTR when Google Shopping is
in the right column. However, a substantial majority of those who clicked on
Google Shopping would have clicked on an algorithmic link had Google
Shopping not been present. Additionally, past research indicates that users are
more likely to click to links closer to the top of the SRP. We take no position
on whether in light of these factors, the CTR on Google Shopping is too little,
too much, or just right—but our research does indicate that Google Shopping
is not disproportionately cannibalizing Google’s existing ads.
Vertical integration, of which Google’s move from ten blue links to universal search is an example, can be pro-competitive and beneficial to consumers.106 It remains to be seen whether Google Shopping is a pro-competitive
example of this phenomenon. Certainly, the European Commission does not
seem to think so.
The small number of respondents who click-through on Google Shopping,
despite its favorable location and visually rich appearance, and the sizeable
number of respondents who indicate they ignore or discount it suggest there
may be less to this dispute than the ferocity of complaints might suggest. Further research will be necessary to fully assess that issue.

B. Impact of Search Page Architecture and Labeling
Search page architecture has a substantial impact on consumer behavior.
Respondents expect to find paid content in the right-hand column and in the
top colored box in the center column. Respondents expect to find unpaid content in the center column below the colored box. The figures in Table 8 reflect
this dynamic: 47% of respondents thought Google Shopping was paid content

106. The literature on vertical integration is vast, and the issue lies beyond the scope of this
article. For a general overview, see Benjamin Klein et al., Vertical Integration, Appropriable
Rents, and the Competitive Contracting Process, 21 J.L. & Econ. 297 (1978); Oliver E.
Williamson, The Economics of Governance, 95 AM. ECON. REV. 1 (2005); Oliver E. Williamson,
The Vertical Integration of Production: Market Failure Considerations, 61 AM. ECON. REV. 112
(1971). For some empirical evidence on the subject, see Francine Lafontaine & Margaret Slade,
Vertical Integration and Firm Boundaries: The Evidence, 45 J. ECON. LIT. 629 (2007).

372

55 JURIMETRICS

Electronic copy available at: https://ssrn.com/abstract=2260942

Search Bias and the Limits of Antitrust
when it was in the right column, versus 31% when Google Shopping was in
the center column.
Respondents pay little attention to labels. Tweaking the label to make it
obvious that Google Shopping included paid content increased these figures
only modestly and did not materially affect CTRs.107 And, the single most
recalled label had not been used for more than two years at the time the surveys/simulations were conducted.108 An appreciable number of respondents
recalled seeing a label that has never been used.109 Finally, respondents’ ability
to correctly identify which regions of the SRP included paid content was low,
with worse results found among those with more limited education and less
familiarity with the way search results are organized and labeled. All of these
findings are consistent with extensive literature indicating that mandated disclosure often has no material impact, apart from unintended side effects.110
We did not test the impact of shading of selected SRP regions on consumer behavior, so are not able to say anything specific about that issue. Additionally, Google’s use of shading has changed over time.111 That said, our
working hypothesis is that shading, as long as it is dark enough to be readily
visible, should have a larger effect on consumer perceptions and behavior than
labeling, although not as large an effect as architecture.112 Empirical testing
will be necessary to confirm this hypothesis.
Regardless, if the goal is to clearly and conspicuously differentiate paid
and unpaid content, it is not obvious why some paid regions have long been
shaded, while others are not. Similarly, if the goal is to clearly and conspicu107. But see Benjamin Edelman & Duncan S. Gilchrist, Advertising Disclosures: Measuring
Labeling Alternatives in Internet Search Engines, 24 INFO. ECON. & POL’Y 75, 75–76 (2012)
(reporting results of an online experiment that demonstrated changing labels from “sponsored
links” and “ads” to “Paid Advertisements” reduced the CTR by 25–27%).
108. See supra Table 4; see also supra note 77. One might argue that respondents were
reacting to the use of the word “Sponsored,” and paid no attention to the word “Links.” This is
certainly plausible; Google began using the word Sponsored in May 2012 to label the Google
Shopping region. But, this point cuts both ways. If people are not paying attention to the presence
or absence of the word “Links,” they are not paying attention to the labels—which, after all, is our
point.
In addition, the question asked respondents about labels they had seen in the last month or
two. Only 26% of respondents reported seeing the Google Shopping label (i.e., “Shop for ‘what
you searched for’ on ‘name of search engine’”)—even though that label appears next to the
“Sponsored” label that 39%–48% of respondents reported seeing, either in association with “Results (39%) or Links (48%). Once again, this indicates respondents are not paying attention to the
labels that appear on the SRP.
109. See supra Table 4.
110. See supra note 56.
111. See, e.g., Graham Charlton, What Will Google’s Paid Search Ads Look Like in 2014?,
ECONSULTANCY (Nov. 14, 2013), https://econsultancy.com/blog/63793-what-will-google-s-paidsearch-ads-look-like-in-2014#i.1m7ipp315ce36x; Ben Edelman, Google’s Advertisement Labeling
in 2014 (Oct. 13, 2014), http://www.benedelman.org/adlabeling/google-colors-oct2014.html; Peter
J. Meyers, Future SERP: A Glimpse at Google 2014, MOZ BLOG (Nov. 14, 2013), http://moz.com/
blog/future-serp-a-glimpse-at-google-2014.
112. See Rolf Winkler, Ads Tied to Web Searches Criticized as Deceptive: FTC Has Pressed
Google, Yahoo, Microsoft to Comply with Requests to Highlight Paid Links, WALL ST. J. (Oct. 13,
2014 2:56 PM), http://www.wsj.com/articles/ads-tied-to-web-searches-criticized-as-deceptive-14132
26602.

SPRING 2015

Electronic copy available at: https://ssrn.com/abstract=2260942

373

Hyman & Franklyn
ously differentiate paid and unpaid content, it is not obvious why different
labels are used to indicate paid content in different regions of the SRP. This
hodgepodge of strategies undermines the goal of clearly and conspicuously
identifying paid content, and seems likely to lead to consumer confusion.
The fact that we find such a substantial effect from occupying the top spot
in the Shopping region indicates that spot may not be readily shareable—and,
shareability has long been an essential element of establishing a right to relief
under the essential facilities doctrine.113 But, in an online world, shareability
has both structural and temporal attributes that can be readily manipulated. In
another article, we test the shareability of the top spot, by splitting it in half
vertically, and randomly allocating the left half to either Google or its competitors. After observing the CTR, we then flip-flop the allocation, and test the
CTR again. This strategy has the potential to effectively create simultaneous
real-time shareability—albeit in a way that is quite different from the conventional understanding of shareable property.
To be sure, architectural, labeling, and shading strategies must be evaluated individually. One should not assume that labeling is never effective and
architecture and shading are always effective—or vice versa. That said, readers should not be optimistically biased about the likely efficacy of labeling for
influencing consumer knowledge and behavior. To the extent competition
policy has emphasized the importance of labeling, or assumed that clear labeling translates into consumer knowledge, our study provides considerable
ground for skepticism.

C. Ad Blocker
For technical reasons, our study deliberately excluded all respondents that
used ad-blocker software and would not turn it off. But, even the low-end
estimate of ad-blocker usage (21% of users) indicates that many consumers
have opted out of the ad-driven model that has sustained the two-sided market
in which search engines and websites compete. It remains to be seen how the
widespread use of ad blockers will affect the ability of search engines and
websites to continue to provide free content and services to users.114
113. See Lao, Search, Essential Facilities, and the Antitrust Duty to Deal, supra note 53, at
302–04 (“A monopolist is not required to ‘share,’ no matter how essential its facility may be to
competition, if ‘sharing would be impractical or would inhibit the defendant’s ability to serve its
customers adequately.’ . . . There is only one first-ranked position, one second-ranked, and so on.
Where a facility cannot accommodate both the monopolist-owner and its rival, the law is clear that
the monopolist does not have to ‘share,’ no matter how essential access may be to competition. If
there is no legal obligation to share in that situation, there would naturally be no need for the
search engine to adopt a ‘neutral’ standard for the allocation of the scarce resource—top-ranking.
Rather, the search engine has the right to use the non-sharable resource itself.” (citation omitted)).
114. See Josh Constine, OkCupid Asks Ad-Blocker Users to Go Ad-Free Forever for $5 with
This Smart, Funny Banner, TECHCRUNCH (Aug. 23, 2012), http://techcrunch.com/2012/08/23/
okcupid-ad-blocker. See generally Ken Fisher, Why Ad Blocking is devastating to the sites you
love, ARS TECHNICA (Mar. 6, 2010, 5:11 PM UTC), http://arstechnica.com/business/2010/03/whyad-blocking-is-devastating-to-the-sites-you-love/; Papa Niero, Half of Destructoid’s Readers
Block Our Ads. Now What? DESTRUCTOID (Mar. 9, 2013, 2:45 AM), http://www.destructoid.com/
half-of-destructoid-s-readers-block-our-ads-now-what--247904.phtml.

374

55 JURIMETRICS

Electronic copy available at: https://ssrn.com/abstract=2260942

Search Bias and the Limits of Antitrust

D. Consumer Protection in an Online World
Historically, consumer protection law has been based on a one-size-fits-all
standardized mandatory minimum approach. But, in an online world, it is
feasible to consider the possibility of less standardized consumer protections,
with individuals selecting the particular level of protection they deem appropriate. One can certainly imagine an approach that “nudges” consumers in the
direction of a particular set of default consumer protections, while allowing
those who do not value the default protections to opt out. Such strategies have
attracted interest from scholars of behavioral economics seeking a more
choice-protecting form of regulation, while simultaneously trying to reduce
opposition to the proposed regulations.
One obvious challenge in designing the nudges/choice architecture: how
should one deal with the reality that many consumers know little (and care
less) about the details of search page architecture and labeling? Attempts to
protect consumers against rational ignorance, whether through defaults or
otherwise, are unlikely to capture consumers’ true preferences, since they do
not have any. Instead, the choices that are made will reflect the preferences of
those responsible for designing the defaults/choice architecture. We should
stop pretending otherwise, the soothing claims of nudge/choice architecture
enthusiasts to the contrary.

E. Implications of Our Findings for Other Legal Issues
Most users were unable to consistently and reliably distinguish between
paid and unpaid content. This finding has implications for a number of other
emerging legal issues. Consider “native advertising,” in which paid content is
presented in ways that suggest it is unpaid editorial content.115 The FTC has
expressed concern about native advertising,116 and national advertising associations appear to be trying to preempt regulation by promulgating “best practices.”117 Our research suggests that the underlying problem (i.e., consumer
confusion about paid versus unpaid content) is likely to be a real one—and
that regulation to address it will prove to be difficult.
Our findings also suggest that labeling remedies, which have dominated
discussion of native advertising, are likely to prove ineffective. In addition, a
115. For a scathing review of native advertising, see Last Week Tonight with John Oliver:
Native Advertising (HBO cable broadcast Aug. 3, 2014) (1:35–3:27), available at https://www.
youtube.com/watch?v=E_F5GxCwizc.
116. Edward Wyatt, As Online Ads Look More Like News Articles, F.T.C. Warns Against
Deception, N.Y. TIMES, Dec. 5, 2013, at B2, available at http://www.nytimes.com/2013/12/05/
business/ftc-says-sponsored-online-ads-can-be-misleading.html?pagewanted=all&_r=0; See Press
Release, Federal Trade Comm’n, FTC Native Advertising Workshop on December 4, 2013 Will
Explore the Blurring of Digital Ads With Digital Content (Sept. 16, 2013), http://www.ftc.gov/
news-events/press-releases/2013/09/ftc-native-advertising-workshop-december-4-2013-will-explore.
117. Jon Carmen, Looking Ahead After the FTC Workshop on Native Advertising:
Publishers Need to Set a Standard, or Risk Regulation, AD AGE (Dec. 12, 2013), http://adage.com/
article/digitalnext/ftc-workshop-native-advertising-ahead/245656/; Alex Kantrowitz, Arguments
Fly During FTC Workshop on Native Advertising, AD AGE (Dec. 4, 2013), http://adage.com/
article/media/arguments-fly-ftc-workshop-native-advertising/245536/.

SPRING 2015

Electronic copy available at: https://ssrn.com/abstract=2260942

375

Hyman & Franklyn
material number of consumers do not seem to care whether content is paid or
unpaid—raising questions about the utility of standardized/universal approaches to consumer protection in this space. We are currently in the process
of completing a study of whether consumers know that native advertising is
paid content. We anticipate publishing our findings in a separate article.
Consumer confusion is also relevant to legal issues beyond native advertising. For example, to prove trademark infringement, one must show that
consumers are confused about the source, sponsorship, or affiliation of the
defendant’s goods or services (i.e., they believe that the defendants’ goods or
services are actually those of the plaintiff). If search results are presented and
labeled in ways that result in confusion about the source or sponsorship of
goods or services, it will certainly affect whether users can navigate the online
commercial environment with confidence and accuracy, and might well give
rise to a claim under federal trademark law. Intentional confusion or blurring
of the distinction between paid and unpaid search results might also give rise
to liability under the law of deceptive trade practices, unfair competition law,
or both.
The right of publicity (often invoked by celebrities and other famous
people) is implicated as well. Advertisers have been known to use the names
and likenesses of famous individuals in ways that suggest an endorsement of
particular products or services. In a search environment where there is blurring
of paid versus unpaid content, there is a significantly increased risk of creating
false and misleading associations between advertised products or services, and
targeted celebrity names and images. Celebrities that wish to protect their
rights of publicity may be forced to spend an increased amount of time and
money litigating these issues, compared to a world in which there is less blurring of paid versus unpaid content.
Finally, it is worth flagging the role of search engines and other entities in
the blurring of the distinction between paid and unpaid content. Consumer
perceptions are the result of deliberate decisions with regard to the architecture, labeling, and presentation of search results. Antitrust law has provided
the main framework for analysis of the issues considered in this article, but
consumer protection law almost certainly has something to say on the subject
as well.

F. Implications of Our Findings for Regulatory Intervention
Our study indicates that labeling remedies are unlikely to be effective,
while architectural remedies can have a substantial effect. These findings have
obvious implications for the framing of a workable remedy, conditional on a
finding that the law has been violated.
However, it is critical to understand that the availability of a workable
remedy does not imply that using that (or any other) remedy is a good idea.118
118. Skeptics should consider the psychological impact of being armed with a hammer on
the frequency with which one encounters nails, and other objects that are thought to require a good
hard pounding.

376

55 JURIMETRICS

Electronic copy available at: https://ssrn.com/abstract=2260942

Search Bias and the Limits of Antitrust
There are sizeable error costs with regulatory interventions, particularly in a
rapidly evolving field like search—and particularly when we are dealing with
architectural remedies. The preferences of regulators (however well informed
and public spirited they might be) are likely to differ—sometimes dramatically—from those of consumers. The limits of antitrust (and of those implementing the antitrust laws) are real.119 Platonic guardians are in short supply,
no matter how high the demand.120

G. Future Research
This study took the basic structure of the Google Shopping region as a
given, and only tested a limited set of architectural variations (right-side column versus center column; top versus bottom). We did not test shading or
more dramatic changes to the Google Shopping region, such as stripping out
the visually rich content of that region. As noted previously, the authors recently completed a study of several “Commitments” proposed by Google in its
settlement proposal to the European Commission, as well as other variations,
and anticipate publishing the results of that study separately.

H. Limitations of Our Work
All empirical work has limitations, and this study is no exception. Our
findings are only as good as the questions we asked. We rely on respondents to
answer questions honestly and accurately. We only tested two search terms –
both of which were for high-end, trademarked products. We only manipulated
the architecture and labeling of the Google Shopping region. We might obtain
different results with different search terms, or if we had modified other vertical search alternatives provided by Google. Although we simulated the experience of conducting a search and presented the variations on existing search
results in random order, these were not real searches. We did not directly observe real-world CTRs, let alone conduct A/B testing.
Finally, the study only tested initial CTRs. Assume that users click
through on Google Shopping (rather than on the link they would click in the
absence of Google Shopping), and do not find what they were expecting or
119. Frank H. Easterbrook, The Limits of Antitrust, 63 TEX. L. REV. 1, 39 (1984) (“Antitrust
is an imperfect tool for the regulation of competition. Imperfect because we rarely know the right
amount of competition there should be, because neither judges nor juries are particularly good at
handling complex economic arguments, and because many plaintiffs are interested in restraining
rather than promoting competition.”).
120. Cf. Richard H. Thaler, Level Playing Fields, in Soccer and Finance, N.Y. TIMES, July
25, 2010, at BU5 (“Consider the Consumer Financial Protection Bureau now being established.
Above all, I’d urge the head of this agency to devise rules under the assumption that, someday, he
or she will be succeeded by a nitwit.” (emphasis added)), available at http://www.nytimes.com/
2010/07/25/business/25view.html. Professor Mark Ramseyer has made a similar argument
regarding judges. J. Mark Ramseyer, Not-so-Ordinary Judges in Ordinary Courts: Teaching
Jordan v. Duff & Phelps, Inc., 120 HARV. L. REV. 1199, 1205–07 (2007) (“Judging is not a job for
unconstrained, innovative minds . . . appointing judges with the intelligence and creativity of
Easterbrook and Posner is—not to mince words—exactly what we should not be doing. As judges,
they simply do too much: they muddy the law in trying to fix it, and they worsen the law by
encouraging (through example) their less talented peers to do so as well.”).

SPRING 2015

Electronic copy available at: https://ssrn.com/abstract=2260942

377

Hyman & Franklyn
hoping to find. Will a material number of users click back or rerun the search
and then click on a different link (in which case the initial click on Google
Shopping causes delay but not permanent diversion)?121 Or will they “settle”
for what they find after they click on Google Shopping? Only the latter scenario seems likely to give rise to antitrust concerns, even under the more restrictive framework employed by the European Commission.
The complications do not end there. Determining whether those who do
not click back are “settling” is virtually impossible, given the absence of a
baseline against which their decisions can be measured. Finally, if a material
number of users click back or rerun their search, the amounts that advertisers
are willing to pay for inclusion in the Google Shopping region will be reduced—which may prompt Google to improve the quality of the results found
in Google Shopping, further undermining the claim for antitrust intervention.122 Further research will be necessary to determine how best to study the
impact of repeat interactions on CTRs.

The dispute over the diagnosis and treatment of search bias has involved a
great deal of spirited advocacy, but relatively little in the way of objective
evidence. For those who believe that search bias raises competition policy
concerns, our study provides insight into the complexities of search and the
degree to which architectural and labeling remedies are likely to be effective –
as well as pointing out some of the significant difficulties with crafting such
remedies. For those who are skeptical that search bias raises competition policy concerns, our study provides additional reasons to tread cautiously. For
people who have not yet made up their minds, our findings point to the central
role that SRP architecture plays in users’ mental processing of search results,
and the difficulties of dislodging consumer expectations that have become
effectively hardwired through repeated exposure.

121. Alternatively, they might switch to a different search engine, and rerun the search.
122. These matters are, of course complex. Cf. Edelman & Lai, supra note 70, at 29–30
(developing theoretical model for circumstances when a search engine will divert users to less
relevant results).

378

55 JURIMETRICS

Electronic copy available at: https://ssrn.com/abstract=2260942

Search Bias and the Limits of Antitrust

APPENDIX A. DEMOGRAPHICS OF RESPONDENTS
1st
Survey/Simulation

2nd
Survey/Simulation

18 – 24

13%

15%

25 – 34

19%

19%

34 – 44

18%

14%

45 – 54

21%

20%

55 – 64

18%

20%

65+

11%

11%

46%

47%

Age

Marital Status
Single
Married

45%

44%

Living together/Domestic partners

9%

9%

Race
Caucasian / White

78%

83%

African-American

11%

7%

Latino / Hispanic

8%

5%

Asian / Pacific Islander/Other

.

.

Income
Prefer not to say

4%

4%

Less than $25,000

21%

25%

$25,000–$49,999

29%

32%

$50,000–$74,999

23%

21%

$75,000–$99,999

13%

9%

$100,000–$199,999

10%

8%

$200,000+

1%

1%

West

21%

20%

Southwest

12%

8%

Midwest

23%

27%

Location

123

Southeast

24%

22%

Northeast

20%

23%

123. Demographics for survey respondents. West = AK, CA, CO, HI, ID, OR, MT, NV, UT,
WA, WY. Southwest = AZ, NM, OK, TX. Midwest = IA, IL, IN, KS, MI, MN, MO, NE, ND, OH,
SD, WI. Southeast = AL, AR, FL, GA, KY, LA, MS, NC, TN, SC, VA, WV. Northeast = CT, DE,
MA, MD, ME, NH, NJ, NY, PA, RI, VT.

SPRING 2015

Electronic copy available at: https://ssrn.com/abstract=2260942

379

Hyman & Franklyn

APPENDIX B. RESULTS OF THE POISSON REGRESSION
Poisson Regression
Dependent Variable: Number of Correct Paid Link Responses
(1)
(2)
(3)
Female
0.10**
0.12***
0.11**
(2.3)
(2.8)
(2.5)
Some college/JC/AA
Degree
0.24***
0.26***
0.23***
(4.5)
(4.8)
(4.3)
Completed BA/BS
0.27***
0.27***
0.26***
(4.7)
(4.5)
(4.6)
Completed MA/Other
graduate degree
0.43***
0.40***
0.41***
(6.6)
(5.8)
(6.3)
Age
-0.00
-0.00
-0.00
(-1.2)
(-1.0)
(-0.8)
Married Dummy
0.00
-0.01
-0.01
(0.1)
(-0.1)
(-0.1)
Child Dummy
-0.03
-0.04
-0.03
(-0.8)
(-1.1)
(-0.7)
White Dummy
0.22***
0.22***
0.22***
(4.0)
(4.0)
(4.0)
Southwest
-0.02
-0.04
-0.03
(-0.3)
(-0.5)
(-0.4)
Midwest
-0.09
-0.07
-0.09
(-1.6)
(-1.3)
(-1.5)
Southeast
-0.04
-0.05
-0.03
(-0.7)
(-0.9)
(-0.6)
Northeast
-0.11**
-0.12**
-0.10*
(-2.0)
(-2.1)
(-1.8)
Income
0.09
(1.3)
Slightly familiar
0.21***
(3.2)
Moderately familiar
0.17**
(2.4)
Very familiar
0.08
(0.9)
Extremely familiar
0.00
(1.6)
Elapse Time

(4)
0.10**
(2.4)
0.25***
(4.5)
0.28***
(4.9)
0.44***
(6.7)
-0.00
(-1.4)
-0.00
(-0.0)
-0.03
(-0.7)
0.22***
(4.1)
-0.02
(-0.3)
-0.08
(-1.4)
-0.03
(-0.5)
-0.10*
(-1.7)
0.08
(1.1)
0.21***
(3.1)
0.17**
(2.4)
0.07
(0.9)

Constant

-0.04
(-0.4)

-0.10
(-1.0)

-0.20*
(-1.8)

0.01***
(3.2)
-0.27**
(-2.3)

Observations

1,494

1,440

1,494

1,494

380

55 JURIMETRICS

Electronic copy available at: https://ssrn.com/abstract=2260942

