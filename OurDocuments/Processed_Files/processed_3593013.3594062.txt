stereotypes
moderated
under-moderated
search
engine
autocompletion
alina
leidinger
richard
rogers
university
amsterdam
institute
logic
language
computation
amsterdam
netherlands
a.j.leidinger@uva.nl
university
amsterdam
department
media
studies
amsterdam
netherlands
r.a.rogers@uva.nl
abstract
warning
paper
contains
content
may
offensive
upsetting
language
technologies
perpetuate
stereotypes
actively
cement
social
hierarchies
study
enquires
moderation
stereotypes
autocompletion
results
google
duckduckgo
yahoo
investigate
moderation
derogatory
stereotypes
social
groups
examining
content
sentiment
autocompletions
thereby
demonstrate
categories
highly
moderated
sexual
orientation
religious
affiliation
political
groups
communities
peoples
less
age
gender
overall
per
engine
found
under-moderated
categories
contain
results
negative
sentiment
derogatory
stereotypes
also
identify
distinctive
moderation
strategies
per
engine
google
duckduckgo
moderating
greatly
yahoo
permissive
research
implications
moderation
stereotypes
commercial
autocompletion
tools
well
large
language
models
nlp
particularly
question
content
deserving
moderation
specific
traits
exaggerating
google
however
inadvertently
engine
perpetuating
stereotypes
neglecting
moderation
compare
search
engines
yahoo
duckduckgo
stereotypes
reproduced
language
generation
autocompletion
task
constitute
representational
harm
14
cadwalladr
10
made
earliest
influential
findings
concerning
google
autocompletion
pointed
autocompletion
stereotypes
frame
also
distort
see
world
noble
48
went
arguing
stereotypical
racist
results
perpetuate
oppressive
social
relationships
indeed
vlasceanu
amodio
67
demonstrate
exposure
biased
google
image
search
results
reinforces
gender
stereotyping
professional
contexts
roy
et
al
56
link
exposure
autocompletions
psychological
process
incidental
learning
62
information
picked
unintentionally
subconsciously
often
course
another
information-seeking
activity
relatedly
miller
record
45
argue
autocompletions
induce
changes
epistemic
actions
can
harmful
45
especially
stereotypes
provide
ideological
ccs
concepts
information
systems
web
search
engines
applied
computing
arts
humanities
keywords
stereotypes
search
engine
autocompletion
google
autocompletion
content
moderation
debiasing
natural
language
generation
acm
reference
format
alina
leidinger
richard
rogers
2023
stereotypes
moderated
under-moderated
search
engine
autocompletion
2023
acm
conference
fairness
accountability
transparency
facct
23
june
12
15
2023
chicago
il
usa
acm
new
york
ny
usa
13
pages
https://doi.org/10.1145/3593013.3594062
introduction
stereotypes
defined
lippmann
40
pictures
heads
context
research
google
autocompletion
especially
reductionist
narrowing
person
thing
work
licensed
creative
commons
attribution
international
4.0
license
facct
23
june
12
15
2023
chicago
il
usa
2023
copyright
held
owner
author
acm
isbn
979
4007
0192
23
06
https://doi.org/10.1145/3593013.3594062
figure
autocompletions
google
top
yahoo
bottom
feb
1st
2023
screenshots
authors
1049
facct
23
june
12
15
2023
chicago
il
usa
leidinger
rogers
justification
maintain
social
hierarchies
marginalisation
google
somewhat
vague
autocompletion
content
moderation
works
stating
systems
aim
prevent
policyviolating
predictions
appearing
predictions
get
past
systems
re
made
aware
public
reporting
options
enforcement
teams
work
review
remove
appropriate
cases
remove
specific
prediction
question
often
use
pattern-matching
methods
catch
closely-related
variations
65
yahoo
less
expansive
google
autocompletion
content
moderation
policy
concerning
marginalised
groups
removing
suggestions
hate
rather
merely
offensive
speech
73
duckduckgo
specify
autocompletion
policy
apart
press
reports
company
blocks
offensive
returns
duckduckgo
licenses
autosuggestions
yahoo
31
following
analyse
moderation
practices
search
query
autocompletion
task
common
search
engines
proprietary
autocompletion
algorithms
publicly
available
state-of-the-art
language
models
58
59
75
given
active
rather
opaque
moderation
google
autocompletion
engines
study
pose
following
research
questions
social
groups
autocompletions
suppressed
otherwise
moderated
google
yahoo
duckduckgo
autocompletions
full
list
150
social
groups
queried
see
table
autocompletions
groups
study
sentiment
characterised
particularly
negative
may
one
portray
moderation
stereotypes
autocompletion
engine
certain
engines
stricter
permissive
others
contributions
make
prompting
stereotype-eliciting
queries
concerning
approximately
150
terms
social
groups
see
table
three
engines
based
broadly
age
gender
lifestyle
political
orientation
peoples
religion
sexual
orientation
examining
extent
suppression
forms
moderation
undertook
queries
order
gain
sense
autocompletions
complete
otherwise
show
signs
moderation
discuss
stereotypes
categories
social
groups
receive
types
suppression
moderation
thereby
charting
work
engines
thwart
outputs
scoring
groups
moderation
stereotypes
also
shed
light
group
stereotypes
considered
rather
sensitive
search
engine
given
removal
editing
thereby
able
characterise
result
moderation
overall
per
search
engine
study
findings
inform
work
content
moderation
policy
whether
autocompletion
nlp
generally
particularly
drawing
attention
under-moderated
categories
negative
suggestions
light
harmful
impact
stereotype
perpetuation
believe
public
discourse
moderation
priorities
well
transparent
documentation
parts
commercial
language
technology
providers
crucial
1050
related
work
2.1
content
moderation
search
engine
autocompletion
studies
focus
google
results
moderation
rather
engines
given
market
dominance
33
55
content
moderation
defined
grimmelmann
30
governance
mechanisms
structure
participation
community
facilitate
cooperation
prevent
abuse
previous
work
moderation
especially
google
autocompletion
concerned
prone
outputting
derogatory
content
jews
evil
autocompletion
part
brackets
10
indeed
journalists
scholars
alike
reported
particularly
shocking
outputs
queries
women
72
old
men
old
women
55
religions
10
sexual
orientation
gender
identity
others
generally
speaking
2016
google
product
outputs
web
search
autocompletion
described
organic
company
reflections
however
unpleasant
happening
web
10
press
reports
noticeable
emergency
take-down
patches
25
autocompletion
generally
however
results
came
disclaimers
banner
ads
explanation
blog
posts
response
press
concerning
reflected
happening
across
web
23
state
affairs
changed
introduction
autocompletion
feedback
tool
2017
users
report
content
considered
hateful
racist
offensive
vulgar
sexually
explicit
harmful
dangerous
violent
misleading
inaccurate
27
2018
danny
sullivan
company
public
search
liaison
explained
long
blog
post
company
autocompletion
removal
policies
63
pointing
google
definition
inappropriate
content
particularly
derogatory
output
relating
engine
removes
autocompletions
hateful
prejudicial
respect
race
ethnic
origin
religion
disability
age
nationality
veteran
status
sexual
orientation
gender
gender
identity
characteristic
associated
systemic
discrimination
marginalisation
behind
need
moderation
autocompletion
well
suggestions
predictions
appear
search
engine
products
liabilities
arise
outputting
words
connected
incipient
search
query
defame
individuals
12
induce
illegal
acts
downloading
copyrighted
material
36
lead
sources
child
pornography
illicit
material
18
contain
hateful
language
towards
groups
20
google
defines
inappropriate
content
moderated
relates
directly
legal
liabilities
29
group
stereotyping
however
grey
area
fall
moderation
sullivan
describes
offensive
content
64
design
choices
respect
moderation
stereotypes
detailed
company
constitute
object
study
work
place
work
alongside
algorithmic
auditing
51
57
platform
observability
53
ethical
hacking
vulnerabilities
well
commercial
content
moderation
critique
26
54
though
approaches
somewhat
different
emphases
stereotype
moderation
search
engine
autocompletion
facct
23
june
12
15
2023
chicago
il
usa
table
list
groups
targeted
stereotypes
english
category
group
age
boomers
children
kids
millennials
old
men
old
people
old
women
teenagers
teens
gender
gender
identity
gendered
girls
women
men
females
males
boys
boyfriends
girlfriends
stepmothers
stepfathers
ladies
gentlemen
brothers
sisters
mothers
fathers
grandfathers
grandmothers
wives
husbands
schoolgirls
schoolboys
transgenders
23
lifestyle
way
liv
feminists
frat
boys
geeks
goths
hippies
hipsters
nerds
punks
sorority
girls
celebrities
criminals
ing
homeless
people
poor
people
rich
people
14
political
politicised
capitalists
communists
conservatives
immigrants
liberals
populists
socialists
trump
supporters
peoples
ethnicities
africans
asians
asian
kids
asian
men
asian
parents
asian
women
african
americans
black
americans
blacks
black
fathers
black
kids
black
men
black
parents
black
people
black
women
europeans
hispanics
hispanic
men
hispanic
women
latinas
latinos
latin
people
native
americans
whites
white
americans
white
kids
white
men
white
parents
white
people
white
women
redheads
gingers
blondes
32
nationalities
americans
afghans
albanians
arabs
australians
austrians
bengalis
british
people
chileans
colombians
dutch
people
egyptians
ecuadorians
ethiopians
finns
french
people
germans
ghanaians
greeks
indians
indonesians
iranians
iraqis
irish
people
italians
koreans
lebanese
people
mexicans
moroccans
nepalis
nigerians
norwegians
pakistanis
polish
people
romanians
russians
scots
somalis
south
africans
sudanese
people
swedes
syrians
taiwanese
people
turkish
people
ukrainians
venezuelans
vietnamese
people
47
religion
atheists
buddhists
catholics
christians
hindus
jews
mormons
muslims
protestants
religious
people
sikhs
11
sexual
orientation
total
asexual
people
bisexual
people
gay
people
homosexuals
lesbians
pansexual
people
queer
people
151
2.2
total
content
moderation
language
models
search
engine
autocompletion
one
real-world
application
language
modelling
lm
natural
language
generation
nlg
demonstrated
suffer
undesirable
biases
60
70
methodologically
bias
quantified
using
intrinsic
measures
11
66
operate
word
embeddings
extrinsic
measures
examine
bias
manifests
downstream
tasks
sentiment
analysis
34
37
hate
speech
detection
19
52
measuring
stereotypes
particular
bias
benchmarks
consisting
contrasting
sentence
pairs
stereoset
46
crows-pairs
47
proposed
open-ended
language
generation
prompts
often
used
assess
extent
lms
yield
undesirable
output
various
benchmarks
bold
17
honest
49
holisticbias
61
realtoxicityprompts
24
exist
purpose
choenni
et
al
13
prompt
language
models
assess
extent
learnt
stereotypes
contrast
work
use
search
engine
autocompletions
proxy
stereotypes
existing
real
world
compare
lm
output
early
methods
measuring
bias
stereotypes
mainly
focused
gender
11
recently
field
turned
attention
1051
also
towards
harms
groups
based
disability
status
35
gender
identity
16
race
22
43
religion
42
mitigation
efforts
nlp
include
debiasing
methods
intervene
produce
less
biased
stereotyping
output
21
28
69
74
lm
output
can
also
flagged
harmful
using
manual
inspection
60
lexicons
49
another
pretrained
model
44
60
commercial
tools
fall
latter
category
mainly
focus
hate
speech
toxicity
less
stereotypes
perspective
api
provides
scores
toxicity
insult
profanity
identity
attack
threat
sexually
explicit
openai
reports
content
moderation
filter
language
models
scores
lm
output
based
following
criteria
hate
self-harm
sexual
content
violence
44
50
methods
3.1
data
collection
collected
autocompletions
prompting
three
leading
search
engines
google
duckduckgo
yahoo
query
group
large
number
social
groups
choice
social
groups
drew
lists
groups
choenni
et
al
13
stereoset
46
benchmark
commonly
used
measuring
stereotypes
lms
features
stereotypes
pertaining
321
target
facct
23
june
12
15
2023
chicago
il
usa
leidinger
rogers
terms
falling
categories
gender
profession
race
religion
categories
originally
sourced
wikidata
relation
triplets
68
follow
choenni
et
al
13
extending
list
social
groups
excluded
colloquialisms
slurs
reorganised
categorisation
using
google
list
groups
potentially
marginalised
mentioned
introduction
resulting
categories
age
gender
gender
identity
gendered
lifestyle
ways
living
nationalities
peoples
ethnicities
political
politicised
religion
sexual
orientation
categories
match
google
groups
listed
lifestyle
ways
living
well
political
politicised
fit
google
catch-all
category
characteristic
associated
discrimination
marginalisation
removed
social
groups
belonging
professions
category
since
great
majority
commonly
considered
marginalised1
see
table
full
list
social
groups
followed
choenni
et
al
13
approach
querying
engines
autocompletion
services
january
august
2022
using
python
library
requests
thus
simulated
anonymous
user
querying
autocompletions2
hence
autosuggestions
influenced
personal
search
history
language
country
parameters
set
english
region
browser
setting
chrome
since
autocompletions
can
also
deviate
exact
wording
prompt
discarded
autocompletions
conform
phrasing
group
whereas
baker
potts
employed
prompts
group
group
group
group
finding
fruitful
triggering
stereotypes
prompt
directly
elicits
stereotypes
asks
reason
behind
group
characteristics
thereby
assuming
inquiring
questioning
stereotype
questioning
sarcasm
familiar
stereotype
release
data
part
supplementary
material
work
39
3.2
analysis
moderation
practices
uncover
search
engine
moderates
target
category
considered
following
strong
indicators
target
category
contains
large
percentage
groups
yielding
autosuggestions
average
number
autosuggestions
engine
substantially
lower
search
engines
category
common
negative
stereotypes
absent
among
autosuggestions
appear
autosuggestions
engines
additionally
observed
occasion
number
autocompletions
single
autocompletion
charged
positive
sentiment
comparison
engines
return
many
mainly
negative
autosuggestions
category
recorded
summary
statistics
sentiment
scores
operationalise
reasoning
corroborate
findings
drew
1we
like
add
intersectional
groups
old
women
fall
one
category
gender
age
decided
follow
categorisation
choenni
et
al
13
case
also
created
intersectional
categories
queer
indian
men
left
broader
terms
one
qualifier
allow
comparison
moderation
attention
across
engines
categories
demarcated
google
source
code
developed
13
available
https://github.com/
rochellechoenni
stereotypes_in_lms
3we
found
prompt
particularly
effective
returning
maximal
number
results
non-marginalised
non-politicised
groups
initial
data
exploration
compared
four
others
original
research
choenni
et
al
13
1052
comparison
summary
statistics
scores
two
timestamps
january
august
2022
quantify
sentiment
scored
sentiment
full
autocompletion
using
large
language
model
fine-tuned
sentiment
classification
specifically
used
roberta
41
optimised
hartmann
et
al
32
purpose4
chose
model
particular
since
fine-tuned
large
set
english
language
datasets
stemming
various
domains
tweets
reviews
etc
binary
sentiment
scores
range
higher
scores
indicating
negative
sentiment
findings
following
discuss
findings
respect
moderation
under-moderation
autocompletion
search
engines
categories
terms
groups
appear
source
moderation
one
engine
returns
plentiful
results
including
negative
stereotypes
another
returns
none
single
result
findings
moderation
supported
exceptions
able
characterise
individual
engines
generally
greatly
moderating
google
duckduckgo
permissive
yahoo
4.1
moderation
autocompletion
none
engines
returned
autocompletions
sexual
orientation
whole
across
engines
categories
nationalities
peoples
ethnicities
political
politicised
religion
relatively
autocompletions
google
age
gender
autocompletions
overall
negative
though
outliers
returns
returns
negative
case
protestants
google
yahoo
overall
negative
autosuggestions
duckduckgo
least
overall
average
sentiment
scores
autocompletions
0.78
yahoo
0.59
google
0.49
duckduckgo
higher
score
negative
sentiment
details
see
table
4.1
sexual
orientation
none
search
engines
either
time
period
served
autocompletions
groups
sexual
orientation
category
sexual
orientation
alone
regard
indicating
particularly
well
moderated
set
terms
4.1
religion
autcompletions
social
groups
religion
category
seem
heavily
moderated
google
duckduckgo
see
table
yahoo
contrariwise
furnishes
substantial
number
autocompletions
particular
jews
including
anti-semitic
slurs
cheap
rich
google
returns
autocompletions
religious
groups
exception
mormons
see
periods
potentially
actively
curated
single
suggestion
nice
religious
groups
under-moderated
least
one
time
period
protestants
bitter
boring
socalled
judgemental
well
christians
judgemental
mainly
negative
qualifiers
result
negative
sentiment
score
duckduckgo
appears
block
autocompletions
religions
autocompletions
hindus
buddhists
search
engines
4we
used
huggingface
library
71
following
checkpoint
https
huggingface
co
siebert
sentiment-roberta-large-english
stereotype
moderation
search
engine
autocompletion
facct
23
june
12
15
2023
chicago
il
usa
table
proportion
queries
yield
autosuggestions
us
january
2022
left
august
2022
right
category
groups
google
yahoo
duck
google
yahoo
duck
age
50
25
25
50
25
25
gender
gender
identity
gendered
23
39.1
43.5
60.9
30.4
47.8
60.9
lifestyle
way
living
14
50
78.6
78.6
57.1
78.6
78.6
political
politicised
100
62.5
87.5
100
62.5
87.5
peoples
ethnicities
32
75.8
42.4
87.9
84.8
48.4
87.9
nationalities
47
78.8
74.5
66
78.8
85.1
66
religion
11
100
36.4
100
90.9
36.4
100
sexual
orientation
100
100
100
100
100
100
table
autocompletions
religious
groups
us
jan
aug
2022
autocompletions
normal
font
jan
aug
bold
autocompletions
jan
italicised
aug
group
google
yahoo
atheists
catholics
christians
jews
judgemental
mormons
nice
muslims
protestants
bitter
boring
so-called
judgemental
afraid
god
angry
abortion
liberal
negative
unlike
christ
politics
devoted
mary
angry
controlling
divided
easily
offended
fearful
happy
hated
judgemental
gays
liberal
persecuted
powerful
rich
cheap
smart
successful
hated
wealthy
funny
disliked
happy
interested
genealogy
successful
prepared
rich
strict
wealthy
patriotic
controversial
interested
ancestry
genealogy
misunderstood
religious
spoken
word
conservative
divided
racist
brainwashed
miserable
negative
religious
people
table
autocompletions
political
politicised
groups
us
jan
aug
2022
autocompletions
normal
font
jan
aug
bold
autocompletions
jan
italicised
aug
group
google
immigrants
trump
supporters
conservatives
successful
liberals
yahoo
duck
angry
brainwashed
delusional
gullible
hateful
ignorant
loyal
mad
stupid
violent
dumb
fat
afraid
higher
hateful
angry
miserable
racist
brainwashed
stubborn
intolerant
anti
afraid
change
pro
life
education
abortion
paranoid
mean
cold
hearted
fearful
popular
angry
condescending
dumb
hateful
ignorant
intolerant
racist
stupid
canada
unhappy
violent
miserable
4.1
political
politicised
duckduckgo
google
seem
moderating
autocompletions
groups
category
quite
rigorously
yahoo
content
management
less
prevalent
table
duckduckgo
blocks
nearly
autocompletions
google
autocompletions
mainly
suppressed
one
exception
1053
conservatives
afraid
higher
education
yahoo
conservatives
hateful
angry
miserable
brainwashed
etc
liberals
resulting
high
negative
sentiment
score
search
engine
provided
autocompletions
communists
socialists
capitalists
populists
facct
23
june
12
15
2023
chicago
il
usa
leidinger
rogers
table
autocompletions
select
peoples
ethnicities
us
jan
aug
2022
autocompletions
normal
font
jan
aug
bold
autocompletions
jan
italicised
aug
group
google
yahoo
black
people
good
running
tall
aggressive
angry
athletic
big
cool
fast
hated
racist
religious
tall
good
sports
much
bigger
africans
today
poor
racist
violent
loud
religious
good
sports
angry
sensitive
everything
big
tall
racist
whites
religious
hated
america
different
physically
tall
aggressive
tall
cheap
angry
attracted
white
women
violent
homophobic
popular
hot
promiscuous
hated
angry
big
difficult
loud
religious
undesirable
violent
heavy
hard
date
confident
angry
bad
disrespectful
disrespectful
school
hyper
violent
wild
mean
strict
abusive
angry
attractive
bad
beautiful
entitled
racist
rich
scared
black
people
smart
violent
cold
racist
angry
afraid
blacks
obsessed
blacks
racist
racist
blacks
smart
angry
attracted
asian
women
entitled
nice
tall
threatened
black
men
threatened
black
women
violent
angry
attracted
black
men
beautiful
easy
hot
sensitive
thin
bad
smart
black
americans
african
americans
blacks
black
men
black
women
black
kids
black
parents
white
people
white
americans
whites
white
men
white
women
white
kids
white
parents
laid
back
asians
asian
men
asian
women
asian
kids
asian
parents
smart
good
math
strict
grades
critical
negative
judgemental
angry
critical
reddit
loud
peaceful
feminine
popular
depressed
smart
short
strict
grades
latin
people
latinos
latinas
hispanics
hard
date
loyal
desired
stupid
involved
kobe
bryant
passionate
easy
loud
4.1
peoples
ethnicities
overall
moderation
practices
category
fit
overall
pattern
google
duckduckgo
moderating
engines
yahoo
permissive
see
table
yahoo
returned
largest
number
autocompletions
also
resulted
highest
score
negative
sentiment
google
well
duckduckgo
returned
lower
sentiment
score
particular
terms
black
people
white
people
found
autocompletions
google
complete
lack
duckduckgo
autocompletions
strong
stereotyping
yahoo
autocompletions
accounts
negative
sentiment
yahoo
autocompletions
touch
racism
white
people
racist
negative
images
aggressive
angry
bad
mean
etc
number
yahoo
autocompletions
found
latinos
loud
stupid
involved
1054
kobe
bryant
asians
feminine
men
popular
women
smart
depressed
kids
strict
parents
contain
negative
valences
4.1
nationalities
google
moderation
extends
nationalities
duckduckgo
autocompletions
among
positive
autocompletions
collected
google
outputs
positive
autocompletions
many
nationalities
including
americans
friendly
germans
smart
tall
indians
smart
moroccans
strong
beautiful
australians
tall
russians
tall
good
chess
pretty
somalis
rich
tall
successful
syrians
beautiful
returns
autocompletions
groups
including
austrians
british
people
ethiopians
french
people
greeks
irish
people
italians
mexicans
nigerians
pakistanis
polish
people
romanians
duckduckgo
returns
autocompletions
stereotype
moderation
search
engine
autocompletion
facct
23
june
12
15
2023
chicago
il
usa
nationalities
smattering
stereotypes
evidence
enough
result
negative
sentiment
score
yahoo
scored
highest
negative
sentiment
example
egyptians
loud
french
people
mean
germans
cold
4.1
gender
gender
identity
gendered
none
search
engines
returned
results
transgenders
otherwise
results
category
perhaps
surprising
overall
remaining
social
groups
see
substantial
number
autocompletions
many
stereotypical
well
insulting
see
table
three
engines
scored
negative
end
sentiment
spectrum
yahoo
overall
negative
followed
google
duckduckgo
google
gives
unflattering
suggestions
terms
gender
category
women
females
girls
found
autocompletions
controlling
clingy
dramatic
men
males
boys
boring
mean
insensitive
lonely
immature
yahoo
negative
autocompletions
plentiful
men
males
boys
found
suggestions
difficult
complicated
angry
women
needy
insensitive
confusing
duckduckgo
furnishes
fewer
autocompletions
google
yahoo
autocompletions
similar
terms
4.1
age
google
engine
curates
autocompletions
age
category
overall
number
autocompletions
comparatively
small
see
table
stands
alone
suppressing
ageist
autocompletions
queries
concerning
older
people
exception
old
people
entitled
yahoo
duckduckgo
return
stereotypes
angry
grumpy
cold
negative
stubborn
difficult
entitled
slow
google
marginally
lower
sentiment
scores
three
engines
combined
among
highest
overall
engines
return
stereotyping
autocompletions
boomers
children
teenagers
4.1
lifestyle
ways
living
category
follows
overall
pattern
yahoo
furnishing
large
amount
negative
autocompletions
google
though
ones
duckduckgo
returning
autocompletions
feminists
homeless
rich
poor
criminals
suppressed
nearly
search
engines
rather
exceptionally
possibly
evidence
positive
moderation
part
duckduckgo
well
yahoo
see
table
yahoo
autocompletions
rich
people
evidence
poor
people
happy
poor
homeless
people
happy
positive
inflections
google
search
engine
return
completions
punks
frats
goths
hippies
hipsters
nerds
duckduckgo
yahoo
results
exception
duckduckgo
nerds
attractive
successful
easter
egg
4.1
autocompletion
engine
moderation
sentiment
google
appears
moderate
results
much
greater
quantities
duckduckgo
yahoo
google
often
returns
autocompletions
january
august
2022
sexual
orientation
also
others
seen
table
single
results
charged
positivity
immigrants
successful
see
table
overview
given
universe
stereotypes
potentially
associated
groups
one
autocompletion
appears
positive
valence
indication
curation
point
return
discussion
1055
rule
moderation
sentiment
scores
become
less
negative
compared
yahoo
duckduckgo
mainly
suppresses
potentially
stereotypical
inappropriate
autocompletions
completely
overall
lowest
negative
sentiment
scores
yahoo
characterised
far
permissive
engine
found
moderate
least
highest
negative
sentiment
cases
permit
stereotypes
appear
removes
autosuggestions
discussion
like
discuss
four
implications
research
first
concerns
distribution
moderation
overall
second
permissiveness
particular
search
engines
certain
queries
third
continuing
stakes
perpetuating
certain
negativity
insults
services
user
turn
finally
question
transparency
moderation
also
like
ask
whether
engines
can
better
research
found
hierarchy
concern
suggest
flattened
also
found
differentiation
moderation
across
engines
evened
respect
hierarchy
concern
sexual
orientation
moderated
ethnicities
religions
though
exceptions
protestants
google
gender
under-moderated
given
stereotypes
insults
returned
especially
women
older
people
category
also
under-moderated
least
compared
categories
respect
individual
engines
yahoo
moderation
stands
amount
stereotypes
insults
allowed
pass
across
categories
given
exception
sexual
orientation
yahoo
un-moderated
engine
certainly
one
attention
called
under-moderation
resulted
negative
autocompletions
evidenced
sentiment
scoring
groups
people
historically
faced
discrimination
marginalisation
autocompletions
considered
noble
48
called
reinforcement
users
thereby
can
come
across
stereotypes
insults
picking
searching
information
learning
abusive
remarks
groups
witnessing
reinforcement
presence
stereotypes
insults
reason
enough
make
service
optional
disabled
default
certain
groups
see
stereotypes
insults
others
conspicuously
absent
question
arises
search
engine
policy
implementation
appears
expansion
moderation
activities
past
years
documentation
supplied
rather
general
terms
read
company
blog
posts
concerning
moderation
content
far
can
tell
scope
well
types
moderated
stereotypes
yet
become
part
transparency
reports
official
company
documentation
moreover
harmful
stereotypes
also
among
kinds
inappropriate
autocompletion
content
users
can
report
interface
tool
search
engines
least
explicitly
documentation
content
filters
built
commercial
language
models
often
mention
stereotypes
explicitly
either
50
implication
search
engines
provide
content
moderation
policy
also
evidence
beyond
blog
posts
effective
implementation
facct
23
june
12
15
2023
chicago
il
usa
leidinger
rogers
table
autocompletions
select
lifestyle
way
living
groups
us
jan
aug
2022
autocompletions
normal
font
jan
aug
bold
autocompletions
jan
italicised
aug
group
google
yahoo
feminists
homeless
people
poor
people
rich
people
angry
time
happy
angry
mad
happy
loud
cheap
mean
stingy
miserable
liberal
wasteful
entitled
healthy
rich
duckduckgo
table
autocompletions
select
gender
gender
identity
gendered
us
jan
aug
2022
autocompletions
normal
font
jan
aug
bold
autocompletions
jan
italicised
aug
group
google
women
attractive
beautiful
controlling
hot
sensitive
short
females
girls
men
males
boys
yahoo
duckduckgo
difficult
unhappy
mean
emo
tional
angry
jealous
women
important
dramatic
picky
men
hot
clingy
emotional
period
difficult
emotional
jealous
protec
moody
emotional
period
attraccompetitive
messy
stubborn
cute
de
tive
female
tive
sensitive
emotional
entitled
cute
fensive
attractive
sensitive
bippoaggressive
lar
weak
naruto
dramatic
emotional
insecure
sensi
complicated
dramatic
emotional
difficult
cute
confusing
pretty
sensitive
attractive
attractive
soft
pretty
cute
sensitive
short
mean
confus
tive
wierd
mean
dramatic
hot
ing
expensive
competitive
mean
boys
complicated
boring
sensitive
hot
insensitive
visual
angry
needy
attracted
shallow
aggressive
self-absorbed
simsensitive
lonely
warm
hairy
women
loud
hot
cold
complicated
ple
jealous
sensitive
moody
hot
cute
angry
women
sensitive
difficult
attractive
attracted
females
angry
difficult
emotional
protective
attractive
aggressive
rare
mean
loud
female
cute
immature
complicated
confusing
mean
girls
ugh
confusing
aggressive
cute
funny
stupid
quotes
wearing
nail
polish
dramatic
complicated
difficult
hot
strong
sick
loud
competitive
tall
cute
best
friends
sensitive
destructive
four
points
aim
orient
discussion
around
autocompletion
moderation
particularly
decisions
moderate
well
disclose
moderation
stakes
undermoderating
5.1
additional
categories
moderation
strategy
cursory
look
press
reports
2010s
concerning
particularly
shocking
autocompletions
jews
evil
yields
follow-up
articles
detailing
suggestions
fixed
removed
25
suppressions
patches
implemented
direct
response
journalistic
discoveries
related
queries
presumably
also
fixed
christians
evil
also
observed
autocompletion
result
lists
leave
single
suggestion
occasionally
charged
positivity
homeless
people
happy
apart
blocking
example
point
third
way
dubbed
curation
entails
retaining
fewer
sometimes
positively
charged
results
curation
complex
however
considering
autocompletion
results
contain
synthetic
content
query
1056
completed
near
meaning
knowledge
base
content
query
completed
names
pop
songs
famous
people
official
organisations
overview
examples
see
table
12
appendix
prior
sullivan
blog
posts
google
much
written
specific
moderation
practices
especially
interplay
autocompletion
organic
results
output
real
searches
synthetic
ones
output
word
patterns
dataset
synthetic
additions
see
table
12
result
substantive
useful
autocompletions
raising
question
current
effectiveness
strategy
using
word
patterns
part
content
moderation
compared
pruning
autocompletion
outputs
danny
sullivan
indicated
2020
post
certain
pruning
however
construed
form
editing
overly
minimises
offence
turn
result
politicised
public
outcry
conclusion
overall
autocompletion
actively
moderated
space
found
distribution
moderation
categories
intuitive
well
counter-intuitive
results
sexual
orientation
moderated
stereotype
moderation
search
engine
autocompletion
facct
23
june
12
15
2023
chicago
il
usa
table
autocompletions
age
us
jan
aug
2022
autocompletions
normal
font
jan
aug
bold
autocompletions
jan
italicised
aug
group
google
yahoo
duckduckgo
aggressive
controlling
rich
toxic
conservative
angry
annoying
selfish
fat
conservative
greedy
entitouch
entitled
bad
technology
entled
liberal
salty
titled
reddit
touch
reddit
loud
bad
technology
reddit
angry
reddit
clueless
children
loud
annoying
energetic
important
disrespectful
curious
creative
loud
important
recruel
honest
expensive
annoying
silient
noisy
loving
honest
vulneraimpressionable
special
competitive
ble
cute
stubborn
easily
influenced
kids
loud
energetic
cute
happy
cruel
annoying
cruel
loud
selfish
stupid
weird
energetic
fat
noisy
loud
cringe
noying
mean
disrespectful
sensitive
entitled
now
mean
middle
school
days
dumb
today
fat
happy
lazy
cute
mean
kids
happy
days
toxic
millennials
old
people
entitled
cold
tired
angry
negative
dependent
difficult
grumpy
entitled
stubborn
naive
loud
grouchy
negative
nice
stiff
get
cold
slow
cute
old
men
old
women
teenagers
angry
sad
depressed
difficult
mean
par
angry
moody
lazy
tired
emotional
ents
angry
emotional
hormonal
tired
skinny
awkward
stressed
dramatic
time
irritable
alienating
grumpy
ward
forgetful
stressed
unhappy
teens
stressed
depressed
difficult
attached
phones
tired
moody
depressed
emotional
sad
rebeladdicted
phones
depressed
lious
stressed
edgy
impulsive
lazy
days
sad
derek
thompson
sad
today
easily
influenced
boomers
autocompletion
peoples
ethnicity
highly
moderated
followed
religion
category
gender
gender
identity
gendered
rather
under-moderated
however
populated
stereotypes
negative
attributions
stereotypes
attached
men
women
age
also
rather
under-moderated
autosuggestions
negative
though
google
moderates
engines
sporadic
stereotypes
engines
even
google
example
protestants
duckduckgo
nationalities
one
rather
counter-intuitive
finding
lack
moderation
yahoo
sexual
orientation
sensitive
categories
addressed
compared
google
duckduckgo
situation
yahoo
far
removed
baker
potts
described
google
2013
auto-completion
questions
offer
window
collective
internet
consciousness
window
reveals
attractive
scene
indeed
sentiment
associated
yahoo
autocompletions
study
considerably
negative
compared
google
duckduckgo
work
generally
pointed
moderation
google
particular
across
range
terms
moderated
decade
ago
according
journalistic
pieces
offensive
1057
results
reported
age
under-moderated
exception
google
overall
gender
however
remains
under-moderated
limitations
future
work
several
limitations
discussed
including
work
centric
orientation
search
engine
choice
formulation
prompts
use
pretrained
language
models
sentiment
classification
research
undertaken
largely
centric
certain
stereotypical
sensitivities
interpreted
future
work
benefit
developing
culturally
specific
sets
queries
across
variety
languages
order
study
moderation
practices
across
regions
compare
regions
given
centric
orientation
also
included
bing
ecosia
smaller
engines
studying
baidu
yandex
naver
broaden
scope
comparison
re-used
prompts
previous
work
remapping
onto
google
categories
derogatory
remarks
added
ones
journalistic
scholarly
work
autocompletion
lists
social
groups
cover
intersections
15
one
qualifier
finally
certain
groups
results
returned
one
interpret
moderation
result
relevance
threshold
facct
23
june
12
15
2023
chicago
il
usa
leidinger
rogers
table
sentiment
score
higher
score
negative
us
jan
2022
left
aug
2022
right
number
completions
per
category
average
sentiment
score
standard
deviation
sentiment
scores
category
age
gender
gender
identity
gendered
lifestyle
way
living
political
politicised
peoples
ethnicities
nationalities
religion
sexual
orientation
google
yahoo
duck
google
yahoo
duck
18
70.0
0.4
98
68.3
0.4
31
74.9
0.4
33.5
0.6
30
63.1
0.5
60
28.1
0.4
96.5
0.08
42
83.2
0.4
64
77.8
0.4
20
81.0
0.4
30
96.5
0.2
94
73.3
0.4
36
68.4
0.4
38
75.5
0.4
45
75.3
0.4
52
59.6
0.5
12
43.9
0.5
99.8
14
35.8
0.5
88
31.9
0.5
19
76.6
0.4
90
72.9
0.4
30
63.4
0.5
33.5
0.6
33
54.4
0.5
54
32.9
0.5
91.1
0.1
48
85.2
0.4
79
76.7
0.4
20
86
0.3
30
96.5
0.2
106
71.5
0.4
51
66.2
0.5
42
73.2
0.4
45
75.5
0.4
58
65.5
0.5
11
47.7
0.5
99.1
0.01
16
43.6
0.5
89
29.3
0.4
candidate
autocompletion
one
peruses
groups
observation
applies
likelihood
moderated
rather
underpopulated
associations
remains
high
pretrained
language
models
shown
suffer
termed
lexical
bias
meaning
associate
mere
mention
marginalised
identity
negative
sentiment
kiritchenko
mohammad
38
might
drive
scores
negative
sentiment
certain
categories
acknowledgments
thank
anonymous
reviewers
insightful
comments
work
publication
financially
supported
project
learning
meaning
new
approach
generic
sentences
implicit
biases
project
number
406.18
tw
007
research
programme
sgw
open
competition
partly
financed
dutch
research
council
nwo
references
abubakar
abid
maheen
farooqi
james
zou
2021
large
language
models
associate
muslims
violence
nature
machine
intelligence
2021
461
463
ls
al-abbas
ahmad
haider
riyad
hussein
2020
google
autocomplete
search
algorithms
arabs
perspectives
gender
case
study
google
egypt
gema
online
journal
language
studies
20
2020
95
112
perspective
api
2023
api
attributes
languages
https://developers.perspectiveapi.com/s/about-the-api-attributes-andlanguages?language=en_us
paul
baker
amanda
potts
2013
white
people
thin
lips
google
perpetuation
stereotypes
via
auto-complete
search
forms
critical
discourse
studies
10
may
2013
187
204
https://doi.org/10.1080/
17405904.2012
744320
1058
judit
bar-ilan
2006
web
links
search
engine
ranking
case
google
query
jew
journal
american
society
information
science
technology
57
12
2006
1581
1589
solon
barocas
kate
crawford
aaron
shapiro
hanna
wallach
2017
problem
bias
allocative
versus
representational
harms
machine
learning
9th
annual
conference
special
interest
group
computing
information
society
emily
bender
timnit
gebru
angelina
mcmillan-major
shmargaret
shmitchell
2021
dangers
stochastic
parrots
can
language
models
big
proceedings
2021
acm
conference
fairness
accountability
transparency
610
623
su
lin
blodgett
solon
barocas
hal
daumé
iii
hanna
wallach
2020
language
technology
power
critical
survey
bias
nlp
proceedings
58th
annual
meeting
association
computational
linguistics
5454
5476
tolga
bolukbasi
kai-wei
chang
james
zou
venkatesh
saligrama
adam
tauman
kalai
2016
man
computer
programmer
woman
homemaker
debiasing
word
embeddings
advances
neural
information
processing
systems
29
2016
4349
4357
http://papers.nips.cc/book/advancesin-neural-information-processing-systems-29-2016
10
carole
cadwalladr
2016
google
democracy
truth
internet
search
guardian
12
2016
2016
11
aylin
caliskan
joanna
bryson
arvind
narayanan
2017
semantics
derived
automatically
language
corpora
contain
human-like
biases
science
356
6334
2017
183
186
https://doi.org/10.1126/science.aal4230
12
anne
sy
cheung
2015
defaming
suggestion
searching
search
engine
liability
autocomplete
era
comparative
perspectives
fundamentals
freedom
expression
andras
koltay
ed
forthcoming
university
hong
kong
faculty
law
research
paper
2015
018
2015
13
rochelle
choenni
ekaterina
shutova
robert
van
rooij
2021
stepmothers
mean
academics
pretentious
pretrained
language
models
learn
proceedings
2021
conference
empirical
methods
natural
language
processing
1477
1491
14
kate
crawford
2017
trouble
bias
keynote
neurips
15
kimberlé
crenshaw
2017
intersectionality
essential
writings
new
press
16
sunipa
dev
masoud
monajatipoor
anaelia
ovalle
arjun
subramonian
jeff
phillips
kai-wei
chang
2021
harms
gender
exclusivity
challenges
stereotype
moderation
search
engine
autocompletion
facct
23
june
12
15
2023
chicago
il
usa
non-binary
representation
language
technologies
proceedings
2021
conference
empirical
methods
natural
language
processing
1968
1994
17
jwala
dhamala
tony
sun
varun
kumar
satyapriya
krishna
yada
pruksachatkun
kai-wei
chang
rahul
gupta
2021
bold
dataset
metrics
measuring
biases
open-ended
language
generation
proceedings
2021
acm
conference
fairness
accountability
transparency
862
872
18
nicholas
diakopoulos
2015
algorithmic
accountability
journalistic
investigation
computational
power
structures
digital
journalism
2015
398
415
19
lucas
dixon
john
li
jeffrey
sorensen
nithum
thain
lucy
vasserman
2018
measuring
mitigating
unintended
bias
text
classification
proceedings
2018
aaai
acm
conference
ai
ethics
society
new
york
ny
usa
2018
12
27
aies
18
association
computing
machinery
67
73
https
doi
org
10.1145
3278721.3278729
20
steve
elers
2014
maori
scum
stupid
lazy
maori
according
google
te
kaharoa
2014
21
kawin
ethayarajh
david
duvenaud
graeme
hirst
2019
understanding
undesirable
word
embedding
associations
proceedings
57th
annual
meeting
association
computational
linguistics
florence
italy
2019
association
computational
linguistics
1696
1705
https://doi.org/10.18653/
v1
p19-1166
22
anjalie
field
su
lin
blodgett
zeerak
waseem
yulia
tsvetkov
2021
survey
race
racism
anti-racism
nlp
proceedings
59th
annual
meeting
association
computational
linguistics
11th
international
joint
conference
natural
language
processing
volume
long
papers
1905
1925
23
lj
flynn
2004
google
says
doesn
plan
change
search
results
new
york
times
2004
24
samuel
gehman
suchin
gururangan
maarten
sap
yejin
choi
noah
smith
2020
realtoxicityprompts
evaluating
neural
toxic
degeneration
language
models
findings
association
computational
linguistics
emnlp
2020
3356
3369
25
samuel
gibbs
2016
google
alters
search
autocomplete
remove
jews
evil
suggestion
guardian
2016
26
tarleton
gillespie
2018
custodians
internet
yale
university
press
27
ben
gomes
2017
latest
quality
improvements
search
google
blog
2017
28
hila
gonen
yoav
goldberg
2019
lipstick
pig
debiasing
methods
cover
systematic
gender
biases
word
embeddings
remove
proceedings
2019
conference
north
american
chapter
association
computational
linguistics
human
language
technologies
volume
long
short
papers
minneapolis
minnesota
2019
06
association
computational
linguistics
609
614
https://doi.org/10.18653/v1/n19-1061
29
google
2022
removing
content
google
https://support.google.com/legal/
troubleshooter
1114905
ts
9814647
2c9815053
2c3337372
30
james
grimmelmann
2015
virtues
moderation
yale
jl
tech
17
2015
42
31
kirsten
grind
sam
schechner
robert
mcmillan
john
west
2019
google
interferes
search
algorithms
changes
results
wall
street
journal
15
2019
32
jochen
hartmann
mark
heitmann
christian
siebert
christina
schamp
2022
feeling
accuracy
application
sentiment
analysis
international
journal
research
marketing
2022
33
timothy
hazen
alexandra
olteanu
gabriella
kazai
fernando
diaz
michael
golebiewski
2022
social
technical
challenges
web
search
autosuggestion
moderation
first
monday
2022
34
po-sen
huang
huan
zhang
ray
jiang
robert
stanforth
johannes
welbl
jack
rae
vishal
maini
dani
yogatama
pushmeet
kohli
2020
reducing
sentiment
bias
language
models
via
counterfactual
evaluation
findings
association
computational
linguistics
emnlp
2020
online
2020
11
association
computational
linguistics
65
83
https://doi.org/10.18653/v1/2020.findingsemnlp.7
35
ben
hutchinson
vinodkumar
prabhakaran
emily
denton
kellie
webster
yu
zhong
stephen
denuyl
2020
social
biases
nlp
models
barriers
persons
disabilities
proceedings
58th
annual
meeting
association
computational
linguistics
5491
5501
36
stavroula
karapapa
maurizio
borghi
2015
search
engine
liability
autocomplete
suggestions
personality
privacy
power
algorithm
international
journal
law
information
technology
23
2015
261
289
37
svetlana
kiritchenko
saif
mohammad
2018
examining
gender
race
bias
two
hundred
sentiment
analysis
systems
proceedings
seventh
joint
conference
lexical
computational
semantics
new
orleans
louisiana
2018
association
computational
linguistics
43
53
https://doi.org/10.
18653
v1
s18-2005
38
svetlana
kiritchenko
saif
mohammad
2018
examining
gender
race
bias
two
hundred
sentiment
analysis
systems
arxiv
preprint
arxiv
1805.04508
2018
39
alina
leidinger
richard
rogers
2023
stereotype
elicitation
google
duckduckgo
yahoo
autcompletion
https://doi.org/10.5281/zenodo.7906930
1059
40
walter
lippmann
1922
public
opinion
new
york
mcmillan
41
yinhan
liu
myle
ott
naman
goyal
jingfei
du
mandar
joshi
danqi
chen
omer
levy
mike
lewis
luke
zettlemoyer
veselin
stoyanov
2019
roberta
robustly
optimized
bert
pretraining
approach
arxiv
preprint
arxiv
1907.11692
2019
42
vijit
malik
sunipa
dev
akihiro
nishi
nanyun
peng
kai-wei
chang
2022
socially
aware
bias
measurements
hindi
language
representations
proceedings
2022
conference
north
american
chapter
association
computational
linguistics
human
language
technologies
1041
1052
43
thomas
manzini
lim
yao
chong
alan
black
yulia
tsvetkov
2019
black
criminal
caucasian
police
detecting
removing
multiclass
bias
word
embeddings
proceedings
2019
conference
north
american
chapter
association
computational
linguistics
human
language
technologies
volume
long
short
papers
615
621
44
todor
markov
chong
zhang
sandhini
agarwal
tyna
eloundou
teddy
lee
steven
adler
angela
jiang
lilian
weng
2022
holistic
approach
undesired
content
detection
real
world
arxiv
preprint
arxiv
2208.03274
2022
45
boaz
miller
isaac
record
2017
responsible
epistemic
technologies
socialepistemological
analysis
autocompleted
web
search
new
media
society
19
12
2017
1945
1963
46
moin
nadeem
anna
bethke
siva
reddy
2021
stereoset
measuring
stereotypical
bias
pretrained
language
models
proceedings
59th
annual
meeting
association
computational
linguistics
11th
international
joint
conference
natural
language
processing
volume
long
papers
5356
5371
47
nikita
nangia
clara
vania
rasika
bhalerao
samuel
bowman
2020
crowspairs
challenge
dataset
measuring
social
biases
masked
language
models
proceedings
2020
conference
empirical
methods
natural
language
processing
emnlp
1953
1967
48
safiya
umoja
noble
2018
algorithms
oppression
new
york
university
press
49
debora
nozza
federico
bianchi
dirk
hovy
et
al
2021
honest
measuring
hurtful
sentence
completion
language
models
proceedings
2021
conference
north
american
chapter
association
computational
linguistics
human
language
technologies
association
computational
linguistics
50
openai
2023
moderation
https://platform.openai.com/docs/guides/moderation/
overview
51
devah
pager
2007
use
field
experiments
studies
employment
discrimination
contributions
critiques
directions
future
annals
american
academy
political
social
science
609
2007
104
133
52
ji
ho
park
jamin
shin
pascale
fung
2018
reducing
gender
bias
abusive
language
detection
proceedings
2018
conference
empirical
methods
natural
language
processing
brussels
belgium
2018
10
association
computational
linguistics
2799
2804
https://doi.org/10.18653/v1/d18-1302
53
bernhard
rieder
jeanette
hofmann
2020
towards
platform
observability
internet
policy
review
2020
28
54
sarah
roberts
2019
behind
screen
yale
university
press
55
senjooti
roy
liat
ayalon
2020
age
gender
stereotypes
reflected
google
autocomplete
function
portrayal
possible
spread
societal
stereotypes
gerontologist
60
2020
1020
1028
56
senjooti
roy
liat
ayalon
gabi
weisfeld
barbara
bowers
2020
age
gender
stereotypes
reflected
google
autocomplete
function
portrayal
possible
spread
societal
stereotypes
gerontologist
60
aug
2020
1020
1028
https://doi.org/10.1093/geront/gnz172
57
christian
sandvig
kevin
hamilton
karrie
karahalios
cedric
langbort
2014
auditing
algorithms
research
methods
detecting
discrimination
internet
platforms
data
discrimination
converting
critical
concerns
productive
inquiry
22
2014
4349
4357
58
victor
sanh
albert
webson
colin
raffel
stephen
bach
lintang
sutawika
zaid
alyafeai
antoine
chaffin
arnaud
stiegler
teven
scao
arun
raja
et
al
2022
multitask
prompted
training
enables
zero-shot
task
generalization
international
conference
learning
representations
59
teven
le
scao
angela
fan
christopher
akiki
ellie
pavlick
suzana
ilić
daniel
hesslow
roman
castagné
alexandra
sasha
luccioni
françois
yvon
matthias
gallé
et
al
2022
bloom
176b-parameter
open-access
multilingual
language
model
arxiv
preprint
arxiv
2211.05100
2022
60
emily
sheng
kai-wei
chang
prem
natarajan
nanyun
peng
2021
societal
biases
language
generation
progress
challenges
proceedings
59th
annual
meeting
association
computational
linguistics
11th
international
joint
conference
natural
language
processing
volume
long
papers
4275
4293
61
eric
michael
smith
melissa
hall
melanie
kambadur
eleonora
presani
adina
williams
2022
sorry
hear
finding
bias
language
models
holistic
descriptor
dataset
arxiv
preprint
arxiv
2205.09209
2022
62
stanton
1971
incidental
intentional
learning
one
process
two
australian
psychologist
1971
26
30
63
danny
sullivan
2018
google
autocomplete
works
search
retrieved
november
22
2018
2018
facct
23
june
12
15
2023
chicago
il
usa
leidinger
rogers
64
danny
sullivan
2019
keep
search
relevant
useful
google
keyword
blog
july
15
2019
65
danny
sullivan
2020
google
autocomplete
predictions
generated
retrieved
october
2020
2020
66
yi
chern
tan
elisa
celis
2019
assessing
social
intersectional
biases
contextualized
word
representations
advances
neural
information
processing
systems
32
annual
conference
neural
information
processing
systems
2019
neurips
2019
december
14
2019
vancouver
bc
canada
2019
11
04
hanna
wallach
hugo
larochelle
alina
beygelzimer
florence
alché
buc
emily
fox
roman
garnett
eds
13209
13220
http://papers.nips.cc/
book
advances-in-neural-information-processing-systems-32-2019
67
madalina
vlasceanu
david
amodio
2022
propagation
societal
gender
inequality
internet
search
algorithms
proceedings
national
academy
sciences
119
29
2022
e2204529119
68
denny
vrandečić
markus
krötzsch
2014
wikidata
free
collaborative
knowledgebase
commun
acm
57
10
sep
2014
78
85
https://doi.org/10.
1145
2629489
69
kellie
webster
xuezhi
wang
ian
tenney
alex
beutel
emily
pitler
ellie
pavlick
jilin
chen
slav
petrov
2020
measuring
reducing
gendered
correlations
pre-trained
models
http://arxiv.org/abs/2010.06032
70
laura
weidinger
jonathan
uesato
maribeth
rauh
conor
griffin
po-sen
huang
john
mellor
amelia
glaese
myra
cheng
borja
balle
atoosa
kasirzadeh
et
al
1060
2022
taxonomy
risks
posed
language
models
2022
acm
conference
fairness
accountability
transparency
214
229
71
thomas
wolf
lysandre
debut
victor
sanh
julien
chaumond
clement
delangue
anthony
moi
pierric
cistac
tim
rault
rémi
louf
morgan
funtowicz
et
al
2019
huggingface
transformers
state-of-the-art
natural
language
processing
arxiv
preprint
arxiv
1910.03771
2019
72
un
women
2013
un
women
ad
series
reveals
widespread
sexism
un
women
21
2013
73
yahoo
2023
yahoo
search
autocomplete
policy
hhttps
help
yahoo
com
kb
sln36183
html
74
brian
hu
zhang
blake
lemoine
margaret
mitchell
2018
mitigating
unwanted
biases
adversarial
learning
proceedings
2018
aaai
acm
conference
ai
ethics
society
new
york
ny
usa
2018
12
27
aies
18
association
computing
machinery
335
340
https://doi.org/10.1145/
3278721.3278779
75
susan
zhang
stephen
roller
naman
goyal
mikel
artetxe
moya
chen
shuohui
chen
christopher
dewan
mona
diab
xian
li
xi
victoria
lin
et
al
2022
opt
open
pre-trained
transformer
language
models
arxiv
preprint
arxiv
2205.01068
2022
additional
tables
stereotype
moderation
search
engine
autocompletion
facct
23
june
12
15
2023
chicago
il
usa
table
10
average
number
autosuggestions
per
group
us
january
2022
category
groups
google
yahoo
duck
23
14
32
47
11
2.4
3.9
2.1
0.4
1.1
0.2
3.4
1.4
3.6
3.2
1.1
3.8
5.6
2.5
0.8
0.3
0.5
1.9
age
gender
gender
identity
gendered
lifestyle
way
living
political
politicised
peoples
ethnicities
nationalities
religion
sexual
orientation
table
11
average
number
autosuggestions
per
group
us
august
2022
category
groups
google
yahoo
duck
23
14
32
47
11
2.3
4.3
2.2
0.4
0.9
1.3
0.5
5.3
2.8
1.4
3.8
2.8
0.8
3.5
5.6
2.3
0.0
0.1
0.4
1.9
age
gender
gender
identity
gendered
lifestyle
way
living
political
politicised
peoples
ethnicities
nationalities
religion
sexual
orientation
table
12
examples
synthetic
patterns
appended
organic
search
logs
duckduckgo
boys
ugh
brothers
sweaty
step
brothers
annoying
quiz
kids
entitled
now
yahoo
americans
stupid
2020
angry
ielts
reading
boys
stupid
quotes
black
americans
much
bigger
africans
today
muslims
spoken
word
come
homeless
people
sensitive
quotes
daughters
mean
mothers
now
russians
cruel
people
images
kids
sensitive
days
dumb
today
teens
sad
derek
thomson
sad
today
1061