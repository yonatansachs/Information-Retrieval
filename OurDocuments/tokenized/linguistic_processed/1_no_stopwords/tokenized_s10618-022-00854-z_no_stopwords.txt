data
mining
knowledge
discovery
2022
36
2074
2152
https://doi.org/10.1007/s10618-022-00854-z
algorithmic
fairness
datasets
story
far
alessandro
fabris1
stefano
messina1
gianmaria
silvello1
gian
antonio
susto1
received
27
august
2021
accepted
july
2022
published
online
17
september
2022
author
2022
abstract
data-driven
algorithms
studied
deployed
diverse
domains
support
critical
decisions
directly
impacting
people
well-being
result
growing
community
researchers
investigating
equity
existing
algorithms
propos
ing
novel
ones
advancing
understanding
risks
opportunities
automated
decision-making
historically
disadvantaged
populations
progress
fair
machine
learning
equitable
algorithm
design
hinges
data
can
appropriately
used
adequately
documented
unfortunately
algorithmic
fairness
commu
nity
whole
suffers
collective
data
documentation
debt
caused
lack
information
specific
resources
opacity
scatteredness
available
infor
mation
sparsity
work
target
data
documentation
debt
surveying
two
hundred
datasets
employed
algorithmic
fairness
research
producing
standardized
searchable
documentation
moreover
rigor
ously
identify
three
popular
fairness
datasets
namely
adult
compas
german
credit
compile
in-depth
documentation
unifying
doc
umentation
effort
supports
multiple
contributions
firstly
summarize
merits
limitations
adult
compas
german
credit
adding
unifying
recent
scholarship
calling
question
suitability
general-purpose
fairness
bench
marks
secondly
document
hundreds
available
alternatives
annotating
domain
supported
fairness
tasks
along
additional
properties
interest
responsible
editor
toon
calders
extended
version
fabris
et
al
2022
alessandro
fabris
fabrisal@dei.unipd.it
gianmaria
silvello
silvello@dei.unipd.it
gian
antonio
susto
gianantonio.susto@unipd.it
dipartimento
di
ingegneria
dell
informazione
università
di
padova
via
giovanni
gradenigo
6b
35131
padua
italy
123
algorithmic
fairness
datasets
story
far
2075
fairness
practitioners
researchers
including
format
cardinality
sen
sitive
attributes
encode
summarize
information
zooming
tasks
domains
roles
resources
finally
analyze
datasets
per
spective
five
important
data
curation
topics
anonymization
consent
inclusivity
labeling
sensitive
attributes
transparency
discuss
different
approaches
levels
attention
topics
making
tangible
distill
set
best
practices
curation
novel
resources
keywords
algorithmic
fairness
datasets
documentation
debt
introduction
following
widespread
study
application
data-driven
algorithms
con
texts
central
people
well-being
large
community
researchers
coalesced
around
growing
field
algorithmic
fairness
investigating
algorithms
lens
justice
equity
bias
power
harms
line
work
gaining
trac
tion
field
intersecting
critical
data
studies
human
computer
interaction
computer-supported
cooperative
work
focuses
data
transparency
standard
ized
documentation
processes
describe
key
characteristics
datasets
gebru
et
al
2018
holland
et
al
2018
bender
friedman
2018
geiger
et
al
2020
jo
gebru
2020
miceli
et
al
2021
prominently
gebru
et
al
2018
holland
et
al
2018
proposed
two
complementary
documentation
frameworks
called
datasheets
datasets
dataset
nutrition
labels
improve
data
curation
practices
favour
informed
data
selection
utilization
dataset
users
overall
line
work
contributed
unprecedented
attention
dataset
documentation
machine
learning
ml
including
novel
track
focused
datasets
confer
ence
neural
information
processing
systems
neurips
initiative
support
dataset
tracking
repositories
scholarly
articles
dedicated
works
producing
retrospective
documentation
existing
datasets
bandy
vincent
2021
garbin
et
al
2021
auditing
properties
prabhu
birhane
2020
tracing
usage
peng
et
al
2021
recent
work
bender
et
al
2021
propose
notion
documentation
debt
relation
training
sets
undocumented
large
document
retrospec
tively
extend
definition
collection
datasets
employed
given
field
research
see
two
components
work
contributing
documentation
debt
research
community
one
hand
opacity
result
poor
documentation
affecting
single
datasets
contributing
misunderstandings
misuse
specific
resources
hand
relevant
information
exists
reach
interested
parties
problem
documentation
sparsity
one
example
particularly
relevant
algorithmic
fairness
community
represented
german
credit
dataset
uci
machine
learning
repository
1994
popular
resource
field
many
works
algorithmic
fairness
including
recent
ones
carry
experiments
dataset
using
sex
protected
attribute
et
al
2020b
yang
https://medium.com/paperswithcode/datasets-on-arxiv-1a5a8f7bd104.
123
2076
fabris
et
al
et
al
2020a
baharlouei
et
al
2020
lohaus
et
al
2020
martinez
et
al
2020
wang
et
al
2021
perrone
et
al
2021
sharma
et
al
2021
existing
yet
overlooked
documentation
shows
feature
reliably
retrieved
grömping
2019
moreover
mere
fact
dataset
exists
relevant
given
task
given
domain
may
unknown
bupt
faces
datasets
instance
presented
second
existing
resource
face
analysis
race
annotations
wang
deng
2020
however
several
resources
already
available
time
including
labeled
faces
wild
han
jain
2014
utk
face
zhang
et
al
2017b
racial
faces
wild
wang
et
al
2019e
diversity
faces
merler
et
al
2019
tackle
documentation
debt
algorithmic
fairness
community
survey
datasets
used
500
articles
fair
ml
equitable
algorithmic
design
presented
seven
major
conferences
considering
edition
period
2014
2021
twenty
domain-specific
workshops
period
find
200
datasets
employed
studies
algorithmic
fairness
produce
compact
standardized
documentation
called
data
briefs
data
briefs
intended
lightweight
format
document
fundamental
properties
data
artifacts
used
algorithmic
fairness
including
purpose
features
particular
attention
sensitive
ones
underlying
labeling
procedure
envisioned
ml
task
favor
domain-based
task-based
search
dataset
users
data
briefs
also
indicate
domain
processes
produced
data
radiology
list
fairness
tasks
studied
given
dataset
fair
ranking
endeavour
contacted
creators
knowledgeable
practitioners
identified
primary
points
contact
datasets
received
feedback
incorporated
final
version
data
briefs
79
curators
practitioners
whose
contribution
acknowledged
end
article
moreover
identify
carefully
analyze
three
datasets
often
utilized
surveyed
articles
adult
compas
german
credit
retrospectively
producing
datasheet
nutrition
label
documentation
efforts
extract
summary
merits
limitations
popular
algorithmic
fairness
benchmarks
categorization
domains
fairness
tasks
existing
datasets
set
best
practices
curation
novel
resources
overall
make
following
contributions
unified
analysis
popular
fairness
benchmarks
produce
datasheets
nutrition
labels
adult
compas
german
credit
extract
summary
merits
limitations
add
unify
recent
scholarship
datasets
calling
question
suitability
general-purpose
fairness
benchmarks
due
contrived
prediction
tasks
noisy
data
severe
coding
mistakes
age
survey
existing
alternatives
compile
standardized
compact
documen
tation
two
hundred
resources
used
fair
ml
research
annotating
domain
tasks
support
roles
play
works
algorithmic
fairness
assembling
sparse
information
hundreds
datasets
sin
gle
document
aim
support
multiple
goals
researchers
practitioners
hereafter
brevity
report
dataset
names
relevant
references
additional
information
can
found
appendix
123
algorithmic
fairness
datasets
story
far
2077
including
domain-oriented
task-oriented
search
dataset
users
contextually
provide
novel
categorization
tasks
domains
investigated
algorithmic
fairness
research
summarized
tables
best
practices
curation
novel
resources
analyze
different
approaches
anonymization
consent
inclusivity
labeling
transparency
across
datasets
comparing
existing
approaches
discussing
advantages
make
underlying
concerns
visible
practical
extract
best
practices
inform
curation
new
datasets
post-hoc
remedies
existing
ones
rest
work
organized
follows
section
introduces
related
works
section
presents
methodology
inclusion
criteria
survey
section
ana
lyzes
perks
limitations
popular
datasets
namely
adult
sect
4.1
compas
sect
4.2
german
credit
sect
4.3
provides
overall
sum
mary
merits
limitations
fairness
benchmarks
sect
4.4
section
discusses
alternative
fairness
resources
perspective
underlying
domains
sect
5.1
fair
ml
tasks
support
sect
5.2
roles
play
sect
5.3
section
presents
important
topics
data
curation
discussing
existing
approaches
best
practices
avoid
re-identification
sect
6.1
elicit
informed
consent
sect
6.2
consider
inclusivity
sect
6.3
collect
sensitive
attributes
sect
6.4
document
datasets
sect
6.5
section
summarizes
broader
benefits
documentation
effort
envisioned
uses
research
community
finally
sect
contains
con
cluding
remarks
recommendations
interested
readers
may
find
data
briefs
appendix
followed
detailed
documentation
produced
adult
com
pas
german
credit
related
work
2.1
algorithmic
fairness
surveys
multiple
surveys
algorithmic
fairness
published
literature
mehrabi
et
al
2021
caton
haas
2020
pessach
shmueli
2020
works
typically
focus
describing
classifying
important
measures
algorithmic
fair
ness
methods
enhance
articles
also
discuss
sources
bias
mehrabi
et
al
2021
software
packages
projects
address
fairness
ml
caton
haas
2020
describe
selected
sub-fields
algorithmic
fairness
pessach
shmueli
2020
datasets
typically
emphasized
works
also
true
domain-specific
surveys
algorithmic
fairness
focused
ranking
pitoura
et
al
2021
natural
language
processing
nlp
sun
et
al
2019
computational
medicine
sun
et
al
2019
exception
pessach
shmueli
2020
zehlike
et
al
2021
list
briefly
describe
12
popular
algorithmic
fairness
datasets
19
datasets
employed
fair
ranking
research
respectivey
123
2078
fabris
et
al
2.2
data
studies
work
closely
related
concurrently
carried
le
quy
et
al
2022
authors
perform
detailed
analysis
15
tabular
datasets
used
works
algorithmic
fairness
listing
important
metadata
domain
protected
attributes
collection
period
location
carrying
exploratory
analysis
prob
abilistic
relationship
features
work
complements
placing
emphasis
rigorous
methodology
inclusion
resources
wider
selection
200
datasets
spanning
different
data
types
including
text
image
timeseries
tabular
data
fine-grained
evaluation
domains
tasks
asso
ciated
dataset
analysis
distillation
best
practices
data
curation
will
interesting
see
different
goals
research
community
selection
appropriate
resources
experimentation
data
studies
can
benefit
breadth
depth
works
works
analyzing
multiple
datasets
along
specific
lines
published
recent
years
crawford
paglen
2021
focus
resources
commonly
used
training
sets
computer
vision
attention
associated
labels
underlying
taxonomies
fabbrizzi
et
al
2021
also
consider
computer
vision
datasets
describing
types
bias
affecting
along
methods
discovering
measuring
bias
peng
et
al
2021
analyze
ethical
concerns
three
popular
face
person
recognition
datasets
stemming
derivative
datasets
models
lack
clarity
licenses
dataset
management
practices
geiger
et
al
2020
evaluate
transparency
documentation
labeling
practices
employed
100
datasets
twitter
leonelli
tempini
2020
study
practices
collection
cleaning
visualization
sharing
analysis
across
variety
research
domains
romei
ruggieri
2014
survey
techniques
data
discrimination
analysis
focused
measuring
rather
enforcing
equity
human
processes
different
yet
related
family
articles
provides
deeper
analyses
single
datasets
prabhu
birhane
2020
focus
imagenet
ilsvrc
2012
analyze
along
lines
consent
problematic
content
individual
re-identification
kizh
ner
et
al
2020
study
issues
representation
google
arts
culture
project
across
countries
cities
institutions
works
provide
datasheets
given
resource
chexpert
garbin
et
al
2021
bookcorpus
bandy
vincent
2021
among
popular
fairness
datasets
compas
drawn
scrutiny
multiple
works
analysing
numerical
idiosyncrasies
barenstein
2019
sources
bias
bao
et
al
2021
ding
et
al
2021
study
numerical
idiosyncrasies
adult
dataset
propose
novel
version
provide
datasheet
grömping
2019
discuss
issues
resulting
coding
mistakes
german
credit
work
combines
breadth
multi-dataset
depth
single-dataset
studies
one
hand
survey
numerous
resources
used
works
algorithmic
fairness
analyzing
across
multiple
dimensions
hand
identify
popular
resources
compiling
datasheet
nutrition
label
summarize
perks
limitations
moreover
making
data
briefs
available
hope
contribute
useful
tool
research
community
favouring
data
studies
analyses
outlined
sect
123
algorithmic
fairness
datasets
story
far
2079
2.3
documentation
frameworks
several
data
documentation
frameworks
proposed
literature
three
popular
ones
described
datasheets
datasets
gebru
et
al
2018
general-purpose
qualitative
framework
fifty
questions
covering
key
aspects
datasets
motivation
composition
collection
preprocessing
uses
dis
tribution
maintenance
another
qualitative
framework
represented
data
statements
bender
friedman
2018
tailored
nlp
requiring
domain
specific
information
language
variety
speaker
demographics
dataset
nutrition
labels
holland
et
al
2018
describe
complementary
quantitative
framework
focused
numerical
aspects
marginal
joint
distribution
variables
popular
datasets
require
close
scrutiny
reason
adopt
frame
works
producing
three
datasheets
nutrition
labels
adult
german
credit
compas
approach
however
scale
wider
documentation
effort
limited
resources
reason
propose
produce
data
briefs
lightweight
documentation
format
designed
algorithmic
fairness
datasets
data
briefs
described
appendix
include
fields
specific
fair
ml
sensitive
attributes
tasks
dataset
used
algorithmic
fairness
literature
methodology
work
consider
every
article
published
proceedings
domain
specific
conferences
acm
conference
fairness
accountability
transparency
facct
aaai
acm
conference
artificial
intelligence
ethics
society
aies
every
article
published
proceedings
well-known
machine
learning
data
mining
conferences
including
ieee
cvf
conference
computer
vision
pattern
recognition
cvpr
conference
neural
information
processing
systems
neurips
international
conference
machine
learning
icml
international
conference
learning
representations
iclr
acm
sigkdd
international
conference
knowledge
discovery
data
min
ing
kdd
every
article
available
past
network
events
older
workshops
events
facct
network
consider
period
2014
year
first
workshop
fairness
accountability
transparency
machine
learning
june
2021
thus
including
works
presented
facct
iclr
aies
cvpr
2021.4
target
works
algorithmic
fairness
select
subsample
articles
whose
titles
contain
either
following
strings
star
symbol
represents
wildcard
character
fair
targeting
fairness
unfair
bias
biased
debiasing
discriminat
discrimination
discriminatory
equal
equality
unequal
equit
equity
equitable
disparate
disparate
impact
parit
par
https://facctconference.org/network/.
working
update
covering
recent
work
including
articles
presented
acm
conference
equity
access
algorithms
mechanisms
optimization
123
2080
fabris
et
al
ity
disparities
selection
criteria
centered
around
equity-based
notions
fairness
typically
operationalized
measuring
disparity
algorithmic
prop
erty
across
individuals
groups
individuals
manual
inspection
two
authors
discard
articles
keywords
used
different
mean
ing
discarded
works
instance
include
articles
handling
pose
distribution
bias
zhao
et
al
2021
compensating
selection
bias
improve
accuracy
without
attention
sensitive
attributes
kato
et
al
2019
enhancing
desirable
discriminating
properties
models
chen
et
al
2018a
generally
focused
model
performance
li
et
al
2018
zhong
et
al
2019
leaves
us
558
articles
articles
pass
initial
screening
select
datasets
treated
impor
tant
data
artifacts
either
used
train
test
algorithm
undergoing
data
audit
in-depth
analysis
different
properties
produce
data
brief
datasets
reading
information
provided
surveyed
articles
consulting
provided
references
reviewing
scholarly
articles
official
websites
found
querying
popular
search
engines
dataset
name
discard
following
word
embeddings
wes
consider
corpora
trained
pro
vided
wes
trained
part
given
work
taken
shelf
toy
datasets
simulations
connection
real-world
processes
unless
used
one
article
take
sign
importance
field
auxiliary
resources
used
minor
source
ancillary
information
percentage
us
residents
state
datasets
available
information
insufficient
happens
seldom
points
outlined
result
little
information
curators
purposes
features
format
dataset
popular
datasets
never
case
226
datasets
satisfying
criteria
produce
data
brief
available
appendix
description
underlying
coding
procedure
effort
rigorously
identify
three
popular
resources
whose
perks
limitations
summarized
next
section
popular
datasets
figure
depicts
number
articles
using
dataset
showing
dataset
uti
lization
surveyed
scholarly
works
follows
long
tail
distribution
100
datasets
used
also
resources
publicly
available
complementing
long
tail
short
head
nine
resources
used
ten
articles
datasets
adult
118
usages
compas
81
german
credit
35
communities
crime
26
bank
marketing
19
law
school
17
celeba
16
movielens
14
credit
card
default
11
tenth
used
resource
toy
dataset
zafar
et
al
2017c
used
articles
section
summarize
positive
negative
aspects
three
popular
datasets
namely
adult
com
123
algorithmic
fairness
datasets
story
far
2081
fig
utilization
datasets
fairness
research
follows
long
tail
distribution
pas
german
credit
informed
extensive
documentation
appendices
4.1
adult
adult
dataset
created
resource
benchmark
performance
machine
learning
algorithms
socially
relevant
data
instance
person
responded
march
1994
us
current
population
survey
represented
along
demographic
socio-economic
dimensions
features
describing
profession
education
age
sex
race
personal
financial
condition
dataset
extracted
census
database
preprocessed
donated
uci
machine
learning
repository
1996
ronny
kohavi
barry
becker
binary
variable
encoding
whether
respondents
income
50
000
chosen
target
prediction
task
associated
resource
adult
inherits
positive
sides
best
practices
employed
us
census
bureau
although
later
filtered
somewhat
arbitrarily
original
sample
designed
representative
us
population
trained
compensated
inter
viewers
collected
data
attributes
dataset
self-reported
provided
consensual
respondents
finally
original
data
us
census
bureau
well
documented
variables
can
mapped
adult
consulting
original
doc
umentation
us
dept
commerce
bureau
census
1995
except
variable
denominated
fnlwgt
whose
precise
meaning
unclear
negative
aspect
dataset
contrived
prediction
task
associated
income
prediction
socio-economic
factors
task
whose
social
utility
appears
rather
limited
even
discounting
aspect
arbitrary
50
000
threshold
binary
prediction
task
high
model
properties
accuracy
fairness
sensitive
ding
et
al
2021
furthermore
several
sources
noise
affecting
data
roughly
data
points
missing
values
plausibly
due
123
2082
fabris
et
al
issues
data
recording
coding
respondents
inability
recall
information
moreover
tendency
household
surveys
respondents
under-report
income
common
concern
census
bureau
moore
et
al
2000
another
source
noise
top-coding
variable
capital-gain
saturation
99
999
avoid
re-identification
certain
individuals
us
dept
commerce
bureau
census
1995
finally
dataset
rather
old
sensitive
attribute
race
contains
outdated
asian
pacific
islander
class
worth
noting
set
similar
resources
recently
made
available
allowing
current
socio-economic
studies
us
population
ding
et
al
2021
4.2
compas
dataset
created
external
audit
racial
biases
correctional
offender
management
profiling
alternative
sanctions
compas
risk
assessment
tool
developed
northpointe
now
equivant
estimates
likelihood
defendant
becoming
recidivist
instances
represent
defendants
scored
compas
broward
county
florida
2013
2014
reporting
demographics
crim
inal
record
custody
compas
scores
defendants
public
criminal
records
obtained
broward
county
clerk
office
website
matching
based
date
birth
first
last
names
dataset
augmented
jail
records
compas
scores
provided
broward
county
sheriff
office
finally
public
incarcera
tion
records
downloaded
florida
department
corrections
website
instances
associated
two
target
variables
is_recid
is_violent_recid
indi
cating
whether
defendants
booked
jail
criminal
offense
potentially
violent
occurred
compas
screening
within
two
years
upside
dataset
recent
captures
relevant
aspects
compas
risk
assessment
tool
criminal
justice
system
broward
county
downside
compiled
disparate
sources
hence
clerical
errors
mismatches
present
larson
et
al
2016
moreover
official
release
prop
ublica
2016
compas
dataset
features
redundant
variables
data
leakage
due
spuriously
time-dependent
recidivism
rates
barenstein
2019
reasons
researchers
must
perform
preprocessing
addition
standard
one
propublica
subjective
choices
required
researchers
interested
counter
factual
evaluation
risk-assessment
tools
due
absence
clear
indication
whether
defendants
detained
released
pre-trial
mishler
et
al
2021
lack
standard
preprocessing
protocol
beyond
one
propublica
propublica
2016
insufficient
handle
factors
may
cause
issues
reproducibility
difficulty
comparing
methods
moreover
according
northpointe
response
propublica
study
several
risk
factors
considered
compas
algorithm
absent
dataset
dieterich
et
al
2016
additional
concern
race
cate
gories
lack
native
hawaiian
pacific
islander
hispanic
redefined
race
instead
ethnicity
bao
et
al
2021
finally
defendants
personal
information
race
criminal
history
available
conjunction
obvious
identifiers
making
re-identification
defendants
trivial
123
table
limitations
popular
algorithmic
fairness
datasets
adult
compas
german
credit
age
old
1994
recent
2013
2016
old
1973
1975
algorithmic
fairness
datasets
story
far
prediction
task
contrived
income
50k
realistic
recidivism
realistic
creditworthiness
sensitive
attributes
outdated
racial
categories
outdated
racial
categories
sex
retrieved
sources
noise
top-coding
tendency
under-report
data
leakage
label
bias
clerical
incorrect
code
table
income
errors
sample
representativeness
us
working
population
convenience
sample
broward
artificial
sample
credit
granted
county
negative
class
oversampled
preprocessing
needed
handling
missing
values
handling
missing
values
80
none
removing
redundant
features
ground
truth
detainment
additional
concerns
accuracy
fairness
sensitive
potential
misguided
discussion
interpretability
exploratory
arbitrary
50k
threshold
criminal
justice
analyses
invalid
2083
123
2084
fabris
et
al
compas
also
represents
case
broad
phenomenon
can
termed
data
bias
terminology
friedler
et
al
2021
comes
datasets
encoding
complex
human
phenomena
often
disconnect
construct
space
aim
measure
observed
space
end
observing
may
especially
problematic
difference
construct
observation
uneven
across
individuals
groups
compas
example
dataset
criminal
offense
offense
central
prediction
target
aimed
encoding
recidivism
available
covariates
summarizing
criminal
history
however
compas
dataset
observed
space
imperfect
proxy
criminal
patterns
summarize
construct
space
prediction
labels
actually
encode
re
arrest
instead
re-offense
larson
et
al
2016
thus
clearly
influenced
spatially
differentiated
policing
practices
fogliato
et
al
2021
also
true
criminal
history
encoded
compas
covariates
mediated
arrest
policing
practices
may
racially
biased
bao
et
al
2021
mayson
2018
result
true
fairness
algorithm
just
like
accuracy
may
differ
significantly
reported
biased
data
example
algorithms
achieve
equality
true
positive
rates
across
sensitive
groups
compas
deemed
fair
equal
opportunity
measure
hardt
et
al
2016
however
training
set
objective
enforced
test
set
measured
affected
race-dependent
noise
described
algorithms
fair
abstract
observed
space
real
construct
space
ultimately
care
friedler
et
al
2021
overall
considerations
paint
mixed
picture
dataset
high
social
rel
evance
extremely
useful
catalyze
attention
algorithmic
fairness
issues
displaying
time
several
limitations
terms
continued
use
flexible
benchmark
fairness
studies
sorts
regard
bao
et
al
2021
suggest
avoiding
use
compas
demonstrate
novel
approaches
algorithmic
fairness
considering
data
without
proper
context
may
lead
misleading
con
clusions
misguidedly
enter
broader
debate
criminal
justice
risk
assessment
4.3
german
credit
german
credit
dataset
created
study
problem
computer-assisted
credit
decisions
regional
bank
southern
germany
instances
represent
loan
applicants
1973
1975
deemed
creditworthy
granted
loan
bringing
natural
selection
bias
within
sample
bad
credits
oversampled
favour
balance
target
classes
grömping
2019
data
summarizes
applicants
financial
situation
credit
history
personal
situation
including
housing
number
liable
people
binary
variable
encoding
whether
loan
recipient
punctually
payed
every
installment
target
classification
task
among
covariates
marital
status
sex
jointly
encoded
single
variable
many
documentation
mistakes
present
uci
entry
associated
resource
uci
machine
learning
repository
1994
revised
version
correct
variable
encodings
called
123
algorithmic
fairness
datasets
story
far
2085
south
german
credit
donated
uci
machine
learning
repository
2019
accompanying
report
grömping
2019
greatest
upside
dataset
fact
captures
real-world
application
credit
scoring
bank
downside
data
half
century
old
significantly
limiting
societally
useful
insights
can
gleaned
importantly
popular
release
dataset
uci
machine
learning
repository
1994
comes
highly
inaccurate
documentation
contains
wrong
variable
codings
example
variable
reporting
whether
loan
recipients
foreign
workers
coding
reversed
apparently
fewer
loan
recipients
dataset
german
luckily
error
impact
numerical
results
obtained
dataset
irrelevant
level
abstraction
afforded
raw
features
exception
potentially
counterintuitive
explanations
works
interpretability
exploratory
analysis
le
quy
et
al
2022
coding
error
along
others
discussed
grömping
2019
corrected
novel
release
dataset
uci
machine
learning
repository
2019
unfortunately
importantly
fair
ml
community
retrieving
sex
loan
applicants
simply
possible
unlike
original
documentation
suggested
due
fact
one
value
feature
used
indicate
women
divorced
separated
married
men
single
original
documentation
reported
feature
value
correspond
same-sex
applicants
either
male-only
female-only
particular
coding
error
ended
non-negligible
impact
fair
ml
community
many
works
studying
group
fairness
extract
sex
joint
variable
use
sensitive
attribute
even
years
redacted
documentation
published
wang
et
al
2021
le
quy
et
al
2022
coding
mistakes
part
documentation
debt
whose
influence
continues
affect
algorithmic
fairness
community
4.4
summary
adult
compas
german
credit
used
datasets
surveyed
algo
rithmic
fairness
literature
despite
limitations
summarized
table
status
de
facto
fairness
benchmarks
probably
due
use
seminal
works
pedreshi
et
al
2008
calders
et
al
2009
influential
articles
angwin
et
al
2016
algo
rithmic
fairness
fame
created
researchers
clear
incentives
study
novel
problems
approaches
datasets
result
become
even
established
benchmarks
algorithmic
fairness
literature
bao
et
al
2021
close
scrutiny
fundamental
merit
datasets
lies
originating
human
processes
encoding
protected
attributes
different
base
rates
target
variable
across
sensitive
groups
use
recent
works
algorithmic
fairness
can
interpreted
signal
authors
basic
awareness
default
data
practices
field
data
made
fit
algorithm
arching
claims
significance
real-world
scenarios
stemming
experiments
datasets
met
skepticism
experiments
claim
extracting
sex
variable
german
credit
dataset
considered
noisy
best
alternatives
bao
et
al
2021
suggest
employing
well-designed
simulations
com
plementary
avenue
seek
different
datasets
relevant
problem
hand
123
2086
fabris
et
al
hope
two
hundred
data
briefs
accompanying
work
will
prove
useful
regard
favouring
domain-oriented
task-oriented
searches
according
classification
discussed
next
section
existing
alternatives
section
discuss
existing
fairness
resources
three
different
perspectives
sect
5.1
describe
different
domains
spanned
fairness
datasets
sect
5.2
provide
categorization
fairness
tasks
supported
resources
sect
5.3
discuss
different
roles
played
datasets
fairness
research
supporting
training
benchmarking
5.1
domain
algorithmic
fairness
concerns
arise
domain
automated
decision
making
adm
systems
may
influence
human
well-being
unsurprisingly
datasets
survey
reflect
variety
areas
adm
systems
studied
deployed
including
criminal
justice
education
search
engines
online
marketplaces
emergency
response
social
media
medicine
hiring
fig
report
subdivision
surveyed
datasets
different
macrodomains
mostly
follow
area-category
taxonomy
scimago
departing
appropriate
example
consider
computer
vision
linguistics
macrodomains
purposes
algorithmic
fairness
much
fair
ml
work
published
disciplines
present
description
macrodomain
main
subdomains
summarized
detail
table
computer
science
datasets
macrodomain
well
represented
comprising
information
systems
social
media
library
information
sciences
com
puter
networks
signal
processing
information
systems
heavily
feature
datasets
search
engines
various
items
text
images
worker
profiles
real
estate
retrieved
response
queries
issued
users
occupations
google
images
scientist
painter
zillow
searches
barcelona
room
rental
burst
taskrab
bit
online
freelance
marketplaces
bing
us
queries
symptoms
queries
datasets
represent
problems
item
recommendation
covering
products
businesses
movies
amazon
recommendations
amazon
reviews
google
local
movie
lens
filmtrust
remaining
datasets
subdomain
represent
knowledge
bases
freebase15k-237
wikidata
automated
screening
systems
cvs
singapore
pymetrics
bias
group
datasets
social
media
focused
links
relationships
people
also
considered
part
computer
science
sur
vey
resources
often
focused
text
powering
tools
analyses
hate
speech
toxicity
civil
comments
twitter
abusive
behavior
twitter
offensive
language
twitter
hate
speech
detection
twitter
online
harassment
dialect
twit
total
exceeds
226
due
multiple
domains
applicable
dataset
see
subject
area
subject
category
drop
menus
https://www.scimagojr.com/
journalrank
php
accessed
march
15
2022
123
algorithmic
fairness
datasets
story
far
2087
fig
datasets
employed
fairness
research
span
diverse
domains
see
table
detailed
breakdown
teraae
political
leaning
twitter
presidential
politics
twitter
far
represented
platform
datasets
facebook
german
political
posts
steeemit
steemit
instagram
instagram
photos
reddit
rtgender
reddit
comments
fitoc
racy
rtgender
youtube
youtube
dialect
accuracy
also
present
datasets
library
information
sciences
mainly
focused
academic
collaboration
networks
cora
papers
citeseer
papers
pubmed
diabetes
papers
arnetminer
cita
tion
network
4area
academic
collaboration
networks
except
dataset
peer
review
scholarly
manuscripts
paper-reviewer
matching
social
sciences
datasets
social
sciences
also
plentiful
spanning
law
education
social
networks
demography
social
work
political
science
transporta
tion
sociology
urban
studies
law
datasets
mostly
focused
recidivism
crowd
judgement
compas
recidivism
felons
probation
state
court
pro
cessing
statistics
los
angeles
city
attorney
office
records
crime
prediction
strategic
subject
list
philadelphia
crime
incidents
stop
question
frisk
real
time
crime
forecasting
challenge
dallas
police
incidents
communities
crime
granularity
spanning
range
individuals
communities
area
education
find
datasets
encode
application
processes
nursery
iit-jee
student
performance
student
law
school
unige
ilea
us
student
performance
indian
student
performance
edgap
berkeley
students
including
attempts
auto
mated
grading
automated
student
assessment
prize
placement
information
school
campus
recruitment
datasets
student
performance
support
studies
differences
across
schools
educational
systems
report
useful
features
law
school
ilea
edgap
remaining
datasets
focused
differences
individual
condition
outcome
students
typically
within
institution
datasets
social
networks
mostly
concern
online
123
2088
fabris
et
al
social
networks
facebook
ego-networks
facebook
large
network
pokec
social
network
rice
facebook
network
twitch
social
networks
university
facebook
net
works
except
high
school
contact
friendship
network
also
featuring
offline
relations
demography
datasets
comprise
census
data
different
countries
dutch
census
indian
census
national
longitudinal
survey
youth
section
203
determi
nations
us
census
data
1990
datasets
social
work
cover
complex
personal
social
problems
including
child
maltreatment
prevention
allegheny
child
wel
fare
emergency
response
harvey
rescue
drug
abuse
prevention
homeless
youths
social
networks
drugnet
resources
political
science
describe
reg
istered
voters
north
carolina
voters
electoral
precincts
mggg
states
polling
2016
us
presidential
poll
sortition
climate
assembly
uk
transportation
data
summarizes
trips
fares
taxis
nyc
taxi
trips
shanghai
taxi
trajecto
ries
ride-hailing
chicago
ridesharing
ride-hailing
app
bike
sharing
services
seoul
bike
sharing
along
public
transport
coverage
equitable
school
access
chicago
sociology
resources
summarize
online
libimseti
offline
dating
columbia
university
speed
dating
finally
assign
safegraph
research
release
urban
studies
computer
vision
area
early
success
artificial
intelligence
fairness
typically
concerns
learned
representations
equality
performance
across
classes
surveyed
articles
feature
several
popular
datasets
image
clas
sification
imagenet
mnist
fashion
mnist
cifar
visual
question
answering
visual
question
answering
segmentation
captioning
ms-coco
open
images
dataset
find
ten
face
analysis
datasets
labeled
faces
wild
utk
face
adience
fairface
ijb-a
celeba
pilot
parliaments
benchmark
ms-celeb
1m
diversity
faces
multi-task
facial
landmark
racial
faces
wild
bupt
faces
including
one
experimental
psychology
faces
fairness
often
intended
robustness
classifiers
across
different
subpopulations
without
much
regard
downstream
benefits
harms
populations
syn
thetic
images
popular
study
relationship
fairness
disentangled
representations
dsprites
cars3d
shapes3d
similar
studies
can
conducted
datasets
spurious
correlations
subjects
backgrounds
waterbirds
benchmarking
attribution
methods
gender
occupation
athletes
health
professionals
finally
image
embedding
association
test
dataset
fairness
benchmark
study
biases
image
embeddings
across
religion
gender
age
race
sexual
orientation
disability
skin
tone
weight
worth
noting
sig
nificant
proportion
computer
vision
datasets
artifact
including
cvpr
list
candidate
conferences
contributed
just
five
additional
datasets
multi-task
facial
landmark
office31
racial
faces
wild
bupt
faces
visual
question
answering
health
macrodomain
comprising
medicine
psychology
pharmacol
ogy
displays
notable
diversity
subdomains
interested
fairness
concerns
specialties
represented
surveyed
datasets
mostly
medical
including
public
health
antelope
valley
networks
willingness-to-pay
vaccine
kidney
matching
kidney
exchange
program
cardiology
heart
disease
arrhythmia
fram
ingham
endocrinology
diabetes
130
us
hospitals
pima
indians
diabetes
dataset
health
policy
heritage
health
meps-hc
specialties
radiology
national
123
algorithmic
fairness
datasets
story
far
2089
lung
screening
trial
mimic-cxr-jpg
chexpert
dermatology
siim-isic
melanoma
classification
ham10000
feature
several
image
datasets
strong
connections
medical
imaging
specialties
include
critical
care
medicine
mimic-iii
neurology
epileptic
seizures
pediatrics
infant
health
develop
ment
program
sleep
medicine
apnea
nephrology
renal
failure
pharmacology
warfarin
psychology
drug
consumption
faces
datasets
often
extracted
care
data
multiple
medical
centers
study
problems
auto
mated
diagnosis
resources
derived
longitudinal
studies
including
framingham
infant
health
development
program
also
present
works
algorithmic
fairness
domain
typically
concerned
obtaining
models
similar
performance
patients
across
race
sex
linguistics
addition
textual
resources
already
described
ones
derived
social
media
several
datasets
employed
algorithmic
fairness
literature
can
assigned
domain
linguistics
natural
language
processing
nlp
many
examples
resources
curated
fairness
benchmarks
different
tasks
including
machine
translation
bias
translation
templates
sentiment
analysis
equity
evaluation
corpus
coreference
resolution
winogender
winobias
gap
coreference
named
entity
recognition
in-situ
language
models
bold
word
embeddings
weat
datasets
considered
size
importance
pretraining
text
representations
wikipedia
dumps
one
billion
word
benchmark
bookcorpus
webtext
utility
nlp
benchmarks
glue
business
entity
resolution
speech
recognition
resources
also
considered
timit
economics
business
macrodomain
comprises
datasets
economics
finance
marketing
management
information
systems
economics
datasets
mostly
consist
census
data
focused
wealth
adult
us
family
income
poverty
colom
bia
costarica
household
survey
resources
summarize
employment
anpe
tariffs
us
harmonized
tariff
schedules
insurance
italian
car
insurance
division
goods
spliddit
divide
goods
finance
resources
feature
data
microcredit
peer-to-peer
lending
mobile
money
loans
kiva
prosper
loans
net
work
mortgages
hmda
loans
german
credit
credit
elasticities
credit
scoring
fico
default
prediction
credit
card
default
marketing
datasets
describe
mar
keting
campaigns
bank
marketing
customer
data
wholesale
advertising
bids
yahoo
a1
search
marketing
finally
datasets
management
information
sys
tems
summarize
information
automated
hiring
cvs
singapore
pymetrics
bias
group
employee
retention
ibm
hr
analytics
miscellaneous
macrodomain
contains
several
datasets
originating
news
domain
yow
news
guardian
articles
latin
newspapers
adressa
reuters
50
50
new
york
times
annotated
corpus
trec
robust04
resources
include
datasets
food
sushi
sports
fantasy
football
fifa
20
players
olympic
athletes
toy
datasets
toy
dataset
arts
humanities
area
mostly
find
literature
datasets
contain
text
literary
works
shakespeare
curatr
british
library
digital
corpus
victorian
era
authorship
attribution
nominees
corpus
riddle
literary
quality
typically
studied
nlp
tools
datasets
domain
include
domain
123
2090
fabris
et
al
specific
information
systems
books
goodreads
reviews
movies
movielens
music
last
fm
million
song
dataset
million
playlist
dataset
natural
sciences
domain
represented
three
datasets
biology
inaturalist
biochemestry
pp-pathways
plant
science
classic
iris
dataset
whole
many
datasets
encode
fundamental
human
activities
algorithms
adm
systems
studied
deployed
alertness
attention
equity
seems
especially
important
specific
domains
including
social
sciences
computer
science
medicine
economics
potential
impact
may
result
large
benefits
also
great
harm
particularly
vulnerable
populations
minorities
likely
neglected
design
training
testing
adm
concentrating
domains
next
section
analyze
variety
tasks
studied
works
algorithmic
fairness
supported
datasets
5.2
task
setting
researchers
practitioners
showing
increasing
interest
algorithmic
fairness
proposing
solutions
many
different
tasks
including
fair
classification
regression
ranking
time
academic
community
developing
improved
understanding
important
challenges
run
across
different
tasks
algorithmic
fairness
space
chouldechova
roth
2020
also
thanks
practitioner
surveys
holstein
et
al
2019
studies
specific
legal
challenges
andrus
et
al
2021
exemplify
presence
noise
corrupting
labels
sensitive
attributes
represents
challenge
may
apply
across
different
tasks
including
fair
classifica
tion
regression
ranking
refer
challenges
settings
describing
second
part
section
work
focuses
fair
ml
datasets
cognizant
wide
variety
tasks
tackled
algorithmic
fairness
literature
captured
specific
field
data
briefs
section
provide
overview
common
tasks
settings
studied
datasets
showing
variety
diversity
table
summarizes
tasks
listing
three
used
datasets
task
describing
task
explicitly
highlight
datasets
particularly
relevant
even
outside
top
three
5.2
task
fair
classification
calders
verwer
2010
dwork
et
al
2012
common
task
far
typically
involves
equalizing
measure
interest
across
subpop
ulations
recall
precision
accuracy
different
racial
groups
hand
individually
fair
classification
focuses
idea
similar
individuals
low
distance
covariate
space
treated
similarly
low
distance
outcome
space
often
formalized
lipschitz
condition
unsurprisingly
common
datasets
fair
classification
popular
ones
overall
sect
adult
compas
german
credit
fair
regression
berk
et
al
2017
concentrates
models
predict
real-valued
target
requiring
average
loss
balanced
across
groups
individual
fairness
123
algorithmic
fairness
datasets
story
far
2091
table
selection
datasets
lens
domain
taxonomy
domain
sample
datasets
computer
science
social
media
toxicity
hate
speech
civil
comments
wikipedia
toxic
comments
twitter
offen
sive
language
political
leaning
twitter
presidential
politics
dialect
twitteraae
library
information
sciences
collaboration
networks
paper-reviewer
matching
4area
arnetminer
citation
net
work
peer
review
paper-reviewer
matching
information
systems
search
engines
online
freelance
marketplaces
bing
us
queries
symptoms
queries
recommender
systems
amazon
recommendations
amazon
reviews
movielens
knowledge
bases
freebase15k-237
wikidata
computer
networks
kdd
cup
99
pattern
recognition
internet
ads
signal
processing
vehicle
social
sciences
urban
studies
safegraph
research
release
social
networks
university
facebook
networks
pokec
social
network
rice
facebook
network
demography
us
census
data
1990
dutch
census
national
longitudi
nal
survey
youth
sociology
columbia
university
speed
dating
libimseti
law
recidivism
prediction
compas
recidivism
felons
probation
state
court
pro
cessing
statistics
crime
prediction
communities
crime
stop
question
frisk
strategic
subject
list
political
science
registered
voters
north
carolina
voters
electoral
precincts
mggg
states
polling
2016
us
presidential
poll
sortition
climate
assembly
uk
education
application
processes
nursery
iit-jee
student
performance
student
law
school
unige
post-education
placement
campus
recruitment
123
2092
fabris
et
al
table
continued
domain
sample
datasets
social
work
child
maltreatment
prevention
allegheny
child
welfare
emergency
response
harvey
rescue
drug
abuse
prevention
homeless
youths
social
networks
drugnet
transportation
taxi
trips
nyc
taxi
trips
shanghai
taxi
trajectories
ride
hailing
chicago
ridesharing
ride-hailing
app
bike
sharing
seoul
bike
sharing
public
transport
equitable
school
access
chicago
computer
vision
general
purpose
imagenet
mnist
cifar
face
analysis
celeba
pilot
parliaments
benchmar
fairface
synthetic
dsprites
cars3d
shapes3d
health
sleep
medicine
apnea
critical
care
medicine
mimic-iii
public
health
kidney
exchange
program
willingness-to-pay
vaccine
kidney
matching
cardiology
arrhythmia
heart
disease
framingham
neurology
epileptic
seizures
pediatrics
infant
health
development
program
ihdp
dermatology
ham10000
siim-isic
melanoma
classification
medicine
stanford
medicine
research
data
repository
pharmacology
warfarin
endocrinology
diabetes
130
us
hospitals
pima
indians
diabetes
dataset
pidd
nephrology
renal
failure
radiology
chexpert
mimic-cxr-jpg
national
lung
screening
trial
nlst
health
policy
heritage
health
meps-hc
applied
psychology
drug
consumption
experimental
psychology
faces
economics
business
economics
census
adult
us
family
income
poverty
colombia
employment
anpe
tariffs
us
harmonized
tariff
schedule
insurance
italian
car
insurance
division
goods
spliddit
divide
goods
123
algorithmic
fairness
datasets
story
far
2093
table
continued
domain
sample
datasets
finance
peer-to-peer
lending
mobile
money
loans
kiva
prosper
loans
network
mortgages
hmda
credit
scoring
fico
credit
german
credit
credit
card
default
credit
elasticities
marketing
marketing
campaigns
bank
marketing
advertising
bids
yahoo
a1
search
marketing
wholesale
management
information
systems
automated
hiring
pymetrics
bias
group
cvs
singapore
employee
retention
ibm
hr
analytics
linguistics
general
purpose
wikipedia
dumps
one
billion
word
benchmark
bookcorpus
fairness
benchmarks
bias
translation
templates
equity
evaluation
corpus
wino
gender
arts
humanities
music
million
playlist
dataset
mpd
million
song
dataset
msd
last
fm
literature
goodreads
reviews
riddle
literary
quality
nominees
cor
pus
movies
movielens
filmtrust
natural
sciences
biology
inaturalist
datasets
biochemestry
pp-pathways
plant
science
iris
miscellaneous
news
trec
robust04
new
york
times
annotated
corpus
reuters
50
50
sports
fantasy
football
fifa
20
players
olympic
athletes
food
sushi
context
may
require
losses
uniform
possible
across
individuals
fair
regression
less
popular
task
often
studied
communities
crime
dataset
task
predicting
rate
violent
crimes
different
communities
fair
ranking
yang
stoyanovich
2017
requires
ordering
candidate
items
based
relevance
current
need
fairness
context
may
concern
people
producing
items
ranked
artists
consuming
items
users
music
streaming
platform
typically
studied
applications
recommendation
movielens
amazon
recommendations
last
fm
million
song
dataset
adressa
search
engines
yahoo
c14b
learning
rank
microsoft
learning
rank
trec
robust04
123
2094
fabris
et
al
table
used
datasets
algorithmic
fairness
task
setting
task
datasets
fair
classification
adult
compas
german
credit
fair
regression
communities
crime
law
school
student
fair
ranking
movielens
german
credit
kiva
fair
matching
nyc
taxi
trips
libimseti
columbia
university
speed
dating
fair
risk
assessment
compas
allegheny
child
welfare
infant
health
development
program
ihdp
fair
representation
learning
adult
compas
dsprites
fair
clustering
adult
bank
marketing
diabetes
130
us
hospitals
fair
anomaly
detection
adult
mnist
credit
card
default
fair
districting
mggg
states
fair
task
assignment
crowd
judgement
compas
fair
spatio-temporal
process
learning
real-time
crime
forecasting
challenge
dallas
police
incidents
harvey
rescue
fair
graph
diffusion
augmentation
university
facebook
networks
antelope
valley
networks
rice
facebook
network
fair
resource
allocation
subset
selection
ml
fairness
gym
us
federal
judges
climate
assembly
uk
fair
data
summarization
adult
student
credit
card
default
fair
data
generation
celeba
movielens
shapes3d
fair
graph
mining
movielens
freebase15k-237
pp-pathways
fair
pricing
willingness-to-pay
vaccine
credit
elasticities
italian
car
insurance
fair
advertising
yahoo
a1
search
marketing
north
carolina
voters
instagram
photos
fair
routing
shanghai
taxi
trajectories
fair
entity
resolution
winogender
winobias
business
entity
resolution
fair
sentiment
analysis
popular
baby
names
equity
evaluation
corpus
eec
twitteraae
bias
word
embeddings
wikipedia
dumps
word
embedding
association
test
weat
popular
baby
names
bias
language
models
twitteraae
bold
glue
fair
machine
translation
bias
translation
templates
fair
speech
recognition
youtube
dialect
accuracy
timit
setting
datasets
rich-subgroup
fairness
adult
compas
communities
crime
fairness
unawareness
adult
compas
hmda
limited-label
fairness
adult
german
credit
compas
robust
fairness
compas
adult
meps-hc
dynamical
fairness
fico
ml
fairness
gym
compas
preference-based
fairness
adult
compas
toy
dataset
multi-stage
fairness
adult
heritage
health
twitter
offensive
language
123
algorithmic
fairness
datasets
story
far
2095
table
continued
setting
datasets
fair
few-shot
learning
communities
crime
toy
dataset
mobile
money
loans
fair
private
learning
utk
face
chexpert
fairface
fair
federated
learning
vehicle
sentiment140
shakespeare
fair
incremental
learning
imagenet
cifar
fair
active
learning
adult
german
credit
heart
disease
fair
selective
classification
chexpert
celeba
civil
comments
fair
matching
kobren
et
al
2019
similar
ranking
tasks
defined
two-sided
markets
task
however
focused
highlighting
matching
pairs
items
sides
market
without
emphasis
ranking
component
datasets
task
diverse
domains
including
dating
libim
seti
columbia
university
speed
dating
transportation
nyc
taxi
trips
ride-hailing
app
organ
donation
kidney
matching
kidney
exchange
program
fair
risk
assessment
coston
et
al
2020
studies
algorithms
score
instances
dataset
according
predefined
type
risk
relevant
domains
include
healthcare
criminal
justice
key
differences
respect
classification
empha
sis
real-valued
scores
rather
labels
awareness
risk
assessment
process
can
lead
interventions
impacting
target
variable
reason
fairness
concerns
often
defined
counterfactual
fashion
popular
dataset
task
compas
followed
datasets
medicine
ihdp
stan
ford
medicine
research
data
repository
social
work
allegheny
child
welfare
economics
anpe
education
edgap
fair
representation
learning
creager
et
al
2019
concerns
study
features
learnt
models
intermediate
representations
inference
tasks
popular
line
work
space
called
disentaglement
aims
learn
representations
single
factor
import
corresponds
single
feature
ideally
approach
select
representations
sensitive
attributes
used
proxies
target
variables
cars3d
dsprites
popular
datasets
task
consisting
synthetic
images
depicting
controlled
shape
types
controlled
set
rotations
post-processing
approaches
also
applicable
obtain
fair
representations
biased
ones
via
debiasing
fair
clustering
chierichetti
et
al
2017
unsupervised
task
concerned
division
sample
homogenous
groups
fairness
may
intended
equitable
representation
protected
subpopulations
cluster
terms
average
distance
cluster
center
adult
common
dataset
problems
fair
clustering
resources
often
used
task
include
bank
marketing
diabetes
130
us
hospitals
credit
card
default
us
census
data
1990
fair
anomaly
detection
zhang
davidson
2021
also
called
outlier
detection
davidson
ravi
2020
aimed
identifying
surprising
anomalous
points
dataset
fairness
requirements
involve
equalizing
salient
quantities
acceptance
123
2096
fabris
et
al
rate
recall
precision
distribution
anomaly
scores
across
populations
interest
problem
particularly
relevant
members
minority
groups
absence
specific
attention
dataset
inclusivity
less
likely
fit
norm
feature
space
fair
districting
schutzman
2020
division
territory
electoral
dis
tricts
political
elections
fairness
notions
brought
forth
space
either
outcome-based
requiring
seats
earned
party
roughly
match
share
popular
vote
procedure-based
ignoring
outcomes
requiring
counties
municipalities
split
little
possible
mggg
states
reference
resource
task
providing
precinct-level
aggregated
information
demographics
political
leaning
voters
us
districts
fair
task
assignment
truth
discovery
goel
faltings
2019
li
et
al
2020d
different
subproblems
area
focused
subdivision
work
aggregation
answers
crowdsourcing
fairness
may
intended
concerning
errors
aggregated
answer
requiring
errors
balanced
across
subpopulations
interest
terms
work
load
imposed
workers
dataset
suitable
task
crowd
judgement
containing
crowd-sourced
recidivism
predictions
fair
spatio-temporal
process
learning
shang
et
al
2020
focuses
estima
tion
models
processes
evolve
time
space
surveyed
applications
include
crime
forecasting
real-time
crime
forecasting
challenge
dallas
police
incidents
disaster
relief
harvey
rescue
fairness
requirements
focused
equalization
performance
across
different
neighbourhoods
special
attention
racial
composition
fair
graph
diffusion
farnad
et
al
2020
models
optimizes
propagation
information
influence
networks
probability
reaching
individ
uals
different
sensitive
groups
applications
include
obesity
prevention
antelope
valley
networks
drug-use
prevention
homeless
youths
social
networks
fair
graph
augmentation
ramachandran
et
al
2021
similar
task
defined
graphs
define
access
resources
based
existing
infrastructure
transportation
can
augmented
budget
increase
equity
task
pro
posed
improve
school
access
equitable
school
access
chicago
information
availability
social
networks
facebook100
fair
resource
allocation
subset
selection
babaioff
et
al
2019
huang
et
al
2020
can
often
formalized
classification
problem
constraints
number
positives
fairness
requirements
similar
classification
subset
selection
may
employed
choose
group
people
wider
set
given
task
us
federal
judges
climate
assembly
uk
resource
allocation
concerns
division
goods
spliddit
divide
goods
resources
ml
fairness
gym
german
credit
fair
data
summarization
celis
et
al
2018
refers
presenting
summary
datasets
equitable
subpopulations
interest
may
involve
finding
small
subset
representative
larger
dataset
strongly
linked
subset
selection
select
ing
important
features
dimensionality
reduction
approaches
task
applied
select
subset
images
scientist
painter
customers
bank
marketing
represent
underlying
population
across
sensitive
demographics
fair
data
generation
xu
et
al
2018
deals
generating
fair
data
points
labels
can
used
training
test
sets
approaches
space
may
123
algorithmic
fairness
datasets
story
far
2097
used
ensure
equitable
representation
protected
categories
data
generation
processes
learnt
biased
datasets
celeba
ibm
hr
analytics
evaluate
biases
existing
classifiers
ms-celeb-1m
data
generation
may
also
limited
synthesizing
artificial
sensitive
attributes
burke
et
al
2018a
fair
graph
mining
kang
et
al
2020
focuses
representations
prediction
tasks
graph
structures
fairness
may
defined
either
lack
bias
represen
tations
respect
final
inference
task
defined
graph
fair
graph
mining
approaches
applied
knowledge
bases
freebase15k-237
wikidata
col
laboration
networks
citeseer
paper
academic
collaboration
networks
social
network
datasets
facebook
large
network
twitch
social
networks
fair
pricing
kallus
zhou
2021
concerns
learning
deploying
optimal
pricing
policy
revenue
maintaining
equity
access
services
con
sumer
welfare
across
sensitive
groups
datasets
employed
fair
pricing
economics
credit
elasticities
italian
car
insurance
transportation
chicago
ridesharing
public
health
domains
willingness-to-pay
vaccine
fair
advertising
celis
et
al
2019a
also
concerned
access
goods
services
comprises
bidding
strategies
auction
mechanisms
may
modified
reduce
discrimination
respect
gender
race
composition
audience
sees
ad
one
publicly
available
dataset
subtask
yahoo
a1
search
marketing
fair
routing
qian
et
al
2015
task
suggesting
optimal
path
starting
location
destination
task
experimentation
carried
semi-synthetic
traffic
dataset
shanghai
taxi
trajectories
proposed
fairness
measure
requires
equalizing
driving
cost
per
customer
across
drivers
fair
entity
resolution
cotter
et
al
2019
task
focused
deciding
whether
multiple
records
refer
entity
useful
instance
construc
tion
maintenance
knowledge
bases
business
entity
resolution
proprietary
dataset
fair
entity
resolution
constraints
performance
equality
across
chain
non-chain
businesses
can
tested
winogender
winobias
publicly
available
datasets
developed
study
gender
biases
pronoun
resolution
fair
sentiment
analysis
kiritchenko
mohammad
2018
well-established
instance
fair
classification
text
snippets
typically
classified
positive
negative
neutral
depending
sentiment
express
fairness
intended
respect
entities
mentioned
text
men
women
central
idea
estimated
sentiment
sentence
change
female
entities
woman
mary
substituted
male
counterparts
man
james
equity
evaluation
corpus
benchmark
developed
assess
gender
race
bias
sentiment
analysis
models
bias
word
embeddings
wes
bolukbasi
et
al
2016
study
unde
sired
semantics
stereotypes
captured
vectorial
representations
words
wes
typically
trained
large
text
corpora
wikipedia
dumps
audited
associ
ations
gendered
words
words
connected
sensitive
attributes
stereotypical
harmful
concepts
ones
encoded
weat
bias
language
models
lms
bordia
bowman
2019
quite
similarly
study
biases
lms
flexible
models
human
language
based
contextualized
word
representations
can
employed
variety
linguistics
123
2098
fabris
et
al
nlp
tasks
lms
trained
large
text
corpora
may
learn
spu
rious
correlations
stereotypes
bold
dataset
evaluation
benchmark
lms
based
prompts
mention
different
socio-demographic
groups
lms
com
plete
prompts
full
sentences
can
tested
along
different
dimensions
sentiment
regard
toxicity
emotion
gender
polarity
fair
machine
translation
mt
stanovsky
et
al
2019
concerns
automatic
trans
lation
text
source
language
target
one
mt
systems
can
exhibit
gender
biases
tendency
translate
gender-neutral
pronouns
source
language
gendered
pronouns
target
language
accordance
gender
stereotypes
example
nurse
mentioned
gender-neutral
context
source
sentence
may
rendered
feminine
grammar
target
language
bias
translation
templates
set
short
templates
test
biases
fair
speech
recognition
tatman
2017
requires
accurate
annotation
spoken
language
text
across
different
demographics
youtube
dialect
accuracy
dataset
developed
audit
accuracy
youtube
automatic
captions
across
two
genders
five
dialects
english
similarly
timit
classic
speech
recognition
dataset
annotated
american
english
dialect
gender
speaker
5.2
setting
noted
beginning
section
several
settings
challenges
run
across
different
tasks
described
settings
specific
fair
ml
ensuring
fairness
across
exponential
number
groups
presence
noisy
labels
sensitive
attributes
settings
connected
common
ml
challenges
including
few-shot
privacy-preserving
learning
describe
common
settings
encountered
surveyed
articles
settings
tested
fairness
datasets
popular
overall
adult
compas
german
credit
highlight
situations
case
potentially
due
given
challenge
arising
naturally
dataset
rich-subgroup
fairness
kearns
et
al
2018
setting
fairness
properties
required
hold
limited
number
protected
groups
across
exponentially
large
number
subpopulations
line
work
represents
attempt
bridge
normative
reasoning
underlying
individual
group
fairness
fairness
unawareness
general
expression
indicate
problems
sensitive
attributes
missing
chen
et
al
2019a
encrypted
kilbertus
et
al
2018
corrupted
noise
lamy
et
al
2019
problems
respond
real-world
chal
lenges
related
confidential
nature
protected
attributes
individuals
may
wish
hide
encrypt
obfuscate
setting
commonly
studied
highly
popular
fairness
dataset
adult
compas
moderately
popular
ones
law
school
credit
card
default
dataset
home
mortgage
applications
us
hmda
limited-label
fairness
comprises
settings
limited
information
target
variable
including
situations
labelled
instances
ji
et
al
2020
noisy
wang
et
al
2021
available
aggregate
form
sabato
yom-tov
2020
robust
fairness
problems
arise
perturbations
training
set
huang
vishnoi
2019
adversarial
attacks
nanda
et
al
2021
dataset
shift
singh
123
algorithmic
fairness
datasets
story
far
2099
et
al
2021
line
research
often
connected
work
robust
machine
learning
extending
stability
requirements
beyond
accuracy-related
metrics
fairness-related
ones
dynamical
fairness
liu
et
al
2018
amour
et
al
2020
entails
repeated
deci
sions
changing
environments
potentially
affected
algorithm
studied
works
space
study
co-evolution
algorithms
populations
act
time
example
algorithm
achieves
equality
accep
tance
rates
across
protected
groups
static
setting
may
generate
incentives
next
generation
individuals
historically
disadvantaged
groups
popular
resources
setting
fico
ml
fairness
gym
preference-based
fairness
zafar
et
al
2017b
denotes
work
informed
explicitly
implicitly
preferences
stakeholders
people
subjected
decision
related
notions
envy-freeness
loss
aversion
ali
et
al
2019b
alternatively
policy-makers
can
express
indications
trade-off
different
fairness
measures
zhang
et
al
2020c
experts
can
provide
demonstrations
fair
outcomes
galhotra
et
al
2021
multi-stage
fairness
madras
et
al
2018b
refers
settings
several
deci
sion
makers
coexist
compound
decision-making
process
decision
makers
humans
algorithmic
may
act
different
levels
coordination
fundamen
tal
question
setting
ensure
fairness
composition
different
decision
mechanisms
fair
few-shot
learning
zhao
et
al
2020b
aims
developing
fair
ml
solutions
presence
small
amount
data
samples
problem
closely
related
possibly
solved
fair
transfer
learning
coston
et
al
2019
goal
exploit
knowledge
gained
problem
solve
different
related
one
datasets
setting
arises
naturally
communities
crime
one
may
restrict
training
set
subset
us
states
mobile
money
loans
consists
data
different
african
countries
fair
private
learning
bagdasaryan
et
al
2019
jagielski
et
al
2019
studies
interplay
privacy-preserving
mechanisms
fairness
constraints
works
space
consider
equity
machine
learning
models
designed
avoid
leakage
information
individuals
training
set
common
domains
datasets
employed
setting
face
analysis
utk
face
fairface
diversity
face
medicine
chexpert
siim-isic
melanoma
classification
mimic-cxr-jpg
additional
settings
less
common
include
fair
federated
learning
li
et
al
2020b
algorithms
trained
across
multiple
decentralized
devices
fair
incre
mental
learning
zhao
et
al
2020a
novel
classes
may
added
learning
problem
time
fair
active
learning
noriega-campero
et
al
2019
allowing
acquisition
novel
information
inference
fair
selective
classification
jones
et
al
2021
predictions
issued
model
confidence
certain
threshold
overall
found
variety
tasks
defined
fairness
datasets
ranging
generic
fair
classification
narrow
specifically
defined
certain
datasets
fair
districting
mggg
states
fair
truth
discovery
crowd
judgement
orthogonally
dimension
many
settings
challenges
may
arise
complicate
tasks
including
noisy
labels
system
dynamics
privacy
concerns
123
2100
fabris
et
al
quite
clearly
algorithmic
fairness
research
expanding
directions
studying
variety
tasks
diverse
challenging
settings
next
section
analyze
roles
played
scholarly
works
surveyed
datasets
5.3
role
datasets
used
algorithmic
fairness
research
can
play
different
roles
example
may
used
train
novel
algorithms
others
suited
test
existing
algorithms
specific
point
view
chapter
barocas
et
al
2019
describes
six
different
roles
datasets
machine
learning
adopt
framework
analyse
fair
ml
datasets
adding
taxonomy
two
roles
specific
fairness
research
source
real
data
synthetic
datasets
simulations
may
suited
demonstrate
specific
properties
novel
method
usefulness
algorithm
typically
established
data
real
world
sign
immediate
applicability
important
challenges
good
performance
real-world
sources
data
signals
researchers
make
data
suit
algorithm
likely
common
role
fairness
datasets
especially
common
ones
hosted
uci
ml
repository
including
adult
german
credit
communities
crime
diabetes
130
us
hospitals
bank
marketing
credit
card
default
us
census
data
1990
resources
owe
popularity
fair
ml
research
product
human
processes
encoding
protected
attributes
quite
simply
sources
real
human
data
catalyst
domain-specific
progress
datasets
can
spur
algorithmic
insight
bring
domain-specific
progress
civil
comments
great
example
role
powering
jigsaw
unintended
bias
toxicity
classification
challenge
chal
lenge
responds
specific
need
space
automated
moderation
toxic
comments
online
discussion
early
attempts
toxicity
detection
resulted
models
associate
mentions
frequently
attacked
identities
gay
toxicity
due
spurious
correlations
training
sets
dataset
associated
challenge
tackle
issue
providing
toxicity
ratings
comments
along
labels
encoding
whether
members
certain
group
mentioned
favouring
measurement
undesired
bias
many
datasets
can
play
similar
role
including
winogender
winobias
equity
evaluation
corpus
broader
sense
compas
accompanying
study
angwin
et
al
2016
important
catalyst
specific
task
fairness
research
overall
way
numerically
track
progress
problem
role
common
machine
learning
benchmarks
also
provide
human
performance
baselines
algorithmic
methods
approaching
surpassing
baselines
often
considered
sign
task
solved
harder
benchmarks
required
barocas
et
al
2019
algorithmic
fairness
complicated
context-dependent
contested
construct
whose
correct
measurement
continuously
debated
due
reason
unaware
dataset
similar
role
algorithmic
fairness
literature
resource
compare
models
practitioners
interested
solving
specific
problem
may
take
large
set
algorithms
test
group
datasets
represen
tative
problem
order
select
promising
ones
well-established
123
algorithmic
fairness
datasets
story
far
2101
ml
challenges
often
leaderboards
providing
concise
comparison
algorithms
given
task
may
used
model
selection
setting
rare
fairness
literature
also
due
inherent
difficulties
establishing
sin
gle
measure
interest
field
one
notable
exception
represented
friedler
et
al
2019
employed
suite
four
datasets
adult
compas
german
credit
ricci
compare
performance
four
different
approaches
fair
classification
source
pre-training
data
flexible
general-purpose
models
often
pre
trained
encode
useful
representations
later
fine-tuned
specific
tasks
domain
example
large
text
corpora
often
employed
train
language
models
word
embeddings
later
specialized
support
variety
stream
nlp
applications
wikipedia
dumps
instance
often
used
train
word
embeddings
investigate
biases
brunet
et
al
2019
liang
acuna
2020
papakyriakopoulos
et
al
2020
several
algorithmic
fairness
works
aim
study
mitigate
undesirable
biases
learnt
representations
corpora
like
wikipedia
dumps
used
obtain
representations
via
realistic
pretraining
procedures
mimic
com
mon
machine
learning
practice
closely
possible
source
training
data
models
specific
task
typically
learnt
training
sets
encode
relations
features
target
variable
representative
fashion
one
example
fairness
literature
large
movie
review
used
train
sentiment
analysis
models
later
audited
fairness
liang
acuna
2020
fairness
audits
one
alternative
resorting
publicly
available
models
sometimes
close
control
training
corpus
procedure
necessary
indeed
interesting
study
issues
model
fairness
relation
biases
present
respective
training
corpora
can
help
explain
causes
bias
brunet
et
al
2019
works
measure
biases
internal
model
representations
fine-tuning
training
set
regard
difference
measure
bias
training
set
babaeianjelodar
et
al
2020
employ
approach
measure
biases
rtgender
civil
comments
datasets
glue
representative
summary
service
much
important
work
fairness
lit
erature
focused
measuring
fairness
harms
real
world
line
work
includes
audits
products
services
rely
datasets
extracted
application
interest
datasets
created
purpose
include
amazon
recom
mendations
pymetrics
bias
group
occupations
google
images
zillow
searches
online
freelance
marketplaces
bing
us
queries
youtube
dialect
accuracy
sev
eral
datasets
originally
created
purpose
later
repurposed
fairness
literature
sources
real
data
including
stop
question
frisk
hmda
law
school
compas
important
source
data
datasets
acquire
pivotal
role
research
industry
point
considered
de-facto
standard
given
purpose
status
warrants
closer
scrutiny
dataset
researchers
aim
uncover
potential
biases
problematic
aspects
may
impact
models
insights
derived
dataset
imagenet
instance
dataset
millions
images
across
thousands
categories
since
release
2011
resource
used
train
benchmark
compare
hundreds
computer
vision
models
given
sta
tus
machine
learning
research
imagenet
subject
two
quantitative
investigations
analyzing
biases
problematic
aspects
person
subtree
123
2102
fabris
et
al
uncovering
issues
representation
yang
et
al
2020b
non-consensuality
prabhu
birhane
2020
different
data
bias
audit
carried
safegraph
research
release
safegraph
data
captures
mobility
patterns
us
data
nearly
50
million
mobile
devices
obtained
maintained
safegraph
private
data
com
pany
recent
academic
release
become
fundamental
resource
pandemic
research
point
used
centers
disease
control
prevention
measure
effectiveness
social
distancing
measures
moreland
et
al
2020
evaluate
representativeness
overall
us
population
coston
et
al
2021
studied
selection
biases
dataset
algorithmic
fairness
research
datasets
play
similar
roles
ones
play
machine
learning
according
barocas
et
al
2019
including
training
catalyzing
attention
signalling
awareness
common
data
practices
one
notable
exception
fairness
datasets
used
track
algorithmic
progress
problem
time
likely
due
fact
consensus
single
measure
reported
hand
two
roles
peculiar
fairness
research
summarizing
service
product
audited
representing
important
resource
whose
biases
ethical
aspects
particularly
worthy
attention
note
roles
mutually
exclusive
datasets
can
play
multiple
roles
compas
example
originally
curated
perform
audit
pretrial
risk
assessment
tools
later
used
extensively
fair
ml
research
source
real
human
data
becoming
overall
catalyst
fairness
research
debate
sum
existing
fairness
datasets
originate
variety
domains
support
diverse
tasks
play
different
roles
algorithmic
fairness
literature
hope
work
will
contribute
establishing
principled
data
practices
field
guide
optimal
usage
resources
next
section
continue
discussion
key
features
datasets
change
perspective
asking
lessons
can
learnt
existing
resources
curation
novel
ones
best
practices
dataset
curation
section
analyze
surveyed
datasets
different
perspectives
typ
ical
critical
data
studies
human
computer
interaction
computer-supported
cooperative
work
particular
discuss
concerns
re-identification
sect
6.1
consent
sect
6.2
inclusivity
sect
6.3
sensitive
attribute
labeling
sect
6.4
transparency
sect
6.5
describe
range
approaches
consideration
topics
ranging
negligent
conscientious
aim
make
concerns
related
desiderata
visible
concrete
help
inform
responsible
curation
novel
fairness
resources
whose
number
increasing
recent
years
fig
6.1
re-identification
motivation
data
re-identification
de-anonymization
practice
instances
dataset
theoretically
representing
people
anonymized
fashion
successfully
mapped
back
respective
individuals
identity
thus
discov
123
algorithmic
fairness
datasets
story
far
2103
fig
datasets
employed
algorithmic
fairness
created
updated
2015
clear
growth
recent
years
ered
associated
information
encoded
dataset
features
examples
external
re-identification
attacks
include
de-anonymization
movie
ratings
netflix
prize
dataset
narayanan
shmatikov
2008
identification
profiles
based
social
media
group
membership
wondracek
et
al
2010
identification
people
depicted
verifiably
pornographic
categories
imagenet
prabhu
birhane
2020
analyses
carried
attacks
external
teams
demonstrative
purposes
dataset
curators
stakeholders
may
undertake
similar
efforts
internally
mckenna
2019b
multiple
harms
connected
data
re-identification
especially
ones
featured
algorithmic
fairness
research
due
social
significance
depending
domain
breadth
information
provided
dataset
malicious
actors
may
acquire
information
mobility
patterns
consumer
habits
political
leaning
psychological
traits
medical
conditions
individuals
just
name
potential
misuse
tremendous
including
phishing
attacks
blackmail
threat
manipulation
kröger
et
al
2021
face
recognition
datasets
especially
prone
successful
re-identification
definition
contain
information
strongly
con
nected
person
identity
problem
also
extends
general
purpose
computer
vision
datasets
recent
dataset
audit
prabhu
birhane
2020
found
images
beach
voyeurism
non-consensual
depictions
imagenet
able
identify
victims
using
reverse
image
search
engines
highlighting
downstream
risks
blackmail
forms
abuse
disparate
consideration
work
find
fairness
datasets
proofed
re-identification
full
range
measures
care
perhaps
surprisingly
datasets
allow
straightforward
re-identification
individuals
providing
full
names
discuss
resources
avoid
amplifying
harms
dis
cussed
datasets
afford
plausible
re-identification
providing
social
media
handles
aliases
twitter
abusive
behavior
sentiment140
facebook
large
123
2104
fabris
et
al
network
google
local
columbia
university
speed
dating
may
also
fall
category
due
restricted
population
sample
drawn
provision
age
field
study
zip
code
participants
grew
addition
con
trast
many
datasets
come
strong
guarantees
de-anonymization
especially
typical
health
data
mimic-iii
heritage
health
el
emam
et
al
2012
indeed
health
domain
culture
patient
record
confiden
tiality
widely
established
strong
attention
harm
avoidance
also
datasets
describing
scholarly
works
academic
collaboration
networks
academic
collaboration
networks
pubmed
diabetes
papers
cora
citeseer
typically
de
identified
numerical
ids
substituting
names
possibly
sign
attention
anonymization
curators
data
represents
potential
colleagues
consequence
researchers
protected
related
harms
posterior
annotation
sensitive
attributes
similarly
biega
et
al
2019
becomes
difficult
impossible
one
notable
exception
arnetminer
citation
network
derived
online
plat
form
especially
focused
data
mining
academic
social
networks
profiling
researchers
mitigating
factors
wide
range
factors
summarized
table
may
help
reduce
risk
re-identification
first
set
approaches
concerns
distribution
data
artefacts
datasets
simply
kept
private
minimizing
risks
regard
include
unige
us
student
performance
apnea
symptoms
queries
pymetrics
bias
group
last
two
proprietary
datasets
disclosed
preserve
intellectual
property
twitter
online
harrassment
available
upon
request
protect
identities
twitter
users
included
another
interesting
approach
mixed
release
strategies
nlsy
publicly
available
data
access
information
may
favour
re-identification
zip
code
census
tract
restricted
crawl-based
datasets
possible
keep
resource
private
providing
code
recreate
bias
bios
may
alleviate
concerns
will
deter
motivated
actors
post-hoc
remedy
proactive
removal
problematic
instances
also
possibility
shown
recent
work
imagenet
yang
et
al
2020b
another
family
approaches
based
redaction
aggregation
injection
noise
obfuscation
typically
involves
distribution
proprietary
company
data
level
abstraction
maintains
utility
company
hindering
recon
struction
underlying
human-readable
data
also
makes
re-identification
highly
unlikely
yahoo
c14b
learn
rank
microsoft
learning
rank
noise
injection
can
take
many
forms
top-coding
adult
saturation
certain
variables
blurring
chicago
ridesharing
disclosure
coarse
granularity
targeted
scrubbing
identifiable
information
also
rather
common
ad-hoc
techniques
applied
different
domains
example
curators
asap
dataset
featuring
student
essays
removed
personally
identifying
information
essays
using
named
entity
recognition
several
heuristics
finally
aggregation
data
subpopulations
interest
also
supports
anonymity
underlying
individuals
fico
far
covered
datasets
feature
human
data
derived
real-world
processes
toy
datasets
hand
perfectly
safe
point
view
however
social
relevance
inevitably
low
work
survey
four
popular
123
algorithmic
fairness
datasets
story
far
2105
table
mitigating
factors
re-identification
mitigating
factor
example
datasets
controlled
distribution
private
dataset
unige
pymetrics
bias
group
availability
upon
request
twitter
online
harrassment
mixed
release
strategy
nlsy
code-based
reconstruction
bias
bios
data
perturbation
obfuscation
yahoo
c14b
learn
rank
microsoft
learning
rank
top-coding
adult
blurring
chicago
ridesharing
targeted
scrubbing
asap
aggregation
fico
synthesis
synthetic
data
toy
dataset
semi-synthetic
data
antelope
valley
networks
kidney
matching
hypothetical
profiles
italian
car
insurance
age
german
credit
ones
taken
zafar
et
al
2017c
donini
et
al
2018
lipton
et
al
2018
singh
joachims
2019
semi-synthetic
datasets
aim
best
worlds
generating
artificial
data
models
emulate
key
characteristics
underlying
processes
case
antelope
valley
networks
kidney
matching
generative
adversarial
network
trained
mcduff
et
al
2019
ms-celeb
1m
data
synthesis
may
also
applied
augment
datasets
artificial
sensitive
attributes
principled
fashion
movielens
burke
et
al
2018a
finally
resources
designed
externally
probe
services
algorithms
platforms
estimate
direct
effect
feature
interest
gender
race
may
rely
hypothetical
profiles
bertrand
mullainathan
2004
fabris
et
al
2021
approach
can
support
evaluations
fairness
unawareness
grgic-hlaca
et
al
2016
italian
car
insurance
example
one
last
important
factor
age
dataset
re-identification
old
information
individuals
requires
matching
auxiliary
resources
period
less
likely
maintained
comparable
resources
recent
years
moreover
even
successful
consequences
re-identification
likely
mitigated
dataset
age
old
information
individuals
less
likely
support
harm
german
credit
dataset
example
represents
loan
applicants
1973
1975
whose
re-identification
subsequent
harm
appears
less
likely
re-identification
recent
datasets
domain
anonymization
vs
social
relevance
utility
privacy
typically
considered
conflicting
objectives
dataset
wieringa
et
al
2021
define
social
rele
vance
breadth
depth
societally
useful
insights
can
derived
dataset
similar
conflict
privacy
becomes
clear
old
datasets
hardly
afford
123
2106
fabris
et
al
insight
actionable
relevant
current
applications
insight
derived
synthetic
datasets
inevitably
questionable
noise
injection
increases
uncertainty
reduces
precision
claims
obfuscation
hinders
subsequent
annotation
sensitive
attributes
conservative
release
strategies
increase
friction
deter
obtaining
analyzing
data
socially
relevant
fairness
datasets
typically
feature
confidential
information
criminal
history
financial
situation
conjunction
sensitive
attributes
individuals
race
sex
reasons
social
impact
afforded
dataset
safety
re-identification
included
indi
viduals
potentially
conflicting
objectives
require
careful
balancing
next
section
discuss
informed
consent
another
important
aspect
privacy
data
subjects
6.2
consent
motivation
context
data
informed
consent
agreement
data
processor
subject
aimed
allowing
collection
use
personal
information
guaranteeing
control
subject
emphasized
article
recitals
42
43
general
data
protection
regulation
european
union
2016
requiring
freely
given
specific
informed
unambiguous
paullada
et
al
2020
note
absence
individual
control
personal
information
anyone
access
data
can
process
little
oversight
possibly
interest
well-being
data
subjects
consent
thus
important
tool
healthy
data
ecosystem
favours
development
trust
dignity
negative
examples
separate
framework
often
conflated
consent
copy
right
licenses
creative
commons
discipline
academic
creative
works
can
shared
built
upon
proper
credit
attribution
according
creative
commons
organization
however
licenses
suited
protect
privacy
cover
research
ethics
merkley
2019
computer
vision
especially
face
recog
nition
consent
copyright
often
considered
discussed
jointly
creative
commons
licenses
frequently
taken
all-inclusive
permit
encompassing
intel
lectual
property
consent
ethics
prabhu
birhane
2020
merler
et
al
2019
example
mention
privacy
copyright
concerns
construction
diver
sity
faces
concerns
apparently
jointly
solved
obtaining
images
yfcc-100m
due
fact
large
portion
photos
creative
com
mons
license
indeed
lack
consent
widespread
far-reaching
problem
face
recognition
datasets
keyes
et
al
2019
prabhu
birhane
2020
find
several
examples
non-consensual
images
large
scale
computer
vision
datasets
partic
ularly
egregious
example
covered
survey
ms-celeb-1m
released
2016
largest
publicly
available
training
set
face
recognition
world
guo
et
al
2016b
suggested
name
dataset
feature
celebrities
enable
training
testing
re-distributing
certain
licenses
guo
et
al
2016b
however
dataset
later
found
feature
several
people
way
celebrities
must
simply
maintain
online
presence
dataset
retracted
reason
murgia
2019
123
algorithmic
fairness
datasets
story
far
2107
positive
examples
faces
experimental
psychology
dataset
emotion
related
stimuli
represents
positive
exception
face
analysis
domain
due
small
cardinality
possible
obtain
informed
consent
every
participant
one
domain
informed
consent
doctrine
well-established
decades
medicine
fairness
datasets
space
typically
sensitive
topic
exper
iments
randomized
controlled
trials
always
require
consent
elicitation
often
discuss
process
respective
articles
infant
health
development
program
ihdp
instance
dataset
used
study
fair
risk
assessment
collected
ihdp
program
carried
1985
1988
us
evaluate
effectiveness
comprehensive
early
intervention
reducing
devel
opmental
health
problems
low
birth
weight
premature
infants
brooks-gunn
et
al
1992
clearly
state
1302
infants
met
enrollment
criteria
274
21
parents
refused
consent
43
withdrawn
entry
assigned
group
longitudinal
studies
require
trust
continued
participation
typically
produce
insights
data
thanks
participants
read
signed
informed
consent
form
examples
datasets
include
framingham
stem
ming
study
cardiovascular
disease
national
longitudinal
survey
youth
following
lives
representative
samples
us
citizens
focusing
labor
market
activities
significant
life
events
field
studies
derived
datasets
drugnet
homeless
youths
social
networks
also
attentive
informed
consent
fries
framework
according
consentful
tech
project
consent
freely
given
reversible
informed
enthusiastic
specific
fries
expand
points
discuss
fairness
datasets
fries
lens
pokec
social
network
summarizes
networks
pokec
users
pop
ular
social
network
slovakia
czech
republic
due
default
privacy
settings
predefined
public
wealth
information
profile
collected
curators
including
information
demographics
politics
education
marital
status
children
takac
zabovsky
2012
privacy
settings
useful
tool
control
personal
data
default
public
settings
arguably
misleading
amount
freely
given
consent
presence
conservative
predefined
set
tings
user
can
explicitly
choose
publicly
share
information
may
interpreted
consent
share
one
information
now
users
loose
interpretations
favouring
data
collection
distribution
also
possible
seem
rather
lacking
specificity
far
clear
choosing
public
profile
settings
entails
consent
become
part
study
publicly
available
dataset
years
come
stands
contrast
framingham
datasets
derived
medical
studies
consent
may
provided
refused
fine
granularity
levy
et
al
2010
regard
let
us
consider
consent
form
recent
framingham
exam
framingham
heart
study
2021
form
comes
five
different
consent
boxes
cover
participation
examination
use
resulting
data
participation
genetic
studies
sharing
data
external
entities
notification
findings
subject
consent
boxes
well-structured
document
informs
participants
https://www.consentfultech.io/.
123
2108
fabris
et
al
reasons
study
clarifies
can
choose
drop
without
penalties
point
provides
point
contact
explains
will
happen
study
risks
subject
examples
accessible
language
open
explanations
include
following
right
refuse
allow
data
samples
used
shared
research
please
check
appropriate
box
selection
potential
risk
genetic
information
used
disadvantage
example
genetic
research
findings
suggest
serious
health
problem
used
make
harder
get
keep
job
insurance
however
guarantee
total
privacy
information
given
outside
parties
promise
will
kept
private
moreover
consent
form
accessible
website
promises
deliver
spanish
version
showing
attention
linguistic
minorities
overall
approach
seems
geared
towards
trust
truly
informed
consent
cases
consent
made
unapplicable
necessity
allegheny
child
wel
fare
instance
stems
initiative
allegheny
county
department
human
services
develop
assistive
tools
support
child
maltreatment
hotline
screening
decisions
individuals
resort
service
situation
need
emergency
makes
enthusiastic
consent
highly
unlikely
similar
considera
tions
arise
situations
data
subjects
state
need
can
access
service
providing
data
clear
example
harvey
rescue
result
crowdsourced
efforts
connect
rescue
parties
people
requesting
help
houston
area
moreover
provision
data
mandatory
cases
us
census
conflicts
meaningful
let
alone
enthusiastic
consent
finally
consent
reversible
giving
individuals
chance
revoke
removed
dataset
active
area
research
studying
specific
tools
consent
management
albanese
et
al
2020
approaches
retroactive
removal
instance
model
training
set
ginart
et
al
2019
unfortunately
even
discontinued
redacted
datasets
remain
available
backchannels
derivatives
ms-celeb-1m
negative
example
regard
dataset
removed
microsoft
widespread
criticism
claims
privacy
infringe
ment
despite
fact
remains
available
via
academic
torrents
peng
et
al
2021
moreover
ms-celeb-1m
used
source
images
several
datasets
derived
including
bupt
faces
racial
faces
wild
datasets
covered
survey
fact
demonstrates
harms
related
data
artefacts
simply
remedied
via
retirement
redaction
ethical
considerations
consent
poten
tial
harms
people
must
afterthought
need
enter
discussion
design
6.3
inclusivity
motivation
issues
representation
inclusion
diversity
central
fair
ml
community
due
historical
biases
stemming
structural
inequalities
pop
ulations
perspectives
underrepresented
certain
domains
related
123
algorithmic
fairness
datasets
story
far
2109
data
artefacts
jo
gebru
2020
example
person
subtree
imagenet
contains
images
skew
toward
male
young
light
skin
individuals
yang
et
al
2020b
female
entities
found
underrepresented
popular
datasets
coreference
resolution
zhao
et
al
2018
even
datasets
match
natural
group
pro
portions
may
support
development
biased
tools
low
accuracy
minorities
recent
works
demonstrated
disparate
performance
tools
sensitive
subpopulations
domains
health
care
obermeyer
mullainathan
2019
speech
recognition
tatman
2017
computer
vision
buolamwini
gebru
2018
inclusivity
diversity
often
considered
primary
solution
regard
training
sets
support
development
better
models
test
sets
capable
flagging
issues
positive
examples
ideally
inclusivity
begin
clear
definition
data
collection
objectives
jo
gebru
2020
indeed
find
diversity
repre
sentation
strong
points
datasets
creted
assess
biases
services
products
algorithms
bold
hmda
fico
law
school
scientist
painter
cvs
singapore
youtube
dialect
accuracy
pilot
parliaments
benchmark
designed
curated
special
attention
sensitive
groups
also
find
instances
ex-post
remedies
issues
diversity
example
curators
imagenet
proposed
demographic
balancing
solution
based
web
interface
removes
images
overrepresented
categories
yang
et
al
2020b
natural
alter
native
collection
novel
instances
solution
adopted
framingham
dataset
stems
study
key
factors
contribute
cardiovascular
disease
participants
recruited
framingham
massachusetts
multiple
decades
recent
cohorts
especially
designed
reflect
greater
racial
ethnic
diversity
town
tsao
vasan
2015
negative
examples
among
datasets
surveyed
highlight
one
whose
low
inclusivity
rather
obvious
webtext
40
gb
text
dataset
supported
training
gpt-2
language
model
radford
et
al
2019
authors
crawled
every
document
reachable
outbound
reddit
links
collected
least
karma
considered
useful
heuristic
achieve
size
quality
ended
skewing
resource
towards
content
appreciated
reddit
users
predominantly
male
young
enjoy
good
internet
access
act
reminder
size
guarantee
diversity
bender
et
al
2021
sampling
biases
almost
inevitable
inclusivity
nuanced
inclusivity
surely
requires
attention
subpop
ulations
precise
definition
may
depend
context
application
based
task
hand
ideal
sample
may
feature
subpopulations
equal
presence
proportionally
share
overall
population
let
us
call
equal
proportional
approach
diversity
equal
approach
typical
datasets
meant
evaluation
benchmarks
pilot
parliaments
benchmark
winobias
allow
statistically
significant
statements
performance
differences
across
groups
hand
proportional
approach
rather
common
datasets
collected
census
offices
us
census
data
1990
resources
aimed
precisely
studying
issues
representation
services
products
occupations
google
images
open-ended
collection
data
ideal
ensure
various
cultures
represented
manner
like
seen
jo
gebru
2020
unfortunately
123
2110
fabris
et
al
found
instance
datasets
sensitive
labels
self-reported
according
open-ended
responses
contrary
individuals
non-conforming
gender
identities
excluded
datasets
analyses
bing
us
queries
proprietary
dataset
used
study
differential
user
satisfaction
bing
search
engine
across
different
demographic
groups
consists
subset
bing
users
provided
gender
registration
according
binary
categorization
misrepresents
simply
excludes
non-binary
users
subset
moreover
dataset
may
inclusive
encode
gender
non-binary
gender
fashion
climate
assembly
uk
used
conjunction
auxiliary
dataset
gender
binary
encoding
common
solution
removing
instances
whose
gender
neither
female
male
flanigan
et
al
2020
inclusivity
guarantee
benefits
avoid
downstream
harms
inclusion
insufficient
context
people
sensitive
groups
repre
sented
always
taken
account
despite
overall
skew
towards
male
subjects
imagenet
high
female-to-male
ratio
classes
bra
bikini
maillot
often
feature
images
voyeuristic
pornographic
non
consensual
prabhu
birhane
2020
similarly
ms-coco
famous
dataset
object
recognition
roughly
female-to-male
ratio
increasing
0.95
images
kitchens
hendricks
et
al
2018
sort
representation
unlikely
benefit
women
way
contrary
may
contribute
reinforce
stereotypes
support
harmful
biases
another
clear
often
ignored
disconnect
inclusion
group
benefits
represented
task
hand
general
possible
uses
afforded
dataset
regard
find
many
datasets
face
recognition
domain
presented
resources
geared
towards
inclusion
diversity
faces
bupt
faces
utk
face
fairface
racial
faces
wild
attention
subpopu
lations
context
still
called
diversity
diversity
faces
fairface
racial
faces
wild
social
awareness
bupt
faces
driven
business
imperatives
goals
robustness
technology
can
easily
employed
surveillance
purposes
become
detrimental
vulnerable
populations
included
datasets
similar
vein
faces
dataset
used
measure
age
bias
emotion
detection
task
whose
applications
benefits
individuals
remain
dubious
overall
attention
subpopulations
upside
many
datasets
surveyed
however
inclusion
representation
diversity
can
defined
different
ways
according
problem
hand
individuals
rather
included
terms
decide
whether
represented
problems
diversity
robustness
clear
commonalities
former
can
seen
means
towards
latter
seems
advisable
maintain
clear
separation
two
avoid
equating
either
one
fairness
algorithmic
fairness
will
solved
simply
collecting
data
granting
equal
performance
across
different
groups
identified
given
sensitive
attribute
123
algorithmic
fairness
datasets
story
far
2111
table
approaches
demographic
data
procurement
approach
example
datasets
self-reported
labels
bing
us
queries
movielens
libimset
adult
hmda
law
school
sushi
willingness-to-pay
vaccine
expert
labels
pilot
parliaments
benchmark
non-expert
labels
celebfaces
attributes
diversity
faces
fairface
occupations
google
images
ml
algorithm
racial
faces
wild
instagram
photos
bupt
faces
utk
face
ml
algorithm
annotators
fairface
open
images
dataset
rule
knowledge-based
algorithm
rtgender
bias
bios
demographics
twitter
twitteraae
6.4
sensitive
attribute
labelling
motivation
datasets
often
taken
factual
information
supports
objective
computation
pattern
extraction
etymology
word
data
meaning
given
rather
revealing
sense
contrary
research
human
computer
interaction
computer-supported
cooperative
work
critical
data
studies
argues
belief
superficial
limited
potentially
harmful
muller
et
al
2019
crawford
paglen
2021
data
quite
simply
human-influenced
entity
miceli
et
al
2021
determined
chain
discretionary
decisions
measurement
sampling
categorization
shape
data
will
collected
annotated
according
taxonomy
based
guidelines
data
science
professionals
often
cognizant
context
surrounding
data
theoretical
researchers
report
significant
awareness
curation
annotation
choices
influence
data
relation
underlying
phenomena
muller
et
al
2019
interview
senior
text
classification
researcher
responsible
ground
truth
annotation
shows
consciousness
influence
datasets
stating
ground
truth
muller
et
al
2019
sensitive
attributes
race
gender
exception
regard
incon
sistencies
racial
annotation
rather
common
within
system
lum
et
al
2020
even
across
different
systems
scheuerman
et
al
2020
khan
fu
2021
external
annotation
either
human
algorithmic
essentially
based
co-occurrence
specific
traits
membership
group
thus
running
risk
encoding
reinforcing
stereotypes
self-reported
labels
overcome
issue
although
still
based
imposed
taxonomy
unless
provided
open-ended
fashion
section
discuss
practices
sensitive
attributes
annotated
datasets
used
algorithmic
fairness
research
summarized
table
procurement
sensitive
attributes
self-reported
labels
sensitive
attributes
typical
datasets
represent
users
service
may
report
demo
graphics
registration
bing
us
queries
movielens
libimseti
123
2112
fabris
et
al
gathered
surveys
hmda
adult
law
school
sushi
willingness-to-pay
vaccine
resources
collection
protected
attributes
envi
sioned
design
potentially
optional
step
however
sensitive
attributes
available
annotation
may
possible
different
mechanisms
common
approach
sensitive
attributes
labelled
non-experts
often
workers
hired
crowdsourcing
platforms
celebfaces
attributes
dataset
celeba
features
images
celebrities
celebfaces
dataset
augmented
annota
tions
landmark
location
categorical
attributes
including
gender
skin
tone
age
annotated
professional
labeling
company
liu
et
al
2015
similar
fashion
diversity
faces
consists
images
labeled
gender
age
workers
hired
figure
eight
crowd-sourcing
platform
creators
fairface
hired
workers
amazon
mechanical
turk
annotate
gender
race
age
public
image
dataset
practice
also
raises
concerns
fair
compensation
labour
discussed
work
creators
employ
algorithms
obtain
sensitive
labels
face
datasets
curators
often
resort
face
api
racial
faces
wild
instagram
photos
bupt
faces
algorithms
utk
face
fairface
essence
labeling
classifying
hence
measuring
reporting
accuracy
procedure
order
rarely
happens
creators
occasionally
note
automated
labels
validated
fairface
substantially
enhanced
open
images
dataset
human
annotators
seldom
report
inter-annotator
agreement
occupations
google
images
examples
external
labels
include
geographic
origin
candidates
resumes
cvs
singapore
political
leaning
us
twitter
profiles
twitter
politi
cal
searches
english
dialect
tweets
twitteraae
gender
subjects
featured
image
search
results
professions
occupations
google
images
annota
tion
may
also
rely
external
knowledge
bases
wikipedia
case
rtgender
situations
text
written
individuals
available
rule-based
approaches
exploiting
gendered
nouns
woman
pronouns
also
appli
cable
bias
bios
demographics
twitter
datasets
may
simply
sensitive
attribute
often
used
works
individual
fairness
may
occasionally
support
studies
group
fairness
example
dsprites
synthetic
computer
vision
dataset
regular
covariates
may
play
role
sensitive
variables
locatello
et
al
2019
alternatively
datasets
can
augmented
simulated
demographics
done
madnani
et
al
2017
randomly
assigned
native
language
test-takers
asap
technique
burke
et
al
2018a
demonstrate
movielens
face
datasets
posterior
annotation
especially
common
computer
vision
datasets
pilot
parliaments
benchmark
instance
devised
testbed
face
analysis
algorithms
consists
images
parliamentary
representatives
three
african
three
european
countries
labelled
surgical
der
matologist
fitzpatrick
skin
type
subjects
fitzpatrick
1988
dermatological
scale
skin
color
can
retrieved
people
appearance
contrary
annotations
race
ethnicity
photo
simplistic
best
clear
actually
capture
perceived
race
perspective
https://en.wikipedia.org/wiki/category:american_female_tennis_players.
123
algorithmic
fairness
datasets
story
far
2113
annotator
fairface
bupt
faces
careful
nomenclature
important
first
step
improve
transparency
dataset
make
underlying
context
visible
similarly
scheuerman
et
al
2020
find
documentation
accompanying
face
recognition
datasets
hardly
ever
describes
specific
taxonomies
gender
race
chosen
conveying
false
impression
objectivity
description
annotation
process
typically
present
minimal
multi-task
facial
landmark
instance
know
ground
truths
related
tasks
labeled
manually
zhang
et
al
2014
annotation
trade-offs
worth
re-emphasizing
sensitive
label
assignment
classification
task
rests
assumptions
annotation
race
gender
images
example
based
idea
can
accurately
ascertained
pictures
oversimplification
constructs
envisioned
classes
binary
gender
another
subjective
choice
stemming
point
view
dataset
curators
may
reflect
narrow
outdated
conceptions
potentially
harm
data
subjects
regard
quote
curators
ms-celeb-1m
annotate
race
consider
sampling
strategy
particularly
striking
cover
major
races
world
caucasian
mongoloid
negroid
guo
et
al
2016b
reasons
external
annotation
sensitive
attributes
controversial
inevitably
influenced
dataset
curators
hand
external
annotation
may
way
test
specific
biases
occupations
google
images
instance
image
dataset
collected
study
gender
skin
tone
diversity
image
search
results
various
professions
creators
hired
workers
amazon
mechanical
turk
label
gender
male
female
fitzpatrick
skin
tone
type
primary
person
image
pilot
parliaments
benchmark
also
annotated
externally
obtain
benchmark
evaluation
face
analysis
technology
balanced
representation
gender
skin
type
different
purposes
can
motivate
data
collection
annotation
sensitive
attributes
purposes
aims
documented
clearly
also
reflecting
uses
potential
misuse
dataset
gebru
et
al
2018
dataset
curators
may
use
documentation
discuss
aspects
specify
limitations
intended
use
resource
peng
et
al
2021
next
section
focus
documentation
represents
key
component
data
curation
6.5
transparency
motivation
transparent
accurate
documentation
fundamental
part
data
quality
absence
may
lead
serious
issues
including
lack
reproducibility
con
cerns
scientific
validity
ethical
problems
harms
barocas
et
al
2019
clear
documentation
can
shine
light
inevitable
choices
made
dataset
creators
context
surrounding
data
absence
information
curation
mechanism
mediating
reality
data
hidden
data
becomes
one
context
article
typically
discuss
sensitive
attributes
following
naming
convention
accompa
nying
documentation
dataset
avoiding
critical
terminology
discussion
123
2114
fabris
et
al
point
interpretation
numerical
results
can
misleading
overarching
bao
et
al
2021
ground
truth
labels
typically
indicated
letter
target
prediction
tasks
datasets
indications
recidivism
compas
especially
sensitive
regard
indeed
accuracy
related
quality
metrics
also
measures
algorithmic
fairness
sufficiency
separation
barocas
et
al
2019
based
labels
ability
ml
algorithms
replicate
implicitly
granting
special
status
truthfulness
reality
however
labels
may
biased
incorrect
due
multiple
causes
including
frequently
disconnect
aim
measure
ideal
construct
space
offense
case
compas
can
actually
measure
observed
space
arrest
friedler
et
al
2021
fair
ml
algorithms
measures
can
partly
overcome
catch
biases
actually
run
risk
reifying
proper
documentation
solve
issue
equips
practitioners
researchers
necessary
awareness
handle
biases
broadly
good
documentation
discuss
explain
features
providing
context
collected
annotated
data
purpose
gebru
et
al
2018
denton
et
al
2020
provides
dataset
users
information
can
leverage
select
appropriate
datasets
tasks
avoid
unintentional
misuse
gebru
et
al
2018
actors
reviewers
may
also
access
official
documentation
dataset
ensure
employed
compliance
stated
purpose
guidelines
terms
use
peng
et
al
2021
positive
examples
survey
find
examples
excellent
documentation
datasets
related
studies
experiments
including
chexpert
framingham
nlsy
indeed
datasets
curated
medical
institutions
census
offices
often
well-documented
ideal
source
good
documentation
descriptor
articles
published
conjunction
dataset
mimic-iii
typically
offering
stronger
guarantees
web
pages
terms
quality
permanence
official
websites
hosting
distributing
datasets
also
important
collect
updates
errata
additional
information
may
available
time
release
million
song
dataset
goodreads
reviews
instance
available
websites
contain
useful
overview
respective
dataset
list
updates
code
samples
pointers
documentation
contacts
questions
negative
examples
hand
datasets
opaque
poorly
docu
mented
among
publicly
available
ones
arrhythmia
distributed
description
features
context
purposes
actors
subjects
involved
data
collection
similarly
whole
curation
process
composition
multi-task
facial
landmark
described
short
paragraph
explaining
consists
10
000
outdoor
face
images
web
labelled
manually
gender
face
datasets
suffer
opaque
documentation
especially
concerning
choice
sensi
tive
labels
annotation
semi-synthetic
resources
proper
documentation
especially
important
let
users
understand
broader
applicability
implications
numerical
analyses
performed
dataset
ibm
hr
analytics
resource
employee
attrition
hosting
website
describes
containing
fictional
data
without
additional
information
nonetheless
data
plausibly
generated
123
algorithmic
fairness
datasets
story
far
2115
principled
fashion
even
partial
disclosure
underlying
data
generation
mechanism
benefit
dataset
users
retrospective
documentation
good
documentation
may
also
produced
ret
rospectively
bandy
vincent
2021
garbin
et
al
2021
german
credit
interesting
example
dataset
poorly
documented
decades
recent
publication
report
correcting
severe
coding
mistakes
grömping
2019
mentioned
sect
4.3
old
documentation
seemed
possible
retrieve
sex
data
subjects
feature
jointly
encoding
sex
marital
status
dataset
archaeology
work
grömping
2019
shows
case
par
ticular
relevance
many
algorithmic
fairness
works
using
dataset
sex
protected
feature
feature
simply
available
numerical
results
obtained
setting
may
artefact
wrong
coding
dataset
still
officially
distributed
uci
machine
learning
repository
1994
report
new
redacted
dataset
uci
machine
learning
repository
2019
become
well-known
old
version
will
remain
prevalent
mistakes
will
made
words
documentation
debt
particular
dataset
ret
rospectively
addressed
opacity
many
algorithmic
fairness
works
published
report
continue
use
german
credit
dataset
sex
protected
attribute
et
al
2020b
yang
et
al
2020a
baharlouei
et
al
2020
lohaus
et
al
2020
martinez
et
al
2020
wang
et
al
2021
issue
documentation
sparsity
right
information
exists
reach
interested
parties
including
researchers
reviewers
documentation
fundamental
part
data
curation
responsibility
resting
creators
however
dataset
users
can
also
play
role
mitigating
documentation
debt
proactively
looking
information
resources
plan
use
brief
summaries
discussing
motivating
chosen
datasets
can
included
scholarly
articles
least
supplementary
materials
conflicting
page
limitations
indeed
documentation
debt
problem
whole
research
community
can
addressed
collectively
retrospective
contributions
clarifications
argue
also
individual
researchers
seek
contextual
information
situating
data
want
use
broader
relevance
community
along
analyses
presented
work
lens
tasks
supported
domains
spanned
roles
played
algorithmic
fairness
datasets
releasing
underlying
data
briefs
contribution
research
community
data
briefs
short
documentation
format
providing
essential
information
datasets
used
fairness
research
data
briefs
composed
ten
fields
detailed
appendix
derived
shared
vocabularies
data
catalog
vocabulary
dcat
compliant
fair
data
principles
wilkinson
et
al
2016
also
defined
schema
called
fdo
model
relationships
terms
make
links
external
vocabularies
explicit
leverage
fdo
format
data
briefs
resource
description
framework
rdf
miller
1998
make
available
123
2116
fabris
et
al
linked
open
data
thus
supporting
data
reuse
interoperability
interpretability
10
final
aim
release
update
maintain
web
app
can
queried
researchers
practitioners
find
relevant
datasets
according
specific
needs
11
envision
several
benefits
algorithmic
fairness
data
studies
communities
informing
choice
datasets
experimental
evaluations
fair
ml
methods
including
domain-oriented
task-oriented
search
directing
studies
data
bias
quantitative
qualitative
analyses
including
retrospective
documentation
efforts
towards
popular
otherwise
important
resources
identifying
areas
sub-problems
understudied
algorithmic
fair
ness
literature
supporting
multi-dataset
studies
focused
resources
united
common
char
acteristic
encoding
given
sensitive
attribute
scheuerman
et
al
2020
concerning
computer
vision
fabbrizzi
et
al
2021
popular
fairness
literature
le
quy
et
al
2022
conclusions
recommendations
algorithmic
fairness
young
research
area
undergoing
fast
expansion
diverse
contributions
terms
methodology
applications
progress
field
hinges
different
resources
including
prominently
datasets
work
extending
fabris
et
al
2022
surveyed
hundreds
datasets
used
fair
ml
algorithmic
equity
literature
help
research
community
reduce
documentation
debt
improve
utilization
existing
datasets
curation
novel
ones
respect
existing
resources
shown
popular
datasets
fairness
literature
adult
compas
german
credit
limited
merits
beyond
originating
human
processes
encoding
protected
attributes
hand
several
negative
aspects
call
question
current
status
general
purpose
fairness
benchmarks
including
contrived
prediction
tasks
noisy
data
severe
coding
mistakes
limitations
encoding
sensitive
attributes
age
documented
two
hundred
datasets
provide
viable
alternatives
annotating
domain
tasks
support
discussing
roles
play
works
algorithmic
fairness
shown
processes
generating
data
belong
many
different
domains
including
instance
criminal
justice
education
search
engines
online
marketplaces
emergency
response
social
media
medicine
hiring
finance
time
described
variety
tasks
studied
resources
ranging
generic
fair
classification
narrow
fair
districting
fair
truth
discovery
overall
diversity
domains
tasks
provides
glimpse
variety
human
activities
applications
can
impacted
automated
decision
making
can
benefit
algorithmic
10
schema
publicly
available
https://fairnessdatasets.dei.unipd.it/schema/;
rdf
publicly
available
https://zenodo.org/record/6518370#.ynoskftmjhf.
11
resource
will
released
https://fairnessdatasets.dei.unipd.it/.
123
algorithmic
fairness
datasets
story
far
2117
fairness
research
tasks
domain
annotations
made
available
data
briefs
facilitate
work
researchers
practitioners
interested
study
algorithmic
fairness
applied
specific
domains
tasks
assembling
sparse
information
hundreds
datasets
single
document
aim
provide
useful
reference
support
domain-oriented
task-oriented
dataset
search
time
analyzed
issues
connected
re-identification
consent
inclusivity
labeling
transparency
running
across
datasets
describing
range
approaches
attentiveness
topics
aim
make
visible
concrete
one
hand
may
prove
valuable
inform
post-hoc
data
interventions
aimed
mitigating
potential
harms
caused
existing
datasets
hand
novel
datasets
increasingly
curated
published
adopted
fairness
research
important
motivate
concerns
make
tangible
distill
existing
approaches
best
practices
summarize
future
endeavours
data
curation
recommendations
complement
replace
growing
body
work
studying
key
aspects
life
cycle
datasets
gebru
et
al
2018
jo
gebru
2020
prabhu
birhane
2020
crawford
paglen
2021
peng
et
al
2021
social
relevance
data
intended
breadth
depth
societally
useful
insights
afforded
datasets
central
requirement
fairness
research
unfor
tunately
may
conflict
user
privacy
favouring
re-identification
leaving
consideration
consent
background
consent
considered
initial
design
dataset
accordance
existing
frameworks
fries
framework
outlined
consentful
tech
project
moreover
different
strategies
available
alleviate
concerns
re-identification
including
noise
injection
conser
vative
release
semi
synthetic
data
generation
algorithmic
fairness
motivated
aims
justice
harm
avoidance
people
extended
data
subjects
inclusivity
also
important
social
relevance
allows
wider
repre
sentation
supports
analyses
take
account
important
groups
however
inclusivity
insufficient
possible
uses
afforded
dataset
always
considered
evaluating
costs
benefits
data
subjects
wider
pop
ulation
absence
considerations
acritical
inclusivity
runs
risk
simply
supporting
system
robustness
across
sensitive
attributes
race
gen
der
rebranded
fairness
sensitive
attributes
key
ingredient
measure
inclusion
increase
social
relevance
dataset
although
often
impractical
typically
preferable
sen
sitive
attributes
self-reported
data
subjects
externally
assigned
labels
taxonomies
can
harm
individuals
erasing
needs
points
view
sensi
tive
attribute
labelling
thus
shortcut
whose
advantages
disadvantages
carefully
weighted
chosen
properly
documented
possible
approaches
based
human
labour
include
expert
non-expert
annotation
automated
approaches
range
simple
rule-based
systems
complex
opaque
algorithms
label
classify
hence
measuring
reporting
per-group
accuracy
order
labeling
endeavours
sensible
others
skin
tone
can
arguably
retrieved
pictures
annotations
race
image
actually
123
2118
fabris
et
al
capture
perceived
race
perspective
annotator
rigorous
nomenclature
favours
better
understanding
clarifies
subjectivity
certain
labels
reliable
documentation
shines
light
inevitable
choices
made
dataset
creators
context
surrounding
data
provides
dataset
users
information
can
leverage
select
appropriate
datasets
tasks
avoid
unintentional
misuse
datasets
curation
choices
poorly
documented
may
appear
objective
first
sight
however
clear
objective
data
turbid
data
different
things
proper
documentation
increases
transparency
trust
understanding
minimum
include
purpose
data
artifact
description
sample
features
related
annotation
procedures
along
explicit
discussion
associated
task
also
clarify
involved
different
stages
data
development
procedure
special
attention
annotation
data
documentation
also
supports
reviewers
readers
academic
research
assessing
whether
dataset
selected
good
reason
utilized
compliance
creators
guidelines
understanding
budgeting
aspects
early
design
phases
rather
collection
release
can
invaluable
data
subjects
data
users
soci
ety
possible
remedies
exist
data
extremely
fluid
asset
allowing
easy
reproduction
derivatives
sorts
remedies
applied
dataset
neces
sarily
benefit
derivates
work
targeted
collective
documentation
debt
algorithmic
fairness
community
resulting
opacity
surrounding
certain
resources
sparsity
existing
documentation
mainly
targeted
sparsity
centralized
documentation
effort
result
found
described
range
weaknesses
best
practices
can
adopted
reduce
opacity
mitigate
concerns
privacy
inclusion
similarly
types
data
interven
tions
useful
documentation
can
produced
release
shown
work
documentation
debt
may
propagate
nonetheless
mature
research
community
curators
users
reviewers
can
contribute
cultivating
data
documentation
culture
keep
overall
documentation
debt
check
supplementary
information
online
version
contains
supplementary
material
available
https://doi.
org
10.1007
s10618-022-00854-z
acknowledgements
authors
like
thank
following
researchers
dataset
creators
useful
feedback
data
briefs
alain
barrat
luc
behaghel
asia
biega
marko
bohanec
chris
burgess
robin
burke
alejandro
noriega
campero
margarida
carvalho
abhijnan
chakraborty
robert
cheetham
won
ik
cho
paulo
cortez
thomas
davidson
maria
de-arteaga
lucas
dixon
danijela
djordjevic
michele
donini
marco
duarte
natalie
ebner
elaine
fehrman
altay
guvenir
moritz
hardt
irina
higgins
yu
hen
hu
rachel
huddart
lalana
kagal
dean
karlan
vijay
keswani
kim
hyunjik
kim
jiwon
kim
svetlana
kiritchenko
pang
wei
koh
joseph
konstan
varun
kumar
jeremy
andrew
irvin
jamie
larson
jure
leskovec
jonathan
levy
andrea
lodi
oisin
mac
aodha
loic
matthey
julian
mcauley
brendan
mcmahan
sergio
moro
luca
oneto
orestis
papakyriakopoulos
stephen
robert
pfohl
christopher
potts
mike
redmond
kit
rodolfa
ben
roshan
veronica
rotemberg
rachel
rudinger
sivan
sabato
kate
saenko
mark
shermis
daniel
slunge
david
solans
luca
soldaini
efstathios
stamatatos
ryan
steed
rachael
tatman
schrasing
tong
alan
tsang
sathishkumar
andreas
van
cranenburgh
lucy
vasserman
roland
vollgraf
alex
wang
zeerak
waseem
kellie
webster
bryan
wilder
nick
wilson
i-cheng
yeh
elad
yom-tov
neil
yorke-smith
michal
zabovsky
yukun
zhu
123
algorithmic
fairness
datasets
story
far
2119
funding
open
access
funding
provided
università
degli
studi
di
padova
within
crui-care
agree
ment
open
access
article
licensed
creative
commons
attribution
4.0
international
license
permits
use
sharing
adaptation
distribution
reproduction
medium
format
long
give
appropriate
credit
original
author
source
provide
link
creative
commons
licence
indicate
changes
made
images
third
party
material
article
included
article
creative
commons
licence
unless
indicated
otherwise
credit
line
material
material
included
article
creative
commons
licence
intended
use
permitted
statutory
regulation
exceeds
permitted
use
will
need
obtain
permission
directly
copyright
holder
view
copy
licence
visit
http://creativecommons.org/licenses/by/4.0/.
references
abbasi
bhaskara
venkatasubramanian
2021
fair
clustering
via
equitable
group
representations
proceedings
2021
acm
conference
fairness
accountability
transparency
association
computing
machinery
new
york
facct
21
pp
504
514
https://doi.org/10.1145/3442188.3445913
adragna
creager
madras
zemel
2020
fairness
robustness
invariant
learning
case
study
toxicity
classification
neurips
2020
workshop
algorithmic
fairness
lens
causality
interpretability
afci
arxiv
2011.06485
agarwal
beygelzimer
dudik
langford
wallach
2018a
reductions
approach
fair
classification
dy
krause
eds
proceedings
35th
international
conference
machine
learning
pmlr
stockholmsmässan
stockholm
sweden
proceedings
machine
learning
research
vol
80
pp
60
69
http://proceedings.mlr.press/v80/agarwal18a.html
agrawal
zitnik
leskovec
et
al
2018b
large-scale
analysis
disease
pathways
human
interactome
psb
world
scientific
pp
111
122
agarwal
dudik
wu
zs
2019
fair
regression
quantitative
definitions
reduction-based
algorithms
chaudhuri
salakhutdinov
eds
proceedings
36th
international
conference
machine
learning
pmlr
long
beach
california
usa
proceedings
machine
learning
research
vol
97
pp
120
129
http://proceedings.mlr.press/v97/agarwal19d.html
ahmadian
epasto
knittel
kumar
mahdian
moseley
pham
vassilvitskii
wang
2020
fair
hierarchical
clustering
larochelle
ranzato
hadsell
balcan
lin
eds
advances
neural
information
processing
systems
33
annual
conference
neural
information
processing
systems
2020
neurips
2020
december
12
2020
virtual
https://proceedings.neurips.
cc
paper
2020
hash
f10f2da9a238b746d2bac55759915f0d-abstract
html
aka
burke
bauerle
greer
mitchell
2021
measuring
model
biases
absence
ground
truth
association
computing
machinery
new
york
pp
327
335
https://doi.org/10.1145/
3461702.3462557
albanese
calbimonte
jp
schumacher
calvaresi
2020
dynamic
consent
management
clinical
trials
via
private
blockchain
technology
amb
intell
human
comput
18
ali
babaei
chakraborty
mirzasoleiman
gummadi
kp
singla
2019a
fairness
time-critical
influence
maximization
social
networks
neurips
2019
workshop
human-centric
machine
learning
arxiv
1905.06618
ali
zafar
mb
singla
gummadi
kp
2019b
loss-aversively
fair
classification
proceedings
2019
aaai
acm
conference
ai
ethics
society
association
computing
machinery
new
york
aies
19
pp
211
218
https://doi.org/10.1145/3306618.3314266,
ali
lahoti
gummadi
kp
2021
accounting
model
uncertainty
algorithmic
discrimination
association
computing
machinery
new
york
pp
336
345
https://doi.org/10.1145/3461702.
3462630
amini
soleimany
ap
schwarting
bhatia
sn
rus
2019
uncovering
mitigating
algorithmic
bias
learned
latent
structure
proceedings
2019
aaai
acm
conference
ai
ethics
society
association
computing
machinery
new
york
aies
19
pp
289
295
https
doi
org
10.1145
3306618.3314243
anderson
1936
species
problem
iris
ann
mo
bot
gard
23
457
509
123
2120
fabris
et
al
andrus
spitzer
brown
xiang
2021
can
measure
can
understand
challenges
demographic
data
procurement
pursuit
fairness
proceedings
2021
acm
conference
fairness
accountability
transparency
association
computing
machinery
new
york
facct
21
pp
249
260
https://doi.org/10.1145/3442188.3445888
andrzejak
rg
lehnertz
mormann
rieke
david
elger
ce
2001
indications
nonlinear
deterministic
finite-dimensional
structures
time
series
brain
electrical
activity
dependence
recording
region
brain
state
phys
rev
64
061907
angwin
larson
mattu
kirchner
2016
machine
bias
https://www.propublica.org/article/machine-
bias-risk-assessments-in-criminal-sentencing
arjovsky
bottou
gulrajani
lopez-paz
2020
invariant
risk
minimization
arxiv
1907.02893
atwood
srinivasan
halpern
sculley
2019
fair
treatment
allocations
social
networks
neurips
2019
workshop
fair
ml
health
arxiv
1911.05489
awasthi
beutel
kleindessner
morgenstern
wang
2021
evaluating
fairness
machine
learning
models
uncertain
incomplete
information
proceedings
2021
acm
conference
fairness
accountability
transparency
association
computing
machinery
new
york
facct
21
pp
206
214
https://doi.org/10.1145/3442188.3445884
babaeianjelodar
lorenz
gordon
matthews
freitag
2020
quantifying
gender
bias
dif
ferent
corpora
companion
proceedings
web
conference
2020
association
computing
machinery
new
york
www
20
pp
752
759
https://doi.org/10.1145/3366424.3383559
babaioff
nisan
talgam-cohen
2019
fair
allocation
competitive
equilibrium
generic
incomes
proceedings
conference
fairness
accountability
transparency
association
computing
machinery
new
york
fat
19
pp
180
https://doi.org/10.1145/3287560.3287582
backurs
indyk
onak
schieber
vakilian
wagner
2019
scalable
fair
clustering
chaudhuri
salakhutdinov
eds
proceedings
36th
international
conference
machine
learning
pmlr
long
beach
california
proceedings
machine
learning
research
vol
97
pp
405
413
http
proceedings
mlr
press
v97
backurs19a
html
bagdasaryan
poursaeed
shmatikov
2019
differential
privacy
disparate
impact
model
accu
racy
wallach
larochelle
beygelzimer
alché-buc
fox
garnett
eds
advances
neural
information
processing
systems
curran
associates
inc
vol
32
https://proceedings.neurips.
cc
paper
2019
file
fc0de4e0396fff257ea362983c2dda5a-paper
pdf
baharlouei
nouiehed
beirami
razaviyayn
2020
rényi
fair
inference
international
con
ference
learning
representations
https://openreview.net/forum?id=hkgsujrtdb
bakker
ma
tu
dp
valdés
hr
gummadi
kp
varshney
kr
weller
pentland
2019
dadi
dynamic
discovery
fair
information
adversarial
reinforcement
learning
neurips
2019
workshop
human-centric
machine
learning
arxiv
1910.13983
bakker
ma
tu
dp
gummadi
kp
pentland
varshney
kr
weller
2021
beyond
reasonable
doubt
improving
fairness
budget-constrained
decision
making
using
confidence
thresholds
association
computing
machinery
new
york
pp
346
356
https://doi.org/10.1145/3461702.3462575
ball-burack
lee
msa
cobbe
singh
2021
differential
tweetment
mitigating
racial
dialect
bias
harmful
tweet
detection
proceedings
2021
acm
conference
fairness
accountability
transparency
association
computing
machinery
new
york
facct
21
pp
116
128
https
doi
org
10.1145
3442188.3445875
bandy
vincent
2021
addressing
documentation
debt
machine
learning
research
retrospective
datasheet
bookcorpus
arxiv
2105.05241
bao
zhou
zottola
brubach
desmarais
horowitz
lum
venkatasubramanian
2021
compaslicated
messy
relationship
rai
datasets
algorithmic
fairness
benchmarks
arxiv
2106.05498
barabas
dinakar
doyle
2019
problems
risk
assessment
tools
https://www.nytimes.com/
2019
07
17
opinion
pretrial-ai
html
barbaro
2007
apparel
tariffs
aren
created
equal
https://www.nytimes.com/2007/04/28/
business
28gender
html
barenstein
2019
propublica
compas
data
revisited
arxiv
1906.04711
barman-adhikari
begun
rice
yoshioka-maxwell
perez-portillo
2016
sociometric
network
structure
association
methamphetamine
use
norms
among
homeless
youth
soc
sci
res
58
292
308
barocas
hardt
narayanan
2019
fairness
machine
learning
fairmlbook
org
http://www.
fairmlbook
org
123
algorithmic
fairness
datasets
story
far
2121
baudry
jp
cardoso
celeux
amorim
mj
ferreira
2015
enhancing
selection
model-based
clustering
external
categorical
variables
adv
data
anal
classif
177
196
behaghel
crépon
gurgand
2014
private
public
provision
counseling
job
seekers
evidence
large
controlled
experiment
econ
appl
econ
142
74
https://doi.org/10.
1257
app
6.4
142
belitz
jiang
bosch
2021
automating
procedurally
fair
feature
selection
machine
learning
association
computing
machinery
new
york
pp
379
389
https://doi.org/10.1145/3461702.
3462585
bender
em
friedman
2018
data
statements
natural
language
processing
toward
mitigating
system
bias
enabling
better
science
trans
assoc
comput
linguist
587
604
https://doi.org/10.1162/
tacl_a_00041
https://www.aclweb.org/anthology/q18-1041
bender
em
gebru
mcmillan-major
shmitchell
2021
dangers
stochastic
parrots
can
language
models
big
association
computing
machinery
new
york
facct
21
pp
610
623
https://doi.org/10.1145/3442188.3445922,
benenson
popov
ferrari
2019
large-scale
interactive
object
segmentation
human
annotators
proceedings
ieee
cvf
conference
computer
vision
pattern
recognition
pp
11700
11709
bera
chakrabarty
flores
negahbani
2019
fair
algorithms
clustering
wallach
larochelle
beygelzimer
alché-buc
fox
garnett
eds
advances
neural
information
processing
systems
curran
associates
inc
vol
32
pp
4954
4965
https://proceedings.neurips.cc/
paper
2019
file
fc192b0c0d270dbf41870a63a8c76c2f-paper
pdf
beretta
vetrò
lepri
martin
jcd
2021
detecting
discriminatory
risk
data
annotation
based
bayesian
inferences
proceedings
2021
acm
conference
fairness
accountability
transparency
association
computing
machinery
new
york
facct
21
pp
794
804
https://doi.
org
10.1145
3442188.3445940
berk
heidari
jabbari
joseph
kearns
morgenstern
neel
roth
2017
convex
framework
fair
regression
kdd
2017
workshop
fairness
accountability
transparency
machine
learning
fat
ml
arxiv
1706.02409
bertin-mahieux
ellis
dpw
whitman
lamere
2011
million
song
dataset
proceedings
12th
international
society
music
information
retrieval
conference
ismir
miami
pp
591
596
https://doi.org/10.5281/zenodo.1415820
bertrand
mullainathan
2004
emily
greg
employable
lakisha
jamal
field
experiment
labor
market
discrimination
econ
rev
94
991
1013
beutel
chen
zhao
chi
eh
2017
data
decisions
theoretical
implications
adversarially
learning
fair
representations
kdd
2017
workshop
fairness
accountability
transparency
machine
learning
fat
ml
arxiv
1707.00075
biega
aj
diaz
ekstrand
md
kohlmeier
2019
overview
trec
2019
fair
ranking
track
twenty-eighth
text
retrieval
conference
trec
2019
proceedings
biswas
mukherjee
2021
ensuring
fairness
prior
probability
shifts
association
computing
machinery
new
york
pp
414
424
https://doi.org/10.1145/3461702.3462596
black
fredrikson
2021
leave-one-out
unfairness
proceedings
2021
acm
conference
fairness
accountability
transparency
association
computing
machinery
new
york
facct
21
pp
285
295
https://doi.org/10.1145/3442188.3445894
black
yeom
fredrikson
2020
fliptest
fairness
testing
via
optimal
transport
proceedings
2020
conference
fairness
accountability
transparency
association
computing
machinery
new
york
fat
20
pp
111
121
https://doi.org/10.1145/3351095.3372845
blodget
sl
connor
2017
racial
disparity
natural
language
processing
case
study
social
media
african-american
english
kdd
2017
workshop
fairness
accountability
transparency
machine
learning
fat
ml
arxiv
1707.00061
blodgett
sl
green
connor
2016
demographic
dialectal
variation
social
media
case
study
african-american
english
proceedings
2016
conference
empirical
methods
natural
language
processing
association
computational
linguistics
austin
pp
1119
1130
https://doi.
org
10.18653
v1
d16-1120
https://www.aclweb.org/anthology/d16-1120
bolukbasi
chang
kw
zou
jy
saligrama
kalai
2016
man
computer
program
mer
woman
homemaker
debiasing
word
embeddings
lee
sugiyama
luxburg
guyon
garnett
eds
advances
neural
information
processing
systems
123
2122
fabris
et
al
curran
associates
inc
vol
29
pp
4349
4357
https://proceedings.neurips.cc/paper/2016/file/
a486cd07e4ac3d270571622f4f316ec5-paper
pdf
bordes
usunier
garcia-duran
weston
yakhnenko
2013
translating
embeddings
mod
eling
multi-relational
data
burges
cjc
bottou
welling
ghahramani
weinberger
kq
eds
advances
neural
information
processing
systems
curran
associates
inc
vol
26
https
proceedings
neurips
cc
paper
2013
file
1cecc7a77928ca8133fa24680a88d2f9-paper
pdf
bordia
bowman
sr
2019
identifying
reducing
gender
bias
word-level
language
models
proceedings
2019
conference
north
american
chapter
association
computational
linguistics
student
research
workshop
association
computational
linguistics
minneapolis
pp
15
https://doi.org/10.18653/v1/n19-3002,
https://aclanthology.org/n19-3002
borkan
dixon
sorensen
thain
vasserman
2019
nuanced
metrics
measuring
unintended
bias
real
data
text
classification
companion
proceedings
2019
world
wide
web
conference
association
computing
machinery
new
york
www
19
pp
491
500
https://doi.
org
10.1145
3308560.3317593
bose
hamilton
2019
compositional
fairness
constraints
graph
embeddings
chaudhuri
salakhutdinov
eds
proceedings
36th
international
conference
machine
learning
pmlr
long
beach
proceedings
machine
learning
research
vol
97
pp
715
724
http://proceedings.mlr.
press
v97
bose19a
html
bower
niss
sun
vargo
2018
debiasing
representations
removing
unwanted
variation
due
protected
attributes
icml
2018
workshop
fairness
accountability
transparency
machine
learning
fat
ml
arxiv
1807.00461
bower
eftekhari
yurochkin
sun
2021
individually
fair
rankings
international
conference
learning
representations
https://openreview.net/forum?id=71zcsp_hubn
brennan
dieterich
ehret
2009
evaluating
predictive
validity
compas
risk
needs
assessment
system
crim
justice
behav
36
21
40
https://doi.org/10.1177/0093854808326545
brockman
cheung
pettersson
schneider
schulman
tang
zaremba
2016
openai
gym
arxiv
1606.01540
brooks-gunn
fr
klebanov
pk
1992
effects
early
intervention
cognitive
function
low
birth
weight
preterm
infants
pediatr
120
350
359
brožovský
2006
recommender
system
dating
service
master
thesis
charles
university
prague
prague
http://colfi.wz.cz/colfi.pdf
brozovsky
petricek
2007
recommender
system
online
dating
service
arxiv
0703042
cs
brubach
chakrabarti
dickerson
khuller
srinivasan
tsepenekas
2020
pairwise
fair
community-preserving
approach
k-center
clustering
iii
hd
singh
eds
proceedings
37th
international
conference
machine
learning
pmlr
virtual
proceedings
machine
learning
research
vol
119
pp
1178
1189
http://proceedings.mlr.press/v119/brubach20a.html
brunet
alkalay-houlihan
anderson
zemel
2019
understanding
origins
bias
word
embeddings
chaudhuri
salakhutdinov
eds
proceedings
36th
international
conference
machine
learning
pmlr
long
beach
proceedings
machine
learning
research
vol
97
pp
803
811
http://proceedings.mlr.press/v97/brunet19a.html
buolamwini
gebru
2018
gender
shades
intersectional
accuracy
disparities
commercial
gender
classification
friedler
sa
wilson
eds
proceedings
1st
conference
fairness
account
ability
transparency
pmlr
new
york
proceedings
machine
learning
research
vol
81
pp
77
91
http://proceedings.mlr.press/v81/buolamwini18a.html
burke
kontny
sonboli
2018a
synthetic
attribute
data
evaluating
consumer-side
fairness
recsys
2018
workshop
workshop
responsible
recommendation
fat
rec
arxiv
1809.04199
burke
sonboli
ordonez-gauger
2018b
balanced
neighborhoods
multi-sided
fairness
recommendation
friedler
sa
wilson
eds
proceedings
1st
conference
fairness
accountability
transparency
pmlr
new
york
proceedings
machine
learning
research
vol
81
pp
202
214
http://proceedings.mlr.press/v81/burke18a.html
buyl
de
bie
2020
debayes
bayesian
method
debiasing
network
embeddings
iii
hd
singh
eds
proceedings
37th
international
conference
machine
learning
pmlr
virtual
proceedings
machine
learning
research
vol
119
pp
1220
1229
http://proceedings.mlr.press/v119/
buyl20a
html
cai
gaebler
garg
goel
2020
fair
allocation
selective
information
acquisition
proceedings
aaai
acm
conference
ai
ethics
society
association
computing
machinery
new
york
aies
20
pp
22
28
https://doi.org/10.1145/3375627.3375823,
123
algorithmic
fairness
datasets
story
far
2123
caldas
duddu
smk
wu
li
konec
ny
mcmahan
hb
smith
talwalkar
2018
leaf
benchmark
federated
settings
arxiv
1812.01097
calders
verwer
2010
three
naive
bayes
approaches
discrimination-free
classification
data
min
knowl
discov
21
277
292
https://doi.org/10.1007/s10618-010-0190-x
calders
kamiran
pechenizkiy
2009
building
classifiers
independency
constraints
2009
ieee
international
conference
data
mining
workshops
pp
13
18
https://doi.org/10.1109/icdmw.
2009.83
caliskan
bryson
narayanan
2017
semantics
derived
automatically
language
corpora
contain
human-like
biases
science
356
6334
183
186
https://doi.org/10.1126/science.aal4230
calmon
wei
vinzamuri
natesan
ramamurthy
varshney
kr
2017
optimized
pre
processing
discrimination
prevention
guyon
luxburg
uv
bengio
wallach
fergus
vishwanathan
garnett
eds
advances
neural
information
processing
sys
tems
curran
associates
inc
vol
30
pp
3992
4001
https://proceedings.neurips.cc/paper/2017/file/
9a49a25d845a483fae4be7e341368e36-paper
pdf
canetti
cohen
dikkala
ramnarayan
scheffler
smith
2019
soft
classifiers
hard
decisions
fair
can
proceedings
conference
fairness
accountability
transparency
association
computing
machinery
new
york
fat
19
pp
309
318
https://doi.
org
10.1145
3287560.3287561
caragiannis
kurokawa
moulin
procaccia
ad
shah
wang
2016
unreasonable
fairness
maximum
nash
welfare
proceedings
2016
acm
conference
economics
computation
association
computing
machinery
new
york
ec
16
pp
305
322
https://doi.org/10.1145/
2940716.2940726
cardoso
rl
meira
jr
almeida
zaki
mj
2019
framework
benchmarking
discrimination-aware
models
machine
learning
proceedings
2019
aaai
acm
conference
ai
ethics
society
association
computing
machinery
new
york
aies
19
pp
437
444
https://doi.org/10.
1145
3306618.3314262
carvalho
lodi
2019
game
theoretical
analysis
kidney
exchange
programs
arxiv
1911.09207
caton
haas
2020
fairness
machine
learning
survey
arxiv
2010.04053
celis
le
keswani
2020
implicit
diversity
image
summarization
proc
acm
hum
comput
interact
cscw2
28
https://doi.org/10.1145/3415210
celis
le
deshpande
kathuria
vishnoi
nk
2016
fair
diverse
dtl
2016
workshop
fairness
accountability
transparency
machine
learning
fat
ml
arxiv
1610.07183
celis
keswani
straszak
deshpande
kathuria
vishnoi
2018
fair
diverse
dpp-based
data
summarization
dy
krause
eds
proceedings
35th
international
conference
machine
learning
pmlr
stockholmsmässan
stockholm
sweden
proceedings
machine
learning
research
vol
80
pp
716
725
http://proceedings.mlr.press/v80/celis18a.html
celis
mehrotra
vishnoi
2019a
toward
controlling
discrimination
online
ad
auctions
chaudhuri
salakhutdinov
eds
proceedings
36th
international
conference
machine
learning
pmlr
long
beach
proceedings
machine
learning
research
vol
97
pp
4456
4465
http://proceedings.mlr.press/v97/mehrotra19a.html
celis
le
huang
keswani
vishnoi
nk
2019b
classification
fairness
constraints
meta
algorithm
provable
guarantees
proceedings
conference
fairness
accountability
transparency
association
computing
machinery
new
york
fat
19
pp
319
328
https://doi.
org
10.1145
3287560.3287586
celis
le
keswani
vishnoi
2020a
data
preprocessing
mitigate
bias
maximum
entropy
based
approach
iii
hd
singh
eds
proceedings
37th
international
conference
machine
learning
pmlr
virtual
proceedings
machine
learning
research
vol
119
pp
1349
1359
http
proceedings
mlr
press
v119
celis20a
html
celis
le
mehrotra
vishnoi
nk
2020b
interventions
ranking
presence
implicit
bias
proceedings
2020
conference
fairness
accountability
transparency
association
computing
machinery
new
york
fat
20
pp
369
380
https://doi.org/10.1145/3351095.3372858
celma
2010
music
recommendation
discovery
long
tail
springer
berlin
chaibub
neto
2020
causal
look
statistical
definitions
discrimination
proceedings
26th
acm
sigkdd
international
conference
knowledge
discovery
data
mining
association
computing
machinery
new
york
kdd
20
pp
873
881
https://doi.org/10.1145/3394486.3403130
chakraborty
patro
gk
ganguly
gummadi
kp
loiseau
2019
equality
voice
towards
fair
representation
crowdsourced
top-k
recommendations
proceedings
conference
fairness
123
2124
fabris
et
al
accountability
transparency
association
computing
machinery
new
york
fat
19
pp
129
138
https://doi.org/10.1145/3287560.3287570
chapelle
chang
2010
yahoo
learning
rank
challenge
overview
proceedings
2010
international
conference
yahoo
learning
rank
challenge-volume
14
jmlr
org
ylrc
10
pp
24
chaudhari
ha
lin
linda
2020
general
framework
fairness
multistakeholder
recom
mendations
recsys
2020
workshop
3rd
facctrec
workshop
responsible
recommendation
arxiv
2009.02423
chelba
mikolov
schuster
ge
brants
koehn
robinson
2014
one
billion
word
benchmark
measuring
progress
statistical
language
modeling
interspeech-2014
chen
deng
shen
2018a
virtual
class
enhanced
discriminative
embedding
learning
bengio
wallach
larochelle
grauman
cesa-bianchi
garnett
eds
advances
neural
information
processing
systems
curran
associates
inc
vol
31
https://proceedings.neurips.cc/paper/2018/file/
d79aac075930c83c2f1e369a511148fe-paper
pdf
chen
cw
lamere
schedl
zamani
2018b
recsys
challenge
2018
automatic
music
playlist
continuation
association
computing
machinery
new
york
recsys
18
pp
527
528
https://doi.
org
10.1145
3240323.3240342
chen
johansson
fd
sontag
2018c
classifier
discriminatory
bengio
wallach
larochelle
grauman
cesa-bianchi
garnett
eds
advances
neural
information
processing
systems
curran
associates
inc
vol
31
https://proceedings.neurips.cc/paper/2018/file/
1f1baa5b8edac74eb4eaa329f14a0361-paper
pdf
chen
kallus
mao
svacha
udell
2019a
fairness
unawareness
assessing
disparity
protected
class
unobserved
proceedings
conference
fairness
accountability
transparency
association
computing
machinery
new
york
fat
19
pp
339
348
https://doi.
org
10.1145
3287560.3287594
chen
fain
lyu
munagala
2019b
proportionally
fair
clustering
chaudhuri
salakhutdinov
eds
proceedings
36th
international
conference
machine
learning
pmlr
long
beach
proceedings
machine
learning
research
vol
97
pp
1032
1041
http://proceedings.mlr.press/v97/
chen19d
html
chen
mahoney
grasso
wali
matthews
middleton
njie
matthews
2021
gender
bias
under-representation
natural
language
processing
across
human
languages
association
computing
machinery
new
york
pp
24
34
https://doi.org/10.1145/3461702.3462530
cheng
hao
yuan
si
carin
2021a
fairfil
contrastive
neural
debiasing
method
pretrained
text
encoders
international
conference
learning
representations
https://openreview.net/forum?
id
n6jecd-pi5w
cheng
suriyakumar
vm
dullerud
joshi
ghassemi
2021b
can
fake
make
impacts
differentially
private
synthetic
data
downstream
classification
fairness
proceedings
2021
acm
conference
fairness
accountability
transparency
association
computing
machinery
new
york
facct
21
pp
149
160
https://doi.org/10.1145/3442188.3445879
chierichetti
kumar
lattanzi
vassilvitskii
2017
fair
clustering
fairlets
guyon
luxburg
uv
bengio
wallach
fergus
vishwanathan
garnett
eds
advances
neural
information
processing
systems
curran
associates
inc
vol
30
pp
5029
5037
https://proceedings.
neurips
cc
paper
2017
file
978fce5bcc4eccc88ad48ce3914124a2-paper
pdf
chiplunkar
kale
ramamoorthy
sn
2020
solve
fair
k-center
massive
data
models
iii
hd
singh
eds
proceedings
37th
international
conference
machine
learning
pmlr
virtual
proceedings
machine
learning
research
vol
119
pp
1877
1886
http://proceedings.mlr.
press
v119
chiplunkar20a
html
cho
hwang
suh
2020
fair
classifier
using
kernel
density
estimation
larochelle
ran
zato
hadsell
balcan
mf
lin
eds
advances
neural
information
processing
systems
curran
associates
inc
vol
33
pp
15088
15099
https://proceedings.neurips.cc/paper/2020/file/
ac3870fcad1cfc367825cda0101eee62-paper
pdf
cho
wi
kim
yang
kim
ns
2021
towards
cross-lingual
generalization
translation
gender
bias
proceedings
2021
acm
conference
fairness
accountability
transparency
association
computing
machinery
new
york
facct
21
pp
449
457
https://doi.org/10.1145/3442188.3445907
choi
grover
singh
shu
ermon
2020a
fair
generative
modeling
via
weak
supervision
iii
hd
singh
eds
proceedings
37th
international
conference
machine
learning
pmlr
123
algorithmic
fairness
datasets
story
far
2125
virtual
proceedings
machine
learning
research
vol
119
pp
1887
1898
http://proceedings.mlr.
press
v119
choi20a
html
choi
dang
den
broeck
gv
2020b
group
fairness
probabilistic
modeling
latent
fair
deci
sions
neurips
2020
workshop
algorithmic
fairness
lens
causality
interpretability
afci
arxiv
2009.09031
chouldechova
2017
fair
prediction
disparate
impact
study
bias
recidivism
prediction
instruments
big
data
153
163
chouldechova
sell
2017
fairer
accurate
kdd
2017
workshop
fairness
accountability
transparency
machine
learning
fat
ml
arxiv
1707.00046
chouldechova
roth
2020
snapshot
frontiers
fairness
machine
learning
commun
acm
63
82
89
https://doi.org/10.1145/3376898
chuang
cy
mroueh
2021
fair
mixup
fairness
via
interpolation
international
conference
learning
representations
https://openreview.net/forum?id=dnl5s5bxebn
chzhen
denis
hebiri
oneto
pontil
2019
leveraging
labeled
unlabeled
data
consistent
fair
binary
classification
wallach
larochelle
beygelzimer
alché-buc
fox
garnett
eds
advances
neural
information
processing
systems
curran
associates
inc
vol
32
pp
12760
12770
https://proceedings.neurips.cc/paper/2019/file/ba51e6158bcaf80fd0d834950251e693-paper.
pdf
chzhen
denis
hebiri
oneto
pontil
2020a
fair
regression
via
plug-in
estimator
recal
ibration
statistical
guarantees
larochelle
ranzato
hadsell
balcan
lin
eds
advances
neural
information
processing
systems
33
annual
conference
neural
information
pro
cessing
systems
2020
neurips
2020
december
12
2020
virtual
https://proceedings.neurips.cc/
paper
2020
hash
ddd808772c035aed16d42ad3559be5f-abstract
html
chzhen
denis
hebiri
oneto
pontil
2020b
fair
regression
wasserstein
barycenters
larochelle
ranzato
hadsell
balcan
mf
lin
eds
advances
neural
information
processing
systems
curran
associates
inc
vol
33
pp
7321
7331
https://proceedings.neurips.cc/
paper
2020
file
51cdbd2611e844ece5d80878eb770436-paper
pdf
cohany
sr
polivka
ae
rothgeb
jm
1994
revisions
current
population
survey
effective
january
1994
emp
earn
41
13
corbett-davies
pierson
feller
goel
huq
2017
algorithmic
decision
making
cost
fairness
proceedings
23rd
acm
sigkdd
international
conference
knowledge
discovery
data
mining
association
computing
machinery
new
york
kdd
17
pp
797
806
https
doi
org
10.1145
3097983.3098095
cortez
silva
amg
2008
using
data
mining
predict
secondary
school
student
performance
proceedings
5th
future
business
technology
conference
coston
ramamurthy
kn
wei
varshney
kr
speakman
mustahsan
chakraborty
2019
fair
transfer
learning
missing
protected
attributes
proceedings
2019
aaai
acm
conference
ai
ethics
society
association
computing
machinery
new
york
aies
19
pp
91
98
https://doi.org/10.1145/3306618.3314236
coston
mishler
kennedy
eh
chouldechova
2020
counterfactual
risk
assessments
evaluation
fairness
proceedings
2020
conference
fairness
accountability
transparency
association
computing
machinery
new
york
fat
20
pp
582
593
https://doi.org/10.1145/
3351095.3372851
coston
guha
ouyang
lu
chouldechova
ho
de
2021
leveraging
administrative
data
bias
audits
assessing
disparate
coverage
mobility
data
covid-19
policy
proceedings
2021
acm
conference
fairness
accountability
transparency
association
computing
machinery
new
york
facct
21
pp
173
184
https://doi.org/10.1145/3442188.3445881
cotter
gupta
jiang
srebro
sridharan
wang
woodworth
2018
training
fairness
constrained
classifiers
generalize
icml
2018
workshop
fairness
accountability
transparency
machine
learning
fat
ml
cotter
gupta
jiang
srebro
sridharan
wang
woodworth
2019
training
well
generalizing
classifiers
fairness
metrics
data-dependent
constraints
chaudhuri
salakhutdinov
eds
proceedings
36th
international
conference
machine
learning
pmlr
long
beach
proceedings
machine
learning
research
vol
97
pp
1397
1405
http://proceedings.
mlr
press
v97
cotter19b
html
crawford
paglen
2021
excavating
ai
politics
images
machine
learning
training
sets
https
excavating
ai
123
2126
fabris
et
al
creager
madras
jacobsen
jh
weis
swersky
pitassi
zemel
2019
flexibly
fair
represen
tation
learning
disentanglement
chaudhuri
salakhutdinov
eds
proceedings
36th
international
conference
machine
learning
pmlr
long
beach
proceedings
machine
learning
research
vol
97
pp
1436
1445
http://proceedings.mlr.press/v97/creager19a.html
creager
madras
pitassi
zemel
2020
causal
modeling
fairness
dynamical
systems
iii
hd
singh
eds
proceedings
37th
international
conference
machine
learning
pmlr
virtual
proceedings
machine
learning
research
vol
119
pp
2185
2195
http://proceedings.mlr.
press
v119
creager20a
html
creager
jacobsen
jh
zemel
2021
exchanging
lessons
algorithmic
fairness
domain
gen
eralization
https://openreview.net/forum?id=dc1im3mkgg,
neurips
2020
workshop
algorithmic
fairness
lens
causality
interpretability
afci
amour
srinivasan
atwood
baljekar
sculley
halpern
2020
fairness
static
deeper
understanding
long
term
fairness
via
simulation
studies
proceedings
2020
conference
fairness
accountability
transparency
association
computing
machinery
new
york
fat
20
pp
525
534
https://doi.org/10.1145/3351095.3372878
dash
chakraborty
ghosh
mukherjee
gummadi
kp
2021
umpire
also
player
bias
private
label
product
recommendations
e-commerce
marketplaces
proceedings
2021
acm
conference
fairness
accountability
transparency
association
computing
machinery
new
york
facct
21
pp
873
884
https://doi.org/10.1145/3442188.3445944
datta
posada
olson
li
reilly
balraj
mesterhazy
pallas
desai
shah
2020
new
paradigm
accelerating
clinical
data
science
stanford
medicine
arxiv
2003.10534
david
ke
liu
fong
2020
debiasing
convolutional
neural
networks
via
meta
orthogonalization
neurips
2020
workshop
algorithmic
fairness
lens
causality
interpretability
afci
arxiv
2011.07453
davidson
ravi
ss
2020
framework
determining
fairness
outlier
detection
ecai
2020
ios
press
pp
2465
2472
davidson
warmsley
macy
mw
weber
2017
automated
hate
speech
detection
problem
offensive
language
proceedings
eleventh
international
conference
web
social
media
icwsm
2017
montréal
may
15
18
2017
aaai
press
pp
512
515
https://aaai.org/ocs/index.php/
icwsm
icwsm17
paper
view
15665
de-arteaga
romanov
wallach
chayes
borgs
chouldechova
geyik
kenthapadi
kalai
2019
bias
bios
case
study
semantic
representation
bias
high-stakes
setting
proceedings
conference
fairness
accountability
transparency
association
computing
machinery
new
york
fat
19
pp
120
128
https://doi.org/10.1145/3287560.3287572
delobelle
temple
perrouin
frénay
heymans
berendt
2020
ethical
adversaries
towards
mitigating
unfairness
adversarial
machine
learning
ecmlpkdd
2020
workshop
bias
2020
bias
fairness
ai
arxiv
2005.06852
deng
dong
socher
li
kai
li
li
fei-fei
2009
imagenet
large-scale
hierarchical
image
database
2009
ieee
conference
computer
vision
pattern
recognition
pp
248
255
https
doi
org
10.1109
cvpr
2009.5206848
denton
hanna
amironesei
smart
nicole
scheuerman
mk
2020
bringing
people
back
contesting
benchmark
machine
learning
datasets
arxiv
2007.07399
deshpande
kv
pan
foulds
jr
2020
mitigating
demographic
bias
ai-based
resume
filtering
adjunct
publication
28th
acm
conference
user
modeling
adaptation
personalization
association
computing
machinery
new
york
umap
20
adjunct
pp
268
275
https://doi.org/
10.1145
3386392.3399569
detrano
janosi
steinbrunn
pfisterer
schmid
jj
sandhu
guppy
kh
lee
froelicher
1989
international
application
new
probability
algorithm
diagnosis
coronary
artery
disease
cardiol
64
304
310
devlin
chang
mw
lee
toutanova
2019
bert
pre-training
deep
bidirectional
transformers
language
understanding
proceedings
2019
conference
north
american
chapter
association
computational
linguistics
human
language
technologies
volume
long
short
papers
association
computational
linguistics
minneapolis
minnesota
pp
4171
4186
dhamala
sun
kumar
krishna
pruksachatkun
chang
kw
gupta
2021
bold
dataset
metrics
measuring
biases
open-ended
language
generation
proceedings
2021
acm
conference
fairness
accountability
transparency
association
computing
machinery
new
york
facct
21
pp
862
872
https://doi.org/10.1145/3442188.3445924
123
algorithmic
fairness
datasets
story
far
2127
diana
gill
kearns
kenthapadi
roth
2021
minimax
group
fairness
algorithms
experi
ments
association
computing
machinery
new
york
pp
66
76
https://doi.org/10.1145/3461702.
3462523
diciccio
vasudevan
basu
kenthapadi
agarwal
2020
evaluating
fairness
using
permuta
tion
tests
association
computing
machinery
new
york
pp
1467
1477
https://doi.org/10.1145/
3394486.3403199
dickens
singh
getoor
2020
hyperfair
soft
approach
integrating
fairness
criteria
recsys
2020
workshop
3rd
facctrec
workshop
responsible
recommendation
arxiv
2009.08952
dieterich
mendoza
brennan
2016
compas
risk
scales
demonstrating
accuracy
equity
pre
dictive
parity
ding
hardt
miller
schmidt
2021
retiring
adult
new
datasets
fair
machine
learning
advances
neural
information
processing
systems
34
dixon
li
sorensen
thain
vasserman
2018
measuring
mitigating
unintended
bias
text
classification
proceedings
2018
aaai
acm
conference
ai
ethics
society
asso
ciation
computing
machinery
new
york
aies
18
pp
67
73
https://doi.org/10.1145/3278721.
3278729
donini
oneto
ben-david
shawe-taylor
js
pontil
2018
empirical
risk
minimization
fairness
constraints
bengio
wallach
larochelle
grauman
cesa-bianchi
garnett
eds
advances
neural
information
processing
systems
curran
associates
inc
vol
31
pp
2791
2801
https://proceedings.neurips.cc/paper/2018/file/83cdcec08fbf90370fcf53bdd56604ff-paper.pdf
dressel
farid
2018
accuracy
fairness
limits
predicting
recidivism
sci
adv
eaao5580
duarte
mf
hu
yh
2004
vehicle
classification
distributed
sensor
networks
parallel
distrib
comput
64
826
838
https://doi.org/10.1016/j.jpdc.2004.03.020
dwork
hardt
pitassi
reingold
zemel
2012
fairness
awareness
proceedings
3rd
innovations
theoretical
computer
science
conference
association
computing
machinery
new
york
itcs
12
pp
214
226
https://doi.org/10.1145/2090236.2090255
dwork
immorlica
kalai
leiserson
2017
decoupled
classifiers
fair
efficient
machine
learning
kdd
2017
workshop
fairness
accountability
transparency
machine
learning
fat
ml
arxiv
1707.06613
dwork
immorlica
kalai
leiserson
2018
decoupled
classifiers
group-fair
efficient
machine
learning
friedler
sa
wilson
eds
proceedings
1st
conference
fairness
accountability
transparency
pmlr
new
york
ny
usa
proceedings
machine
learning
research
vol
81
pp
119
133
http://proceedings.mlr.press/v81/dwork18a.html
ebner
nc
riediger
lindenberger
2010
faces-a
database
facial
expressions
young
middle
aged
older
women
men
development
validation
behav
res
methods
42
351
362
eidinger
enbar
hassner
2014
age
gender
estimation
unfiltered
faces
ieee
trans
inf
forensics
secur
12
2170
2179
https://doi.org/10.1109/tifs.2014.2359646
ekstrand
md
tian
azpiazu
im
ekstrand
jd
anuyah
mcneill
pera
ms
2018
cool
kids
fit
popularity
demographic
biases
recommender
evaluation
effectiveness
friedler
sa
wilson
eds
proceedings
1st
conference
fairness
accountability
transparency
pmlr
new
york
proceedings
machine
learning
research
vol
81
pp
172
186
http://proceedings.mlr.press/v81/ekstrand18b.html
el
emam
arbuckle
koru
eze
gaudette
neri
rose
howard
gluck
2012
de
identification
methods
open
health
data
case
heritage
health
prize
claims
dataset
med
internet
res
14
e33
el
halabi
mitrovic
norouzi-fard
tardos
tarnawski
jm
2020
fairness
streaming
submodular
maximization
algorithms
hardness
larochelle
ranzato
hadsell
balcan
mf
lin
eds
advances
neural
information
processing
systems
curran
associates
inc
vol
33
pp
13609
13622
https://proceedings.neurips.cc/paper/2020/file/9d752cb08ef466fc480fba981cfa44a1-
paper
pdf
elzayn
jabbari
jung
kearns
neel
roth
schutzman
2019
fair
algorithms
learning
allocation
problems
proceedings
conference
fairness
accountability
transparency
association
computing
machinery
new
york
fat
19
pp
170
179
https://doi.org/10.1145/
3287560.3287571
epstein
landes
posner
2013
behavior
federal
judges
theoretical
empirical
study
rational
choice
harvard
university
press
https://books.google.it/books?id=rcqebeic3ecc
123
2128
fabris
et
al
equivant
2019
practitioner
guide
compas
core
https://www.equivant.com/wp-content/uploads/
practitioners-guide-to-compas-core-040419
pdf
esmaeili
brubach
tsepenekas
dickerson
2020
probabilistic
fair
clustering
larochelle
ranzato
hadsell
balcan
mf
lin
eds
advances
neural
information
processing
sys
tems
curran
associates
inc
vol
33
pp
12743
12755
https://proceedings.neurips.cc/paper/2020/
file
95f2b84de5660ddf45c8a34933a2e66f-paper
pdf
european
union
2016
regulation
eu
2016
679
european
parliament
council
27
april
2016
protection
natural
persons
regard
processing
personal
data
free
movement
data
repealing
directive
95
46
ec
general
data
protection
regulation
https
eur-lex
europa
eu
eli
reg
2016
679
2016
05
04
fabbrizzi
papadopoulos
ntoutsi
kompatsiaris
2021
survey
bias
visual
datasets
arxiv
2107.07919
fabris
mishler
gottardi
carletti
daicampi
susto
ga
silvello
2021
algorithmic
audit
italian
car
insurance
evidence
unfairness
access
pricing
association
computing
machinery
new
york
pp
458
468
https://doi.org/10.1145/3461702.3462569
fabris
messina
silvello
susto
ga
2022
tackling
documentation
debt
survey
algorithmic
fairness
datasets
equity
access
algorithms
mechanisms
optimization
association
computing
machinery
new
york
ny
https://doi.org/10.1145/3551624.3555286
farnad
babaki
gendreau
2020
unifying
framework
fairness-aware
influence
maximization
companion
proceedings
web
conference
2020
association
computing
machinery
new
york
www
20
pp
714
722
https://doi.org/10.1145/3366424.3383555
farnadi
kouki
thompson
sk
srinivasan
getoor
2018
fairness-aware
hybrid
recom
mender
system
recsys
2018
workshop
workshop
responsible
recommendation
fat
rec
arxiv
1809.09030
farnadi
babaki
carvalho
2019
enhancing
fairness
kidney
exchange
program
ranking
solutions
neurips
2019
workshop
fair
ml
health
arxiv
1911.05489
fehrman
muhammad
ak
mirkes
em
egan
gorban
2017
five
factor
model
personality
evaluation
drug
consumption
risk
palumbo
montanari
vichi
eds
data
science
springer
cham
pp
231
242
fehrman
egan
gorban
levesley
mirkes
em
muhammad
ak
2019
personality
traits
drug
consumption
story
told
data
springer
berlin
feldman
friedler
sa
moeller
scheidegger
venkatasubramanian
2015
certifying
removing
disparate
impact
proceedings
21th
acm
sigkdd
international
conference
knowledge
discovery
data
mining
association
computing
machinery
new
york
kdd
15
pp
259
268
https://doi.org/10.1145/2783258.2783311
ferraro
bogdanov
serra
yoon
2019
artist
style
exposure
bias
collaborative
filtering
based
music
recommendations
ismir
2019
workshop
workshop
designing
human-centric
mir
systems
arxiv
1911.04827
fish
kun
lelkes
2015
fair
boosting
case
study
icml
2015
workshop
fairness
account
ability
transparency
machine
learning
fat
ml
fisher
ra
1936
use
multiple
measurements
taxonomic
problems
ann
eugen
179
188
fisher
palfrey
christodoulopoulos
mittal
2020
measuring
social
bias
knowledge
graph
embed
dings
akbc
2020
workshop
bias
automatic
knowledge
graph
construction
arxiv
1912.02761
fisman
iyengar
kamenica
simonson
2006
gender
differences
mate
selection
evidence
speed
dating
experiment
econ
121
673
697
https://doi.org/10.1162/qjec.2006.121.2.673
fitzpatrick
tb
1988
validity
practicality
sun-reactive
skin
types
vi
arch
dermatol
124
869
871
flanigan
gölz
gupta
procaccia
ad
2020
neutralizing
self-selection
bias
sampling
sortition
larochelle
ranzato
hadsell
balcan
lin
eds
advances
neural
information
processing
systems
33
annual
conference
neural
information
processing
systems
2020
neurips
2020
december
12
2020
virtual
https://proceedings.neurips.cc/paper/2020/hash/
48237d9f2dea8c74c2a72126cf63d933-abstract
html
florez
ou
2019
unintended
social
bias
training
language
generation
models
data
local
media
neurips
2019
workshop
human-centric
machine
learning
arxiv
1911.00461
fogliato
xiang
lipton
nagin
chouldechova
2021
validity
arrest
proxy
offense
race
likelihood
arrest
violent
crimes
proceedings
4th
aaai
acm
123
algorithmic
fairness
datasets
story
far
2129
conference
ai
ethics
society
aies
2021
virtual
event
pp
100
111
https://doi.org/10.
1145
3461702.3462538
founta
djouvas
chatzakou
leontiadis
blackburn
stringhini
vakali
sirivianos
kourtellis
2018
large
scale
crowdsourcing
characterization
twitter
abusive
behavior
proceedings
twelfth
international
conference
web
social
media
icwsm
2018
stan
ford
june
25
28
2018
aaai
press
pp
491
500
https://aaai.org/ocs/index.php/icwsm/icwsm18/
paper
view
17909
framingham
heart
study
2021
framingham
heart
study
offspring
exam
10
omni
exam
research
consent
form
https://framinghamheartstudy.org/files/2021/01/fhs-offspring-exam-10-
omni-1-exam-5-informed-consent-english-language-v21
pdf
friedler
sa
scheidegger
venkatasubramanian
choudhary
hamilton
ep
roth
2019
compar
ative
study
fairness-enhancing
interventions
machine
learning
proceedings
conference
fairness
accountability
transparency
association
computing
machinery
new
york
fat
19
pp
329
338
https://doi.org/10.1145/3287560.3287589
friedler
sa
scheidegger
venkatasubramanian
2021
im
possibility
fairness
different
value
systems
require
different
mechanisms
fair
decision
making
commun
acm
64
136
143
https
doi
org
10.1145
3433949
galhotra
saisubramanian
zilberstein
2021
learning
generate
fair
clusters
demonstrations
association
computing
machinery
new
york
pp
491
501
https://doi.org/10.1145/3461702.
3462558
garbin
rajpurkar
irvin
lungren
mp
marques
2021
structured
dataset
documentation
datasheet
chexpert
arxiv
2105.03020
garg
perot
limtiaco
taly
chi
eh
beutel
2019
counterfactual
fairness
text
classification
robustness
proceedings
2019
aaai
acm
conference
ai
ethics
society
association
computing
machinery
new
york
aies
19
pp
219
226
https://doi.org/10.1145/
3306618.3317950
gastwirth
jl
miao
2009
formal
statistical
analysis
data
disparate
impact
cases
provides
sounder
inferences
us
government
four-fifths
rule
examination
statistical
evidence
ricci
destefano
law
probab
risk
171
191
ge
caverlee
lu
2016
taper
contextual
tensor-based
approach
personalized
expert
rec
ommendation
proceedings
10th
acm
conference
recommender
systems
association
computing
machinery
new
york
recsys
16
pp
261
268
https://doi.org/10.1145/2959100.
2959151
gebru
morgenstern
vecchione
vaughan
jw
wallach
daumé
iii
crawford
2018
datasheets
datasets
arxiv
1803.09010
geiger
rs
yu
yang
dai
qiu
tang
huang
2020
garbage
garbage
machine
learning
application
papers
social
computing
report
human-labeled
training
data
comes
proceedings
2020
conference
fairness
accountability
transparency
association
computing
machinery
new
york
fat
20
pp
325
336
https://doi.org/10.1145/3351095.3372862
gelman
fagan
kiss
2007
analysis
new
york
city
police
department
stop-and-frisk
policy
context
claims
racial
bias
stat
assoc
102
479
813
823
gerritse
ej
de
vries
ap
2020
effect
debiasing
information
retrieval
boratto
faralli
marras
stilo
eds
bias
social
aspects
search
recommendation
springer
cham
pp
35
42
ghadiri
samadi
vempala
2021
socially
fair
k-means
clustering
proceedings
2021
acm
conference
fairness
accountability
transparency
association
computing
machinery
new
york
facct
21
pp
438
448
https://doi.org/10.1145/3442188.3445906
ginart
guan
valiant
zou
jy
2019
making
ai
forget
data
deletion
machine
learning
wallach
larochelle
beygelzimer
alché-buc
fox
garnett
eds
advances
neural
information
processing
systems
vol
32
curran
associates
inc
https://proceedings.neurips.cc/paper/
2019
file
cb79f8fa58b91d3af6c9c991f63962d3-paper
pdf
go
bhayani
huang
2009
twitter
sentiment
classification
using
distant
supervision
processing
150
goel
faltings
2019
crowdsourcing
fairness
diversity
budget
constraints
proceedings
2019
aaai
acm
conference
ai
ethics
society
association
computing
machinery
new
york
aies
19
pp
297
304
https://doi.org/10.1145/3306618.3314282
goel
rao
jm
shroff
et
al
2016
precinct
prejudice
understanding
racial
disparities
new
york
city
stop-and-frisk
policy
ann
appl
stat
10
365
394
123
2130
fabris
et
al
goel
perelman
shroff
sklansky
2017
combatting
police
discrimination
age
big
data
new
crim
law
rev
20
181
232
https://doi.org/10.1525/nclr.2017.20.2.181
goel
yaghini
faltings
2018
non-discriminatory
machine
learning
convex
fairness
cri
teria
proceedings
2018
aaai
acm
conference
ai
ethics
society
association
computing
machinery
new
york
aies
18
pp
116
https://doi.org/10.1145/3278721.3278722
goel
amayuelas
deshpande
sharma
2020
importance
modeling
data
missingness
algorithmic
fairness
causal
perspective
neurips
2020
workshop
algorithmic
fairness
lens
causality
interpretability
afci
arxiv
2012.11448
goelz
kahng
procaccia
ad
2019
paradoxes
fair
machine
learning
wallach
larochelle
beygelzimer
alché-buc
fox
garnett
eds
advances
neural
information
processing
systems
curran
associates
inc
vol
32
pp
8342
8352
https://proceedings.neurips.cc/paper/2019/
file
bbc92a647199b832ec90d7cf57074e9e-paper
pdf
golbeck
ashktorab
banjo
ro
berlinger
bhagwan
buntain
cheakalos
geller
aa
gergory
gnanasekaran
rk
gunasekaran
rr
hoffman
km
hottle
jienjitlert
khare
lau
martindale
mj
naik
nixon
hl
ramachandran
rogers
km
rogers
sarin
ms
shahane
thanki
vengataraman
wan
wu
dm
2017
large
labeled
corpus
online
harassment
research
proceedings
2017
acm
web
science
conference
association
computing
machinery
new
york
websci
17
pp
229
233
https://doi.org/10.1145/3091478.3091509
goldstein
1991
multilevel
modelling
survey
data
stat
soc
ser
statist
40
235
244
http
www.jstor.org/stable/2348496
gong
liu
jain
ak
2021
mitigating
face
recognition
bias
via
group
adaptive
classifier
proceedings
ieee
cvf
conference
computer
vision
pattern
recognition
cvpr
pp
3414
3424
gordaliza
barrio
ed
fabrice
loubes
jm
2019
obtaining
fairness
using
optimal
transport
theory
chaudhuri
salakhutdinov
eds
proceedings
36th
international
conference
machine
learning
pmlr
long
beach
california
proceedings
machine
learning
research
vol
97
pp
2357
2365
http://proceedings.mlr.press/v97/gordaliza19a.html
gordon
babaeianjelodar
matthews
2020
studying
political
bias
via
word
embeddings
com
panion
proceedings
web
conference
2020
association
computing
machinery
new
york
www
20
pp
760
764
https://doi.org/10.1145/3366424.3383560
goyal
khot
summers-stay
batra
parikh
2017
making
vqa
matter
elevating
role
image
understanding
visual
question
answering
proceedings
ieee
conference
computer
vision
pattern
recognition
pp
6904
6913
graffam
shinkfield
aj
hardcastle
2008
perceived
employability
ex-prisoners
offenders
int
offender
ther
comp
criminol
52
673
685
https://doi.org/10.1177/0306624x07307783
green
chen
2019
disparate
interactions
algorithm-in-the-loop
analysis
fairness
risk
assess
ments
proceedings
conference
fairness
accountability
transparency
association
computing
machinery
new
york
ny
fat
19
pp
90
99
https://doi.org/10.1145/3287560.
3287563
greenwald
ag
mcghee
de
schwartz
jl
1998
measuring
individual
differences
implicit
cognition
implicit
association
test
pers
soc
psychol
74
1464
grgic-hlaca
zafar
gummadi
weller
2016
case
process
fairness
learning
feature
selection
fair
decision
making
neurips
2016
workshop
machine
learning
law
grömping
2019
south
german
credit
data
correcting
widely
used
data
set
report
tech
rep
beuth
university
applied
sciences
berlin
http://www1.beuth-hochschule.de/fb_ii/reports/
report-2019-004
pdf
gulla
ja
zhang
liu
özgöbek
su
2017
adressa
dataset
news
recommendation
pro
ceedings
international
conference
web
intelligence
association
computing
machinery
new
york
wi
17
pp
1042
1048
https://doi.org/10.1145/3106426.3109436
gungor
2018
benchmarking
authorship
attribution
techniques
using
thousand
books
fifty
victorian
era
novelists
master
thesis
purdue
university
guo
caliskan
2021
detecting
emergent
intersectional
biases
contextualized
word
embeddings
contain
distribution
human-like
biases
association
computing
machinery
new
york
pp
122
133
https://doi.org/10.1145/3461702.3462536
guo
zhang
yorke-smith
2016a
novel
evidence-based
bayesian
similarity
measure
recom
mender
systems
acm
trans
web
https://doi.org/10.1145/2856037
123
algorithmic
fairness
datasets
story
far
2131
guo
zhang
hu
gao
2016b
ms-celeb-1m
dataset
benchmark
large-scale
face
recognition
leibe
matas
sebe
welling
eds
computer
vision
eccv
2016
springer
cham
pp
87
102
guvenir
ha
acar
demiroz
cekin
1997
supervised
machine
learning
algorithm
arrhythmia
analysis
computers
cardiology
1997
ieee
pp
433
436
han
jain
ak
2014
age
gender
race
estimation
unconstrained
face
images
http
biometrics
cse
msu
edu
publications
face
hanjain_unconstrainedagegenderraceestimation_
msutechreport2014
pdf
hannák
wagner
garcia
mislove
strohmaier
wilson
2017
bias
online
freelance
marketplaces
evidence
taskrabbit
fiverr
proceedings
2017
acm
conference
computer
supported
cooperative
work
social
computing
association
computing
machinery
new
york
cscw
17
pp
1914
1933
https://doi.org/10.1145/2998181.2998327
har-peled
mahabadi
2019
near
neighbor
fairest
wallach
larochelle
beygelzimer
alché-buc
fox
garnett
eds
advances
neural
information
processing
systems
vol
32
curran
associates
inc
pp
13176
13187
https://proceedings.neurips.cc/paper/2019/
file
742141ceda6b8f6786609d31c8ef129f-paper
pdf
harb
lam
hs
2020
kfc
scalable
approximation
algorithm
k-center
fair
clustering
larochelle
ranzato
hadsell
balcan
mf
lin
eds
advances
neural
information
processing
sys
tems
vol
33
curran
associates
inc
pp
14509
14519
https://proceedings.neurips.cc/paper/2020/
file
a6d259bfbfa2062843ef543e21d7ec8e-paper
pdf
hardt
price
price
srebro
2016
equality
opportunity
supervised
learning
lee
sugiyama
luxburg
guyon
garnett
eds
advances
neural
information
processing
sys
tems
vol
29
curran
associates
inc
pp
3315
3323
https://proceedings.neurips.cc/paper/2016/file/
9d2682367c3935defcb1f9e247a97c0d-paper
pdf
harper
fm
konstan
ja
2015
movielens
datasets
history
context
acm
trans
interact
intell
syst
https://doi.org/10.1145/2827872
hashimoto
srivastava
namkoong
liang
2018
fairness
without
demographics
repeated
loss
minimization
dy
krause
eds
proceedings
35th
international
conference
machine
learning
pmlr
stockholmsmässan
stockholm
sweden
proceedings
machine
learning
research
vol
80
pp
1929
1938
http://proceedings.mlr.press/v80/hashimoto18a.html
mcauley
2016
ups
downs
proceedings
25th
international
conference
world
wide
web
https://doi.org/10.1145/2872427.2883037
kang
wc
mcauley
2017
translation-based
recommendation
proceedings
eleventh
acm
conference
recommender
systems
association
computing
machinery
new
york
recsys
17
pp
161
169
https://doi.org/10.1145/3109859.3109882
burghardt
guo
lerman
2020a
inherent
trade-offs
fair
allocation
treatments
neurips
2020
workshop
algorithmic
fairness
lens
causality
interpretability
afci
arxiv
2010.16409
burghardt
lerman
2020b
geometric
solution
fair
representations
proceedings
aaai
acm
conference
ai
ethics
society
association
computing
machinery
new
york
aies
20
pp
279
285
https://doi.org/10.1145/3375627.3375864
heidari
ferrari
gummadi
krause
2018
fairness
behind
veil
ignorance
wel
fare
analysis
automated
decision
making
bengio
wallach
larochelle
grau
man
cesa-bianchi
garnett
eds
advances
neural
information
processing
systems
vol
31
curran
associates
inc
pp
1265
1276
https://proceedings.neurips.cc/paper/2018/file/
be3159ad04564bfb90db9e32851ebf9c-paper
pdf
heidari
loi
gummadi
kp
krause
2019a
moral
framework
understanding
fair
ml
economic
models
equality
opportunity
proceedings
conference
fairness
account
ability
transparency
association
computing
machinery
new
york
fat
19
pp
181
190
https://doi.org/10.1145/3287560.3287584
heidari
nanda
gummadi
2019b
long-term
impact
algorithmic
decision
policies
effort
unfairness
feature
segregation
social
learning
chaudhuri
salakhutdinov
eds
proceedings
36th
international
conference
machine
learning
pmlr
long
beach
proceed
ings
machine
learning
research
vol
97
pp
2692
2701
http://proceedings.mlr.press/v97/heidari19a.
html
123
2132
fabris
et
al
hendricks
la
burns
saenko
darrell
rohrbach
2018
women
also
snowboard
overcoming
bias
captioning
models
ferrari
hebert
sminchisescu
weiss
eds
computer
vision-eccv
2018
springer
cham
pp
793
811
higgins
matthey
pal
burgess
glorot
botvinick
mohamed
lerchner
2017
beta-vae
learning
basic
visual
concepts
constrained
variational
framework
iclr
holland
hosny
newman
joseph
chmielinski
2018
dataset
nutrition
label
framework
drive
higher
data
quality
standards
arxiv
1805.03677
hollywood
mckay
woods
agniel
2019
real
time
crime
centers
chicago
https://www.rand.
org
content
dam
rand
pubs
research_reports
rr3200
rr3242
rand_rr3242
pdf
holmes
md
smith
bw
freng
ab
muñoz
ea
2008
minority
threat
crime
control
police
resource
allocation
southwestern
united
states
crime
delinq
54
128
152
https://doi.org/10.1177/
0011128707309718
holstein
wortman
vaughan
daumé
iii
dudik
wallach
2019
improving
fairness
machine
learning
systems
industry
practitioners
need
proceedings
acm
conference
human
factors
computing
systems
chi
2019
glasgow
pp
16
houvardas
stamatatos
2006
n-gram
feature
selection
authorship
identification
international
conference
artificial
intelligence
methodology
systems
applications
springer
pp
77
86
hu
chen
2020
fair
classification
social
welfare
proceedings
2020
conference
fairness
accountability
transparency
association
computing
machinery
new
york
fat
20
pp
535
545
https://doi.org/10.1145/3351095.3372857
hu
wu
zhang
wu
2020
fair
multiple
decision
making
soft
interventions
larochelle
ranzato
hadsell
balcan
lin
eds
advances
neural
infor
mation
processing
systems
33
annual
conference
neural
information
processing
systems
2020
neurips
2020
december
12
2020
virtual
https://proceedings.neurips.cc/paper/2020/hash/
d0921d442ee91b89ad95059d13df618-abstract
html
huan
wu
zhang
wu
2020
fairness
equality
effort
companion
proceedings
web
conference
2020
association
computing
machinery
new
york
www
20
pp
743
751
https://doi.org/10.1145/3366424.3383558,
huang
vishnoi
2019
stable
fair
classification
chaudhuri
salakhutdinov
eds
proceed
ings
36th
international
conference
machine
learning
pmlr
long
beach
proceedings
machine
learning
research
vol
97
pp
2879
2890
http://proceedings.mlr.press/v97/huang19e.html
huang
gb
ramesh
berg
learned-miller
2007
labeled
faces
wild
database
studying
face
recognition
unconstrained
environments
huang
jiang
vishnoi
2019
coresets
clustering
fairness
constraints
advances
neural
information
processing
systems
pp
7589
7600
huang
wei
celis
2020
towards
just
fair
interpretable
methods
judicial
subset
selection
proceedings
aaai
acm
conference
ai
ethics
society
association
computing
machinery
new
york
aies
20
pp
293
299
https://doi.org/10.1145/3375627.3375848
hull
1994
database
handwritten
text
recognition
research
ieee
trans
pattern
anal
mach
intell
16
550
554
https://doi.org/10.1109/34.291440
hussain
dahan
na
ba-alwib
fm
ribata
2018
educational
data
mining
analysis
students
academic
performance
using
weka
indones
electr
eng
comput
sci
447
459
hutchinson
prabhakaran
denton
webster
zhong
denuyl
2020
unintended
machine
learning
biases
social
barriers
persons
disabilities
sigaccess
access
comput
vol
125https
doi
org
10.1145
3386296.3386305
häußler
walter
1979
empirische
ergebnisse
zu
diskriminationsverfahren
bei
kreditscoringsystemen
https://link.springer.com/article/10.1007/bf01917956
international
warfarin
pharmacogenetics
consortium
2009
estimation
warfarin
dose
clinical
pharmacogenetic
data
engl
med
360
753
764
irvin
rajpurkar
ko
yu
ciurea-ilcus
chute
marklund
haghgoo
ball
shpanskaya
seekins
mong
halabi
sandberg
jones
larson
langlotz
patel
lungren
ng
2019
chexpert
large
chest
radiograph
dataset
uncertainty
labels
expert
compari
son
33rd
aaai
conference
artificial
intelligence
aaai
2019
31st
innovative
applications
artificial
intelligence
conference
iaai
2019
9th
aaai
symposium
educational
advances
artificial
intelligence
eaai
2019
aaai
press
33rd
aaai
conference
artificial
intelligence
aaai
2019
31st
innovative
applications
artificial
intelligence
conference
iaai
2019
9th
aaai
symposium
educational
advances
artificial
intelligence
eaai
2019
pp
590
597
pub
123
algorithmic
fairness
datasets
story
far
2133
lisher
copyright
2019
association
advancement
artificial
intelligence
www.aaai.org).
rights
reserved
33rd
aaai
conference
artificial
intelligence
aaai
2019
31st
annual
con
ference
innovative
applications
artificial
intelligence
iaai
2019
9th
aaai
symposium
educational
advances
artificial
intelligence
eaai
2019
conference
date
27
01
2019
01
02
2019
islam
pan
foulds
jr
2021
can
obtain
fairness
free
association
computing
machinery
new
york
pp
586
596
https://doi.org/10.1145/3461702.3462614
jabbari
ou
hc
lakkaraju
tambe
2020
empirical
study
trade-offs
interpretabil
ity
fairness
icml
2020
workshop
human
interpretability
machine
learning
preliminary
version
icml
2020
workshop
workshop
human
interpretability
machine
learning
whi
jagielski
kearns
mao
oprea
roth
malvajerdi
ss
ullman
2019
differentially
private
fair
learning
chaudhuri
salakhutdinov
eds
proceedings
36th
international
conference
machine
learning
pmlr
long
beach
proceedings
machine
learning
research
vol
97
pp
3000
3008
http://proceedings.mlr.press/v97/jagielski19a.html
ji
smyth
steyvers
2020
can
trust
fairness
metric
assessing
fairness
unlabeled
data
bayesian
inference
larochelle
ranzato
hadsell
balcan
lin
eds
advances
neural
information
processing
systems
33
annual
conference
neural
information
processing
systems
2020
neurips
2020
december
12
2020
virtual
https://proceedings.neurips.cc/paper/
2020
hash
d83de59e10227072a9c034ce10029c39-abstract
html
jiang
pardos
za
2021
towards
equity
algorithmic
fairness
student
grade
prediction
association
computing
machinery
new
york
pp
608
617
https://doi.org/10.1145/3461702.3462623
jo
es
gebru
2020
lessons
archives
strategies
collecting
sociocultural
data
machine
learning
proceedings
2020
conference
fairness
accountability
transparency
associ
ation
computing
machinery
new
york
fat
20
pp
306
316
https://doi.org/10.1145/3351095.
3372829
johnson
ae
pollard
tj
shen
lehman
lh
feng
ghassemi
moody
szolovits
celi
la
mark
rg
2016
mimic-iii
freely
accessible
critical
care
database
sci
data
160035
johnson
ae
pollard
tj
greenbaum
nr
lungren
mp
deng
cy
peng
lu
mark
rg
berkowitz
sj
horng
2019
mimic-cxr-jpg
large
publicly
available
database
labeled
chest
radiographs
arxiv
1901.07042
jones
nguyen
nguyen
2020
fair
k-centers
via
maximum
matching
iii
hd
singh
eds
proceedings
37th
international
conference
machine
learning
pmlr
virtual
proceedings
machine
learning
research
vol
119
pp
4940
4949
http://proceedings.mlr.press/v119/jones20a.html
jones
sagawa
koh
pw
kumar
liang
2021
selective
classification
can
magnify
disparities
across
groups
international
conference
learning
representations
https://openreview.net/forum?
id
n0m_4bkq05i
jung
lee
park
moon
2021
fair
feature
distillation
visual
recognition
proceedings
ieee
cvf
conference
computer
vision
pattern
recognition
cvpr
pp
12115
12124
kallus
zhou
2018
residual
unfairness
fair
machine
learning
prejudiced
data
dy
krause
eds
proceedings
35th
international
conference
machine
learning
pmlr
stock
holmsmässan
stockholm
sweden
proceedings
machine
learning
research
vol
80
pp
2439
2448
http://proceedings.mlr.press/v80/kallus18a.html
kallus
zhou
2019a
assessing
disparate
impact
personalized
interventions
identifiability
bounds
wallach
larochelle
beygelzimer
alché-buc
fox
garnett
eds
advances
neural
information
processing
systems
vol
32
curran
associates
inc
pp
3426
3437
https
proceedings
neurips
cc
paper
2019
file
d54e99a6c03704e95e6965532dec148b-paper
pdf
kallus
zhou
2019b
fairness
risk
scores
beyond
classification
bipartite
ranking
xauc
metric
wallach
larochelle
beygelzimer
alché-buc
fox
garnett
eds
advances
neural
information
processing
systems
vol
32
curran
associates
inc
pp
3438
3448
https://proceedings.neurips.cc/paper/2019/file/73e0f7487b8e5297182c5a711d20bf26-paper.pdf
kallus
zhou
2021
fairness
welfare
equity
personalized
pricing
proceedings
2021
acm
conference
fairness
accountability
transparency
association
computing
machinery
new
york
facct
21
pp
296
314
https://doi.org/10.1145/3442188.3445895
kallus
mao
zhou
2020
assessing
algorithmic
fairness
unobserved
protected
class
using
data
combination
proceedings
2020
conference
fairness
accountability
transparency
association
computing
machinery
new
york
fat
20
pp
110
https://doi.org/10.1145/3351095.
3373154
123
2134
fabris
et
al
kamishima
2003
nantonac
collaborative
filtering
recommendation
based
order
responses
proceedings
ninth
acm
sigkdd
international
conference
knowledge
discovery
data
mining
association
computing
machinery
new
york
kdd
03
pp
583
588
https://doi.org/10.
1145
956750.956823
kang
maciejewski
tong
2020
inform
individual
fairness
graph
mining
association
computing
machinery
new
york
pp
379
389
https://doi.org/10.1145/3394486.3403080
kannel
wb
mcgee
dl
1979
diabetes
cardiovascular
disease
framingham
study
jama
241
19
2035
2038
karako
manggala
2018
using
image
fairness
representations
diversity-based
re-ranking
rec
ommendations
umap
2018
workshop
fairness
user
modeling
adaptation
personalization
fairumap
arxiv
1809.03577
karkkainen
joo
2021
fairface
face
attribute
dataset
balanced
race
gender
age
bias
measurement
mitigation
proceedings
ieee
cvf
winter
conference
applications
computer
vision
pp
1548
1558
karlan
ds
zinman
2008
credit
elasticities
less-developed
economies
implications
microfinance
econ
rev
98
1040
68
kasy
abebe
2021
fairness
equality
power
algorithmic
decision-making
proceedings
2021
acm
conference
fairness
accountability
transparency
association
computing
machinery
new
york
facct
21
pp
576
586
https://doi.org/10.1145/3442188.3445919
kato
teshima
honda
2019
learning
positive
unlabeled
data
selection
bias
international
conference
learning
representations
https://openreview.net/forum?id=rjzlcicqkm
kearns
neel
roth
wu
zs
2018
preventing
fairness
gerrymandering
auditing
learning
subgroup
fairness
dy
krause
eds
proceedings
35th
international
conference
machine
learning
pmlr
stockholmsmässan
stockholm
sweden
proceedings
machine
learning
research
vol
80
pp
2564
2572
http://proceedings.mlr.press/v80/kearns18a.html
kearns
neel
roth
wu
zs
2019
empirical
study
rich
subgroup
fairness
machine
learn
ing
proceedings
conference
fairness
accountability
transparency
association
computing
machinery
new
york
fat
19
pp
100
109
https://doi.org/10.1145/3287560.3287592
keswani
lease
kenthapadi
2021
towards
unbiased
accurate
deferral
multiple
experts
association
computing
machinery
new
york
pp
154
165
https://doi.org/10.1145/3461702.
3462516
keyes
stevens
wernimont
2019
government
using
vulnerable
people
test
facial
recognition
software
khan
fu
2021
one
label
one
billion
faces
usage
consistency
racial
categories
computer
vision
proceedings
2021
acm
conference
fairness
accountability
transparency
association
computing
machinery
new
york
facct
21
pp
587
597
https://doi.org/10.1145/
3442188.3445920
kilbertus
gascon
kusner
veale
gummadi
weller
2018
blind
justice
fairness
encrypted
sensitive
attributes
dy
krause
eds
proceedings
35th
international
confer
ence
machine
learning
pmlr
stockholmsmässan
stockholm
sweden
proceedings
machine
learning
research
vol
80
pp
2630
2639
http://proceedings.mlr.press/v80/kilbertus18a.html
kim
mnih
2018
disentangling
factorising
dy
krause
eds
proceedings
35th
international
conference
machine
learning
pmlr
proceedings
machine
learning
research
vol
80
pp
2649
2658
http://proceedings.mlr.press/v80/kim18b.html
kim
mp
ghorbani
zou
2019
multiaccuracy
black-box
post-processing
fairness
classifica
tion
proceedings
2019
aaai
acm
conference
ai
ethics
society
association
computing
machinery
new
york
aies
19
pp
247
254
https://doi.org/10.1145/3306618.3314287
kim
js
chen
talwalkar
2020
fact
diagnostic
group
fairness
trade-offs
iii
hd
singh
eds
proceedings
37th
international
conference
machine
learning
pmlr
virtual
proceed
ings
machine
learning
research
vol
119
pp
5264
5274
http://proceedings.mlr.press/v119/kim20a.
html
kim
bryant
srikanth
howard
2021
age
bias
emotion
detection
analysis
facial
emotion
recognition
performance
young
middle-aged
older
adults
association
computing
machinery
new
york
pp
638
644
https://doi.org/10.1145/3461702.3462609
kiritchenko
mohammad
2018
examining
gender
race
bias
two
hundred
sentiment
analysis
systems
proceedings
seventh
joint
conference
lexical
computational
semantics
123
algorithmic
fairness
datasets
story
far
2135
association
computational
linguistics
new
orleans
pp
43
53
https://doi.org/10.18653/v1/s18-
2005
https://aclanthology.org/s18-2005
kizhner
terras
rumyantsev
khokhlova
demeshkova
rudov
afanasieva
2020
digital
cultural
colonialism
measuring
bias
aggregated
digitized
content
held
google
arts
culture
digital
scholarship
humanities
36
607
640
https://doi.org/10.1093/llc/fqaa055,
https
academic
oup
com
dsh
article-pdf
36
607
40873280
fqaa055
pdf
klare
bf
klein
taborsky
blanton
cheney
allen
grother
mah
jain
ak
2015
pushing
frontiers
unconstrained
face
detection
recognition
iarpa
janus
benchmark
proceedings
ieee
conference
computer
vision
pattern
recognition
cvpr
kleindessner
awasthi
morgenstern
2019a
fair
k-center
clustering
data
summarization
chaudhuri
salakhutdinov
eds
proceedings
36th
international
conference
machine
learning
pmlr
long
beach
california
usa
proceedings
machine
learning
research
vol
97
pp
3448
3457
http://proceedings.mlr.press/v97/kleindessner19a.html
kleindessner
samadi
awasthi
morgenstern
2019b
guarantees
spectral
clustering
fairness
constraints
chaudhuri
salakhutdinov
eds
proceedings
36th
international
conference
machine
learning
pmlr
long
beach
proceedings
machine
learning
research
vol
97
pp
3458
3467
http://proceedings.mlr.press/v97/kleindessner19b.html
knees
hübler
2019
towards
uncovering
dataset
biases
investigating
record
label
diversity
music
playlists
ismir
2019
workshop
workshop
designing
human-centric
mir
systems
kobren
saha
mccallum
2019
paper
matching
local
fairness
constraints
proceedings
25th
acm
sigkdd
international
conference
knowledge
discovery
data
mining
association
computing
machinery
new
york
kdd
19
pp
1247
1257
https://doi.org/10.1145/3292500.
3330899
kocijan
camburu
om
lukasiewicz
2020
gap
gap
tackling
problem
differing
data
distributions
bias-measuring
datasets
neurips
2020
workshop
algorithmic
fairness
lens
causality
interpretability
afci
arxiv
2011.01837
kohavi
1996
scaling
accuracy
naive-bayes
classifiers
decision-tree
hybrid
proceedings
second
international
conference
knowledge
discovery
data
mining
aaai
press
kdd
96
pp
202
207
komiyama
takeda
honda
shimao
2018
nonconvex
optimization
regression
fairness
constraints
dy
krause
eds
proceedings
35th
international
conference
machine
learning
pmlr
stockholmsmässan
stockholm
sweden
proceedings
machine
learning
research
vol
80
pp
2737
2746
http://proceedings.mlr.press/v80/komiyama18a.html
konstantakis
promponas
dretakis
papadakos
2020
bias
goggles
exploring
bias
web
domains
eyes
users
boratto
faralli
marras
stilo
eds
bias
social
aspects
search
recommendation
springer
cham
pp
66
71
koolen
2018
reading
beyond
female
relationship
perception
author
gender
literary
quality
phd
thesis
university
amsterdam
koolen
van
cranenburgh
2017
stereotypes
looking
bias
fairness
authorial
gender
attribution
proceedings
first
acl
workshop
ethics
natural
language
processing
association
computational
linguistics
valencia
pp
12
22
https://doi.org/10.18653/
v1
w17-1602
https://www.aclweb.org/anthology/w17-1602
krizhevsky
2009
learning
multiple
layers
features
tiny
images
kröger
jl
miceli
müller
2021
data
can
used
people
classification
personal
data
misuses
available
ssrn
3887097
kuhlman
rundensteiner
2020
rank
aggregation
algorithms
fair
consensus
proc
vldb
endow
13
12
2706
2719
https://doi.org/10.14778/3407790.3407855
kuhlman
gerych
rundensteiner
2021
measuring
group
advantage
comparative
study
fair
ranking
metrics
proceedings
2021
aaai
acm
conference
ai
ethics
society
association
computing
machinery
new
york
aies
21
pp
674
682
https://doi.org/10.1145/
3461702.3462588
kulshrestha
eslami
messias
zafar
mb
ghosh
gummadi
kp
karahalios
2017
quantifying
search
bias
investigating
sources
bias
political
searches
social
media
proceedings
2017
acm
conference
computer
supported
cooperative
work
social
computing
association
computing
machinery
new
york
cscw
17
pp
417
432
https://doi.org/10.1145/2998181.
2998321
123
2136
fabris
et
al
kushmerick
1999
learning
remove
internet
advertisements
proceedings
third
annual
conference
autonomous
agents
association
computing
machinery
new
york
agents
99
pp
175
181
https://doi.org/10.1145/301136.301186,
kusner
mj
loftus
russell
silva
2017
counterfactual
fairness
guyon
luxburg
uv
bengio
wallach
fergus
vishwanathan
garnett
eds
advances
neural
information
processing
systems
vol
30
curran
associates
inc
pp
4066
4076
https://proceedings.neurips.cc/paper/2017/
file
a486cd07e4ac3d270571622f4f316ec5-paper
pdf
kuznetsova
rom
alldrin
uijlings
krasin
pont-tuset
kamali
popov
malloci
kolesnikov
et
al
2020
open
images
dataset
v4
int
comput
vis
128
1956
1981
kügelgen
jv
karimi
ah
bhatt
valera
weller
schölkopf
2021
fairness
causal
algorithmic
recourse
neurips
2020
workshop
algorithmic
fairness
lens
causality
interpretability
afci
arxiv
2010.06529
lahoti
beutel
chen
lee
prost
thain
wang
chi
2020
fairness
without
demographics
adversarially
reweighted
learning
larochelle
ranzato
hadsell
balcan
mf
lin
eds
advances
neural
information
processing
systems
vol
33
curran
associates
inc
pp
728
740
https://proceedings.neurips.cc/paper/2020/file/07fc15c9d169ee48573edd749d25945d-paper.pdf
lake
bm
salakhutdinov
tenenbaum
jb
2015
human-level
concept
learning
probabilistic
program
induction
science
350
6266
1332
1338
https://doi.org/10.1126/science.aab3050
lamy
zhong
menon
ak
verma
2019
noise-tolerant
fair
classification
wallach
larochelle
beygelzimer
alché-buc
fox
garnett
eds
advances
neural
information
processing
systems
vol
32
curran
associates
inc
pp
294
306
https://proceedings.neurips.cc/paper/2019/file/
8d5e957f297893487bd98fa830fa6413-paper
pdf
lan
huan
2017
discriminatory
transfer
kdd
2017
workshop
fairness
accountability
trans
parency
machine
learning
fat
ml
arxiv
1707.00780
larson
mattu
kirchner
angwin
2016
analyzed
compas
recidivism
algorithm
https
www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm
le
quy
roy
iosifidis
zhang
ntoutsi
2022
survey
datasets
fairness-aware
machine
learning
wires
data
mining
knowledge
discovery
e1452
https://doi.org/10.1002/
widm
1452
https://wires.onlinelibrary.wiley.com/doi/abs/10.1002/widm.1452
leavy
meaney
wade
greene
2019
curatr
platform
semantic
analysis
curation
historical
literary
texts
pp
354
366
https://doi.org/10.1007/978-3-030-36599-8_31
leavy
meaney
wade
greene
2020
mitigating
gender
bias
machine
learning
data
sets
boratto
faralli
marras
stilo
eds
bias
social
aspects
search
recommendation
springer
cham
pp
12
26
lecun
bottou
bengio
haffner
1998
gradient-based
learning
applied
document
recognition
proc
ieee
86
11
2278
2324
https://doi.org/10.1109/5.726791
lecun
fu
jie
huang
bottou
2004
learning
methods
generic
object
recognition
invariance
pose
lighting
proceedings
2004
ieee
computer
society
conference
computer
vision
pattern
recognition
2004
cvpr
2004
vol
pp
ii
104
https://doi.org/10.1109/cvpr.
2004.1315150
lee
kizilcec
rf
2020
evaluation
fairness
trade-offs
predicting
student
success
interna
tional
conference
educational
data
mining
workshop
fairness
accountability
transparency
educational
data
mining
arxiv
2007.00088
leonelli
tempini
2020
data
journeys
sciences
springer
berlin
leskovec
mcauley
2012
learning
discover
social
circles
ego
networks
pereira
burges
cjc
bottou
weinberger
kq
eds
advances
neural
information
pro
cessing
systems
vol
25
curran
associates
inc
https://proceedings.neurips.cc/paper/2012/file/
7a614fd06c325499f1680b9896beedeb-paper
pdf
leskovec
kleinberg
faloutsos
2007
graph
evolution
densification
shrinking
diameters
acm
trans
knowl
discov
data
tkdd
lesmana
ns
zhang
bei
2019
balancing
efficiency
fairness
on-demand
ridesourcing
wallach
larochelle
beygelzimer
alché-buc
fox
garnett
eds
advances
neural
information
processing
systems
vol
32
curran
associates
inc
pp
5309
5319
https://proceedings.
neurips
cc
paper
2019
file
3070e6addcd702cb58de5d7897bfdae1-paper
pdf
levy
splansky
gl
strand
nk
atwood
ld
benjamin
ej
blease
cupples
la
agostino
rb
sr
fox
cs
kelly-hayes
et
al
2010
consent
genetic
research
framingham
heart
study
med
genet
152
1250
1256
123
algorithmic
fairness
datasets
story
far
2137
li
zhao
liu
huang
mei
chen
2018
learning
history
present
next-item
recommendation
via
discriminatively
exploiting
user
behaviors
proceedings
24th
acm
sigkdd
international
conference
knowledge
discovery
data
mining
association
com
puting
machinery
new
york
kdd
18
pp
1734
1743
https://doi.org/10.1145/3219819.3220014
li
zhao
liu
2020a
deep
fair
clustering
visual
learning
ieee
cvf
conference
computer
vision
pattern
recognition
cvpr
li
sanjabi
beirami
smith
2020b
fair
resource
allocation
federated
learning
international
conference
learning
representations
https://openreview.net/forum?id=byexelsydr
li
ning
liu
wu
hui
wang
2020c
fairness
classification
using
users
social
relationships
online
peer-to-peer
lending
companion
proceedings
web
conference
2020
association
computing
machinery
new
york
www
20
pp
733
742
https://doi.org/10.1145/3366424.
3383557
li
sun
wang
wh
2020d
towards
fair
truth
discovery
biased
crowdsourced
answers
association
computing
machinery
new
york
pp
599
607
https://doi.org/10.1145/3394486.3403102
li
wang
zhao
hong
liu
2021
dyadic
fairness
exploring
mitigating
bias
graph
connections
international
conference
learning
representations
https://openreview.net/forum?
id
xggs6pmznq6
liang
acuna
de
2020
artificial
mental
phenomena
psychophysics
framework
detect
per
ception
biases
ai
models
proceedings
2020
conference
fairness
accountability
transparency
association
computing
machinery
new
york
fat
20
pp
403
412
https://doi.
org
10.1145
3351095.3375623
lin
ty
maire
belongie
hays
perona
ramanan
dollár
zitnick
cl
2014
microsoft
coco
common
objects
context
fleet
pajdla
schiele
tuytelaars
eds
computer
vision-eccv
2014
springer
cham
pp
740
755
lipton
mcauley
chouldechova
2018
mitigating
ml
impact
disparity
require
treatment
dis
parity
bengio
wallach
larochelle
grauman
cesa-bianchi
garnett
eds
advances
neural
information
processing
systems
vol
31
curran
associates
inc
https://proceedings.neurips.
cc
paper
2018
file
8e0384779e58ce2af40eb365b318cc32-paper
pdf
liu
burke
2018
personalizing
fairness-aware
re-ranking
recsys
2018
workshop
workshop
responsible
recommendation
fat
rec
arxiv
1809.02921
liu
luo
wang
tang
2015
deep
learning
face
attributes
wild
arxiv
1411.7766
liu
lt
dean
rolf
simchowitz
hardt
2018
delayed
impact
fair
machine
learning
dy
krause
eds
proceedings
35th
international
conference
machine
learning
pmlr
stockholmsmässan
stockholm
sweden
proceedings
machine
learning
research
vol
80
pp
3150
3158
http://proceedings.mlr.press/v80/liu18c.html
liu
lt
simchowitz
hardt
2019
implicit
fairness
criterion
unconstrained
learning
chaudhuri
salakhutdinov
eds
proceedings
36th
international
conference
machine
learning
pmlr
long
beach
proceedings
machine
learning
research
vol
97
pp
4051
4060
http://proceedings.mlr.press/v97/liu19f.html
liu
lt
wilson
haghtalab
kalai
borgs
chayes
2020
disparate
equilibria
algorithmic
decision
making
individuals
invest
rationally
proceedings
2020
conference
fairness
accountability
transparency
association
computing
machinery
new
york
fat
20
pp
381
391
https://doi.org/10.1145/3351095.3372861
liu
shafi
fleisher
eliassi-rad
alfeld
2021
rawlsnet
altering
bayesian
networks
encode
rawlsian
fair
equality
opportunity
association
computing
machinery
new
york
pp
745
755
https://doi.org/10.1145/3461702.3462618
locatello
abbati
rainforth
bauer
schölkopf
bachem
2019
fairness
disentangled
representations
wallach
larochelle
beygelzimer
alché-buc
fox
garnett
eds
advances
neural
information
processing
systems
vol
32
curran
associates
inc
pp
14611
14624
https://proceedings.neurips.cc/paper/2019/file/1b486d7a5189ebe8d8c46afc64b0d1b4-paper.pdf
lohaus
perrot
luxburg
uv
2020
relaxed
fair
iii
hd
singh
eds
proceedings
37th
international
conference
machine
learning
pmlr
virtual
proceedings
machine
learning
research
vol
119
pp
6360
6369
http://proceedings.mlr.press/v119/lohaus20a.html
louizos
swersky
li
welling
zemel
rs
2016
variational
fair
autoencoder
bengio
lecun
eds
4th
international
conference
learning
representations
iclr
2016
san
juan
puerto
rico
may
2016
conference
track
proceedings
arxiv
1511.00830
123
2138
fabris
et
al
lowe
ferris
ta
hernandez
weber
2009
stride
integrated
standards-based
translational
research
informatics
platform
amia
ann
sympos
proc
amia
sympos
2009
391
lu
getoor
2003
link-based
classification
proceedings
twentieth
international
conference
international
conference
machine
learning
aaai
press
icml
03
pp
496
503
lum
johndrow
2016
statistical
framework
fair
predictive
algorithms
dtl
2016
workshop
fairness
accountability
transparency
machine
learning
fat
ml
arxiv
1610.08077
lum
boudin
price
2020
impact
overbooking
pre-trial
risk
assessment
tool
proceedings
2020
conference
fairness
accountability
transparency
association
computing
machinery
new
york
fat
20
pp
482
491
https://doi.org/10.1145/3351095.3372846,
luong
bt
ruggieri
turini
2016
classification
rule
mining
supported
ontology
discrimination
discovery
2016
ieee
16th
international
conference
data
mining
workshops
icdmw
pp
868
875
https://doi.org/10.1109/icdmw.2016.0128
maas
al
daly
re
pham
pt
huang
ng
ay
potts
2011
learning
word
vectors
sentiment
analysis
proceedings
49th
annual
meeting
association
computational
linguistics
human
language
technologies
association
computational
linguistics
portland
pp
142
150
https
www.aclweb.org/anthology/p11-1015
madnani
loukina
von
davier
burstein
cahill
2017
building
better
open-source
tools
support
fairness
automated
scoring
proceedings
first
acl
workshop
ethics
natural
language
processing
association
computational
linguistics
valencia
pp
41
52
https://doi.org/
10.18653
v1
w17-1605
https://www.aclweb.org/anthology/w17-1605
madras
creager
pitassi
zemel
2018a
learning
adversarially
fair
transferable
representations
dy
krause
eds
proceedings
35th
international
conference
machine
learning
pmlr
stockholmsmässan
proceedings
machine
learning
research
vol
80
pp
3384
3393
http
proceedings
mlr
press
v80
madras18a
html
madras
pitassi
zemel
2018b
predict
responsibly
improving
fairness
accuracy
learning
defer
bengio
wallach
larochelle
grauman
cesa-bianchi
garnett
eds
advances
neural
information
processing
systems
vol
31
curran
associates
inc
pp
6147
6157
https
proceedings
neurips
cc
paper
2018
file
09d37c08f7b129e96277388757530c72-paper
pdf
madras
creager
pitassi
zemel
2019
fairness
causal
awareness
learning
causal
latent
variable
models
biased
data
proceedings
conference
fairness
accountability
transparency
association
computing
machinery
new
york
fat
19
pp
349
358
https://doi.
org
10.1145
3287560.3287564
mahabadi
vakilian
2020
individual
fairness
k-clustering
iii
hd
singh
eds
proceedings
37th
international
conference
machine
learning
pmlr
virtual
proceedings
machine
learning
research
vol
119
pp
6586
6596
http://proceedings.mlr.press/v119/mahabadi20a.html
maity
xue
yurochkin
sun
2021
statistical
inference
individual
fairness
international
conference
learning
representations
https://openreview.net/forum?id=z9k8bwl-_2u
mandal
deng
jana
wing
jm
hsu
dj
2020
ensuring
fairness
beyond
training
data
larochelle
ranzato
hadsell
balcan
lin
eds
advances
neural
infor
mation
processing
systems
33
annual
conference
neural
information
processing
systems
2020
neurips
2020
december
12
2020
virtual
https://proceedings.neurips.cc/paper/2020/hash/
d6539d3b57159bab6a72e106beb45bd-abstract
html
manjunatha
saini
davis
ls
2019
explicit
bias
discovery
visual
question
answering
models
proceedings
ieee
cvf
conference
computer
vision
pattern
recognition
cvpr
martinez
bertran
sapiro
2020
minimax
pareto
fairness
multi
objective
perspective
iii
hd
singh
eds
proceedings
37th
international
conference
machine
learning
pmlr
virtual
proceedings
machine
learning
research
vol
119
pp
6755
6764
http://proceedings.mlr.press/v119/
martinez20a
html
mary
calauzènes
karoui
ne
2019
fairness-aware
learning
continuous
attributes
treatments
chaudhuri
salakhutdinov
eds
proceedings
36th
international
conference
machine
learning
pmlr
long
beach
proceedings
machine
learning
research
vol
97
pp
4382
4391
http
proceedings
mlr
press
v97
mary19a
html
mastrandrea
fournet
barrat
2015
contact
patterns
high
school
comparison
data
collected
using
wearable
sensors
contact
diaries
friendship
surveys
plos
one
10
e0136497
https://doi.org/10.1371/journal.pone.0136497
123
algorithmic
fairness
datasets
story
far
2139
mattei
saffidine
walsh
2018a
axiomatic
empirical
analysis
mechanisms
online
organ
matching
proceedings
7th
international
workshop
computational
social
choice
comsoc
mattei
saffidine
walsh
2018b
fairness
deceased
organ
matching
proceedings
2018
aaai
acm
conference
ai
ethics
society
association
computing
machinery
new
york
aies
18
pp
236
242
https://doi.org/10.1145/3278721.3278749
mayson
sg
2018
bias
bias
yale
lj
128
2218
mcauley
targett
shi
van
den
hengel
2015
image-based
recommendations
styles
substi
tutes
proceedings
38th
international
acm
sigir
conference
research
development
information
retrieval
association
computing
machinery
new
york
sigir
15
pp
43
52
https://doi.org/10.1145/2766462.2767755,
mccallum
ak
nigam
rennie
seymore
2000
automating
construction
internet
portals
machine
learning
inf
retr
127
163
mcduff
ma
song
kapoor
2019
characterizing
bias
classifiers
using
generative
models
wallach
larochelle
beygelzimer
alché-buc
fox
garnett
eds
advances
neural
information
processing
systems
vol
32
curran
associates
inc
pp
5403
5414
https://proceedings.
neurips
cc
paper
2019
file
7f018eb7b301a66658931cb8a93fd6e8-paper
pdf
mcfee
bertin-mahieux
ellis
dp
lanckriet
gr
2012
million
song
dataset
challenge
proceed
ings
21st
international
conference
world
wide
web
association
computing
machinery
new
york
www
12
companion
pp
909
916
https://doi.org/10.1145/2187980.2188222
mckenna
2019a
history
current
population
survey
disclosure
avoidance
https://www2.
census
gov
adrm
ced
papers
fy20
2019
04
mckenna-cps
20and
20da
pdf
mckenna
2019b
history
us
census
bureau
disclosure
review
board
https://www2.census.
gov
adrm
ced
papers
fy20
2019
04
mckenna-drb
pdf
mcmahan
moore
ramage
hampson
arcas
ba
2017
communication-efficient
learning
deep
networks
decentralized
data
singh
zhu
eds
proceedings
20th
international
conference
artificial
intelligence
statistics
pmlr
fort
lauderdale
proceedings
machine
learning
research
vol
54
pp
1273
1282
http://proceedings.mlr.press/v54/mcmahan17a.html
mcnamara
2019
equalized
odds
implies
partially
equalized
outcomes
realistic
assumptions
proceedings
2019
aaai
acm
conference
ai
ethics
society
association
computing
machinery
new
york
aies
19
pp
313
320
https://doi.org/10.1145/3306618.3314290
meek
thiesson
heckerman
2002
learning-curve
sampling
method
applied
model-based
clustering
mach
learn
res
feb
397
418
mehrabi
morstatter
saxena
lerman
galstyan
2021
survey
bias
fairness
machine
learning
acm
comput
surv
https://doi.org/10.1145/3457607
mehrotra
celis
le
2021
mitigating
bias
set
selection
noisy
protected
attributes
proceedings
2021
acm
conference
fairness
accountability
transparency
association
computing
machinery
new
york
facct
21
pp
237
248
https://doi.org/10.1145/3442188.3445887
mehrotra
anderson
diaz
sharma
wallach
yilmaz
2017
auditing
search
engines
differential
satisfaction
across
demographics
proceedings
26th
international
conference
world
wide
web
companion
international
world
wide
web
conferences
steering
committee
republic
canton
geneva
che
www
17
companion
pp
626
633
https://doi.org/10.1145/3041021.
3054197
merkley
2019
use
fair
use
statement
shared
images
facial
recognition
ai
merler
ratha
feris
rs
smith
jr
2019
diversity
faces
arxiv
1901.10436
metevier
giguere
brockman
kobren
brun
brunskill
thomas
ps
2019
offline
con
textual
bandits
high
probability
fairness
guarantees
wallach
larochelle
beygelzimer
alché-buc
fox
garnett
eds
advances
neural
information
processing
systems
vol
32
curran
associates
inc
pp
14922
14933
https://proceedings.neurips.cc/paper/2019/file/
d69768b3da745b77e82cdbddcc8bac98-paper
pdf
mhasawade
chunara
2021
causal
multi-level
fairness
association
computing
machinery
new
york
pp
784
794
https://doi.org/10.1145/3461702.3462587
miao
2010
results
promotion
exams
disparate
impact
minorities
using
statistical
evidence
ricci
destefano
stat
educ
18
miceli
yang
naudts
schuessler
serbanescu
hanna
2021
documenting
computer
vision
datasets
invitation
reflexive
data
practices
proceedings
2021
acm
conference
123
2140
fabris
et
al
fairness
accountability
transparency
association
computing
machinery
new
york
facct
21
pp
161
172
miller
1998
introduction
resource
description
framework
d-lib
magazine
mirkin
nowson
brun
perez
2015
motivating
personality-aware
machine
translation
pro
ceedings
2015
conference
empirical
methods
natural
language
processing
association
computational
linguistics
lisbon
pp
1102
1108
https://doi.org/10.18653/v1/d15-1130,
https
www.aclweb.org/anthology/d15-1130
mishler
kennedy
eh
chouldechova
2021
fairness
risk
assessment
instruments
post-processing
achieve
counterfactual
equalized
odds
proceedings
2021
acm
conference
fairness
accountability
transparency
association
computing
machinery
new
york
facct
21
pp
386
400
https://doi.org/10.1145/3442188.3445902
mishra
belli
2020
assessing
demographic
bias
named
entity
recognition
akbc
2020
workshop
bias
automatic
knowledge
graph
construction
arxiv
2008.03415
mislove
viswanath
gummadi
kp
druschel
2010
know
inferring
user
profiles
online
social
networks
proceedings
third
acm
international
conference
web
search
data
mining
association
computing
machinery
new
york
wsdm
10
pp
251
260
https
doi
org
10.1145
1718487.1718519
moore
jc
stinson
ll
welniak
ej
2000
income
measurement
error
surveys
review
stat
16
331
362
moreland
herlihy
tynan
ma
sunshine
mccord
rf
hilton
poovey
werner
ak
jones
cd
fulmer
eb
et
al
2020
timing
state
territorial
covid-19
stay-at-home
orders
changes
population
movement-united
states
march
may
31
2020
morb
mortal
wkly
rep
69
35
1198
moro
cortez
rita
2014
data-driven
approach
predict
success
bank
telemarketing
decis
support
syst
62
22
31
mozannar
ohannessian
srebro
2020
fair
learning
private
demographic
data
iii
hd
singh
eds
proceedings
37th
international
conference
machine
learning
pmlr
virtual
proceedings
machine
learning
research
vol
119
pp
7066
7075
http://proceedings.mlr.press/v119/
mozannar20a
html
mukherjee
yurochkin
banerjee
sun
2020
two
simple
ways
learn
individual
fairness
metrics
data
iii
hd
singh
eds
proceedings
37th
international
conference
machine
learning
pmlr
virtual
proceedings
machine
learning
research
vol
119
pp
7097
7107
http
proceedings
mlr
press
v119
mukherjee20a
html
muller
lange
wang
piorkowski
tsay
liao
qv
dugan
erickson
2019
data
science
workers
work
data
discovery
capture
curation
design
creation
association
computing
machinery
new
york
pp
15
https://doi.org/10.1145/3290605.3300356
murgia
2019
microsoft
quietly
deletes
largest
public
face
recognition
data
set
https://www.ft.com/
content
7d3e0d6a-87a0-11e9-a028-86cea8523dc2
nabi
malinsky
shpitser
2019
learning
optimal
fair
policies
chaudhuri
salakhutdinov
eds
proceedings
36th
international
conference
machine
learning
pmlr
long
beach
proceedings
machine
learning
research
vol
97
pp
4674
4682
http://proceedings.mlr.press/v97/
nabi19a
html
namata
london
getoor
huang
edu
2012
query-driven
active
surveying
collective
classification
10th
international
workshop
mining
learning
graphs
vol
nanda
xu
sankararaman
ka
dickerson
jp
srinivasan
2020
balancing
tradeoff
profit
fairness
rideshare
platforms
high-demand
hours
proceedings
aaai
acm
conference
ai
ethics
society
association
computing
machinery
new
york
aies
20
pp
131
https://doi.org/10.1145/3375627.3375818
nanda
dooley
singla
feizi
dickerson
jp
2021
fairness
robustness
investigating
robustness
disparity
deep
learning
proceedings
2021
acm
conference
fairness
accountability
transparency
association
computing
machinery
new
york
facct
21
pp
466
477
https://doi.org/10.1145/3442188.3445910
narayanan
shmatikov
2008
robust
de-anonymization
large
sparse
datasets
2008
ieee
symposium
security
privacy
sp
2008
ieee
pp
111
125
nasr
tschantz
mc
2020
bidding
strategies
gender
nondiscrimination
constraints
online
ad
auctions
proceedings
2020
conference
fairness
accountability
transparency
association
computing
machinery
new
york
fat
20
pp
337
347
https://doi.org/10.1145/
3351095.3375783
123
algorithmic
fairness
datasets
story
far
2141
ngong
ic
maughan
near
jp
2020
towards
auditability
fairness
deep
learning
neurips
2020
workshop
algorithmic
fairness
lens
causality
interpretability
afci
arxiv
2012.00106
nlst
trial
research
team
2011
national
lung
screening
trial
overview
study
design
radiology
258
243
253
noriega-campero
bakker
ma
garcia-bulle
pentland
2019
active
fairness
algorithmic
decision
making
proceedings
2019
aaai
acm
conference
ai
ethics
society
asso
ciation
computing
machinery
new
york
aies
19
pp
77
83
https://doi.org/10.1145/3306618.
3314277
noriega-campero
garcia-bulle
cantu
lf
bakker
ma
tejerina
pentland
2020
algorithmic
targeting
social
policies
fairness
accuracy
distributed
governance
proceedings
2020
conference
fairness
accountability
transparency
association
computing
machinery
new
york
fat
20
pp
241
251
https://doi.org/10.1145/3351095.3375784
nuttall
dl
goldstein
prosser
rasbash
1989
differential
school
effectiveness
int
educ
res
13
769
776
https://doi.org/10.1016/0883-0355(89)90027-x
obermeyer
mullainathan
2019
dissecting
racial
bias
algorithm
guides
health
decisions
70
million
people
proceedings
conference
fairness
accountability
transparency
association
computing
machinery
new
york
fat
19
89
https://doi.org/10.1145/3287560.
3287593
ogura
takeda
2020
convex
fairness
constrained
model
using
causal
effect
estimators
companion
proceedings
web
conference
2020
association
computing
machinery
new
york
www
20
pp
723
732
https://doi.org/10.1145/3366424.3383556
olave
rajkovic
bohanec
1989
application
admission
public
school
systems
expert
syst
pub
admin
145
160
oneto
siri
luria
anguita
2017
dropout
prediction
university
genoa
privacy
preserving
data
driven
approach
esann
oneto
donini
elders
pontil
2019a
taking
advantage
multitask
learning
fair
classifica
tion
proceedings
2019
aaai
acm
conference
ai
ethics
society
association
computing
machinery
new
york
aies
19
pp
227
237
https://doi.org/10.1145/3306618.3314255
oneto
donini
maurer
pontil
2019b
learning
fair
transferable
representations
neurips
2019
workshop
human-centric
machine
learning
oneto
donini
luise
ciliberto
maurer
pontil
2020
exploiting
mmd
sinkhorn
divergences
fair
transferable
representation
learning
larochelle
ranzato
hadsell
balcan
lin
eds
advances
neural
information
processing
systems
33
annual
conference
neural
information
processing
systems
2020
neurips
2020
december
12
2020
virtual
https
proceedings
neurips
cc
paper
2020
hash
af9c0e0c1dee63e5cad8b7ed1a5be96-abstract
html
pandey
caliskan
2021
disparate
impact
artificial
intelligence
bias
ridehailing
economy
price
discrimination
algorithms
association
computing
machinery
new
york
pp
822
833
https
doi
org
10.1145
3461702.3462561
papakyriakopoulos
hegelich
serrano
jcm
marco
2020
bias
word
embeddings
proceedings
2020
conference
fairness
accountability
transparency
association
computing
machinery
new
york
fat
20
pp
446
457
https://doi.org/10.1145/3351095.3372843
paraschakis
nilsson
2020
matchmaking
fairness
constraints
speed
dating
case
study
ecir
2020
workshop
international
workshop
algorithmic
bias
search
recommendation
bias
2020
patro
gk
chakraborty
ganguly
gummadi
kp
2019
incremental
fairness
two-sided
market
plat
forms
smoothly
updating
recommendations
neurips
2019
workshop
human-centric
machine
learning
arxiv
1909.10005
paullada
raji
id
bender
em
denton
hanna
2020
data
dis
contents
survey
dataset
development
use
machine
learning
research
arxiv
2012.05345
pedreshi
ruggieri
turini
2008
discrimination-aware
data
mining
proceedings
14th
acm
sigkdd
international
conference
knowledge
discovery
data
mining
association
computing
machinery
new
york
kdd
08
pp
560
568
https://doi.org/10.1145/1401890.1401959
peng
mathur
narayanan
2021
mitigating
dataset
harms
requires
stewardship
lessons
1000
papers
arxiv
2108.02922
123
2142
fabris
et
al
perrone
donini
zafar
mb
schmucker
kenthapadi
archambeau
2021
fair
bayesian
optimization
association
computing
machinery
new
york
pp
854
863
https://doi.org/10.1145/
3461702.3462629
pessach
shmueli
2020
algorithmic
fairness
arxiv
2001.09784
peters
lecocq
2013
content
extraction
using
diverse
feature
sets
proceedings
22nd
international
conference
world
wide
web
pp
89
90
peters
neumann
iyyer
gardner
clark
lee
zettlemoyer
2018
deep
contextual
ized
word
representations
proceedings
2018
conference
north
american
chapter
association
computational
linguistics
human
language
technologies
vol
long
papers
association
computational
linguistics
new
orleans
pp
2227
2237
pfohl
marafino
coulet
rodriguez
palaniappan
shah
nh
2019
creating
fair
models
atherosclerotic
cardiovascular
disease
risk
proceedings
2019
aaai
acm
conference
ai
ethics
society
association
computing
machinery
new
york
aies
19
pp
271
278
https://doi.org/10.1145/3306618.3314278
pinard
2010
collateral
consequences
criminal
convictions
confronting
issues
race
dignity
nyul
rev
85
457
pitoura
stefanidis
koutrika
2021
fairness
rankings
recommendations
overview
vldb
28
pleiss
raghavan
wu
kleinberg
weinberger
kq
2017
fairness
calibration
guyon
luxburg
uv
bengio
wallach
fergus
vishwanathan
garnett
eds
advances
neural
information
processing
systems
vol
30
curran
associates
inc
pp
5680
5689
https://proceedings.
neurips
cc
paper
2017
file
b8b9c74ac526fffbeb2d39ab038d1cd7-paper
pdf
pont-tuset
uijlings
changpinyo
soricut
ferrari
2020
connecting
vision
language
localized
narratives
european
conference
computer
vision
springer
pp
647
664
prabhu
vu
birhane
2020
large
image
datasets
pyrrhic
win
computer
vision
arxiv
2006.16923
preot
iuc-pietro
ungar
2018
user-level
race
ethnicity
predictors
twitter
text
proceedings
27th
international
conference
computational
linguistics
association
computational
linguistics
santa
fe
pp
1534
1545
https://www.aclweb.org/anthology/c18-1130
propublica
2016
compas
analysis
github
repository
https://github.com/propublica/compas-analysis
propublica
2021
propublica
data
store
terms
https://www.propublica.org/datastore/terms
pujol
mckenna
kuppam
hay
machanavajjhala
miklau
2020
fair
decision
making
using
privacy-protected
data
proceedings
2020
conference
fairness
accountability
transparency
association
computing
machinery
new
york
fat
20
pp
189
199
https://doi.
org
10.1145
3351095.3372872
qian
cao
mouël
fl
sahel
li
2015
scram
sharing
considered
route
assignment
mechanism
fair
taxi
route
recommendations
proceedings
21th
acm
sigkdd
international
conference
knowledge
discovery
data
mining
association
computing
machinery
new
york
kdd
15
pp
955
964
https://doi.org/10.1145/2783258.2783261
qin
liu
ty
2013
introducing
letor
4.0
datasets
arxiv
1306.2597
quadrianto
sharmanska
2017
recycling
privileged
learning
distribution
matching
fair
ness
guyon
luxburg
uv
bengio
wallach
fergus
vishwanathan
garnett
eds
advances
neural
information
processing
systems
vol
30
curran
associates
inc
pp
677
688
https://proceedings.neurips.cc/paper/2017/file/250cf8b51c773f3f8dc8b4be867a9a02-paper.pdf
quadrianto
sharmanska
thomas
2019
discovering
fair
representations
data
domain
proceedings
ieee
cvf
conference
computer
vision
pattern
recognition
cvpr
radford
narasimhan
salimans
sutskever
2018
improving
language
understanding
generative
pre-training
radford
wu
child
luan
amodei
sutskever
2019
language
models
unsupervised
multitask
learners
radin
2017
digital
natives
medical
indigenous
histories
matter
big
data
osiris
32
43
64
raff
sylvester
2018
gradient
reversal
discrimination
icml
2018
workshop
fairness
accountability
transparency
machine
learning
fat
ml
arxiv
1807.00392
raff
sylvester
mills
2018
fair
forests
regularized
tree
induction
minimize
model
bias
proceedings
2018
aaai
acm
conference
ai
ethics
society
association
computing
machinery
new
york
aies
18
pp
243
250
https://doi.org/10.1145/3278721.3278742,
123
algorithmic
fairness
datasets
story
far
2143
rahmattalabi
vayanos
fulginiti
rice
wilder
yadav
tambe
2019
exploring
algo
rithmic
fairness
robust
graph
covering
problems
wallach
larochelle
beygelzimer
alché-buc
fox
garnett
eds
advances
neural
information
processing
systems
vol
32
curran
associates
inc
pp
15776
15787
https://proceedings.neurips.cc/paper/2019/file/
1d7c2aae840867027b7edd17b6aaa0e9-paper
pdf
raj
wood
montoly
ekstrand
md
2020
comparing
fair
ranking
metrics
recsys
2020
workshop
3rd
facctrec
workshop
responsible
recommendation
arxiv
2009.01311
raji
id
buolamwini
2019
actionable
auditing
investigating
impact
publicly
naming
biased
performance
results
commercial
ai
products
proceedings
2019
aaai
acm
conference
ai
ethics
society
association
computing
machinery
new
york
aies
19
pp
429
435
https://doi.org/10.1145/3306618.3314244
ramachandran
gs
brugere
varshney
lr
xiong
2021
gaea
graph
augmentation
equitable
access
via
reinforcement
learning
association
computing
machinery
new
york
pp
884
894
https://doi.org/10.1145/3461702.3462615
ramaswamy
vv
kim
ssy
russakovsky
2021
fair
attribute
classification
latent
space
de
biasing
proceedings
ieee
cvf
conference
computer
vision
pattern
recognition
cvpr
pp
9301
9310
red
kelsic
ed
mucha
pj
porter
ma
2011
comparing
community
structure
characteristics
online
collegiate
social
networks
siam
rev
53
526
543
redmond
baveja
2002
data-driven
software
tool
enabling
cooperative
information
sharing
among
police
departments
eur
oper
res
141
660
678
https://doi.org/10.1016/s0377-
2217
01
00264
redmond
cunningham
2013
temporal
network
analysis
reveals
unprofitability
arbitrage
prosper
marketplace
expert
syst
appl
40
3715
3721
https://doi.org/10.1016/j.eswa.2012.12.
077
reed
se
zhang
zhang
lee
2015
deep
visual
analogy-making
cortes
lawrence
lee
sugiyama
garnett
eds
advances
neural
information
processing
systems
vol
28
curran
associates
inc
pp
1252
1260
https://proceedings.neurips.cc/paper/2015/file/
e07413354875be01a996dc560274708e-paper
pdf
rezaei
liu
memarrast
ziebart
2021
robust
fairness
covariate
shift
neurips
2020
workshop
algorithmic
fairness
lens
causality
interpretability
afci
arxiv
2010.05166
riederer
chaintreau
2017
price
fairness
location
based
advertising
https://doi.org/10.
18122
b2md8c
recsys
2017
workshop
workshop
responsible
recommendation
fat
rec
rocher
hendrickx
jm
de
montjoye
ya
2019
estimating
success
re-identifications
incomplete
datasets
using
generative
models
nat
commun
10
rodolfa
kt
salomon
haynes
mendieta
ih
larson
ghani
2020
case
study
predictive
fairness
reduce
misdemeanor
recidivism
social
service
interventions
proceedings
2020
conference
fairness
accountability
transparency
association
computing
machinery
new
york
fat
20
pp
142
153
https://doi.org/10.1145/3351095.3372863
roh
lee
whang
suh
2020
fr-train
mutual
information-based
approach
fair
robust
training
iii
hd
singh
eds
proceedings
37th
international
conference
machine
learning
pmlr
virtual
proceedings
machine
learning
research
vol
119
pp
8147
8157
http
proceedings
mlr
press
v119
roh20a
html
roh
lee
whang
se
suh
2021
fairbatch
batch
selection
model
fairness
international
conference
learning
representations
https://openreview.net/forum?id=ynnpaakecfx
romano
bates
candes
2020
achieving
equalized
odds
resampling
sensitive
attributes
larochelle
ranzato
hadsell
balcan
mf
lin
eds
advances
neural
information
pro
cessing
systems
vol
33
curran
associates
inc
pp
361
371
https://proceedings.neurips.cc/paper/
2020
file
03593ce517feac573fdaafa6dcedef61-paper
pdf
romei
ruggieri
2014
multidisciplinary
survey
discrimination
analysis
knowl
eng
rev
29
582
638
https://doi.org/10.1017/s0269888913000039
rotemberg
kurtansky
betz-stablein
caffery
chousakos
codella
combalia
dusza
guitera
gutman
et
al
2021
patient-centric
dataset
images
metadata
identifying
melanomas
using
clinical
context
sci
data
rozemberczki
allen
sarkar
2021
multi-scale
attributed
node
embedding
complex
netw
cnab014
123
2144
fabris
et
al
rudinger
may
van
durme
2017
social
bias
elicited
natural
language
inferences
proceedings
first
acl
workshop
ethics
natural
language
processing
association
computational
lin
guistics
pp
74
79
https://doi.org/10.18653/v1/w17-1609,
https://www.aclweb.org/anthology/w17-
1609
rudinger
naradowsky
leonard
van
durme
2018
gender
bias
coreference
resolution
proceedings
2018
conference
north
american
chapter
association
computational
linguistics
human
language
technologies
volume
short
papers
association
computational
linguistics
new
orleans
pp
14
https://doi.org/10.18653/v1/n18-2002,
https://www.aclweb.org/
anthology
n18-2002
ruoss
balunovic
fischer
vechev
2020
learning
certified
individually
fair
representations
larochelle
ranzato
hadsell
balcan
mf
lin
eds
advances
neural
information
processing
systems
vol
33
curran
associates
inc
pp
7584
7596
https://proceedings.neurips.cc/
paper
2020
file
55d491cf951b1b920900684d71419282-paper
pdf
russell
kusner
mj
loftus
silva
2017
worlds
collide
integrating
different
coun
terfactual
assumptions
fairness
guyon
luxburg
uv
bengio
wallach
fer
gus
vishwanathan
garnett
eds
advances
neural
information
processing
systems
vol
30
curran
associates
inc
pp
6414
6423
https://proceedings.neurips.cc/paper/2017/file/
1271a7029c9df08643b631b02cf9e116-paper
pdf
sabato
yom-tov
2020
bounding
fairness
accuracy
classifiers
population
statistics
iii
hd
singh
eds
proceedings
37th
international
conference
machine
learning
pmlr
virtual
proceedings
machine
learning
research
vol
119
pp
8316
8325
http://proceedings.mlr.
press
v119
sabato20a
html
saenko
kulis
fritz
darrell
2010
adapting
visual
category
models
new
domains
pro
ceedings
11th
european
conference
computer
vision
part
iv
springer
berlin
heidelberg
eccv
10
pp
213
226
sagawa
koh
pw
hashimoto
tb
liang
2020
distributionally
robust
neural
networks
international
conference
learning
representations
https://openreview.net/forum?id=ryxgujrfvs
samadi
tantipongpipat
morgenstern
jh
singh
vempala
2018
price
fair
pca
one
extra
dimension
bengio
wallach
larochelle
grauman
cesa-bianchi
garnett
eds
advances
neural
information
processing
systems
vol
31
curran
associates
inc
pp
10976
10987
https://proceedings.neurips.cc/paper/2018/file/cc4af25fa9d2d5c953496579b75f6f6c-paper.pdf
savani
white
govindarajulu
ns
2020
intra-processing
methods
debiasing
neural
net
works
larochelle
ranzato
hadsell
balcan
lin
eds
advances
neural
information
processing
systems
33
annual
conference
neural
information
processing
systems
2020
neurips
2020
december
12
2020
virtual
https://proceedings.neurips.cc/paper/2020/hash/
1d8d70dddf147d2d92a634817f01b239-abstract
html
scheuerman
mk
wade
lustig
brubaker
jr
2020
ve
taught
algorithms
see
identity
constructing
race
gender
image
databases
facial
analysis
proceedings
acm
human
computer
interaction
cscw1
https://doi.org/10.1145/3392866
schumann
ricco
prabhu
ferrari
pantofaru
2021
step
toward
inclusive
people
annotations
fairness
association
computing
machinery
new
york
pp
916
925
https://doi.
org
10.1145
3461702.3462594
schutzman
2020
trade-offs
fair
redistricting
proceedings
aaai
acm
conference
ai
ethics
society
association
computing
machinery
new
york
aies
20
pp
159
165
https
doi
org
10.1145
3375627.3375802
segal
adi
pinkas
baum
ganesh
keshet
2021
fairness
eyes
data
certifying
machine-learning
models
association
computing
machinery
new
york
pp
926
935
https://doi.
org
10.1145
3461702.3462554
sen
namata
bilgic
getoor
galligher
eliassi-rad
2008
collective
classification
network
data
ai
mag
29
93
93
shah
gupta
deshpande
bhattacharyya
2021
rawlsian
fair
adaptation
deep
learning
classifiers
association
computing
machinery
new
york
pp
936
945
https://doi.org/10.1145/3461702.
3462592
shang
sun
lam
ns
2020
list-wise
fairness
criterion
point
processes
association
computing
machinery
new
york
pp
1948
1958
https://doi.org/10.1145/3394486.3403246
sharifi-malvajerdi
kearns
roth
2019
average
individual
fairness
algorithms
generalization
experiments
wallach
larochelle
beygelzimer
alché-buc
fox
garnett
eds
123
algorithmic
fairness
datasets
story
far
2145
advances
neural
information
processing
systems
vol
32
curran
associates
inc
pp
8242
8251
https://proceedings.neurips.cc/paper/2019/file/0e1feae55e360ff05fef58199b3fa521-paper.pdf
sharma
henderson
ghosh
2020a
certifai
common
framework
provide
explanations
analyse
fairness
robustness
black-box
models
proceedings
aaai
acm
conference
ai
ethics
society
association
computing
machinery
new
york
aies
20
pp
166
172
https://doi.org/10.1145/3375627.3375812
sharma
zhang
ríos
aliaga
jm
bouneffouf
muthusamy
varshney
kr
2020b
data
augmentation
discrimination
prevention
bias
disambiguation
proceedings
aaai
acm
conference
ai
ethics
society
association
computing
machinery
new
york
aies
20
pp
358
364
https://doi.org/10.1145/3375627.3375865
sharma
gee
ah
paydarfar
ghosh
2021
fair-n
fair
robust
neural
networks
structured
data
association
computing
machinery
new
york
pp
946
955
https://doi.org/10.1145/3461702.
3462559
shekhar
shah
akoglu
2021
fairod
fairness-aware
outlier
detection
proceedings
2021
aaai
acm
conference
ai
ethics
society
association
computing
machinery
new
york
aies
21
pp
210
220
https://doi.org/10.1145/3461702.3462517
shen
jh
fratamico
rahwan
rush
2018
darling
babygirl
investigating
stylistic
bias
senti
ment
analysis
kdd
2018
workshop
fairness
accountability
transparency
machine
learning
fat
ml
shermis
md
2014
state-of-the-art
automated
essay
scoring
competition
results
future
directions
united
states
demonstration
assess
writ
20
53
76
https://doi.org/10.1016/j.asw.2013.04.001
singh
joachims
2018
fairness
exposure
rankings
proceedings
24th
acm
sigkdd
international
conference
knowledge
discovery
data
mining
association
computing
machin
ery
new
york
kdd
18
pp
2219
2228
https://doi.org/10.1145/3219819.3220088
singh
joachims
2019
policy
learning
fairness
ranking
wallach
larochelle
beygelzimer
alché-buc
fox
garnett
eds
advances
neural
information
process
ing
systems
vol
32
curran
associates
inc
pp
5426
5436
https://proceedings.neurips.cc/paper/
2019
file
9e82757e9a1c12cb710ad680db11f6f1-paper
pdf
singh
ramamurthy
kn
2019
understanding
racial
bias
health
using
medical
expenditure
panel
survey
data
neurips
2019
workshop
fair
ml
health
arxiv
1911.01509
singh
singh
mhasawade
chunara
2021
fairness
violations
mitigation
covariate
shift
proceedings
2021
acm
conference
fairness
accountability
transparency
association
computing
machinery
new
york
facct
21
pp
13
https://doi.org/10.1145/3442188.3445865
slack
friedler
givental
2019a
fair
meta-learning
learning
learn
fairly
https
drive
google
com
file
1f5yf1ar1hj7l2h7zisc35szxowquylvw
view
neurips
2019
workshop
human-centric
machine
learning
slack
friedler
givental
2019b
fairness
warnings
https://drive.google.com/file/d/
1eeu703ulwkehk0weepydwxg2kxswozc2
view
neurips
2019
workshop
human-centric
machine
learning
slack
friedler
sa
givental
2020
fairness
warnings
fair-maml
learning
fairly
minimal
data
proceedings
2020
conference
fairness
accountability
transparency
association
computing
machinery
new
york
fat
20
pp
200
209
https://doi.org/10.1145/3351095.3372839
slunge
2015
willingness
pay
vaccination
tick-borne
encephalitis
implications
public
health
policy
evidence
sweden
plos
one
10
12
e0143875
smith
jw
everhart
dickson
knowler
johannes
1988
using
adap
learning
algorithm
forecast
onset
diabetes
mellitus
proceedings
symposium
computer
applications
medical
care
pp
261
265
https://europepmc.org/articles/pmc2245318
solans
fabbri
calsamiglia
castillo
bonchi
2021
comparing
equity
effectiveness
dif
ferent
algorithms
application
room
rental
market
association
computing
machinery
new
york
pp
978
988
https://doi.org/10.1145/3461702.3462600
sonboli
burke
2019
localized
fairness
recommender
systems
adjunct
publication
27th
conference
user
modeling
adaptation
personalization
association
computing
machinery
new
york
umap
19
adjunct
pp
295
300
https://doi.org/10.1145/3314183.3323845
sonboli
burke
mattei
eskandanian
gao
2020
winner
dynamic
lotteries
multi-group
fairness-aware
recommendation
recsys
2020
workshop
3rd
facctrec
workshop
responsible
recommendation
arxiv
2009.02590
123
2146
fabris
et
al
speakman
sridharan
markus
2018
three
population
covariate
shift
mobile
phone-based
credit
scoring
proceedings
1st
acm
sigcas
conference
computing
sustainable
societies
association
computing
machinery
new
york
ny
usa
compass
18
speicher
ali
venkatadri
ribeiro
fn
arvanitakis
benevenuto
gummadi
kp
loiseau
mislove
2018a
potential
discrimination
online
targeted
advertising
friedler
sa
wilson
eds
proceedings
1st
conference
fairness
accountability
transparency
pmlr
new
york
proceedings
machine
learning
research
vol
81
pp
19
http://proceedings.mlr.press/v81/
speicher18a
html
speicher
heidari
grgic-hlaca
gummadi
kp
singla
weller
zafar
mb
2018b
uni
fied
approach
quantifying
algorithmic
unfairness
measuring
individual
group
unfairness
via
inequality
indices
proceedings
24th
acm
sigkdd
international
conference
knowl
edge
discovery
anddata
mining
association
computing
machinery
new
york
kdd
18
pp
2239
2248
https://doi.org/10.1145/3219819.3220046
squire
rf
2019
measuring
correcting
sampling
bias
safegraph
patterns
accurate
demographic
analysis
https://www.safegraph.com/blog/measuring-and-correcting-sampling-
bias-for-accurate-demographic-analysis
utm_source
content
utm_medium
referral
utm_
campaign
colabnotebook
utm_content
panel_bias
stanovsky
smith
na
zettlemoyer
2019
evaluating
gender
bias
machine
translation
pro
ceedings
57th
annual
meeting
association
computational
linguistics
association
computational
linguistics
florence
pp
1679
1684
https://doi.org/10.18653/v1/p19-1164,
https
aclanthology
org
p19-1164
steed
caliskan
2021
image
representations
learned
unsupervised
pre-training
contain
human
like
biases
proceedings
2021
acm
conference
fairness
accountability
transparency
association
computing
machinery
new
york
facct
21
pp
701
713
https://doi.org/10.1145/
3442188.3445932
strack
deshazo
gennings
olmo
ortiz
jl
ventura
cios
clore
2014
impact
hba1c
mea
surement
hospital
readmission
rates
analysis
70
000
clinical
database
patient
records
biomed
res
int
2014
781670
https://doi.org/10.1155/2014/781670
sühr
biega
aj
zehlike
gummadi
kp
chakraborty
2019
two-sided
fairness
repeated
match
ings
two-sided
markets
case
study
ride-hailing
platform
proceedings
25th
acm
sigkdd
international
conference
knowledge
discovery
data
mining
association
com
puting
machinery
new
york
kdd
19
pp
3082
3092
https://doi.org/10.1145/3292500.3330793
sühr
hilgard
lakkaraju
2021
fair
ranking
improve
minority
outcomes
understanding
interplay
human
algorithmic
biases
online
hiring
association
computing
machinery
new
york
pp
989
999
https://doi.org/10.1145/3461702.3462602
sun
han
gao
yu
2009
itopicmodel
information
network-integrated
topic
modeling
2009
ninth
ieee
international
conference
data
mining
pp
493
502
https://doi.org/10.1109/icdm.
2009.43
sun
gaut
tang
huang
elsherief
zhao
mirza
belding
chang
kw
wang
wy
2019
mitigating
gender
bias
natural
language
processing
literature
review
proceedings
57th
annual
meeting
association
computational
linguistics
association
computational
lin
guistics
florence
pp
1630
1640
https://doi.org/10.18653/v1/p19-1159,
https://aclanthology.org/
p19-1159
swinger
de-arteaga
heffernan
iv
nt
leiserson
md
kalai
2019
biases
word
embedding
proceedings
2019
aaai
acm
conference
ai
ethics
society
association
computing
machinery
new
york
aies
19
pp
305
311
https://doi.org/10.1145/
3306618.3314270
takac
zabovsky
2012
data
analysis
public
social
networks
international
scientific
conference
international
workshop
present
day
trends
innovations
vol
tan
yc
celis
le
2019
assessing
social
intersectional
biases
contextualized
word
representations
wallach
larochelle
beygelzimer
alché-buc
fox
garnett
eds
advances
neural
information
processing
systems
vol
32
curran
associates
inc
pp
13230
13241
https
proceedings
neurips
cc
paper
2019
file
201d546992726352471cfea6b0df0a48-paper
pdf
tang
zhang
yao
li
zhang
su
2008
arnetminer
extraction
mining
academic
social
networks
pp
990
998
https://doi.org/10.1145/1401890.1402008
tantipongpipat
samadi
singh
morgenstern
jh
vempala
2019
multi-criteria
dimen
sionality
reduction
applications
fairness
wallach
larochelle
beygelzimer
123
algorithmic
fairness
datasets
story
far
2147
alché-buc
fox
garnett
eds
advances
neural
information
processing
systems
vol
32
curran
associates
inc
pp
15161
15171
https://proceedings.neurips.cc/paper/2019/file/
2201611d7a08ffda97e3e8c6b667a1bc-paper
pdf
taskesen
blanchet
kuhn
nguyen
va
2021
statistical
test
probabilistic
fairness
pro
ceedings
2021
acm
conference
fairness
accountability
transparency
association
computing
machinery
new
york
facct
21
pp
648
665
https://doi.org/10.1145/3442188.3445927
tatman
2017
gender
dialect
bias
youtube
automatic
captions
proceedings
first
acl
workshop
ethics
natural
language
processing
association
computational
linguis
tics
valencia
pp
53
59
https://doi.org/10.18653/v1/w17-1606,
https://www.aclweb.org/anthology/
w17-1606
tavallaee
bagheri
lu
ghorbani
aa
2009
detailed
analysis
kdd
cup
99
data
set
2009
ieee
symposium
computational
intelligence
security
defense
applications
pp
https://doi.org/10.1109/cisda.2009.5356528
team
conduent
public
safety
solutions
2018
real
time
crime
forecasting
challenge
post-mortem
analysis
challenge
performance
tjong
kim
sang
ef
de
meulder
2003
introduction
conll-2003
shared
task
language
independent
named
entity
recognition
proceedings
seventh
conference
natural
language
learning
hlt-naacl
2003
pp
142
147
https://www.aclweb.org/anthology/w03-0419
tong
kagal
2020
investigating
bias
image
classification
using
model
explanations
icml
2020
workshop
workshop
human
interpretability
machine
learning
whi
arxiv
2012.05463
toutanova
chen
pantel
poon
choudhury
gamon
2015
representing
text
joint
embedding
text
knowledge
bases
https://doi.org/10.18653/v1/d15-1174
tsang
wilder
rice
tambe
zick
2019
group-fairness
influence
maximization
inter
national
joint
conference
artificial
intelligence
tsao
cw
vasan
rs
2015
cohort
profile
framingham
heart
study
fhs
overview
milestones
cardiovascular
epidemiology
int
epidemiol
44
1800
1813
tschandl
rosendahl
kittler
2018
ham10000
dataset
large
collection
multi-source
der
matoscopic
images
common
pigmented
skin
lesions
sci
data
tziavelis
giannakopoulos
doka
koziris
karras
2019
equitable
stable
matchings
quadratic
time
wallach
larochelle
beygelzimer
alché-buc
fox
garnett
eds
advances
neural
information
processing
systems
vol
32
curran
associates
inc
pp
457
467
https
proceedings
neurips
cc
paper
2019
file
cb70ab375662576bd1ac5aaf16b3fca4-paper
pdf
uci
machine
learning
repository
1994
statlog
german
credit
data
data
set
https://archive.ics.uci.edu/
ml
datasets
statlog
german
credit
data
uci
machine
learning
repository
1996
adult
data
set
https://archive.ics.uci.edu/ml/datasets/adult
uci
machine
learning
repository
2019
south
german
credit
data
set
https://archive.ics.uci.edu/ml/
datasets
south
german
credit
us
dept
commerce
bureau
census
1978
current
population
survey
design
methodology
us
dept
commerce
bureau
census
1995
current
population
survey
annual
demographic
file
1994
us
federal
reserve
2007
report
congress
credit
scoring
effects
availability
affordability
credi
ustun
westover
mb
rudin
bianchi
mt
2016
clinical
prediction
models
sleep
apnea
importance
medical
history
symptoms
clin
sleep
med
12
02
161
168
https://doi.org/10.
5664
jcsm
5476
ustun
liu
parkes
2019
fairness
without
harm
decoupled
classifiers
preference
guarantees
chaudhuri
salakhutdinov
eds
proceedings
36th
international
conference
machine
learning
pmlr
long
beach
proceedings
machine
learning
research
vol
97
pp
6373
6382
http
proceedings
mlr
press
v97
ustun19a
html
ve
cho
2020
rule-based
model
seoul
bike
sharing
demand
prediction
using
weather
data
eur
remote
sens
53
sup1
166
183
https://doi.org/10.1080/22797254.2020.1725789
park
cho
2020
using
data
mining
techniques
bike
sharing
demand
prediction
metropoli
tan
city
comput
commun
153
353
366
https://doi.org/10.1016/j.comcom.2020.02.007
vaithianathan
putnam-hornstein
jiang
nand
maloney
2017
developing
predictive
models
support
child
maltreatment
hotline
screening
decisions
allegheny
county
methodol
ogy
implementation
https://www.alleghenycountyanalytics.us/wp-content/uploads/2019/05/16-
acdhs-26_predictiverisk_package_050119_final-2
pdf
123
2148
fabris
et
al
valera
singla
gomez
rodriguez
2018
enhancing
accuracy
fairness
human
decision
mak
ing
bengio
wallach
larochelle
grauman
cesa-bianchi
garnett
eds
advances
neural
information
processing
systems
curran
associates
inc
vol
31
pp
1769
1778
https
proceedings
neurips
cc
paper
2018
file
0a113ef6b61820daa5611c870ed8d5ee-paper
pdf
van
horn
mac
aodha
song
cui
sun
shepard
adam
perona
belongie
2018
inaturalist
species
classification
detection
dataset
arxiv
1707.06642
van
horn
cole
beery
wilber
belongie
mac
aodha
2021
benchmarking
representation
learning
natural
world
image
collections
proceedings
ieee
cvf
conference
computer
vision
pattern
recognition
pp
12884
12893
vargo
zhang
yurochkin
sun
2021
individually
fair
gradient
boosting
international
con
ference
learning
representations
https://openreview.net/forum?id=jbaa9we1al
vig
gehrmann
belinkov
qian
nevo
singer
shieber
sm
2020
investigating
gender
bias
language
models
using
causal
mediation
analysis
larochelle
ranzato
hadsell
balcan
lin
eds
advances
neural
information
processing
systems
33
annual
conference
neural
information
processing
systems
2020
neurips
2020
december
12
2020
virtual
https
proceedings
neurips
cc
paper
2020
hash
92650b2e92217715fe312e6fa7b90d82-abstract
html
vijayaraghavan
vosoughi
roy
2017
twitter
demographic
classification
using
deep
multi-modal
multi-task
learning
proceedings
55th
annual
meeting
association
computational
linguistics
volume
short
papers
association
computational
linguistics
vancouver
pp
478
483
https://doi.org/10.18653/v1/p17-2076,
https://www.aclweb.org/anthology/p17-2076
voigt
jurgens
prabhakaran
jurafsky
tsvetkov
2018
rtgender
corpus
studying
differen
tial
responses
gender
proceedings
eleventh
international
conference
language
resources
evaluation
lrec
2018
european
language
resources
association
elra
miyazaki
https
www.aclweb.org/anthology/l18-1445
voorhees
2005
overview
trec
2005
robust
retrieval
track
https://trec.nist.gov/pubs/trec13/papers/
robust
overview
pdf
wadsworth
vera
piech
2018
achieving
fairness
adversarial
learning
application
recidivism
prediction
icml
2018
workshop
fairness
accountability
transparency
machine
learning
fat
ml
arxiv
1807.00199
wah
branson
welinder
perona
belongie
2011
caltech-ucsd
birds200-2011
dataset
advances
water
resources-adv
water
resour
wan
mcauley
2018
item
recommendation
monotonic
behavior
chains
proceedings
12th
acm
conference
recommender
systems
association
computing
machinery
new
york
recsys
18
pp
86
94
https://doi.org/10.1145/3240323.3240369
wang
deng
2020
mitigating
bias
face
recognition
using
skewness-aware
reinforcement
learning
ieee
cvf
conference
computer
vision
pattern
recognition
cvpr
wang
saar-tsechansky
2020
augmented
fairness
interpretable
model
augmenting
decision
makers
fairness
neurips
2020
workshop
algorithmic
fairness
lens
causality
interpretability
afci
arxiv
2011.08398
wang
pruksachatkun
nangia
singh
michael
hill
levy
bowman
2019a
super
glue
stickier
benchmark
general-purpose
language
understanding
systems
wallach
larochelle
beygelzimer
alché-buc
fox
garnett
eds
advances
neural
information
processing
systems
vol
32
curran
associates
inc
https://proceedings.neurips.cc/paper/2019/file/
4496bf24afe7fab6f046bf4923da8de6-paper
pdf
wang
singh
michael
hill
levy
bowman
sr
2019b
glue
multi-task
benchmark
analysis
platform
natural
language
understanding
international
conference
learning
representations
https://openreview.net/forum?id=rj4km2r5t7
wang
grgic-hlaca
lahoti
gummadi
kp
weller
2019c
empirical
study
learning
fairness
metrics
compas
data
human
supervision
neurips
2019
workshop
human-centric
machine
learning
arxiv
1910.10255
wang
ustun
calmon
2019d
repairing
without
retraining
avoiding
disparate
impact
coun
terfactual
distributions
chaudhuri
salakhutdinov
eds
proceedings
36th
international
conference
machine
learning
pmlr
long
beach
proceedings
machine
learning
research
vol
97
pp
6618
6627
http://proceedings.mlr.press/v97/wang19l.html
wang
deng
hu
tao
huang
2019e
racial
faces
wild
reducing
racial
bias
infor
mation
maximization
adaptation
network
proceedings
ieee
cvf
international
conference
computer
vision
pp
692
702
123
algorithmic
fairness
datasets
story
far
2149
wang
guo
narasimhan
cotter
gupta
jordan
2020a
robust
optimization
fairness
noisy
protected
groups
larochelle
ranzato
hadsell
balcan
mf
lin
eds
advances
neural
information
processing
systems
vol
33
curran
associates
inc
pp
5190
5203
https
proceedings
neurips
cc
paper
2020
file
37d097caf1299d9aa79c2c2b843d2d78-paper
pdf
wang
qinami
karakozis
ic
genova
nair
hata
russakovsky
2020b
towards
fairness
visual
recognition
effective
strategies
bias
mitigation
ieee
cvf
conference
computer
vision
pattern
recognition
cvpr
wang
liu
levy
2021
fair
classification
group-dependent
label
noise
proceedings
2021
acm
conference
fairness
accountability
transparency
association
computing
machinery
new
york
facct
21
pp
526
536
https://doi.org/10.1145/3442188.3445915,
waseem
hovy
2016
hateful
symbols
hateful
people
predictive
features
hate
speech
detection
twitter
proceedings
naacl
student
research
workshop
association
computational
linguistics
san
diego
pp
88
93
https://doi.org/10.18653/v1/n16-2013,
https://www.aclweb.org/
anthology
n16-2013
webster
recasens
axelrod
baldridge
2018
mind
gap
balanced
corpus
gendered
ambiguous
pronouns
arxiv
1810.05201
weeks
clair
borgatti
radda
schensul
2002
social
networks
drug
users
high-risk
sites
finding
connections
aids
behav
193
206
https://doi.org/10.1023/a:1015457400897
wick
panda
tristan
jb
2019
unlocking
fairness
trade-off
revisited
wallach
larochelle
beygelzimer
alché-buc
fox
garnett
eds
advances
neural
information
processing
systems
curran
associates
inc
vol
32
pp
8783
8792
https://proceedings.neurips.cc/paper/2019/
file
373e4c5d8edfa8b74fd4b6791d0cf6dc-paper
pdf
wieringa
kannan
ma
reutterer
risselada
skiera
2021
data
analytics
privacy-concerned
world
bus
res
122
915
925
https://doi.org/10.1016/j.jbusres.2019.05.005
wightman
ramsey
council
lsa
1998
lsac
national
longitudinal
bar
passage
study
lsac
research
report
series
law
school
admission
council
https://books.google.it/books?
id
wda7aqaaiaaj
wilder
ou
hc
de
la
haye
tambe
2018
optimizing
network
structure
preventative
health
proceedings
17th
international
conference
autonomous
agents
multiagent
systems
international
foundation
autonomous
agents
multiagent
systems
richland
sc
aamas
18
pp
841
849
wilkinson
md
dumontier
aalbersberg
ij
appleton
axton
baak
blomberg
boiten
jw
da
silva
santos
lb
bourne
pe
et
al
2016
fair
guiding
principles
scientific
data
management
stewardship
sci
data
williams
jv
razavian
2019
quantification
bias
machine
learning
healthcare
case
study
renal
failure
prediction
https://drive.google.com/file/d/1dvjfvvliqveekalrmlxfx6lcvtzhkdq0/
view
neurips
2019
workshop
fair
ml
health
williamson
menon
2019
fairness
risk
measures
chaudhuri
salakhutdinov
eds
proceedings
36th
international
conference
machine
learning
pmlr
long
beach
proceedings
machine
learning
research
vol
97
pp
6786
6797
http://proceedings.mlr.press/v97/williamson19a.html
wilson
ghosh
jiang
mislove
baker
szary
trindel
polli
2021
tbuilding
auditing
fair
algorithms
case
study
candidate
screening
proceedings
2021
acm
conference
fairness
accountability
transparency
association
computing
machinery
new
york
facct
21
pp
666
677
https://doi.org/10.1145/3442188.3445928
wondracek
holz
kirda
kruegel
2010
practical
attack
de-anonymize
social
network
users
2010
ieee
symposium
security
privacy
pp
223
238
https://doi.org/10.1109/sp.2010.21
wu
zhang
wu
2018
discrimination
discovery
removal
ranked
data
using
causal
graph
proceedings
24th
acm
sigkdd
international
conference
knowledge
discovery
data
mining
association
computing
machinery
new
york
kdd
18
pp
2536
2544
https://doi.org/
10.1145
3219819.3220087
wu
zhang
wu
tong
2019
pc-fairness
unified
framework
measuring
causality-based
fairness
wallach
larochelle
beygelzimer
alché-buc
fox
garnett
eds
advances
neural
information
processing
systems
vol
32
curran
associates
inc
pp
3404
3414
https
proceedings
neurips
cc
paper
2019
file
44a2e0804995faf8d2e3b084a1e2db1d-paper
pdf
xiao
rasul
vollgraf
2017
fashion-mnist
novel
image
dataset
benchmarking
machine
learning
algorithms
arxiv
1708.07747
123
2150
fabris
et
al
xiao
zhao
pan
song
zheng
vw
yang
2019
beyond
personalization
social
content
recommendation
creator
equality
consumer
satisfaction
proceedings
25th
acm
sigkdd
international
conference
knowledge
discovery
data
mining
association
com
puting
machinery
new
york
kdd
19
pp
235
245
https://doi.org/10.1145/3292500.3330965,
xie
lauritsen
jl
2012
racial
context
crime
reporting
test
black
stratification
hypothesis
quant
criminol
28
265
293
xu
yuan
zhang
wu
2018
fairgan
fairness-aware
generative
adversarial
networks
2018
ieee
international
conference
big
data
big
data
ieee
pp
570
575
xu
cui
kuang
li
zhou
shen
cui
2020
algorithmic
decision
making
conditional
fairness
association
computing
machinery
new
york
pp
2125
2135
https://doi.org/10.1145/
3394486.3403263
xu
huang
shen
li
li
huang
li
cui
2021
consistent
instance
false
positive
improves
fairness
face
recognition
proceedings
ieee
cvf
conference
computer
vision
pattern
recognition
cvpr
pp
578
586
yang
stoyanovich
2017
measuring
fairness
ranked
outputs
proceedings
29th
international
conference
scientific
statistical
database
management
association
computing
machinery
new
york
ssdbm
17
https://doi.org/10.1145/3085504.3085526
yang
kim
2019
benchmarking
attribution
methods
relative
feature
importance
arxiv
1907.09701
yang
cisse
koyejo
2020a
fairness
overlapping
groups
probabilistic
perspective
larochelle
ranzato
hadsell
balcan
mf
lin
eds
advances
neural
information
pro
cessing
systems
vol
33
curran
associates
inc
pp
4067
4078
https://proceedings.neurips.cc/paper/
2020
file
29c0605a3bab4229e46723f89cf59d83-paper
pdf
yang
qinami
fei-fei
deng
russakovsky
2020b
towards
fairer
datasets
filtering
balancing
distribution
people
subtree
imagenet
hierarchy
proceedings
2020
conference
fairness
accountability
transparency
association
computing
machinery
new
york
fat
20
pp
547
558
https://doi.org/10.1145/3351095.3375709
yao
huang
2017a
beyond
parity
fairness
objectives
collaborative
filtering
guyon
luxburg
uv
bengio
wallach
fergus
vishwanathan
garnett
eds
advances
neural
information
processing
systems
vol
30
curran
associates
inc
pp
2921
2930
https://proceedings.neurips.cc/
paper
2017
file
e6384711491713d29bc63fc5eeb5ba4f-paper
pdf
yao
huang
2017b
new
fairness
metrics
recommendation
embrace
differences
kdd
2017
workshop
fairness
accountability
transparency
machine
learning
fat
ml
arxiv
1706.09838
yeh
ic
hui
lien
2009
comparisons
data
mining
techniques
predictive
accuracy
probability
default
credit
card
clients
expert
syst
appl
36
part
2473
2480
https://doi.org/
10.1016
eswa
2007.12
020
yi
xiaogang
xiaoou
2013
deep
convolutional
network
cascade
facial
point
detection
2013
ieee
conference
computer
vision
pattern
recognition
pp
3476
3483
https://doi.org/10.
1109
cvpr
2013.446
yi
wang
joshi
ghassemi
2019
fair
robust
treatment
effect
estimates
estimation
treatment
outcome
disparity
deep
neural
models
https://drive.google.com/file/d/
1huhrovnfzxnpaseltczzuqfvgu9jbti1
view
neurips
2019
workshop
fair
ml
health
yurochkin
sun
2021
sensei
sensitive
set
invariance
enforcing
individual
fairness
interna
tional
conference
learning
representations
https://openreview.net/forum?id=dktzb97_fx
yurochkin
bower
sun
2020
training
individually
fair
ml
models
sensitive
subspace
robustness
international
conference
learning
representations
https://openreview.net/forum?
id
b1gdkxhfdh
zafar
mb
valera
gomez
rodriguez
gummadi
kp
2017a
fairness
beyond
disparate
treatment
disparate
impact
learning
classification
without
disparate
mistreatment
proceedings
26th
international
conference
world
wide
web
international
world
wide
web
conferences
steering
committee
republic
canton
geneva
che
www
17
pp
1171
1180
https://doi.org/10.
1145
3038912.3052660
zafar
mb
valera
rodriguez
gummadi
weller
2017b
parity
preference-based
notions
fairness
classification
guyon
luxburg
uv
bengio
wallach
fergus
vishwanathan
garnett
eds
advances
neural
information
processing
systems
vol
30
curran
associates
inc
123
algorithmic
fairness
datasets
story
far
2151
pp
229
239
https://proceedings.neurips.cc/paper/2017/file/82161242827b703e6acf9c726942a1e4-
paper
pdf
zafar
mb
valera
rogriguez
mg
gummadi
kp
2017c
fairness
constraints
mechanisms
fair
clas
sification
artificial
intelligence
statistics
pmlr
pp
962
970
zehlike
yang
stoyanovich
2021
fairness
ranking
survey
arxiv
2103.14000
zhang
2005
bayesian
graphical
model
adaptive
information
filtering
phd
thesis
carnegie
mellon
university
zhang
bareinboim
2018
equality
opportunity
classification
causal
approach
bengio
wallach
larochelle
grauman
cesa-bianchi
garnett
eds
advances
neural
information
processing
systems
vol
31
curran
associates
inc
pp
3671
3681
https://proceedings.neurips.cc/
paper
2018
file
ff1418e8cc993fe8abcfe3ce2003e5c5-paper
pdf
zhang
davidson
2021
towards
fair
deep
anomaly
detection
proceedings
2021
acm
conference
fairness
accountability
transparency
association
computing
machinery
new
york
facct
21
pp
138
148
https://doi.org/10.1145/3442188.3445878
zhang
neill
db
2017
identifying
significant
predictive
bias
classifiers
kdd
2017
workshop
fair
ness
accountability
transparency
machine
learning
fat
ml
arxiv
1611.08292
zhang
luo
loy
cc
tang
2014
facial
landmark
detection
deep
multi-task
learning
https
doi
org
10.1007
978
319
10599
4_7
zhang
luo
loy
cc
tang
2015
learning
deep
representation
face
alignment
auxiliary
attributes
ieee
trans
pattern
anal
mach
intell
38
918
930
zhang
wu
wu
2017a
achieving
non-discrimination
data
release
proceedings
23rd
acm
sigkdd
international
conference
knowledge
discovery
data
mining
association
computing
machinery
new
york
kdd
17
pp
13350
1344
https://doi.org/10.1145/3097983.
3098167
zhang
song
qi
2017b
age
progression
regression
conditional
adversarial
autoencoder
proceedings
ieee
conference
computer
vision
pattern
recognition
cvpr
zhang
bh
lemoine
mitchell
2018
mitigating
unwanted
biases
adversarial
learning
pro
ceedings
2018
aaai
acm
conference
ai
ethics
society
association
computing
machinery
new
york
aies
18
pp
335
340
https://doi.org/10.1145/3278721.3278779
zhang
khaliligarekani
tekin
liu
2019
group
retention
using
machine
learning
sequen
tial
decision
making
interplay
user
dynamics
fairness
wallach
larochelle
beygelzimer
alché-buc
fox
garnett
eds
advances
neural
information
processing
systems
vol
32
curran
associates
inc
pp
15269
15278
https://proceedings.neurips.cc/paper/2019/
file
7690dd4db7a92524c684e3191919eb6b-paper
pdf
zhang
lu
ax
abdalla
mcdermott
ghassemi
2020a
hurtful
words
quantifying
biases
clinical
contextual
word
embeddings
proceedings
acm
conference
health
inference
learning
association
computing
machinery
new
york
chil
20
pp
110
120
https://doi.
org
10.1145
3368555.3384448
zhang
tu
liu
liu
kjellström
zhang
zhang
2020b
fair
decisions
fare
long-term
qualification
larochelle
ranzato
hadsell
balcan
lin
eds
advances
neural
information
processing
systems
33
annual
conference
neural
information
processing
systems
2020
neurips
2020
december
12
2020
virtual
https://proceedings.neurips.cc/paper/
2020
hash
d6d231705f96d5a3aeb3a76402e49a3-abstract
html
zhang
bellamy
varshney
2020c
joint
optimization
ai
fairness
utility
human-centered
approach
proceedings
aaai
acm
conference
ai
ethics
society
association
computing
machinery
new
york
aies
20
pp
400
406
https://doi.org/10.1145/3375627.3375862
zhao
gordon
2019
inherent
tradeoffs
learning
fair
representations
wallach
larochelle
beygelzimer
alché-buc
fox
garnett
eds
advances
neural
information
processing
systems
vol
32
curran
associates
inc
pp
15675
15685
https://proceedings.neurips.cc/paper/2019/
file
b4189d9de0fb2b9cce090bd1a15e3420-paper
pdf
zhao
wang
yatskar
ordonez
chang
kw
2017
men
also
like
shopping
reducing
gender
bias
amplification
using
corpus-level
constraints
proceedings
2017
conference
empiri
cal
methods
natural
language
processing
association
computational
linguistics
copenhagen
denmark
pp
2979
2989
https://doi.org/10.18653/v1/d17-1323,
https://www.aclweb.org/anthology/
d17-1323
zhao
wang
yatskar
ordonez
chang
kw
2018
gender
bias
coreference
resolution
evaluation
debiasing
methods
proceedings
2018
conference
north
american
chapter
123
2152
fabris
et
al
association
computational
linguistics
human
language
technologies
volume
short
papers
association
computational
linguistics
new
orleans
pp
15
20
https://doi.org/10.18653/v1/n18-
2003
https://www.aclweb.org/anthology/n18-2003
zhao
xiao
gan
zhang
xia
st
2020a
maintaining
discrimination
fairness
class
incre
mental
learning
ieee
cvf
conference
computer
vision
pattern
recognition
cvpr
zhao
li
li
chen
2020b
fair
meta-learning
few-shot
classification
2020
ieee
inter
national
conference
knowledge
graph
ickg
pp
275
282
https://doi.org/10.1109/icbk50248.
2020.00047
zhao
coston
adel
gordon
gj
2020c
conditional
learning
fair
representations
international
conference
learning
representations
https://openreview.net/forum?id=hkekl0nfpr
zhao
kong
fowlkes
2021
camera
pose
matters
improving
depth
prediction
mitigating
pose
distribution
bias
proceedings
ieee
cvf
conference
computer
vision
pattern
recog
nition
cvpr
pp
15759
15768
zheng
dave
mishra
kumar
2018
fairness
reciprocal
recommendations
speed-dating
study
adjunct
publication
26th
conference
user
modeling
adaptation
personalization
association
computing
machinery
new
york
umap
18
pp
29
34
https://doi.org/10.1145/
3213586.3226207
zhong
deng
wang
hu
peng
tao
huang
2019
unequal-training
deep
face
recognition
long-tailed
noisy
data
proceedings
ieee
cvf
conference
computer
vision
pattern
recognition
cvpr
zhou
lapedriza
khosla
oliva
torralba
2018
places
10
million
image
database
scene
recognition
ieee
trans
pattern
anal
mach
intell
40
1452
1464
https://doi.org/10.1109/tpami.
2017.2723009
zhu
kiros
zemel
salakhutdinov
urtasun
torralba
fidler
2015
aligning
books
movies
towards
story-like
visual
explanations
watching
movies
reading
books
arxiv
1506.06724
zhu
wang
zhang
caverlee
2018
fairness-aware
recommendation
information
curators
recsys
2018
workshop
workshop
responsible
recommendation
fat
rec
arxiv
1809.03040
žliobaité
2015
relation
accuracy
fairness
binary
classification
icml
2015
work
shop
fairness
accountability
transparency
machine
learning
fat
ml
arxiv
1505.05723
žliobaité
kamiran
calders
2011
handling
conditional
discrimination
2011
ieee
11th
interna
tional
conference
data
mining
pp
992
1001
https://doi.org/10.1109/icdm.2011.72
publisher
note
springer
nature
remains
neutral
regard
jurisdictional
claims
published
maps
institutional
affiliations
123