information
retrieval
journal
2022
25
26
https://doi.org/10.1007/s10791-021-09399-z
search
results
diversification
for
effective
fair
ranking
in
academic
search
graham
mcdonald1
craig
macdonald1
iadh
ounis1
received
25
july
2020
accepted
28
october
2021
published
online
december
2021
the
author
2021
abstract
providing
users
with
relevant
search
results
has
been
the
primary
focus
of
information
retrieval
research
however
focusing
on
relevance
alone
can
lead
to
undesirable
side
effects
for
example
small
differences
between
the
relevance
scores
of
documents
that
are
ranked
by
relevance
alone
can
result
in
large
differences
in
the
exposure
that
the
authors
of
relevant
documents
receive
the
likelihood
that
the
documents
will
be
seen
by
searchers
therefore
developing
fair
ranking
techniques
to
try
to
ensure
that
search
results
are
not
dominated
for
example
by
certain
information
sources
is
of
growing
interest
to
mitigate
against
such
biases
in
this
work
we
argue
that
generating
fair
rankings
can
be
cast
as
search
results
diversification
problem
across
number
of
assumed
fairness
groups
where
groups
can
represent
the
demographics
or
other
characteristics
of
information
sources
in
the
context
of
academic
search
as
in
the
trec
fair
ranking
track
which
aims
to
be
fair
to
unknown
groups
of
authors
we
evaluate
three
well-known
search
results
diversification
approaches
from
the
literature
to
generate
rankings
that
are
fair
to
multiple
assumed
fairness
groups
early-career
researchers
vs
highly-experienced
authors
our
experiments
on
the
2019
and
2020
trec
datasets
show
that
explicit
search
results
diversification
is
viable
approach
for
generating
effective
rankings
that
are
fair
to
information
sources
in
particular
we
show
that
building
on
xquad
diversification
as
fairness
component
can
result
in
significant
0.05
increase
up
to
50
in
our
experiments
in
the
fairness
of
exposure
that
authors
from
unknown
protected
groups
receive
keywords
fair
ranking
search
results
diversification
expected
exposure
academic
search
graham
mcdonald
graham.mcdonald@glasgow.ac.uk
craig
macdonald
craig.macdonald@glasgow.ac.uk
iadh
ounis
iadh.ounis@glasgow.ac.uk
university
of
glasgow
scotland
uk
13
vol
0123456789
information
retrieval
journal
2022
25
26
introduction
the
objective
of
an
information
retrieval
ir
system
has
traditionally
been
seen
as
being
to
maximise
the
fraction
of
results
presented
to
the
user
that
are
relevant
to
the
user
query
or
to
address
the
user
information
need
as
close
to
the
top
rank
position
as
possible
however
many
studies
have
shown
that
focusing
on
relevance
alone
as
measure
of
search
success
can
lead
to
undesirable
side
effects
that
can
have
negative
societal
impacts
baeza-yates
2018
epstein
et
al
2017
kay
et
al
2015
mehrotra
et
al
2018
interventions
in
computational
decision-support
systems
such
as
ir
systems
cannot
solve
such
societal
issues
abebe
et
al
2020
however
developing
systematic
interventions
can
support
broader
attempts
at
understanding
and
addressing
social
problems
therefore
in
recent
years
there
has
been
an
increased
interest
in
the
societal
implications
of
how
ir
systems
select
or
present
documents
to
users
and
the
potential
for
ir
systems
to
systematically
discriminate
against
particular
groups
of
people
pleiss
et
al
2017
ir
systems
and
machine
learned
models
can
encode
and
perpetuate
any
biases
that
exist
in
the
test
collections
that
they
use
zehlike
et
al
2017
bender
et
al
2021
moreover
search
engines
that
are
used
to
find
for
example
jobs
or
news
can
have
significant
negative
impact
on
information
sources
that
produce
relevant
content
but
are
often
unfairly
under-represented
in
the
search
results
therefore
it
is
imperative
that
the
ir
community
focuses
on
minimising
the
potentially
negative
human
social
and
economic
impact
of
such
biases
in
search
systems
culpepper
et
al
2018
particularly
for
disadvantaged
or
protected
groups
of
society
pedreschi
et
al
2008
one
way
to
mitigate
against
such
biases
that
is
receiving
increasing
attention
in
the
ir
community
is
to
develop
fair
ranking
strategies
to
try
to
ensure
that
certain
users
or
information
sources
are
not
discriminated
against
culpepper
et
al
2018
ekstrand
et
al
2019
olteanu
et
al
2019b
the
increasing
importance
this
topic
is
exemplified
by
the
text
retrieval
conference
trec
fair
ranking
track
biega
et
al
2020
when
defining
fairness
for
ranking
strategies
we
agree
with
singh
and
joachims
2018
that
there
is
not
one
definitive
definition
and
judgement
of
fairness
is
context
specific
in
this
work
we
take
the
view
that
for
search
engine
ranking
to
be
considered
as
being
fair
relevant
information
sources
should
be
given
fair
exposure
to
the
search
engine
users
following
singh
and
joachims
2018
we
consider
fair
exposure
to
mean
that
the
exposure
that
document
receives
should
be
proportional
to
the
relevance
of
the
document
with
respect
to
user
query
in
the
context
of
an
ir
system
that
presents
documents
to
user
that
are
ranked
in
decreasing
order
of
their
estimated
relevance
to
the
user
query
documents
that
are
placed
lower
in
the
ranking
will
receive
less
exposure
than
higher
ranked
documents
the
reduction
or
drop-off
in
exposure
that
document
at
position
posj
in
ranking
gets
can
be
estimated
as
this
is
the
user
model
that
encapsulates
position
bias
that
is
exposure
posj
log
pos
commonly
used
in
the
discounted
cumulative
gain
dcg
j√§rvelin
and
kek√§l√§inen
2002
measure
moreover
the
amount
of
exposure
that
document
receives
accumulates
over
repeated
instances
of
query
we
refer
to
this
as
sequence
of
rankings
therefore
in
this
work
as
our
definitions
of
fairness
we
adopt
the
disparate
treatment
and
disparate
impact
fairness
constraints
of
singh
and
joachims
2018
disparate
treatment
enforces
the
exposure
of
two
fairness
groups
g0
and
g1
authors
from
protected
societal
group
to
be
proportional
to
the
average
relevance
of
the
group
documents
and
is
defined
as
13
information
retrieval
journal
2022
25
26
exposure
g0
exposure
g1
g0
g1
where
is
doubly
stochastic
matrix
where
the
cell
ùêèi
is
the
probability
that
ranking
di
at
rank
and
the
average
utility
relevance
of
group
gk
is
calplaces
document
culated
as
gk
g1
di
gk
ùêÆi
where
is
the
individual
utility
scores
of
each
of
the
documents
in
the
group
gk
the
disparate
impact
constraint
builds
on
disparate
treatment
with
the
additional
constraint
that
the
clickthrough
rates
for
the
groups
as
determined
by
their
exposure
and
relevance
are
proportional
to
their
average
utility
disparate
impact
is
defined
as
ctr
g1
ctr
g0
g0
g1
where
the
average
clickthrough
rate
of
group
ctr
g0
is
defined
as
ctr
gk
ùêèi
ùêÆi
ùêØj
gk
gk
for
documents
with
utility
and
attention
exposure
drop-off
the
probability
of
document
being
clicked
is
calculated
using
the
click
model
of
richardson
et
al
2007
as
follows
click
on
document
examining
is
relevant
exposure
di
is
relevant
ùêèi
ùêØj
ùêÆi
in
our
experiments
we
view
the
disparate
treatment
and
the
disparate
impact
constraints
as
the
target
exposures
for
each
of
the
fairness
groups
g0
and
g1
under
two
different
fairness
constraints
and
measure
how
much
sequence
of
rankings
violates
each
of
the
constraints
many
approaches
in
recent
years
have
tried
to
ensure
that
items
documents
that
represent
particular
societal
groups
gender
or
ethnicity
receive
fair
exposure
within
single
ranking
however
queries
are
often
searched
repeatedly
either
by
the
same
user
over
period
of
time
or
by
multiple
users
and
if
the
same
static
ranking
is
produced
for
each
instance
of
the
query
then
inequalities
of
exposure
can
emerge
over
time
for
example
consider
fairness
policy
that
ensures
that
in
single
ranking
50
of
relevant
documents
are
by
authors
from
protected
societal
group
if
for
particular
query
the
highest
ranked
of
the
documents
are
not
by
authors
from
the
protected
group
then
although
the
single
ranking
could
be
considered
to
be
fair
over
time
the
documents
in
the
top-ranked
positions
would
cumulatively
receive
more
exposure
than
the
authors
from
the
protected
group
that
have
also
produced
relevant
documents
however
there
is
also
the
potential
to
compensate
for
any
under-exposure
of
the
documents
in
previous
rankings
if
the
search
engine
introduces
fair
ranking
policy
biega
et
al
2018
this
scenario
where
authors
receive
exposure
to
users
over
repeated
queries
is
addressed
in
the
context
of
academic
search
by
the
trec
fair
ranking
track
biega
et
al
2020
13
information
retrieval
journal
2022
25
26
fig
an
example
academic
search
engine
ui
the
figure
illustrates
the
10
blue-links
ux
of
the
semantic
scholar
search
engine
academic
search
addresses
the
scenario
in
which
search
engine
indexes
scientific
articles
such
as
research
papers
books
or
theses
that
have
been
published
in
academic
journals
or
the
proceedings
of
scientific
conferences
examples
of
such
search
engines
include
semantic
scholar
google
scholar2
and
the
cornell
university
search
engine
arxiv
typically
academic
search
engines
adhere
to
the
ten-blue-links
ux
presentation
strategy
for
presenting
user
with
the
results
of
their
query
fig
provides
an
illustration
of
the
user
interface
of
the
semantic
scholar
search
engine
in
an
academic
search
scenario
fair
ranking
should
not
be
dominated
by
single
author
or
institution
if
there
are
equally
relevant
papers
from
other
authors
or
institutions
moreover
an
author
or
institution
should
not
receive
disproportionately
high
or
low
exposure
over
time
compared
to
other
authors
or
institutions
that
produce
relevant
papers
for
example
in
response
to
the
query
information
retrieval
the
results
at
the
top
rank
positions
should
not
all
be
from
the
same
research
group
since
there
will
be
multiple
groups
that
have
produced
relevant
papers
moreover
as
query
is
repeated
over
time
different
relevant
information
sources
should
be
given
the
opportunity
to
appear
in
higher
ranked
positions
we
argue
that
generating
fair
ranking
towards
information
sources
can
be
cast
as
search
results
diversification
santos
et
al
2015
task
in
search
results
diversification
an
ir
system
aims
to
maximise
the
number
of
sub-topics
or
aspects
of
an
ambiguous
query
that
are
represented
within
the
results
list
we
postulate
that
fair
rankings
can
be
generated
by
viewing
the
characteristics
of
groups
that
we
aim
to
be
fair
to
as
latent
aspects
of
relevance
and
maximising
the
number
of
such
groups
that
are
represented
within
the
search
results
https://‚Äãseman‚Äãticsc‚Äãholar.‚Äãorg
https://‚Äãschol‚Äãar.‚Äãgoogle.‚Äãcom
https://‚Äãarxiv.‚Äãorg
13
information
retrieval
journal
2022
25
26
in
this
work
we
evaluate
three
well-known
search
results
diversification
approaches
from
the
literature
as
fair
ranking
strategies
our
experiments
on
the
2019
and
2020
trec
fair
ranking
track
datasets
show
that
explicit
search
results
diversification
is
particularly
effective
for
generating
rankings
that
provide
fair
exposure
for
authors
from
protected
societal
groups
when
the
definition
of
the
protected
groups
are
unknown
in
particular
we
show
that
leveraging
xquad
santos
et
al
2010
search
result
diversification
as
fair
ranking
strategy
can
result
in
significant
0.05
increase
up
to
50
in
our
experiments
in
the
fairness
of
exposure
that
authors
from
unknown
protected
groups
receive
when
exposure
is
evaluated
for
multiple
instances
of
repeated
query
indeed
the
tailored
xquad
search
result
diversification
model
with
our
proposed
assumed
fairness
groups
was
the
best
performing
system
submitted
to
the
trec
2019
fair
ranking
track
in
terms
of
fairness
for
both
of
the
official
trec
evaluation
groupings
moreover
in
this
work
we
show
that
diversifying
over
assumed
fairness
groups
that
model
the
topical
contents
of
documents
is
particularly
promising
approach
and
can
result
in
significantly
increased
group
fairness
relative
to
the
relevance
of
the
documents
from
the
group
compared
to
when
the
ranking
is
optimised
for
relevance
only
the
remainder
of
this
paper
is
as
follows
in
sect
we
discuss
prior
work
on
fairness
in
information
access
systems
we
introduce
the
fair
ranking
task
in
sect
before
defining
our
proposed
assumed
fairness
groups
in
sect
we
present
how
we
propose
to
cast
fair
ranking
as
search
result
diversification
task
in
sect
before
presenting
our
experimental
setup
in
sect
then
our
results
in
sect
concluding
remarks
follow
in
sect
related
work
in
this
section
we
firstly
discuss
work
related
to
fairness
in
classification
systems
and
search
engines
before
presenting
prior
work
on
search
results
diversification
fairness
most
of
the
previous
work
on
measuring
or
enforcing
fairness
in
information
access
systems
has
focused
on
fairness
in
machine
learning
classifiers
such
classifiers
might
be
deployed
in
decision-making
tasks
such
as
loan
or
parole
applications
chouldechova
2017
hardt
et
al
2016
kleinberg
et
al
2016
woodworth
et
al
2017
zafar
et
al
2017
where
discrimination
amongst
individuals
or
sections
of
society
can
have
serious
implications
for
those
who
are
discriminated
against
many
approaches
for
developing
fair
classifiers
have
focused
on
removing
bias
from
the
data
that
the
classifier
is
trained
on
hajian
and
domingo-ferrer
2013
kamiran
and
calders
2009
zemel
et
al
2013
or
from
external
resources
such
as
word
embeddings
bolukbasi
et
al
2016
however
the
majority
of
the
literature
on
fair
classification
focuses
on
enforcing
fairness
constraints
in
the
classifier
predictions
for
example
dwork
et
al
2012
calders
and
verwer
2010
pleiss
et
al
2017
woodworth
et
al
2017
zafar
et
al
2017
there
are
two
main
notions
of
fairness
that
classifiers
typically
try
to
integrate
firstly
in
individual
fairness
dwork
et
al
2012
classifier
probability
or
confidence
score
should
be
comparable
for
all
individuals
irrespective
of
the
classification
group
that
they
truly
belong
to
for
example
in
the
case
of
loan
repayment
for
all
subjects
individuals
classification
score
of
0.8
should
represent
the
same
likelihood
of
repayment
irrespective
of
the
actual
class
that
the
subject
belongs
to
the
second
notion
of
fairness
that
is
commonly
enforced
in
classification
systems
is
group
fairness
examples
of
group
fairness
include
statistical
parity
and
balancing
for
the
positive
negative
class
for
statistical
parity
as
in
calders
and
verwer
2010
kamiran
13
information
retrieval
journal
2022
25
26
and
calders
2009
kamishima
et
al
2011
equal
percentages
of
each
of
the
protected
groups
should
be
classified
as
belonging
to
the
positive
class
differently
in
balancing
for
the
positive
negative
class
kleinberg
et
al
2016
the
average
prediction
score
for
the
positive
negative
class
should
be
the
same
for
each
of
the
protected
groups
the
ethical
implications
and
the
potential
effects
on
society
that
arise
from
search
engines
have
been
recognised
for
many
years
see
belkin
and
robertson
1976
variations
in
queries
issued
by
different
demographic
groups
can
result
in
for
example
differences
in
satisfaction
levels
between
older
and
younger
users
mehrotra
et
al
2017
however
there
has
been
much
less
work
on
encoding
or
measuring
fairness
in
search
engines
compared
to
classification
systems
castillo
2018
lately
integrating
fairness
into
ranking
algorithms
has
received
more
attention
in
the
literature
for
example
at
the
inaugural
facts-ir
workshop
olteanu
et
al
2019a
and
the
trec
fair
ranking
track
biega
et
al
2020
indeed
at
the
recent
strategic
workshop
on
information
retrieval
in
lorne
culpepper
et
al
2018
fairness
in
search
systems
was
identified
as
one
of
the
most
important
emerging
topics
for
ir
research
there
are
four
main
differences
in
the
ways
in
which
fairness
is
implemented
and
evaluated
in
search
systems
compared
to
classification
systems
ekstrand
et
al
2019
firstly
evaluating
search
system
requires
user
model
for
example
the
usefulness
of
search
result
can
depend
on
the
other
results
that
user
has
previously
looked
at
moreover
the
probability
that
user
will
view
any
particular
document
will
also
vary
depending
on
the
position
that
the
document
appears
in
the
ranking
and
how
far
down
the
ranked
list
the
user
is
prepared
to
look
for
relevant
documents
secondly
search
queries
can
be
repeated
within
the
same
or
over
multiple
search
sessions
this
provides
an
opportunity
to
compensate
for
any
unfairness
in
the
results
of
previous
instances
of
the
query
thirdly
the
desired
outcome
of
search
system
relevance
or
utility
is
subjective
notion
that
can
be
confounded
by
other
intentions
of
the
system
such
as
the
personalisation
of
results
fourthly
search
engines
have
multiple
sets
of
stakeholders
that
each
have
their
own
fairness
concerns
for
example
information
consumers
users
want
fairness
in
access
to
information
whereas
information
producers
want
fair
opportunity
to
be
discovered
by
users
mehrotra
et
al
2018
most
of
the
work
on
fairness
in
ranking
systems
has
investigated
latent
biases
in
search
engines
white
2013
baeza-yates
2018
de-arteaga
et
al
2019
or
correcting
for
biases
in
learning
to
rank
scenarios
singh
and
joachims
2019
yadav
et
al
2019
morik
et
al
2020
however
recently
there
has
also
been
an
interest
in
developing
ranking
algorithms
that
aim
to
enforce
group
fairness
through
fairness
constraints
that
require
the
ranker
to
assign
certain
portion
of
the
top
rank
positions
to
members
of
protected
or
minority
classes
zehlike
et
al
2017
celis
et
al
2018
singh
and
joachims
2018
differently
from
constraint-based
approaches
which
rely
on
the
protected
groups
being
known
priori
in
this
work
we
propose
to
cast
the
fair
ranking
task
where
the
protected
groups
are
unknown
priori
as
search
results
diversification
task
indeed
gao
and
shah
2020
recently
showed
that
diversity
and
relevance
are
highly
correlated
with
statistical
parity
fairness
identifying
the
most
appropriate
method
of
evaluating
fairness
in
systems
that
output
ranked
results
is
developing
area
of
research
diaz
et
al
2020
early
work
on
developing
fair
ranking
metrics
focused
on
directly
applying
fairness
approaches
from
classification
such
as
statistical
parity
yang
and
stoyanovich
2017
and
group
fairness
sapiezynski
et
al
2019
biega
et
al
2018
proposed
fairness
evaluation
metric
akin
to
evaluating
individual
fairness
dwork
et
al
2012
their
approach
evaluated
position
bias
and
was
modelled
on
the
premises
that
the
attention
of
searchers
13
information
retrieval
journal
2022
25
26
should
be
distributed
fairly
and
information
producers
should
receive
attention
from
users
in
proportion
to
their
relevance
to
given
search
task
to
account
for
the
fact
that
no
single
ranking
can
achieve
individual
fairness
the
authors
introduced
amortized
fairness
where
attention
is
accumulated
over
series
of
rankings
in
this
work
we
are
interested
evaluating
the
fairness
of
the
exposure
that
authors
from
protected
groups
are
likely
to
receive
in
ranking
singh
and
joachims
2018
introduced
the
disparate
treatment
ratio
dtr
and
disparate
impact
ratio
dir
metrics
to
evaluate
such
scenario
therefore
we
select
to
use
these
metrics
to
evaluate
our
proposed
approaches
we
present
full
details
of
dtr
and
dir
in
sect
search
results
diversification
queries
submitted
to
web
search
engine
are
often
short
and
ambiguous
sp√§rck-jones
et
al
2007
therefore
it
is
often
desirable
to
diversify
the
search
results
to
include
relevant
documents
for
multiple
senses
or
aspects
of
the
query
there
are
two
main
families
of
search
result
diversification
approaches
namely
implicit
and
explicit
diversification
implicit
diversification
approaches
for
example
carbonell
and
goldstein
1998
chen
and
karger
2006
wang
and
zhu
2009
radlinski
et
al
2008
assume
that
documents
that
are
similar
in
content
will
cover
the
same
aspects
of
query
such
approaches
increase
the
coverage
of
aspects
in
ranking
by
demoting
to
lower
ranked
documents
that
are
similar
to
higher-ranked
documents
maximal
marginal
relevance
mmr
carbonell
and
goldstein
1998
was
one
of
the
first
implicit
diversification
approaches
mmr
aims
to
increase
the
amount
of
novel
information
in
ranked
list
by
selecting
documents
that
are
dissimilar
to
the
documents
that
have
already
been
selected
for
the
results
list
in
this
work
we
evaluate
mmr
as
fair
ranking
strategy
based
on
implicit
diversification
however
differently
from
when
mmr
is
deployed
for
search
result
diversification
as
in
carbonell
and
goldstein
1998
we
instead
evaluate
the
effectiveness
of
selecting
documents
from
information
sources
that
have
dissimilar
characteristics
we
provide
details
of
how
we
build
on
mmr
in
sect
5.1
explicit
diversification
approaches
santos
et
al
2010
radlinski
and
dumais
2006
agrawal
et
al
2009
dang
and
croft
2012
directly
model
the
query
aspects
with
an
aim
to
maximise
the
coverage
of
aspects
that
are
represented
in
the
search
results
for
example
explicit
query
aspect
diversification
santos
et
al
2010
xquad
uses
query
reformulations
to
represent
possible
information
needs
of
an
ambiguous
query
and
iteratively
generates
ranking
by
selecting
documents
that
maximise
the
novelty
and
diversity
of
the
search
results
dang
and
croft
dang
and
croft
2012
proposed
an
explicit
approach
called
pm-2
that
was
based
on
proportional
representation
the
intuition
of
pm-2
is
that
for
each
aspect
of
an
ambiguous
query
the
number
of
documents
relating
to
the
aspect
that
are
included
in
the
search
results
should
be
proportional
to
the
number
of
documents
relating
to
the
aspect
in
larger
ranked
list
of
documents
that
the
search
results
are
sampled
from
for
example
for
the
query
java
if
10
of
the
documents
in
the
list
of
ranked
documents
that
the
search
results
are
sampled
from
are
about
java
the
island
then
10
of
the
search
results
should
also
be
about
java
the
island
in
this
work
we
build
on
the
xquad
santos
et
al
2010
and
pm-2
dang
and
croft
2012
explicit
diversification
approaches
to
generate
fair
rankings
however
differently
from
the
work
of
santos
et
al
2010
and
dang
and
croft
2012
we
explicitly
diversify
over
the
characteristics
of
assumed
groups
that
we
wish
to
be
fair
to
we
provide
details
of
how
we
leverage
xquad
and
pm-2
in
sect
5.2
castillo
2018
argued
that
search
results
diversification
differs
from
fair
ranking
in
that
the
former
focuses
on
utility
for
the
searcher
while
the
latter
focuses
on
the
utility
of
sources
of
relevant
information
we
agree
that
intuitively
the
tasks
are
different
however
in
this
work
we
postulate
that
fair
rankings
that
also
provide
utility
for
the
search
engine
13
information
retrieval
journal
2022
25
26
table
examples
of
informational
queries
in
the
context
of
academic
search
the
queries
are
topics
from
the
trec
2019
fair
ranking
track
and
are
real
queries
from
the
semantic
scholar
academic
search
engine
roman
chamomile
oil
drones
bystander
effect
positive
psychology
and
academic
performance
cost
management
theory
users
can
be
generated
by
diversifying
over
set
of
assumed
groups
that
we
aim
to
be
fair
to
to
maximise
the
representation
of
such
groups
in
the
search
results
fair
ranking
task
in
this
section
we
introduce
the
fair
ranking
task
and
provide
formal
definition
of
the
problem
as
it
is
set
out
by
the
trec
fair
ranking
track
biega
et
al
2020
2021
as
previously
stated
in
sect
the
task
is
set
within
the
context
of
academic
search
in
response
to
an
informational
query
broder
2002
there
may
be
multiple
relevant
documents
for
each
query
search
system
should
return
ranked
list
of
relevant
published
or
potentially
pre-published
research
papers
table
provides
examples
of
such
informational
queries
in
the
context
of
academic
search
the
queries
presented
in
table
are
queries
from
the
trec
2019
fair
ranking
track
test
collection
biega
et
al
2020
they
are
real
users
queries
from
the
query
logs
of
the
semantic
scholar
academic
search
engine
for
search
system
to
be
fair
to
the
information
producers
for
such
generic
topic-based
queries
the
generated
rankings
should
not
be
dominated
by
single
author
or
institution
moreover
an
author
or
institution
should
not
receive
disproportionately
high
or
low
amount
of
exposure
to
users
over
period
of
time
compared
to
relevant
work
from
other
authors
or
institutions
for
example
adapting
the
simplified
example
from
singh
and
joachims
2018
we
consider
ranking
of
six
documents
that
are
all
judged
to
be
relevant
by
the
search
engine
users
the
authors
of
of
the
documents
are
from
institution
and
the
authors
of
the
other
documents
are
from
institution
the
search
engine
estimated
relevance
scores
for
the
documents
from
institution
are
0.80
0.79
and
0.78
while
the
estimated
relevance
scores
for
the
documents
from
institution
are
0.77
0.76
and
0.75
following
singh
and
joachims
2018
to
allow
meaningful
argument
on
their
relative
difference
we
assume
that
the
estimated
relevance
scores
are
probabilities
if
the
documents
are
ranked
in
accordance
with
the
probability
ranking
principle
robertson
1977
according
to
position
bias
user
model
of
the
dcg
measure
the
exposure
drop-off
of
document
in
other
words
we
expect
users
at
position
in
the
ranking
is
exposure
posj
log
pos
to
start
at
the
top
of
the
ranking
and
consider
the
relevance
of
each
document
in-turn
the
further
down
the
ranking
relevant
document
appears
the
more
likely
it
is
that
user
will
have
stopped
before
reaching
the
relevant
document
in
our
example
ranking
the
documents
from
institution
will
receive
30
less
exposure
than
the
documents
from
institution
however
the
difference
in
average
estimated
relevance
between
the
documents
from
institution
and
institution
is
just
0.03
in
other
words
small
difference
in
estimated
relevance
can
lead
to
large
difference
in
the
exposure
or
opportunity
to
be
seen
by
13
information
retrieval
journal
2022
25
26
fig
illustration
of
exposure
exp
vs
estimated
relevance
est
rel
in
the
context
of
the
fair
ranking
task
where
the
fairness
of
the
search
results
are
evaluated
over
multiple
instances
of
repeated
query
the
users
that
the
documents
receive
moreover
if
the
same
ranking
is
displayed
to
users
each
time
the
query
is
issued
to
the
search
engine
this
disparity
in
exposure
will
increase
over
time
with
this
in
mind
fairness
in
ranking
systems
should
be
evaluated
over
sequences
of
queries
biega
et
al
2018
to
enable
system
to
address
any
potential
unfairness
that
might
have
been
present
in
the
results
of
previous
instance
of
repeated
query
ekstrand
et
al
2019
such
that
the
rankings
are
both
relevant
to
the
users
and
fair
to
the
information
produces
the
fair
ranking
task
addresses
such
scenario
in
response
to
repeated
instances
of
query
fair
ir
system
should
therefore
output
sequence
of
ranked
results
that
balances
the
trade-off
between
maximising
the
relevance
or
utility
of
the
results
for
the
user
and
minimising
any
unfairness
in
the
exposure
that
the
information
producers
get
over
the
sequence
of
queries
in
practice
there
are
three
main
approaches
that
ir
systems
typically
take
for
balancing
this
trade-off
namely
optimising
for
relevance
while
enforcing
fairness
constraints
zehlike
et
al
2017
celis
et
al
2018
deploying
fairness-focused
regularisation
mehrotra
et
al
2018
or
jointly
optimising
for
relevance
and
fairness
mehrotra
et
al
2018
figure
illustrates
how
the
unfair
exposure
that
the
documents
in
our
example
receive
can
be
addressed
within
the
context
of
the
fair
ranking
task
as
illustrated
in
fig
the
first
instance
of
the
query
returns
the
documents
ranked
as
we
previously
described
however
in
subsequent
instances
of
the
query
the
system
tries
to
compensate
for
any
unfairness
of
exposure
by
reordering
the
presentation
of
the
documents
to
the
user
in
our
illustration
after
four
instances
of
the
query
have
been
submitted
to
the
search
engine
the
average
cumulative
exposure
for
institutions
and
is
equal
hence
the
exposure
that
the
two
institutions
receive
are
equal
to
their
relative
relevances
as
judged
by
the
user
it
is
important
to
note
that
in
this
simplified
example
the
groups
that
we
wish
to
be
fair
to
are
known
however
in
the
fair
ranking
task
the
protected
groups
are
unknown
the
fair
ranking
task
is
therefore
defined
as
follows
for
query
qi
with
associated
set
of
candidate
documents
ri
generate
sequence
of
rankings
si
for
repeated
instances
of
the
query
qi
where
ri
is
the
generated
permutation
of
ri
for
the
th
13
10
information
retrieval
journal
2022
25
26
instance
of
qi
such
that
items
that
are
relevant
for
qi
get
fair
exposure
to
users
over
the
sequence
of
rankings
si
the
initial
set
of
candidate
documents
ri
for
the
query
qi
is
the
same
for
every
instance
of
qi
however
the
number
of
candidate
documents
associated
to
different
queries
can
vary
defining
fairness
groups
for
academic
search
fairness
in
this
section
we
provide
details
of
the
assumed
fairness
groups
that
we
propose
to
use
for
generating
fair
rankings
in
the
context
of
academic
search
the
information
sources
that
we
aim
to
be
fair
to
are
the
authors
of
papers
in
particular
we
aim
to
be
fair
to
members
of
sub-groups
of
unknown
groups
of
authors
where
each
group
is
defined
by
certain
demographic
or
characteristic
for
example
gender
grouping
would
include
sub-groups
for
male
authors
and
female
authors
and
potentially
other
additional
sub-groups
depending
on
the
definition
of
the
grouping
in
this
example
male
authors
and
female
authors
should
both
receive
fair
exposure
in
the
ranking
there
are
many
characteristics
of
authors
that
it
may
be
desirable
to
provide
fair
exposure
to
for
example
we
may
wish
to
be
fair
to
the
characteristic
experience
and
ensure
that
the
search
results
provide
fair
exposure
to
the
sub-groups
early
career
researcher
and
highly
experienced
professorial
in
fact
the
available
options
for
selecting
characteristics
or
groups
that
we
would
like
to
be
fair
to
are
potentially
infinite
moreover
there
are
characteristics
of
document
that
can
potentially
be
used
to
uncover
latent
author
characteristics
for
example
the
specific
topics
that
document
is
about
could
be
good
indicator
of
an
author
main
research
interests
therefore
our
approach
to
fairness
is
based
on
defining
fairness
groups
by
identifying
attributes
of
document
document
authors
publication
venue
or
topics
that
have
characteristics
that
we
argue
are
intuitively
desirable
to
be
fair
to
in
the
context
of
academic
search
we
note
that
in
practice
our
assumed
fairness
group
definitions
may
or
may
not
match
the
unknown
protected
groups
indeed
this
is
akin
to
the
official
vs
system
generated
sub-topics
in
search
result
diversification
santos
et
al
2015
to
generate
fair
rankings
with
respect
to
an
assumed
fairness
group
for
each
paper
that
is
to
be
ranked
we
need
list
of
scores
that
represent
the
amount
that
specific
instance
of
document
attribute
an
author
publication
venue
or
topic
represents
characteristic
that
we
wish
to
be
fair
to
experience
in
the
case
of
authors
popularity
exposure
in
the
case
of
publication
venues
or
aboutness
in
the
case
of
topics
high
or
low
score
is
not
intended
as
measure
of
how
good
or
bad
paper
is
but
is
an
indicator
of
how
representative
the
paper
is
of
particular
characteristic
of
an
assumed
fairness
group
for
example
when
considering
topics
each
score
represents
the
probability
that
document
is
about
particular
topic
each
of
our
proposed
approaches
that
we
present
in
this
section
outputs
list
of
such
scores
that
can
be
directly
used
as
an
input
for
each
of
the
diversification
approaches
that
we
present
later
in
sect
in
the
remainder
of
this
section
we
provide
details
of
and
define
our
three
proposed
approaches
for
generating
assumed
fairness
groupings
for
evaluating
the
effectiveness
of
search
results
diversification
for
generating
fair
rankings
in
the
context
of
academic
search
13
11
information
retrieval
journal
2022
25
26
4.1
author
experience
the
first
assumed
fairness
group
that
we
propose
aims
to
provide
fair
exposure
to
authors
that
are
at
different
stages
of
their
careers
early
career
researchers
vs
highly
experienced
researchers
intuitively
this
approach
aims
to
reduce
the
preponderance
of
individual
authors
at
the
top
of
the
ranking
for
given
query
hence
prolific
or
highly
experienced
authors
should
not
overwhelm
other
authors
in
the
ranking
and
relevant
work
that
is
produced
by
early
career
researchers
should
receive
fair
exposure
to
the
users
for
defining
this
fairness
group
we
need
score
to
represent
the
amount
of
experience
that
an
author
has
there
are
many
possible
signals
that
could
be
used
as
proxies
for
estimating
the
amount
of
experience
that
an
author
has
for
example
the
number
and
or
dates
of
the
author
publications
or
the
dates
and
or
trends
of
their
citations
in
this
work
to
estimate
an
author
experience
we
use
the
total
number
of
citations
that
the
author
has
in
the
collection
calculated
as
follows
citations
experience
da
where
is
document
authored
by
in
the
set
of
all
documents
da
that
is
an
author
of
and
citations
is
the
number
of
documents
that
cite
given
document
is
then
represented
as
list
of
author
experience
scores
one
for
each
of
the
authors
of
this
document
representation
can
then
be
used
as
input
to
the
search
results
diversification
approaches
that
we
evaluate
approaches
that
use
our
author
experience
assumed
fairness
group
for
diversification
are
denoted
with
the
subscript
in
sect
in
this
approach
the
group
characteristic
that
we
are
aiming
to
be
fair
to
is
the
authors
experience
and
the
sub-groups
of
this
assumed
fairness
group
gi
ga
are
early
career
researchers
and
highly
experienced
professorial
researchers
authors
with
high
experience
score
are
likely
to
be
more
senior
researchers
that
have
accumulated
more
citations
over
time
4.2
journal
exposure
the
second
assumed
fairness
group
that
we
propose
aims
to
provide
fair
exposure
to
papers
from
different
publication
venues
in
the
corpus
intuitively
this
approach
aims
to
surface
relevant
search
results
from
publication
venues
that
may
usually
be
underrepresented
by
search
systems
for
example
within
the
ir
research
field
the
search
results
for
particular
query
may
be
unfairly
dominated
by
papers
from
conference
proceedings
sigir
and
journals
that
output
lot
of
material
while
other
sources
smaller
journals
or
trec
notebooks
may
be
underrepresented
with
respect
to
their
relevance
or
utility
to
the
user
moreover
it
is
also
the
case
that
papers
that
are
published
in
more
well-known
venues
such
as
the
acm
digital
library
are
likely
to
unfairly
benefit
from
rich-get-richer
dynamics
compared
to
lesser-known
venues
therefore
our
journal
exposure
strategy
aims
to
provide
fair
exposure
to
papers
from
venues
that
are
underrepresented
in
the
search
results
in
this
approach
the
group
characteristic
that
we
are
aiming
to
be
fair
to
is
the
paper
exposure
through
publication
venues
for
given
document
and
the
publication
venues
https://‚Äãdl.‚Äãacm.‚Äãorg/
13
12
information
retrieval
journal
2022
25
26
journals
that
is
published
in
the
journal
coverage
score
coverage
for
venue
is
the
total
number
of
documents
in
the
collection
that
are
published
in
the
coverage
of
the
publication
venue
for
our
proposed
journal
exposure
assumed
fairness
group
is
then
represented
as
list
of
coverage
scores
one
for
each
of
the
venues
that
is
published
in
and
the
list
of
scores
are
input
into
the
diversification
approaches
that
we
evaluate
the
sub-groups
of
this
assumed
fairness
group
gi
ga
that
we
aim
to
be
fair
to
are
low
coverage
and
high
coverage
publication
venues
approaches
that
use
our
journal
exposure
assumed
fairness
group
for
diversification
are
denoted
with
the
subscript
in
sect
4.3
topical
grouping
the
third
and
final
assumed
fairness
group
that
we
propose
aims
to
provide
fair
exposure
to
different
authors
that
publish
papers
on
the
same
research
topics
our
intuition
for
this
grouping
is
that
query
results
may
be
dominated
by
for
example
an
author
that
primarily
publishes
work
on
particularly
popular
sub-topic
of
the
query
this
may
be
problematic
for
broadly
defined
queries
that
can
have
multiple
relevant
sub-topics
as
per
the
examples
that
were
presented
in
table
for
example
for
the
query
interactive
information
retrieval
iir
it
may
be
the
case
that
the
retrieved
results
are
dominated
by
documents
that
discuss
iir
user
studies
moreover
these
results
may
be
further
dominated
by
an
author
that
is
particularly
well-known
for
iir
user
studies
however
other
sub-topics
of
iir
are
also
likely
to
be
relevant
for
example
user
modelling
or
interaction
simulation
and
the
authors
that
publish
in
these
fields
may
be
under-exposed
we
expect
that
diversifying
the
rankings
over
the
topics
that
are
discussed
in
the
retrieved
documents
will
likely
give
more
exposure
to
such
under-exposed
authors
to
account
for
this
potential
disparity
in
exposure
for
different
sub-topics
within
the
relevant
search
results
we
build
on
topic
modelling
approach
to
generate
topical
groupings
based
on
the
textual
content
of
the
documents
we
note
that
our
topical
grouping
may
not
be
the
most
appropriate
approach
for
very
specific
or
narrowly
defined
queries
such
as
when
searcher
is
looking
for
papers
to
cite
however
as
previously
discussed
in
sect
the
majority
of
the
queries
in
the
trec
fair
ranking
task
which
are
from
the
query
logs
of
the
semantic
scholar
academic
search
engine
are
broadly-defined
informational
queries
for
generating
our
topical
groupings
we
use
topic
modelling
approach
to
identify
the
main
latent
topics
that
are
discusses
in
the
documents
text
the
topical
grouping
is
defined
as
the
probability
that
document
discusses
latent
topic
zi
where
is
the
set
of
latent
topics
that
are
discussed
in
all
of
the
documents
in
collection
topic
zi
can
then
be
seen
as
group
characteristic
that
we
wish
to
be
fair
to
in
this
approach
the
group
characteristic
that
we
are
aiming
to
be
fair
to
is
the
topics
that
the
paper
is
about
the
sub-groups
of
this
assumed
fairness
group
gi
ga
are
therefore
the
topics
that
are
discussed
by
the
papers
in
the
collection
with
this
in
mind
when
diversifying
over
topics
document
is
represented
by
its
top
topics
where
the
document
score
for
top
topic
zi
is
zi
the
document
score
for
all
other
topics
that
are
discussed
in
the
in
the
trec
fair
ranking
track
test
collection
each
paper
is
only
published
in
single
venue
therefore
in
this
work
there
is
only
one
non-zero
value
in
the
list
for
each
document
the
size
of
the
list
is
equal
to
the
number
of
publications
venues
in
the
collection
however
in
practice
it
is
often
the
case
that
paper
can
be
available
through
multiple
venues
for
example
through
the
acm
digital
library
and
through
arxiv
our
proposed
approach
handles
such
case
without
any
adaptation
13
13
information
retrieval
journal
2022
25
26
collection
is
in
other
words
each
document
is
associated
with
fixed
number
of
topics
and
the
probability
that
document
discusses
each
of
the
topics
varies
approaches
that
use
our
topical
assumed
fairness
group
for
diversification
are
denoted
with
the
subscript
in
sect
casting
fair
ranking
as
search
results
diversification
as
previously
discussed
in
sect
we
argue
that
generating
fair
ranking
towards
information
sources
can
be
cast
as
search
results
diversification
task
by
viewing
the
characteristics
of
groups
that
we
aim
to
be
fair
to
as
latent
aspects
of
relevance
and
maximising
the
number
of
groups
that
are
represented
within
the
top
rank
positions
of
the
search
results
as
is
the
objective
of
search
results
diversification
in
this
section
we
present
the
three
search
results
diversification
approaches
from
the
literature
that
we
build
on
and
how
we
propose
to
adapt
and
tailor
each
of
them
to
generate
fair
rankings
section
5.1
presents
the
implicit
diversification
approach
that
we
evaluate
while
sect
5.2
presents
the
two
explicit
diversification
approaches
that
we
evaluate
5.1
implicit
diversification
for
fairness
as
our
implicit
diversification
approach
to
fairness
we
leverage
the
well-known
maximal
marginal
relevance
carbonell
and
goldstein
1998
mmr
diversification
approach
at
each
iteration
of
the
algorithm
mmr
selects
from
the
remaining
documents
the
one
with
the
maximal
marginal
relevance
calculated
as
follows
def
mmr
arg
max
sim1
di
max
sim2
di
dj
di
dj
where
is
query
is
ranking
of
the
subset
of
documents
in
the
collection
that
are
candidate
documents
with
respect
to
their
relevance
to
is
the
subset
of
documents
in
that
have
already
been
selected
and
is
the
set
of
documents
in
that
have
not
been
selected
sim1
is
metric
that
measures
the
relevance
of
document
query
and
sim2
is
metric
to
measure
the
similarity
of
document
and
each
of
the
previously
selected
documents
to
leverage
mmr
as
fairness
component
we
define
the
dissimilarity
function
fairsim
for
two
document
representations
ùêùùê¢
and
ùêùùê£
that
are
output
from
one
of
our
proposed
approaches
presented
in
sect
as
follows
ai
aj
ai
aj
fairsim
ùêùùê¢
ùêùùê£
ai
aj
where
ai
aj
is
the
set
of
attributes
that
are
common
to
both
ùêùùê¢
and
ùêùùê£
ai
aj
is
the
absolute
difference
in
the
scores
for
particular
attribute
and
ai
aj
is
the
number
of
attributes
that
are
common
to
ùêùùê¢
and
ùêùùê£
if
di
and
dj
do
not
have
any
common
attributes
then
fairsim
ùêùùê¢
ùêùùê£
fairsim
is
designed
to
identify
to
what
extent
two
documents
represent
the
same
or
similar
fairness
sub-group
of
an
assumed
fairness
group
ga
in
practice
an
attribute
is
an
index
of
that
has
non-zero
value
however
when
deploying
fairsim
ùêùùê¢
ùêùùê£
for
our
author
experience
grouping
we
assume
that
any
index
that
is
nonzero
in
either
ùêùùê¢
or
ùêùùê£
is
non-zero
in
both
ùêùùê¢
and
ùêùùê£
13
information
retrieval
journal
2022
25
26
14
for
example
when
deploying
our
topical
groupings
presented
in
sect
4.3
document
can
discuss
many
topics
user
studies
and
user
modelling
the
score
that
represents
how
much
the
document
is
about
particular
topic
is
the
probability
of
observing
the
topic
given
the
document
di
zi
if
ùêùùê¢
and
ùêùùê£
have
three
common
topics
and
the
topic
scores
for
each
are
ùêùùê¢
0.3
0.3
0.3
and
0.1
fairsim
ùêùùê¢
ùêùùê£
0.3
0.2
0.3
0.2
0.3
0.2
ùêùùê£
0.2
0.2
0.2
then
however
if
the
scores
are
ùêùùê¢
0.3
0.3
0.3
and
ùêùùê£
0.1
0.1
0.1
then
0.2
in
other
words
the
documents
in
the
secfairsim
ùêùùê¢
ùêùùê£
0.3
0.1
0.3
0.1
0.3
0.1
ond
example
are
less
similar
than
the
documents
in
the
first
example
because
there
is
greater
difference
in
how
strongly
they
are
related
to
their
common
topics
in
practice
this
is
could
be
viewed
as
hybrid
approach
as
apposed
to
purely
implicit
diversification
approach
since
instead
of
calculating
the
similarity
over
the
entire
text
of
document
as
in
the
original
mmr
formulation
mmr
calculates
the
documents
similarities
based
on
the
characteristic
scores
that
are
output
from
our
proposed
assumed
fairness
groups
approaches
mmr
then
generates
fair
rankings
by
selecting
the
documents
that
are
most
dissimilar
from
the
previously
selected
documents
with
respect
to
the
characteristics
of
assumed
fairness
groups
5.2
explicit
diversification
for
fairness
the
first
explicit
diversification
approach
that
we
build
on
is
xquad
santos
et
al
2010
xquad
is
probabilistic
framework
for
explicit
search
result
diversification
that
guides
the
diversification
process
of
an
ambiguous
query
through
set
of
sub-queries
each
having
possible
interpretation
for
the
original
query
for
given
query
and
an
initial
ranking
xquad
builds
new
ranking
by
iteratively
selecting
the
highest
scored
document
from
with
the
following
probability
mixture
model
ùúÜp
where
is
the
estimated
relevance
of
document
with
respect
to
the
initial
query
and
is
the
diversity
of
with
respect
to
how
relevant
is
to
the
subtopic
queries
that
are
least
represented
in
xquad
objective
is
to
cover
as
many
of
the
interpretations
of
the
queries
in
the
search
results
while
also
ensuring
novelty
to
generate
fair
rankings
using
xquad
we
leverage
the
fact
that
for
given
sub-query
qi
qi
is
calculated
as
qi
qi
qi
where
qi
is
the
probability
of
document
being
relevant
to
the
sub-query
qi
and
qi
provides
measure
of
novelty
the
probability
of
qi
not
being
satisfied
by
any
of
the
documents
already
selected
in
we
view
the
documents
attributes
authors
publication
venues
or
topics
as
sub-queries
and
document
attribute
characteristic
score
as
measure
of
the
attribute
fairness
sub-group
coverage
we
then
calculate
the
relevance
and
novelty
of
document
with
respect
to
fairness
sub-group
gi
as
follows
gi
gi
gi
10
where
gi
is
the
probability
of
document
being
associated
to
the
group
gi
and
of
gi
not
being
associated
to
any
of
the
documents
already
gi
is
the
probability
selected
in
gi
is
obtained
using
gi
while
gi
is
directly
observable
13
15
information
retrieval
journal
2022
25
26
in
other
words
xquad
iteratively
adds
documents
to
by
prioritising
documents
that
belong
to
assumed
fairness
sub-groups
that
have
relatively
few
documents
belonging
to
them
gi
and
documents
that
belong
to
fairness
sub-groups
that
do
not
have
many
documents
belonging
to
them
in
the
partially
constructed
ranking
gi
for
example
when
deploying
our
topical
assumed
fairness
groups
if
there
are
relatively
few
documents
that
belong
to
the
latent
topic
interaction
simulation
then
these
documents
will
be
prioritised
for
selection
unless
relatively
many
of
the
documents
that
have
previously
been
selected
for
also
belong
to
this
assumed
fairness
group
in
that
case
documents
that
belong
to
another
less
rare
but
underrepresented
group
will
be
prioritised
in
doing
so
the
coverage
of
the
assumed
fairness
groups
is
maximised
in
the
top
rank
positions
by
promoting
documents
that
belong
to
underrepresented
groups
we
now
move
on
to
discuss
the
second
explicit
diversification
approach
that
we
build
on
for
generating
fair
rankings
namely
pm-2
dang
and
croft
2012
pm-2
is
proportional
representation
approach
that
aims
to
generate
useful
and
diversified
ranked
list
of
search
results
of
any
given
size
by
sampling
documents
from
larger
list
of
documents
that
have
been
ranked
with
respect
to
their
relevance
to
user
query
the
aim
of
pm-2
is
to
generate
list
of
search
results
in
which
the
number
of
documents
relating
to
query
aspect
ai
that
are
included
in
the
search
results
are
proportional
to
the
number
of
documents
relating
to
the
aspect
in
the
larger
list
of
documents
that
the
search
results
are
sampled
from
in
other
words
for
the
query
java
if
90
of
the
documents
in
the
larger
ranked
list
of
documents
are
about
java
the
island
then
90
of
the
search
results
should
also
be
about
the
island
pm-2
selects
documents
to
add
to
the
ranking
as
follows
qa
dj
ai
qa
dj
ai
11
vi
vi
is
the
number
of
documents
that
discuss
aspect
ai
si
is
the
number
where
qa
is
2s
of
rank
positions
that
are
assigned
to
ai
proportional
to
the
popularity
of
ai
in
the
larger
list
of
documents
that
the
search
results
are
sampled
from
dj
ai
is
document
fairness
characteristic
score
for
aspect
ai
and
ai
is
an
aspect
that
has
already
been
selected
for
when
generating
fair
rankings
with
pm-2
we
view
the
documents
attributes
as
the
query
aspects
ai
we
view
the
proportionality
of
an
aspect
ai
as
the
fraction
of
documents
in
the
whole
document
collection
that
also
contain
the
aspect
and
replace
vi
in
equation
11
with
the
probability
ai
of
the
aspect
ai
in
the
collection
the
fraction
of
documents
in
the
collection
that
contain
ai
in
other
words
for
each
of
the
attributes
in
an
assumed
fairness
group
in
turn
documents
that
have
relatively
large
characteristic
score
for
that
attribute
but
also
have
characteristic
scores
for
many
attributes
are
prioritised
for
selection
in
the
ranking
until
the
allocated
portion
of
the
ranking
proportional
to
the
frequency
of
the
attribute
in
the
entire
collection
is
filled
by
documents
that
contain
ai
as
consequence
this
ensures
the
promotion
of
documents
that
contain
group
fairness
attributes
which
are
underrepresented
with
respect
to
their
proportionality
in
the
collection
experimental
setup
in
this
section
we
present
our
experimental
setup
for
evaluating
the
effectiveness
of
leveraging
search
results
diversification
to
generate
fair
rankings
of
search
results
we
aim
to
answer
the
following
research
questions
13
information
retrieval
journal
2022
25
26
16
table
per-query
statistics
for
relevant
and
non-relevant
candidate
documents
for
the
2019
and
2020
trec
fair
ranking
track
evaluation
queries
2019
collection
max
min
2020
collection
mean
std
max
min
mean
std
relevant
20
3.35
1.50
14
3.48
2.43
non-relevant
all
candidate
documents
25
32
2.48
6.83
3.48
2.73
299
312
10
20.58
24.07
22.66
23.66
rq1
is
leveraging
search
results
diversification
as
fairness
component
effective
for
generating
fair
rankings
rq2
which
family
of
search
results
diversification
explicit
vs
implicit
is
most
effective
as
fairness
component
rq3
does
diversifying
over
multiple
assumed
fairness
groupings
results
in
increased
fairness
we
evaluate
our
research
questions
on
the
test
collections
of
the
2019
and
2020
trec
fair
ranking
tracks
as
previously
stated
in
sect
it
is
appropriate
to
evaluate
the
fairness
of
an
ir
system
over
sequence
of
possibly
repeating
queries
to
allow
the
system
to
correct
for
any
potential
unfairness
in
the
results
of
previous
query
instances
the
trec
fair
ranking
track
is
designed
to
evaluate
such
scenario
within
the
context
of
an
academic
search
application
the
2019
and
2020
fair
ranking
track
test
collections
both
consist
of
documents
academic
paper
abstracts
sampled
from
the
semantic
scholar
s2
open
corpus
ammar
et
al
2018
from
the
allen
institute
for
artificial
intelligence
along
with
training
and
evaluation
queries
both
of
the
collections
are
constructed
from
the
same
7903
document
abstracts
however
each
of
the
collections
have
different
set
of
queries
the
approaches
that
we
evaluate
in
this
work
are
all
unsupervised
approaches
therefore
we
use
the
evaluation
queries
from
each
of
the
collections
the
task
is
setup
as
re-ranking
task
where
each
of
the
queries
has
an
associated
set
of
candidate
document
with
relevance
judgements
and
fairness
group
ground
truth
labels
the
number
of
candidate
documents
that
are
to
be
re-ranked
varies
per-query
ranging
from
to
312
table
provides
statistics
about
the
per-query
candidate
documents
for
the
evaluation
collections
there
are
4040
documents
that
have
relevance
judgements
for
the
635
evaluation
queries
of
the
2019
collection
and
4693
documents
have
relevance
judgements
for
the
200
evaluation
queries
of
the
2020
collection
in
our
experiments
we
evaluate
our
approaches
over
100
instances
of
each
of
the
queries
the
collections
include
relevance
assessments
for
two
unknown
evaluation
fairness
groups
the
groups
were
not
known
by
the
track
participants
and
did
not
influence
our
proposed
fairness
approaches
both
of
the
evaluation
fairness
groups
define
sub-groups
that
system
should
be
fair
to
the
first
evaluation
group
is
the
h-index
of
paper
authors
this
evaluation
group
evaluates
if
system
gives
fair
exposure
to
papers
that
have
authors
from
low
h-index
sub-group
h-index
15
and
high
h-index
sub-group
https://‚Äãallen‚Äãai.‚Äãorg/
13
17
information
retrieval
journal
2022
25
26
h-index
15
the
second
evaluation
group
is
the
international
monetary
fund7
imf
economic
development
level
of
the
countries
of
the
authors
affiliations
the
sub-groups
that
this
group
evaluates
if
system
gives
fair
exposure
to
are
papers
that
have
authors
from
less
developed
countries
and
more
developed
countries
for
the
h-index
and
imf
evaluation
groups
paper
can
have
authors
from
both
of
the
defined
sub-groups
in
this
case
in
our
experiments
we
assign
the
paper
to
the
low
h-index
sub-group
or
the
less
developed
country
sub-group
and
not
to
the
high
h-index
sub-group
or
the
more
developed
country
sub-group
for
example
in
the
case
of
the
h-index
fairness
sub-group
if
paper
has
three
authors
and
the
h-indices
of
the
three
authors
are
and
20
then
the
paper
is
assigned
to
the
low
h-index
fairness
sub-group
in
the
ground
truth
since
at
least
one
of
the
authors
has
an
h-index
of
15
as
noted
by
biega
et
al
2020
identifying
fairness
groups
for
generating
ground
truth
evaluation
is
difficult
task
since
attributes
of
the
authors
such
as
gender
or
prestige
are
not
readily
available
nevertheless
the
trec
fair
ranking
track
collections
despite
their
limitations
are
currently
the
only
public
ir
test
collections
that
enable
us
to
evaluate
approaches
for
this
emerging
and
important
culpepper
et
al
2018
topic
in
ir
to
index
the
corpus
we
use
the
terrier
org
information
retrieval
ir
platform
v5
macdonald
et
al
2012
ounis
et
al
2006
and
apply
standard
stopword
removal
and
porter
stemming
we
deploy
the
dph
he
et
al
2008
parameter
free
document
weighting
model
from
the
divergence
from
randomness
dfr
framework
as
relevance-oriented
baseline
there
is
no
explicit
fairness
component
deployed
in
this
approach
denoted
as
dph
in
sect
moreover
we
use
the
relevance
scores
from
the
dph
baseline
approach
as
the
relevance
component
for
each
of
the
diversification
approaches
that
we
evaluate
as
our
metrics
we
report
the
mean
disparate
treatment
ratio
denoted
as
dtr
and
mean
disparate
impact
ratio
denoted
as
dir
that
were
proposed
by
singh
and
joachims
2018
dtr
and
dir
measure
how
much
sequence
of
rankings
violates
the
disparate
treatment
and
disparate
impact
constraints
that
we
introduced
in
sect
respectively
for
two
groups
g0
and
g1
dtr
measures
the
extent
that
the
groups
exposures
are
proportional
to
their
utility
for
given
query
and
doubly
stochastic
matrix
that
estimates
the
probability
of
each
candidate
document
being
ranked
at
each
rank
position
over
distribution
of
rankings
that
have
maximal
utility
see
singh
and
joachims
2018
for
full
details
of
how
is
computed
dtr
is
defined
as
dtr
g0
g1
exposure
g0
g0
exposure
g1
g1
12
where
the
utility
of
group
gk
is
calculated
as
the
sum
of
the
binary
relevances
of
each
of
the
documents
di
in
gk
and
is
defined
as
gk
ui
gk
di
gk
13
following
singh
and
joachims
2018
we
estimate
the
exposure
drop-off
of
document
at
position
posj
in
ranking
using
the
position
bias
user
model
of
dcg
j√§rvelin
and
kek√§l√§inen
2002
exposure
posj
log
pos
https://‚Äãwww.‚Äãimf.‚Äãorg
the
threshold
imf
economic
development
level
that
was
used
to
separate
countries
into
less
or
more
developed
has
not
been
disclosed
by
the
trec
fair
ranking
track
organisers
13
information
retrieval
journal
2022
25
26
18
dir
measures
the
contribution
of
each
of
group
members
documents
to
the
overall
utility
of
the
group
defined
as
dir
g0
g1
ctr
g0
g0
ctr
g1
g1
14
where
ctr
is
the
sum
of
the
expected
click-through
rates
of
the
documents
in
group
gk
and
the
click-through
rate
of
document
di
is
estimated
as
exposure
di
di
is
relevant
for
dtr
and
dir
value
of
shows
that
both
of
the
groups
have
proportionate
exposure
and
impact
respectively
within
the
generated
rankings
values
less
than
or
greater
than
show
the
amount
that
one
of
the
groups
is
being
disadvantaged
by
the
rankings
with
respect
to
the
utility
relevance
of
the
documents
in
the
group
we
note
again
here
that
the
number
of
candidate
documents
that
are
associated
to
query
varies
on
per-query
basis
therefore
the
size
of
the
ranking
and
the
depth
to
which
dtr
and
dir
is
calculated
also
varies
per-query
to
test
for
statistical
significance
we
use
the
paired
t-test
over
all
of
the
query
instances
we
select
0.05
as
our
significance
threshold
and
apply
bonferroni
correction
dunn
1961
to
adjust
for
multiple
comparisons
approaches
that
perform
significantly
better
than
the
next
best
performing
system
with
the
same
assumed
fairness
groups
configuration
for
an
individual
metric
dtr
are
denoted
with
for
example
for
the
systems
that
diversify
over
the
author
experience
and
topical
assumed
fairness
groups
together
denoted
by
subscript
at
system
is
compared
with
the
next
best
performing
system
in
pairwise
manner
pm2at
vs
mmrat
the
specific
metric
dtr
if
there
is
significant
difference
in
the
systems
performance
then
the
best
performing
system
is
denoted
by
approaches
that
perform
significantly
better
than
the
dph
relevance-only
approach
for
an
individual
metric
are
denoted
with
results
in
this
section
we
report
the
results
of
our
experiments
when
evaluating
the
effectiveness
of
our
proposed
approaches
we
are
primarily
concerned
with
the
suitability
of
search
results
diversification
for
generating
rankings
that
provide
fair
exposure
to
unknown
protected
groups
in
other
words
protected
group
should
receive
an
exposure
that
is
proportional
to
the
average
relevance
of
the
group
with
respect
to
user
query
with
this
in
mind
the
metrics
that
we
report
in
this
section
namely
disparate
treatment
ratio
dtr
and
disparate
impact
ratio
dir
consider
the
exposure
that
the
authors
of
papers
from
the
sub-groups
of
protected
group
receive
in
proportion
to
the
relevance
utility
of
the
papers
it
is
important
to
note
that
for
both
of
the
metrics
dtr
and
dir
protected
group
has
two
sub-groups
low
h-index
and
high
h-index
and
score
of
1.0
denotes
that
both
of
the
sub-groups
receive
an
exposure
that
is
proportional
to
the
utility
relevance
of
the
documents
in
the
sub-group
values
less
than
or
greater
than
show
that
one
of
the
sub-groups
is
disadvantaged
by
the
rankings
with
respect
to
the
utility
relevance
of
the
documents
in
the
sub-group
table
presents
the
performance
of
our
diversification
approaches
for
fair
rankings
namely
mmr
xquad
and
pm-2
with
each
of
our
assumed
fairness
groups
author
experience
denoted
as
journal
exposure
denoted
as
and
topics
denoted
as
individually
and
combined
the
table
presents
each
of
the
proposed
approaches
performance
in
13
19
information
retrieval
journal
2022
25
26
table
mean
disparate
treatment
ratio
dtr
and
mean
disparate
impact
ratio
dir
for
each
of
the
approaches
the
h-index
and
imf
evaluation
groups
of
the
2019
and
2020
trec
fair
ranking
track
test
collections
2019
2020
h-index
dtr
imf
h-index
imf
dir
dtr
dir
dtr
dir
dtr
dir
1.99
1.61
0.28
0.44
0.32
1.91
3.76
0.61
4.90
1.99
0.88
0.28
1.43
0.48
0.44
2.04
0.91
1.91
1.10
1.01
0.47
0.45
single
groupings
mmra
5.63
xquada
5.24
pm2a
5.51
mmrj
5.38
xquadj
5.61
2.03
pm2j
5.60
2.05
0.84
0.30
mmrt
5.72
2.02
0.29
xquadt
5.37
2.04
0.91
1.00
5.66
paired
groupings
mmraj
5.34
2.02
0.92
0.29
2.04
0.77
0.29
pm2t
xquadaj
5.20
2.06
2.07
pm2aj
5.51
2.05
mmrat
5.43
2.02
xquadat
5.24
2.06
pm2at
5.49
2.01
mmrjt
5.31
2.05
xquadjt
5.22
2.05
pm2jt
5.52
2.05
5.33
2.05
5.17
2.07
5.51
no
fairness
component
dph
7.99
random
8.14
all
groupings
mmrajt
xquadajt
pm2ajt
0.73
0.73
0.80
0.61
0.82
0.29
0.29
0.29
0.32
0.30
0.29
0.32
0.28
0.79
0.29
0.68
0.30
0.74
0.30
0.76
0.29
0.75
0.31
2.05
0.73
0.30
4.05
3.03
1.19
1.39
0.11
0.21
4.77
4.95
1.99
1.99
1.43
5.14
1.95
1.42
5.25
1.96
1.51
5.00
1.95
1.54
4.68
4.48
0.47
0.45
0.45
1.96
1.54
5.00
1.95
1.51
0.45
4.65
1.97
1.19
0.47
4.73
2.00
1.20
0.48
5.13
1.96
1.31
4.81
1.94
1.39
0.47
0.45
4.77
1.99
4.62
1.93
4.61
4.73
1.10
0.49
0.45
1.99
1.16
1.96
1.18
0.47
0.46
5.13
1.96
1.29
0.47
4.63
1.98
1.19
0.47
4.60
2.00
1.13
0.47
5.13
1.96
1.31
0.47
6.83
7.37
3.92
2.91
2.19
1.97
0.18
0.33
1.31
the
table
show
the
results
for
each
of
our
assumed
fairness
groups
author
experience
journal
exposure
and
topical
groups
also
included
are
our
dph
relevance-only
baseline
and
random
permutation
of
the
result
set
where
is
the
candidate
set
of
documents
that
have
been
returned
by
the
relevance
only
retrieval
model
denoted
as
random
for
each
metric
approaches
that
are
significantly
better
than
the
next
best
performing
system
with
the
same
assumed
fairness
groups
configuration
pm2at
vs
mmrat
are
denoted
as
while
approaches
that
perform
significantly
better
than
the
relevance-only
dph
approach
are
denoted
as
terms
of
dtr
and
dir
each
of
the
official
trec
evaluation
groups
namely
h-index
and
imf
economic
level
denoted
as
imf
for
the
2019
and
2020
trec
fair
ranking
track
collections
in
addition
the
table
shows
the
results
of
our
dph
relevance-only
13
20
information
retrieval
journal
2022
25
26
baseline
and
random
permutation
of
the
result
set
returned
by
the
relevance-only
model
denoted
as
random
firstly
addressing
rq1
we
are
interested
in
whether
leveraging
search
results
diversification
as
fairness
component
is
effective
for
generating
fair
rankings
we
note
from
table
that
all
of
our
proposed
fair
diversification
approaches
result
in
fairer
exposure
for
the
authors
of
relevant
documents
than
both
the
relevance-only
dph
approach
and
the
random
permutation
approach
in
terms
of
dtr
and
dir
for
both
of
the
evaluation
fairness
groups
h-index
and
imf
on
both
the
2019
and
the
2020
collections
moreover
twelve
of
the
twenty
one
approaches
that
we
evaluate
result
in
significantly
fairer
levels
of
exposure
for
the
h-index
evaluation
fairness
grouping
on
the
2019
collection
and
both
of
the
evaluation
groupings
on
the
2020
collection
in
terms
of
dtr
and
dir
0.05
denoted
as
in
table
all
of
the
diversification
approaches
for
fairness
that
we
evaluate
in
this
work
use
our
dph
approach
for
estimating
relevance
this
shows
that
for
the
diversification
approaches
that
we
evaluate
leveraging
diversification
to
integrate
fairness
component
into
the
rankings
strategy
does
indeed
lead
to
protected
groups
receiving
fairer
exposure
that
is
more
in-line
with
their
utility
or
relevance
therefore
in
response
to
rq1
we
conclude
that
diversifying
over
assumed
fairness
groupings
can
indeed
result
in
fairer
rankings
when
the
actual
protected
groups
are
not
known
moving
to
rq2
which
addresses
which
of
the
families
of
search
results
diversification
implicit
or
explicit
is
the
most
effective
for
deploying
as
fairness
component
in
terms
of
dtr
xquad
explicit
diversification
consistently
results
in
rankings
that
are
the
fairest
in
terms
of
ensuring
that
protected
group
receives
an
exposure
proportional
to
the
overall
utility
of
the
documents
from
the
group
this
observation
is
true
when
xquad
is
deployed
on
either
of
the
2019
or
2020
collections
and
evaluated
for
either
of
the
evaluation
fairness
groupings
h-index
or
imf
on
the
2019
collection
xquadj
achieves
5.20
dtr
for
the
h-index
evaluation
grouping
and
xquadt
achieves
perfect
1.00
dtr
for
the
imf
evaluation
grouping
on
the
2020
collection
xquadt
achieves
4.48
dtr
for
the
h-index
evaluation
grouping
while
xquada
and
xquadat
both
achieve
1.10
dtr
for
the
imf
evaluation
grouping
we
note
that
the
1.10
dtr
achieved
by
xquada
and
xquadat
for
the
imf
fairness
grouping
on
the
2020
collection
is
49.7
increase
in
fairness
of
exposure
compared
to
the
2.19
dtr
of
the
dph
relevance-only
approach
when
deployed
on
the
2020
fair
ranking
collection
the
xquad
approaches
perform
significantly
better
in
terms
of
dtr
than
the
next
best
performing
diversification
approach
deployed
with
the
same
assumed
fairness
groupings
denoted
as
in
table
for
the
h-index
evaluation
group
xquadt
achieves
4.48
dtr
while
pm2t
and
mmrt
only
achieve
5.00
dtr
for
the
imf
evaluation
group
xquadat
achieves
1.10
dtr
while
pm2at
only
achieves
1.31
dtr
moreover
xquada
achieves
1.10
dtr
while
pm2a
only
achieves
1.43
dtr
however
we
note
that
in
terms
of
dtr
the
differences
between
diversification
approaches
that
are
deployed
with
the
same
assumed
fairness
groupings
are
not
significant
when
the
approaches
are
deployed
on
the
2019
trec
fair
ranking
track
collection
turning
our
attention
to
how
well
explicit
and
implicit
diversification
approaches
perform
in
terms
of
dir
we
note
from
table
that
there
is
no
approach
that
consistently
performs
best
for
both
of
the
evaluation
groups
or
on
both
of
the
trec
fair
ranking
note
that
the
size
of
is
equal
to
the
number
of
candidate
documents
that
are
associated
to
query
and
varies
on
per-query
basis
13
information
retrieval
journal
2022
25
26
21
collections
for
the
h-index
evaluation
grouping
mmra
and
pm2a
achieve
the
best
dir
score
for
on
the
2019
and
2020
collections
achieving
1.99
dir
and
1.91
dir
respectively
however
the
approaches
are
not
significantly
better
than
the
2.06
dir
2019
and
1.99
2020
dir
that
is
achieved
by
xquada
for
the
imf
evaluation
grouping
on
the
2019
collection
xquadaj
and
xquadat
are
the
best
performing
approaches
and
achieve
0.32
dir
however
they
do
not
perform
significantly
better
than
the
mmr
or
pm2
approaches
in
terms
of
dir
moreover
notably
none
of
the
fair
diversification
approaches
actually
perform
significantly
better
than
the
dph
relevance-only
approach
or
the
random
approach
for
the
imf
evaluation
grouping
on
the
2019
collection
when
deployed
on
the
2020
collection
xquadat
performs
best
in
terms
of
dir
for
the
imf
evaluation
grouping
0.49
dir
however
xquadat
is
not
significantly
better
than
mmrat
or
pm2a
in
terms
of
dir
for
the
imf
evaluation
grouping
on
the
2020
collection
these
findings
provide
some
evidence
that
from
the
approaches
that
we
evaluate
explicit
search
results
diversification
is
potentially
the
more
viable
diversification
approach
for
developing
fair
ranking
strategies
within
an
academic
search
context
this
finding
is
supported
by
the
observation
that
xquad
explicit
search
results
diversification
is
consistently
the
best
performing
approach
in
terms
of
dtr
for
both
of
the
evaluation
fairness
groupings
when
deployed
on
either
of
the
trec
fair
ranking
track
collections
therefore
in
response
to
rq2
we
conclude
that
explicit
search
results
diversification
appears
to
be
the
most
effective
approach
within
an
academic
search
context
for
ensuring
that
protected
groups
receive
fair
exposure
that
is
proportional
to
their
utility
relevance
to
the
users
as
is
measured
by
dtr
however
more
work
needs
to
be
done
to
identify
what
is
the
most
effective
diversification
approach
for
ensuring
that
each
of
the
members
of
protected
group
contribute
proportionate
amount
of
gain
to
the
protected
group
overall
exposure
the
individual
exposure
of
each
of
the
members
of
the
protected
group
as
is
measured
by
dir
lastly
addressing
rq3
we
conclude
that
on
our
experiments
diversifying
over
multiple
assumed
fairness
groups
does
not
lead
to
increased
fairness
as
can
be
seen
from
the
numbers
in
bold
in
table
three
out
of
the
four
best
performing
approaches
in
terms
of
dtr
diversify
over
single
assumed
fairness
group
namely
xquadt
for
the
imf
evaluation
grouping
on
the
2019
collection
and
for
the
h-index
evaluation
grouping
on
the
2020
collection
and
xquada
for
the
imf
grouping
on
the
2020
collection
moreover
in
terms
of
dir
mmra
and
pm2a
achieve
the
best
scores
for
the
h-index
evaluation
grouping
on
both
the
2019
and
2020
collection
the
remaining
best
performing
approaches
namely
xquadaj
and
xquadat
both
diversify
over
two
assumed
fairness
groups
however
none
of
the
approaches
perform
best
for
any
of
the
evaluation
fairness
groupings
of
trec
collections
when
they
diversify
over
all
three
assumed
fairness
groups
this
suggests
that
further
work
is
needed
to
adequately
integrate
multiple
assumed
fairness
groups
in
diversification
approach
we
expect
that
explicitly
diversifying
across
multiple
dimensions
yigit-sert
et
al
2021
of
the
groups
will
improve
this
however
we
leave
this
interesting
area
of
research
to
future
work
finally
we
note
that
in
our
experiments
diversifying
over
the
documents
authors
experience
seems
to
be
particularly
promising
approach
for
generating
fair
ranking
strategies
in
academic
search
five
of
the
six
best
performing
diversification
approaches
in
terms
of
dtr
and
dir
diversify
over
this
assumed
fairness
group
either
as
single
group
or
in
combination
with
one
other
assumed
fairness
group
mmra
xquada
pm2a
xquadaj
and
xquadat
we
note
however
that
our
approach
for
calculating
an
author
experience
is
only
first
reasonable
attempt
to
model
this
assumed
fairness
grouping
and
13
22
information
retrieval
journal
2022
25
26
there
remains
room
for
improvement
for
example
it
is
possible
that
when
lesser
known
researcher
is
an
author
on
very
highly
cited
paper
such
as
resource
paper
this
will
potentially
skew
the
system
view
of
the
author
experience
moreover
we
note
that
our
experiments
only
investigate
the
exposure
that
the
groups
receive
for
single
browsing
model
in
practice
variations
in
users
browsing
behaviour
will
potentially
lead
to
varying
exposures
for
individual
papers
and
authors
and
for
the
overall
group
that
the
paper
and
or
author
belong
to
furthermore
the
diversification
approaches
that
we
evaluate
in
this
work
are
deterministic
processes
next
logical
step
in
developing
diversification
approaches
for
fairness
would
seem
to
be
to
introduce
non-deterministic
element
to
proactively
compensate
for
the
under
or
over
exposure
of
protected
groups
however
we
leave
the
investigation
of
these
interesting
questions
to
future
work
conclusions
in
this
work
we
proposed
to
cast
the
task
of
generating
rankings
that
provide
fair
exposure
to
unknown
protected
groups
of
authors
as
search
results
diversification
task
we
leveraged
three
well-known
search
results
diversification
models
from
the
literature
as
fair
ranking
strategies
moreover
we
proposed
to
adapt
search
results
diversification
to
diversify
the
search
results
with
respect
to
multiple
assumed
fairness
group
definitions
such
as
early-career
researchers
vs
highly-experienced
authors
our
experiments
on
the
2019
and
2020
trec
fair
ranking
track
datasets
showed
that
leveraging
adequately
tailored
search
results
diversification
can
be
an
effective
approach
for
generating
fair
rankings
within
the
context
of
academic
search
moreover
we
found
that
explicit
search
results
diversification
performed
better
than
implicit
diversification
for
providing
fair
exposure
for
protected
author
groups
while
ensuring
that
the
group
exposure
is
in-line
with
the
utility
or
relevance
of
the
groups
papers
in
terms
of
disparate
treatment
ratio
dtr
xquad
explicit
search
results
diversification
was
the
most
effective
approach
for
generating
fair
rankings
both
of
the
trec
fair
ranking
track
evaluation
groupings
h-index
and
imf
when
the
approach
was
deployed
on
either
of
the
2019
or
2020
collections
this
work
has
provided
an
in-depth
analysis
of
how
search
results
diversification
can
be
effective
as
an
approach
for
addressing
the
important
topic
of
ensuring
fairness
of
exposure
in
the
results
of
search
systems
the
search
results
diversification
literature
is
very
broad
ranging
and
although
diversification
is
not
the
same
task
as
fairness
of
exposure
there
are
potentially
many
other
interesting
and
useful
approaches
that
can
build
on
the
similarities
between
the
tasks
to
improve
the
exposure
of
disadvantaged
or
under-represented
societal
groups
within
the
results
of
search
engines
in
summary
this
work
has
provided
foundation
on
which
future
work
on
integrating
fairness
into
ir
systems
and
in-particular
diversification-based
approaches
can
build
on
as
this
emerging
field
continues
to
develop
acknowledgements
we
wish
to
thank
the
associate
editor
and
the
three
peer
reviewers
for
their
thorough
comments
and
helpful
suggestions
funding
not
applicable
availability
of
data
and
material
the
datasets
are
available
from
the
trec
fair
ranking
track
nist
usa
our
assumed
fairness
groups
can
be
directly
calculated
from
the
datasets
code
availability
all
of
the
diversification
approaches
that
we
leverage
are
in
the
public
domain
13
information
retrieval
journal
2022
25
26
23
declarations
conflict
of
interest
none
open
access
this
article
is
licensed
under
creative
commons
attribution
4.0
international
license
which
permits
use
sharing
adaptation
distribution
and
reproduction
in
any
medium
or
format
as
long
as
you
give
appropriate
credit
to
the
original
author
and
the
source
provide
link
to
the
creative
commons
licence
and
indicate
if
changes
were
made
the
images
or
other
third
party
material
in
this
article
are
included
in
the
article
creative
commons
licence
unless
indicated
otherwise
in
credit
line
to
the
material
if
material
is
not
included
in
the
article
creative
commons
licence
and
your
intended
use
is
not
permitted
by
statutory
regulation
or
exceeds
the
permitted
use
you
will
need
to
obtain
permission
directly
from
the
copyright
holder
to
view
copy
of
this
licence
visit
http://‚Äãcreat‚Äãiveco‚Äãmmons.‚Äãorg/‚Äãlicen‚Äãses/‚Äãby/4.‚Äã0/.
references
abebe
barocas
kleinberg
levy
raghavan
robinson
2020
roles
for
computing
in
social
change
in
proceedings
of
the
fat
conference
on
fairness
accountability
and
transparency
barcelona
spain
january
27
30
2020
acm
pp
252
260
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1145/‚Äã
33510
95
33728
71
agrawal
gollapudi
halverson
ieong
2009
diversifying
search
results
in
proceedings
of
the
second
international
conference
on
web
search
and
web
data
mining
wsdm
2009
barcelona
spain
february
11
2009
acm
pp
14
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1145/‚Äã14987‚Äã59.‚Äã14987‚Äã66.
ammar
groeneveld
bhagavatula
beltagy
crawford
downey
dunkelberger
elgohary
feldman
ha
kinney
kohlmeier
lo
murray
ooi
peter
power
skjonsberg
wang
wilhelm
yuan
van
zuylen
etzioni
2018
construction
of
the
literature
graph
in
semantic
scholar
in
proceedings
of
the
2018
conference
of
the
north
american
chapter
of
the
association
for
computational
linguistics
human
language
technologies
naacl-hlt
2018
new
orleans
louisiana
usa
june
2018
volume
industry
papers
association
for
computational
linguistics
pp
84
91
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã18653/‚Äãv1/‚Äãn18-‚Äã3011.
baeza-yates
2018
bias
on
the
web
communication
in
acm
61
54
61
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1145/‚Äã
32095
81
belkin
robertson
1976
some
ethical
implications
of
theoretical
research
in
information
science
inthe
asis
annual
meeting
bender
gebru
mcmillan-major
shmitchell
2021
on
the
dangers
of
stochastic
parrots
can
language
models
be
too
big
in
proceedings
of
the
facct
21
2021
acm
conference
on
fairness
accountability
and
transparency
virtual
event
toronto
canada
march
10
2021
acm
pp
610
623
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1145/‚Äã34421‚Äã88.‚Äã34459‚Äã22.
biega
gummadi
weikum
2018
equity
of
attention
amortizing
individual
fairness
in
rankings
in
proceedings
of
the
41st
international
acm
sigir
conference
on
research
development
in
information
retrieval
sigir
2018
ann
arbor
mi
usa
july
08
12
2018
acm
pp
405
414
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1145/‚Äã32099‚Äã78.‚Äã32100‚Äã63.
biega
diaz
ekstrand
kohlmeier
2020
overview
of
the
trec
2019
fair
ranking
track
corr
arxiv
abs
2003
11650
biega
diaz
ekstrand
feldman
kohlmeier
2021
overview
of
the
trec
2020
fair
ranking
track
corr
arxiv
abs
2108
05135
bolukbasi
chang
zou
saligrama
kalai
2016
man
is
to
computer
programmer
as
woman
is
to
homemaker
debiasing
word
embeddings
in
proceedings
of
the
advances
in
neural
information
processing
systems
29
annual
conference
on
neural
information
processing
systems
2016
december
10
2016
barcelona
spain
pp
4349
4357
broder
2002
taxonomy
of
web
search
sigir
forum
36
10
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1145/‚Äã
792550
792552
calders
verwer
2010
three
naive
bayes
approaches
for
discrimination-free
classification
data
mining
and
knowledge
discovery
21
277
292
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1007/‚Äãs10618-‚Äã010-‚Äã0190-x
carbonell
goldstein
1998
the
use
of
mmr
diversity-based
reranking
for
reordering
documents
and
producing
summaries
in
proceedings
of
the
21st
annual
international
acm
sigir
conference
on
research
and
development
in
information
retrieval
august
24
28
1998
melbourne
australia
acm
pp
335
336
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1145/‚Äã290941.‚Äã291025.
13
24
information
retrieval
journal
2022
25
26
castillo
2018
fairness
and
transparency
in
ranking
sigir
forum
52
64
71
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã
1145
33087
74
33087
83
celis
straszak
vishnoi
2018
ranking
with
fairness
constraints
in
proceedings
of
the
45th
international
colloquium
on
automata
languages
and
programming
icalp
2018
july
13
2018
prague
czech
republic
lipics
vol
107
pp
28
28
15
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã4230/‚Äãlipics.‚Äã
icalp
2018
28
chen
karger
2006
less
is
more
probabilistic
models
for
retrieving
fewer
relevant
documents
in
proceedings
of
the
29th
annual
international
acm
sigir
conference
on
research
and
development
in
information
retrieval
seattle
washington
usa
august
11
2006
acm
pp
429
436
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1145/‚Äã11481‚Äã70.‚Äã11482‚Äã45
chouldechova
2017
fair
prediction
with
disparate
impact
study
of
bias
in
recidivism
prediction
instruments
big
data
153
163
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1089/‚Äãbig.‚Äã2016.‚Äã0047
culpepper
diaz
smucker
2018
research
frontiers
in
information
retrieval
report
from
the
third
strategic
workshop
on
information
retrieval
in
lorne
swirl
2018
sigir
forum
52
34
90
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1145/‚Äã32747‚Äã84.‚Äã32747‚Äã88
dang
croft
2012
diversity
by
proportionality
an
election-based
approach
to
search
result
diversification
in
proceedings
of
the
35th
international
acm
sigir
conference
on
research
and
development
in
information
retrieval
sigir
12
portland
or
usa
august
12
16
2012
acm
pp
65
74
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1145/‚Äã23482‚Äã83.‚Äã23482‚Äã96.
de-arteaga
romanov
wallach
chayes
borgs
chouldechova
geyik
kenthapadi
kalai
2019
bias
in
bios
case
study
of
semantic
representation
bias
in
high-stakes
setting
in
proceedings
of
the
conference
on
fairness
accountability
and
transparency
fat
2019
atlanta
ga
usa
january
29
31
2019
acm
pp
120
128
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1145/‚Äã
32875
60
32875
72
diaz
mitra
ekstrand
biega
carterette
2020
evaluating
stochastic
rankings
with
expected
exposure
in
proceedings
of
the
29th
acm
international
conference
on
information
and
knowledge
management
virtual
event
ireland
october
19
23
2020
acm
pp
275
284
https://‚Äãdoi.‚Äã
org
10
1145
33405
31
34119
62
dunn
1961
multiple
comparisons
among
means
journal
of
the
american
statistical
association
56
293
52
64
dwork
hardt
pitassi
reingold
zemel
2012
fairness
through
awareness
in
proceedings
of
the
innovations
in
theoretical
computer
science
conference
cambridge
ma
usa
january
10
2012
acm
pp
214
226
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1145/‚Äã20902‚Äã36.‚Äã20902‚Äã55.
ekstrand
burke
diaz
2019
fairness
and
discrimination
in
retrieval
and
recommendation
in
proceedings
of
the
42nd
international
acm
sigir
conference
on
research
and
development
in
information
retrieval
sigir
2019
paris
france
july
21
25
2019
acm
pp
1403
1404
https://‚Äã
doi
org
10
1145
33311
84
33313
80
epstein
robertson
lazer
wilson
2017
suppressing
the
search
engine
manipulation
effect
seme
acm
on
human-computer
interaction
cscw
42
42
22
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1145/‚Äã
31346
77
gao
shah
2020
toward
creating
fairer
ranking
in
search
engine
results
information
processing
and
management
57
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1016/j.‚Äãipm.‚Äã2019.‚Äã102138.
hajian
domingo-ferrer
2013
methodology
for
direct
and
indirect
discrimination
prevention
in
data
mining
ieee
transactions
on
knowledge
and
data
engineering
25
1445
1459
https://‚Äãdoi.‚Äã
org
10
1109
tkde
2012
72
hardt
price
srebro
2016
equality
of
opportunity
in
supervised
learning
in
proceedings
of
the
neural
information
processing
systems
annual
conference
december
10
2016
barcelona
spain
pp
3315
3323
he
macdonald
ounis
peng
santos
2008
university
of
glasgow
at
trec
2008
experiments
in
blog
enterprise
and
relevance
feedback
tracks
with
terrier
in
proceedings
of
the
seventeenth
text
retrieval
conference
trec
2008
gaithersburg
maryland
usa
november
18
21
2008
nist
special
publication
vol
500
277
http://‚Äãtrec.‚Äãnist.‚Äãgov/‚Äãpubs/‚Äãtrec17/‚Äãpapers/‚Äãuglas‚Äãgow.‚Äãblog.‚Äã
ent
rf
rev
pdf
j√§rvelin
kek√§l√§inen
2002
cumulated
gain-based
evaluation
of
ir
techniques
acm
transactions
on
information
systems
20
422
446
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1145/‚Äã582415.‚Äã582418.
kamiran
calders
2009
classifying
without
discriminating
in
proceedings
of
the
2nd
international
conference
on
computer
control
and
communication
ieee
pp
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1109/‚Äã
ic4
2009
49091
97
kamishima
akaho
sakuma
2011
fairness-aware
learning
through
regularization
approach
in
proceedings
of
the
11th
international
conference
on
data
mining
workshops
vancouver
bc
13
information
retrieval
journal
2022
25
26
25
canada
december
11
2011
ieee
computer
society
pp
643
650
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1109/‚Äãicdmw.‚Äã
2011
83
kay
matuszek
munson
2015
unequal
representation
and
gender
stereotypes
in
image
search
results
for
occupations
in
proceedings
of
the
33rd
annual
acm
conference
on
human
factors
in
computing
systems
chi
2015
seoul
republic
of
korea
april
18
23
2015
acm
pp
3819
3828
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1145/‚Äã27021‚Äã23.‚Äã27025‚Äã20.
kleinberg
mullainathan
raghavan
2016
inherent
trade-offs
in
the
fair
determination
of
risk
scores
corr
arxiv
abs
1609
05807
macdonald
mccreadie
santos
ounis
2012
from
puppy
to
maturity
experiences
in
developing
terrier
in
proceedings
of
the
sigir
2012
workshop
on
open
source
information
retrieval
osir
sigir
2012
portland
oregon
usa
16th
august
2012
university
of
otago
dunedin
new
zealand
pp
60
63
mehrotra
anderson
diaz
sharma
wallach
yilmaz
2017
auditing
search
engines
for
differential
satisfaction
across
demographics
in
proceedings
of
the
26th
international
conference
on
world
wide
web
companion
perth
australia
april
2017
acm
pp
626
633
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1145/‚Äã30410‚Äã21.‚Äã30541‚Äã97.
mehrotra
mcinerney
bouchard
lalmas
diaz
2018
towards
fair
marketplace
counterfactual
evaluation
of
the
trade-off
between
relevance
fairness
satisfaction
in
recommendation
systems
in
proceedings
of
the
27th
acm
international
conference
on
information
and
knowledge
management
cikm
2018
torino
italy
october
22
26
2018
acm
pp
2243
2251
https://‚Äãdoi.‚Äã
org
10
1145
32692
06
32720
27
morik
singh
hong
joachims
2020
controlling
fairness
and
bias
in
dynamic
learningto-rank
in
proceedings
of
the
43rd
international
acm
sigir
conference
on
research
and
development
in
information
retrieval
sigir
2020
virtual
event
china
july
25
30
2020
acm
pp
429
438
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1145/‚Äã33972‚Äã71.‚Äã34011‚Äã00
olteanu
garcia-gathright
de
rijke
ekstrand
2019a
in
proceedings
of
facts-ir
corr
arxiv
abs
1907
05755
olteanu
garcia-gathright
de
rijke
ekstrand
roegiest
lipani
et
al
2019
facts-ir
fairness
accountability
confidentiality
transparency
and
safety
in
information
retrieval
sigir
forum
53
20
43
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1145/‚Äã34585‚Äã53.‚Äã34585‚Äã56.
ounis
amati
plachouras
he
macdonald
lioma
2006
terrier
high
performance
and
scalable
information
retrieval
platform
in
proceedings
of
the
sigir
2006
workshop
on
open
source
information
retrieval
osir
sigir
2006
seattle
wa
usa
august
2006
pp
18
25
pedreschi
ruggieri
turini
2008
discrimination-aware
data
mining
in
proceedings
of
the
14th
acm
sigkdd
international
conference
on
knowledge
discovery
and
data
mining
las
vegas
nevada
usa
august
24
27
2008
acm
pp
560
568
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1145/‚Äã14018‚Äã90.‚Äã14019‚Äã59.
pleiss
raghavan
wu
kleinberg
weinberger
2017
on
fairness
and
calibration
in
proceedings
of
the
advances
in
neural
information
processing
systems
conference
december
2017
long
beach
ca
usa
pp
5680
5689
radlinski
dumais
2006
improving
personalized
web
search
using
result
diversification
in
proceedings
of
the
29th
annual
international
acm
sigir
conference
on
research
and
development
in
information
retrieval
seattle
washington
usa
august
11
2006
acm
pp
691
692
https://‚Äã
doi
org
10
1145
11481
70
11483
20
radlinski
kleinberg
joachims
2008
learning
diverse
rankings
with
multi-armed
bandits
in
proceedings
of
the
twenty-fifth
international
conference
on
machine
learning
helsinki
finland
june
2008
acm
acm
international
conference
proceeding
series
vol
307
pp
784
791
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1145/‚Äã13901‚Äã56.‚Äã13902‚Äã55.
richardson
dominowska
ragno
2007
predicting
clicks
estimating
the
click-through
rate
for
new
ads
in
proceedings
of
the
16th
international
conference
on
world
wide
web
www
2007
banff
alberta
canada
may
12
2007
acm
pp
521
530
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1145/‚Äã12425‚Äã72.‚Äã12426‚Äã
43
robertson
1977
the
probability
ranking
principle
in
ir
journal
of
documentation
santos
peng
macdonald
ounis
2010
explicit
search
result
diversification
through
sub-queries
in
proceedings
of
the
32nd
european
conference
on
information
retrieval
milton
keynes
uk
march
28
31
2010
proceedings
springer
lecture
notes
in
computer
science
vol
5993
pp
87
99
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1007/‚Äã978-3-‚Äã642-‚Äã12275-0_‚Äã11.
santos
macdonald
ounis
2015
search
result
diversification
foundations
and
trends
in
information
retrieval
90
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1561/‚Äã15000‚Äã00040.
sapiezynski
zeng
robertson
mislove
wilson
2019
quantifying
the
impact
of
user
attentionon
fair
group
representation
in
ranked
lists
in
companion
of
the
2019
world
wide
web
13
26
information
retrieval
journal
2022
25
26
conference
www
2019
san
francisco
ca
usa
may
13
17
2019
acm
pp
553
562
https://‚Äãdoi.‚Äã
org
10
1145
33085
60
33175
95
singh
joachims
2018
fairness
of
exposure
in
rankings
in
proceedings
of
the
24th
acm
sigkdd
international
conference
on
knowledge
discovery
data
mining
kdd
2018
london
uk
august
19
23
2018
acm
pp
2219
2228
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1145/‚Äã32198‚Äã19.‚Äã32200‚Äã88.
singh
joachims
2019
policy
learning
for
fairness
in
ranking
corr
arxiv
abs
1902
04056
sp√§rck-jones
robertson
sanderson
2007
ambiguous
requests
implications
for
retrieval
tests
systems
and
theories
in
acm
sigir
forum
41
17
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1145/‚Äã13289‚Äã64.‚Äã13289‚Äã65
wang
zhu
2009
portfolio
theory
of
information
retrieval
in
proceedings
of
the
32nd
annual
international
acm
sigir
conference
on
research
and
development
in
information
retrieval
sigir
2009
boston
ma
usa
july
19
23
2009
acm
pp
115
122
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1145/‚Äã15719‚Äã41.‚Äã
15719
63
white
2013
beliefs
and
biases
in
web
search
in
proceedings
of
the
36th
international
acm
sigir
conference
on
research
and
development
in
information
retrieval
sigir
13
dublin
ireland
july
28
august
01
2013
acm
pp
12
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1145/‚Äã24840‚Äã28.‚Äã24840‚Äã53.
woodworth
gunasekar
ohannessian
srebro
2017
learning
non-discriminatory
predictors
corr
arxiv
abs
1702
06081
yadav
du
joachims
2019
fair
learning-to-rank
from
implicit
feedback
corr
arxiv
abs
1911
08054
yang
stoyanovich
2017
measuring
fairness
in
ranked
outputs
in
proceedings
of
the
29th
international
conference
on
scientific
and
statistical
database
management
chicago
il
usa
june
27
29
2017
acm
pp
22
22
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1145/‚Äã30855‚Äã04.‚Äã30855‚Äã26.
yigit-sert
altingovde
macdonald
ounis
ulusoy
2021
explicit
diversification
of
search
results
across
multiple
dimensions
for
educational
search
the
journal
of
the
association
for
information
science
and
technology
72
315
330
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1002/‚Äãasi.‚Äã24403.
zafar
valera
gomez-rodriguez
gummadi
2017
fairness
beyond
disparate
treatment
disparate
impact
learning
classification
without
disparate
mistreatment
in
proceedings
of
the
26th
international
conference
on
world
wide
web
www
2017
perth
australia
april
2017
acm
pp
1171
1180
https://‚Äãdoi.‚Äãorg/‚Äã10.‚Äã1145/‚Äã30389‚Äã12.‚Äã30526‚Äã60.
zehlike
bonchi
castillo
hajian
megahed
baeza-yates
2017
fa
ir
fair
top-k
ranking
algorithm
in
proceedings
of
the
2017
acm
conference
on
information
and
knowledge
management
cikm
2017
singapore
november
06
10
2017
acm
pp
1569
1578
https://‚Äãdoi.‚Äãorg/‚Äã
10
1145
31328
47
31329
38
zemel
wu
swersky
pitassi
dwork
2013
learning
fair
representations
in
proceedings
of
the
30th
international
conference
on
machine
learning
icml
2013
atlanta
ga
usa
16
21
june
2013
jmlr
org
jmlr
workshop
and
conference
proceedings
vol
28
pp
325
333
http://‚Äãproce‚Äãedings.‚Äãmlr.‚Äãpress/‚Äãv28/‚Äãzemel‚Äã13.‚Äãhtml.
publisher
note
springer
nature
remains
neutral
with
regard
to
jurisdictional
claims
in
published
maps
and
institutional
affiliations
13