information
retrieval
33
59
2001
2001
kluwer
academic
publishers
manufactured
netherlands
measuring
search
engine
quality
david
hawking
david.hawking@cmis.csiro.au
nick
craswell
csiro
mathematical
information
sciences
gpo
box
664
canberra
australia
2601
peter
bailey
computer
science
department
australian
national
university
canberra
australia
0200
kathleen
griffiths
centre
mental
health
research
australian
national
university
canberra
australia
0200
received
july
2000
accepted
november
28
2000
abstract
effectiveness
twenty
public
search
engines
evaluated
using
trec-inspired
methods
set
54
queries
taken
real
web
search
logs
world
wide
web
taken
test
collection
combination
crawler
text
retrieval
system
evaluated
engines
compared
range
measures
derivable
binary
relevance
judgments
first
seven
live
results
returned
statistical
testing
reveals
significant
difference
engines
high
intercorrelations
measures
surprisingly
given
dynamic
nature
web
time
elapsed
also
high
correlation
results
study
previous
study
gordon
pathak
nearly
engines
gradual
decline
precision
increasing
cutoff
initial
fluctuation
performance
engines
group
found
inferior
group
participants
trec8
large
web
task
although
best
engines
approach
median
systems
shortcomings
current
web
search
evaluation
methodology
identified
recommendations
made
future
improvements
particular
present
study
predecessors
deal
queries
assumed
derive
need
find
selection
documents
relevant
topic
contrast
real
web
search
reflects
range
information
need
types
require
different
judging
different
measures
keywords
web
search
search
engines
evaluation
introduction
publication
accurate
meaningful
evaluation
quality
results
returned
public
web
search
engines
enables
informed
consumer
choice
also
assists
encourages
search
engine
operators
improve
standard
service
since
many
search
engines
claim
using
novel
techniques
effectiveness
comparisons
engines
systems
employing
published
methods
potentially
interest
information
retrieval
ir
research
community
known
search
engine
operators
already
perform
extensive
internal
evaluations
clear
evaluations
properties
blindness
independence
reproducibility
normally
expected
published
studies
ir
hand
possible
model
user
retrieval
task
implicit
evaluations
34
hawking
et
al
accurately
represents
everyday
web
search
models
assumed
much
published
ir
work
countless
evaluations
text
retrieval
systems
eg
salton
lesk
1997
voorhees
harman
1998
measured
effectiveness
relevance
ranking
schemes
context
well-defined
static
document
collection
sufficiently
complete
relevance
information
available
evaluations
reproducible
can
provide
accurate
measurements
recall
proportion
relevant
documents
retrieved
far
well
precision
proportion
retrieved
documents
relevant
early
test
collections
described
cleverdon
1997
salton
lesk
1997
small
enough
permit
relevance
judgments
every
document
every
request
exhaustive
judging
infeasible
collections
size
trec
voorhees
harman
1998
almost
complete
judgments
collected
assessing
pool
documents
retrieved
large
diverse
set
retrieval
methods
unjudged
documents
assumed
irrelevant
trec
subject
continual
evolution
now
models
specific
features
web
search
example
trec-8
large
web
task
involved
blind
effectiveness
evaluations
retrieval
systems
operating
18.5
million
pages
crawled
web
hawking
et
al
1999
participant
required
process
10
000
queries
taken
web
search
engine
logs
return
top
20
ranked
documents
approximately
50
queries
selected
post
hoc
relevance
assessment
using
binary
measures
large
number
queries
size
data
set
served
rule
use
unrealistically
inefficient
algorithms
report
application
extended
trec-8
large
web
task
methodology
effectiveness
evaluation
20
public
search
engines
evaluating
public
search
engines
without
knowledge
cooperation
operators
fixed
test
collection
consequently
necessary
evaluate
crawling
document
retrieval
algorithms
combination
finally
present
analysis
extent
characteristics
web
search
captured
experiment
argue
methodological
developments
improve
applicability
evaluation
results
reduce
cost
obtaining
relationship
studies
gordon
pathak
1999
distinguish
two
types
search
engine
evaluation
testimonials
encompassing
informal
impressionistic
appraisals
feature-list
comparisons
shootouts
correspond
closely
traditional
ir
effectiveness
experiments
latter
considered
gordon
pathak
present
table1
twelve
earlier
shootout
studies
identify
three
including
make
use
appropriate
experimental
design
evaluation
gordon
pathak
comprehensive
recent
ding
marchionini
1996
evaluated
three
engines
five
topics
1996
found
statistically
significant
difference
effectiveness
means
19972
leighton
srivastava
1999
compared
five
engines
using
15
topics
found
three
engines
measuring
search
engine
quality
35
superior
two
using
new
measure
based
precision
cutoff
20
assigning
different
weights
top
three
next
seven
next
ten
results
leighton
srivastava
constructed
set
topics
variety
sources
intended
model
information
needs
undergraduate
students
generated
queries
topics
seven
queries
simple
bag
words
queries
seven
structured
way
one
attempted
locate
information
person
leighton
srivastava
used
automatic
scripts
submit
queries
engines
fetch
results
suppressing
information
engine
retrieved
page
judged
relevance
using
four
categories
relevance
also
identified
dead
links
duplicate
pages
analysed
data
several
times
using
different
relevance
thresholds
without
penalising
duplicates
gordon
pathak
obtained
33
real
information
needs
volunteers
among
faculty
members
university
business
school
recorded
considerable
detail
passed
skilled
search
intermediaries
given
task
generating
near-optimal
queries
eight
search
engines
interactive
iterative
process
top
20
live
results
generated
engines
response
final
queries
printed
returned
originating
faculty
member
assessment
four
point
relevance
scale
found
search
effectiveness
generally
low
significant
differences
engines
ranking
engines
extent
dependent
upon
strictness
relevance
criterion
characteristics
leighton
srivastava
gordon
pathak
studies
compared
present
experiment
table
compare
results
gordon
pathak
section
4.3
2.1
evaluation
philosophy
gordon
pathak3
present
list
seven
evaluation
features
claim
present
maximise
accuracy
informativeness
evaluation
paraphrasing
brevity
searches
motivated
genuine
user
need
search
intermediary
employed
primary
searcher
information
need
fully
captured
possible
transmitted
full
intermediary
large
number
search
topics
must
used
major
search
engines
included
effective
combination
specific
features
search
engine
exploited
ie
queries
submitted
engines
need
relevance
judgments
must
made
individual
needs
information
experiments
well
designed
conducted
features
essential
features
useful
scientific
study
feature
certainly
desirable
applicable
however
value
feature
dependent
upon
goals
evaluation
general-purpose
evaluation
propose
additional
feature
search
topics
represent
range
information
needs
respect
subject
type
results
wanted
see
section
36
hawking
et
al
table
comparison
present
experiment
two
closely
related
previous
studies
gordon
pathak
1999
detail
leighton
srivastava
1997
present
study
number
search
engines
20
number
topics
33
15
54
relevant
found
per
topic
125
mean
42.2
stated
255
mean
88.5
date
queries
submitted
1998
early
1997
20
sep
1999
genuine
yes
yes
presumed
originators
faculty
members
library
clients
anonymous
searchers
length
topic
statement
approx
100
wds
4.9
wds
5.9
wds
range
subjects
business
broad
broad
types
answer
required
selection
rel
pages
selection
rel
pages
variety
information
needs
queries
generated
human
intermediary
experimenter
web
logs
verbal
requests
verbatim
average
number
words
stated
4.9
9a
used
query
operators
yes
many
results
judged
top
20
live
top
20
top
20
liveb
inquirers
experimenters
research
assistants
topic
originator
yes
pages
judged
result
lists
merged
yes
yes
yes
blind
judging
yes
yes
yes
follow
hyperlinks
text
images
raw
html
rendered
text
presentation
printed
paper
emacs
text
editor
browser
page
truncation
ten
pages
order
presentation
random
stated
increasing
length
auto
search
aids
judging
none
stated
ratc
relevance
categories
4d
graphs
weighted
yesb
15
20
yes
average
yes
yes
20
yes
yesb
prec
based
strict
rel
yes
yes
mrr1
yes
measures
reported
20
continued
next
page
37
measuring
search
engine
quality
table
continued
detail
gordon
pathak
1999
leighton
srivastava
1997
present
study
relative
recall
20
yes
trec-style
ave
prec
yes
including
stopwords
result
page
changeover
bug
engines
see
text
operation
rat
relevance
assessment
tool
described
text
plus
duplicate
dead
link
categories
subject
remainder
features
original
gordon
pathak
list
merit
detailed
discussion
restricting
searches
genuine
user
needs
feature
requiring
person
original
need
evaluate
results
feature
must
inevitably
limit
scope
evaluations
example
gordon
pathak
study
limited
information
needs
faculty
members
business
school
acknowledge
judgments
relevance
vary
person
person
time
time
however
empirical
evidence
retrieval
system
rankings
remain
stable
across
different
sets
relevance
judgments
voorhees
1998
prefer
say
searches
representative
genuine
user
need
relevance
judging
across
aggregated
search
results
consistent
one
judge
evaluate
responses
topic
short
time
possible
feature
quite
contentious
well-known
public
search
engines
designed
produce
list
results
set
query
words
without
operators
special
syntax
typed
search
box
provided
therefore
perfectly
reasonable
compare
quality
results
produced
search
engines
given
identical
input
queries
form
furthermore
queries
far
typical
web
search
sophisticated
queries
exploiting
advanced
query
language
features
analyses
query
logs
silverstein
et
al
1999
example
show
typical
search
engine
users
rarely
use
form
query
operator
frequently
make
errors
measures
obtained
studies
adopt
approach
trying
find
best
query
formulation
search
engine
feature
certainly
interesting
particularly
indicated
near-optimal
queries
performed
dramatically
better
simple
queries
however
gordon
pathak
study
compare
performance
highly
tuned
queries
simpler
versions
initial
boolean
queries
supplied
search
originators
simple
word
lists
unfortunately
order
achieve
fifth
desideratum
within
study
gordon
pathak
introduced
set
confounding
variables
due
introduction
skilled
search
intermediaries
charged
converting
user
topic
specifications
near-optimal
queries
engine
evaluated
fact
set
combinations
human
intermediary
search
engine
human
variability
entails
use
human
intermediaries
also
seems
somewhat
inconsistent
reasoning
behind
requiring
relevance
assessments
conducted
originator
information
need
feature
order
form
queries
original
user
topic
statement
38
hawking
et
al
judge
variant
query
performs
best
intermediary
must
make
type
interpretations
need
made
relevance
judges
topic
originator
experiment
applied
trec-style
methodology
evaluation
web
search
engines
operated
september
20
1999
used
queries
taken
real
query
logs
study
exhibits
eight
features
listed
preceding
section
except
numbered
applicable
discussed
preceding
section
feel
strong
reasons
adopt
feature
reasons
feature
may
necessary
3.1
evaluated
current
web
search
engines
consist
two
key
components
one
crawler
koster
whose
job
create
web
snapshot4
identifying
selecting
fetching
documents
text
retrieval
system
trs
operating
snapshot
collection
quality
search
results
clearly
depends
upon
performance
search
engine
components
relevant
document
documents
may
fail
retrieved
either
fetched
crawler
trs
failed
rank
appropriately
evidence
hawking
et
1999
suggests
precision
fixed
cutoff
increases
collection
size
evaluated
components
combination
necessary
extension
conventional
evaluation
methodology
static
well-defined
test
collection
trs
evaluated
3.2
search
engines
lawrence
giles
1999
report
measurements
taken
february
1999
coverage
freshness
indexes
maintained
web
search
engines
measurements
relate
principally
performance
crawler
rather
trs
found
none
popular
search
engines
covered
16
estimated
total
800
million
indexable
web
pages
add
extra
dimension
data
presented
lawrence
giles
measured
result-list
precision
eleven
engines
considered
study
northern
light
snap
altavista
hotbot
microsoft
infoseek
google
yahoo
excite
lycos
euroseek
added
two
metasearch
engines
metacrawler
mentioned
studied
lawrence
giles
accessing
com
altavista
directhit
excite
goto
com
infoseek
looksmart
lycos
thunderstone
webcrawler
yahoo
inquirus
operated
lawrence
giles
limited-access
basis
accessing
altavista
directhit
measuring
search
engine
quality
39
euroseek
excite
fast
google
hotbot
infoseek
lycos
northernlight
open
directory
snap
thunderstone
yahoo
yahoo
inktomi
metasearchers
index
documents
rather
forward
queries
number
primary
search
engines
form
composite
result
list
fast
also
known
alltheweb
new
large
search
engine
aims
index
whole
web
euroferret
another
europe-focused
search
service
wished
compare
euroseek
directhit
system
takes
page
popularity
terms
access
frequency
account
ranking
pages
three
search
engines
providing
search
within
australia
new
zealand
area
anzwers
exciteaus
web
wombat
directory
service
looksmart
australia
service
presents
australian
results
first
appends
results
looksmart
worldwide
counterpart
note
several
services
fully
automatic
generate
responses
least
partially
basis
classifications
made
stored
human
editors
prominent
examples
include
yahoo
lycos
looksmart
australia
directory
services
given
services
accepted
queries
presented
results
fashion
appeared
ordered
considered
reasonable
evaluate
alongside
search
services
whose
degree
manual
intervention
less
list
twenty
engines
included
gordon
pathak
1999
study
except
opentext
magellan
overlap
two
studies
therefore
comprises
six
engines
altavista
excite
infoseek
hotbot
lycos
yahoo
leighton
srivastava
1999
studied
first
five
report
comparable
measures
3.3
queries
result
lists
started
two
sets
100
000
single-sentence
natural
language
queries
logs
supplied
us
alta
vista
electric
monk
used
natural
language
queries
believed
easier
judges
interpret
inquirer
actually
seeking
merged
two
sets
filtered
queries
either
likely
offensive
people
contained
fewer
two
non-stopwords
randomly
selected
queries
merged
set
asked
experienced
judge
decide
whether
colleagues
able
interpret
inquirer
seeking
able
judge
relevance
results
returned
rejected
719
total
59
queries
accepted
due
pair
near-duplicate
queries
problems
assessor
availability
57
judged
trec
large
web
track
subset
54
search
engines
sample
judged
queries
shown
figure
correct
typographical
errors
queries
slobadan
figure
submitted
search
engines
exactly
shown
used
scripts
present
queries
search
engine
first
20
live
results
engine
query
retrieved
merged
single
pool
40
hawking
et
al
figure
sample
queries
used
experiments
pages
judged
enable
fair
comparison
trec
systems
dead
inaccessible
results
ignored
engines
penalised
returning
3.4
relevance
assessors
judging
instructions
employed
team
six
judges
australian
university
degree
specific
expertise
computer
science
information
retrieval
allegiance
search
engine
retrieval
system
asked
judge
whether
documents
relevant
particular
queries
pages
retrieved
search
engines
combined
single
pool
query
presented
judges
without
indication
search
engine
retrieved
documents
rendered
using
text-only
browser
lynx
images
sounds
presented
hyperlinks
presented
numbered
references
eg
judges
follow
asked
judges
imagine
submitted
queries
evaluate
answers
basis
however
also
instructed
judge
document
independently
others
score
relevant
page
included
material
on-topic
contributed
information
contained
query
asked
make
judgment
correctness
information
given
require
pages
returned
response
question
form
answer
measuring
search
engine
quality
41
line
past
trec
methodology
judgments
binary
made
basis
textual
content
alone
either
document
contained
relevant
content
judged
relevant
judged
irrelevant
ensure
consistency
results
documents
retrieved
query
judged
person
document
retrieved
response
query
judged
one
judge
earlier
work
hawking
thistlewaite
1997
voorhees
1998
failed
demonstrate
particular
benefit
multiple
judgments
3.5
relevance
assessment
tool
rat
used
special
relevance
judging
software
known
rat
relevance
assessment
tool
developed
jason
haines
paul
thistlewaite
1996
use
trec
large
collection
web
tracks
since
maintained
nick
craswell
figure
shows
screen
snapshot
rat
action
commencing
judgments
new
query
judge
required
enter
concepts
use
evaluating
relevance
criterion
relevance
example
concepts
last
query
figure
vegetarian
restaurants
new
york
criterion
relevance
conjunction
concepts
encouraged
judges
accumulate
lists
using
rat
facilities
words
phrases
part-words
view
constituted
evidence
presence
concept
example
ny
yc
manhattan
new
york
city
well
new
york
constituted
evidence
presence
new
york
city
concept
judges
entered
evidence
either
typing
add
evidence
box
selecting
text
presented
pages
rat
displays
concept
criterion
information
throughout
judging
process
aid
maintaining
consistency
however
information
provided
assistance
judges
free
make
judgments
regardless
whether
criteria
actually
satisfied
shown
figure
occurrences
evidence
highlighted
document
rat
colour
associated
concept
enabling
judge
easily
spot
multicoloured
potentially
relevant
sections
long
documents
hypothetical
document
containing
sentence
luigi
pasta
restaurant
2301
7th
avenue
manhattan
caters
vegetarians
vegans
thus
show
highlighting
three
colours
judge
instantly
home
sentence
decide
document
relevant
might
also
decide
save
part-word
vegan
additional
evidence
vegetarian
concept
54
topics
number
concepts
defined
per
topic
judges
ranged
mean
3.7
average
number
pieces
evidence
defined
concepts
combined
30.9
3.6
presentation
order
order
presentation
documents
judging
shown
affect
judgments
made
eisenberg
barry
1998
first
used
rat
trec-5
1996
compared
three
different
presentation
orders
ascending
length
descending
length
random
42
hawking
et
al
figure
screenshot
relevance
assessment
tool
rat
used
present
experiments
coloured
rectangles
representing
concepts
top
case
concept
dummy
entry
created
assessor
didn
like
colour
assigned
list
documents
seen
far
shown
top
left
text
current
document
highlighting
concept
evidence
right
bottom
left
panel
includes
text
current
query
heading
otherwise
unused
description
narrative
fields
filled
trec
ad
hoc
topics
judged
judgment
current
document
recorded
clicking
appropriate
icon
far
top
right
screen
judgment
made
next
document
button
enabled
unless
last
document
topic
case
next
topic
button
enabled
point
within
topic
judge
may
revisit
previously
seen
documents
will
displayed
concept
evidence
currently
available
desired
change
judgment
found
descending
length
impractical
judges
felt
needed
read
long
document
order
sure
sections
relevant
extreme
case
judge
spent
six
hours
single
document
contrast
judges
found
working
shortest
documents
first
enabled
accumulate
sufficient
evidence
confident
reached
long
document
use
scrolling
quickly
locate
paragraphs
contained
potentially
relevant
material
low
probability
missing
relevant
material
concluded
presentation
ascending
length
order
increased
probability
short
relevant
sections
long
documents
identified
maximising
high
measuring
search
engine
quality
43
lightable
evidence
available
accordingly
used
presentation
order
judging
since
1996
eisenberg
barry
study
documents
already
assessed
multilevel
relevance
scale
found
documents
presented
relevance
order
either
increasing
decreasing
subjects
tended
hedge
first
documents
seen
allocating
scores
closer
mean
otherwise
seems
unlikely
presentation
order
effects
seriously
affected
experiment
hedging
possible
two
possible
relevance
values
judges
free
reassess
previously
judged
documents
felt
harsh
lenient
association
document
length
relevance
unlikely
strong
judge
reason
expect
first
document
relevant
order
effects
confounded
comparative
results
certain
engines
tended
disproportionately
return
short
long
documents
3.7
measures
used
judgment
first
20
live
results
allows
calculation
range
precision-oriented
measures
including
precision
20
documents
retrieved
mean
reciprocal
rank
first
relevant
document
mrr1
trec-style
average
precision
tsap
10
unfortunately
data
analysis
long
data
collected
revealed
bug
scripts
used
send
queries
fetch
result
lists
documents
meant
engines
nine
altogether
queries
contained
question-mark
29
54
script
failed
move
second
page
ten
results11
meaning
results
lists
artificially
truncated
engines
affected
bug
10
20
certainly
underestimated
also
likely
comparison
engines
precision
earlier
cutoff
10
unfair
dead
links
first
ten
results
replaced
live
ones
engines
subject
bug
available
evidence
suggests
web
users
generally
look
results
indeed
silverstein
et
al
1999
table
10
report
sample
half
billion
queries
submitted
alta
vista
85.2
requested
single
result
page
accordingly
completely
avoid
effects
bug
main
analysis
based
first
seven
live
results
however
acknowledge
precision
early
cutoff
likely
result
less
stable
system
rankings
see
buckley
voorhees
2000
statistical
significance
likely
harder
achieve
later
cutoffs
compatibility
gordon
pathak
study
performed
principal
analyses
average
precisions
cutoffs
also
present
results
mrr1
tsap
plot
separately
groups
engines
affected
affected
bug
unlike
gordon
pathak
measure
recall
since
meaningfulness
recall
values
depends
heavily
upon
accuracy
estimates
many
relevant
documents
really
44
hawking
et
al
table
summary
results
twenty
search
engines
based
first
seven
live
results
tsap
means
trec-style
average
precision
mrr1
mean
reciprocal
rank
first
relevant
document
means
precision
documents
retrieved
average
precision
values
ranking
cutoff
run
tsap
mrr1
anzwers
0.1111
0.2673
0.1852
0.1667
0.1787
altavista
0.3714
0.582
0.5
0.4519
0.4691
directhit
0.244
0.4455
0.4074
0.3111
0.3474
euroferret
0.284
0.5553
0.4444
0.3704
0.4043
euroseek
0.0733
0.1185
0.1296
0.0858
excite
0.2695
0.4994
0.3889
0.363
0.3593
exciteaus
0.2288
0.4596
0.3704
0.3
0.318
fast
0.2939
0.4843
0.4074
0.3593
0.3725
google
0.3939
0.6133
0.463
0.4889
0.4848
hotbot
0.3064
0.5705
0.463
0.4111
0.4196
infoseek
0.3698
0.594
0.4444
0.4852
0.4838
inquirus
0.404
0.5833
0.463
0.4963
0.4965
looksmart
0.3641
0.5575
0.463
0.4333
0.4502
lycos
0.2893
0.5244
0.3889
0.3926
0.3946
metacrawler
0.3075
0.5764
0.4259
0.4222
0.4329
microsoft
0.3522
0.5974
0.5
0.437
0.4624
northernlight
0.3846
0.6897
0.5556
0.5037
0.5211
snap
0.2939
0.5209
0.3519
0.3963
0.3944
webwombat
0.1765
0.3639
0.2963
0.2333
0.2535
yahoo
0.222
0.4336
0.3519
0.2889
0.3278
results
main
results
presented
table
figures
10
shown
figure
range
values
recorded
quite
large
multiple
analysis
variance
manova12
data
confirms
significant
difference
performance
search
engines
19
35
6.865
0.001
multiple
pairwise
comparisons
using
least
significant
difference
test
conducted
although
northern
light
top
ranked
engine
basis
differences
next
nine
engines
statistically
significant
differences
northernlight
engines
euroferret
lycos
snap
fast
excite
directhit
etc
significant
0.05
190
pairwise
correlations
engines
positive
pearson
values
ranging
0.066
0.885
155
achieved
significance
0.05
13
four
pairs
exhibited
correlations
excess
0.7
looksmart
altavista
microsoft
altavista
snap
hotbot
microsoft
looksmart
understood
time
evaluation
snap
hotbot
used
inktomi
search
technology
measuring
search
engine
quality
45
figure
20
public
search
engines
compared
basis
precision
averaged
across
cutoffs
type
search
engine
general
metasearch
regional
color-coded
according
key
top
right
horizontal
black
line
gives
corresponding
performance
1999
trec
system
see
section
4.2
table
details
commercial
relationships
microsoft
looksmart
microsoft
altavista
altavista
looksmart
table
shows
search
engine
rated
lawrence
giles
largest
coverage
northernlight
also
scored
highest
measures
except
tsap
however
fast
engine
claimed
coverage
nearly
50
larger
northernlight
performed
relatively
poorly
figure
shows
scatter
plot
coverage
lawrence
giles
engines
correlation
coverage
statistically
significant
metasearcher
works
broadcasting
incoming
queries
large
number
11
14
two
examples
primary
search
engines
merging
results
lists
metasearchers
therefore
achieve
high
effective
coverage
two
metasearch
engines
performed
creditably
well
best
individual
engines
surprisingly
given
general
nature
test
queries
unrestricted-domain
search
engines
generally
achieved
better
results
restricted
european
australasian
domains
46
hawking
et
al
figure
relationship
coverage
percentage
estimated
publicly
indexable
web
reported
lawrence
giles
eleven
lawrence
giles
engines
plus
fast
whose
claimed
size
known
time
experiments
pearson
coefficient
correlation
0.370
significant
0.05
level
two-tailed
figure
shows
mean
reciprocal
rank
first
relevant
document
counted
zero
relevant
document
appeared
first
results
first
relevant
document
appears
second
position
reciprocal
rank
0.5
figure
compares
performance
tsap
measure
explained
section
3.7
figure
compares
performance
basis
equivalent
probability
first
result
relevant
nonparametric
test
revealed
highly
significant
difference
performance
engines
measure
cochran
82.3
0.001
14
many
tied
scores
20
reflecting
quantisation
due
fact
54
possible
scores
former
case
1080
latter
note
euroseek
find
single
relevant
document
rank
scored
zero
measure
figure
documents
variation
varies
20
search
engines
affected
result
changeover
bug
figure
shows
variation
remaining
enginges
range
affected
bug
ignoring
fluctuations
small
engines
exhibited
gradual
decline
across
range
studied
general
pattern
also
found
engines
shown
corresponding
gordon
pathak
figure
figure
156
except
opentext
studied
directhit
yahoo
present
study
also
exceptions
declined
sharply
4.1
intercorrelation
measures
table
shows
pearson
intercorrelations
four
different
measures
based
top
results
significantly
intercorrelated
0.01
similar
cases
even
higher
intercorrelations
observed
combined
trec
search
engine
groups
measuring
search
engine
quality
47
figure
20
public
search
engines
compared
basis
mean
reciprocal
rank
first
relevant
page
found
engines
scored
zero
query
relevant
document
found
first
results
colors
identify
type
search
engine
horizontal
black
line
gives
corresponding
performance
1999
trec
system
considering
eleven
engines
affected
result-page
bug
correlation
0.97
0.01
20
0.87
20
0.01
4.2
search
engines
compare
1999
trec
systems
performance
groups
participating
trec-8
large
web
task
reported
detail
hawking
et
al
1999
summarised
table
queries
judged
large
web
task
slightly
larger
superset
queries
used
present
study
trec
results
reported
re-analysed
take
account
data
54
queries
judged
trec
systems
search
engines
trec
results
also
represented
horizontal
black
lines
figure
instead
crawling
data
current
web
runs
used
first
18.5
million
pages
100
gigabytes
crawling
run
carried
early
1997
trec
run
thus
simulates
operation
search
engine
small
out-of-date
coverage
comparable
size
estimated
lawrence
giles
lycos
48
hawking
et
al
figure
20
public
search
engines
compared
basis
trec-style
average
precision
based
top
rankings
colors
identify
type
search
engine
horizontal
black
line
gives
corresponding
performance
1999
trec
system
documents
trec
systems
judged
separate
batch
search
engine
documents
judges
assigned
query
presentation
documents
identical
conditions
held
constant
trec
batch
judged
first
judging
search
engine
batch
following
immediately
afterward
concepts
evidence
accumulated
relevance
assessment
tool
rat
see
section
3.5
trec
judging
carried
search
engine
batch
number
trec
documents
judged
11
654
25.8
3008
judged
relevant
number
relevant
per
query
ranged
136
mean
55.7
maximum
achievable
mean
based
total
known
relevant
pages
0.9259
comparison
number
documents
judged
search
engines
14
951
32.0
4780
judged
relevant
number
relevant
ranged
255
mean
88.5
maximum
achievable
mean
based
total
known
relevant
pages
0.9741
group
trec
systems
compared
group
search
engines
using
separate
mann-whitney
15
tests
following
measures
averaged
across
measuring
search
engine
quality
49
figure
20
public
search
engines
compared
basis
colors
identify
type
search
engine
horizontal
black
line
gives
corresponding
performance
1999
trec
system
figure
variation
engines
affected
bug
ranked
50
hawking
et
al
table
intercorrelation
various
measures
twenty
search
engines
tsap
means
trec-style
average
precision
mrr1
mean
reciprocal
rank
first
relevant
document
means
precision
documents
retrieved
measure
tsap
mrr1
tsap
0.947
0.909
0.989
mrr1
0.947
0.968
0.96
0.909
0.968
0.897
0.989
0.96
0.897
table
summary
results
participating
groups
trec-8
large
web
task
results
presented
averages
runs
submitted
group
tsap
means
trec-style
average
precision
mrr1
mean
reciprocal
rank
first
relevant
document
means
precision
documents
retrieved
run
figure
tsap
mrr1
umass
0.3927
0.5698
0.463
0.4741
0.4741
acsys
0.2796
0.4668
0.3889
0.3519
0.3682
research
0.507
0.7074
0.6111
0.6074
0.6178
fujitsu
labs
0.428
0.6179
0.537
0.4926
0.5038
microsoft
research
0.4561
0.6528
0.5741
0.5333
0.5449
msr
city
univ
0.457
0.6582
0.5926
0.5259
0.5512
uwaterloo
0.5218
0.7399
0.6852
0.5778
0.6183
variation
search
engines
affected
bug
ranked
measuring
search
engine
quality
51
figure
10
public
search
engines
included
gordon
pathak
study
present
experiment
correlation
coefficient
scores
0.89
significant
0.05
level
two-tailed
queries
mrr1
tsap
measure
trec
systems
significantly
better
0.05
cases
4.3
present
results
relate
gordon
pathak
figure
10
compares
scores
lenient
cutoff
obtained
gordon
pathak
corresponding
scores
engines
obtained
present
study
shown
results
highly
correlated
figure
10
line
best
fit
passes
origin
slope
1.5
words
scores
tended
50
higher
observed
gordon
pathak
based
lenient
encoding
despite
advantage
presumably
conferred
use
highly
tuned
queries
advanced
query
syntax
may
explained
either
systematic
difference
topic
difficulty
difference
judging
standards
discussion
main
findings
follows
high
correlation
0.89
scores
study
reported
gordon
pathak
experiment
conducted
year
earlier
surprising
expected
updating
indexes
improvements
algorithms
caused
much
volatility
furthermore
considerable
differences
way
two
studies
conducted
found
significant
correlation
index
coverage
early
precision
figure
provided
coverage
sufficient
include
enough
relevant
documents
52
hawking
et
al
chosen
topics
ranking
algorithm
seems
determining
factor
coverage
become
critical
queries
relevant
answers
task
different
example
involved
locating
obscure
known
items
locating
documents
matching
specification
present
experiment
trec
large
web
systems
group
outperformed
search
engines
however
performance
best
search
engines
approached
one
case
surpassed
median
performance
participants
trec-8
large
web
task
figures
suggests
search
engines
indeed
using
reasonably
good
retrieval
methods
however
noted
large
web
collection
small
fraction
size
data
indexed
northernlight
google
previous
work
hawking
et
al
1999
shows
precision
fixed
cutoff
tends
increase
collection
size
increases
furthermore
trec
participants
almost
certainly
sacrificed
effectiveness
methods
order
achieve
speed
processing
therefore
fully
representative
trec
state-of-the-art
still
room
improvement
vlc2
content
nearly
three
years
date
respect
web
time
experiments
importantly
believe
out-of-date
respect
query
set
well
known
precisely
queries
employed
originally
submitted
obtained
search
engine
companies
late
1998
early
1999
however
none
queries
seem
relate
subjects
well
covered
web
1997
1999
slight
bias
due
age
vlc2
crawl
likely
operated
favour
search
engines
rather
great
majority
engines
declined
slowly
increasing
figures
high
intercorrelation
measures
observed
section
4.1
20
engines
complete
result
lists
strongly
predicted
almost
strongly
predicted
despite
large
effective
coverage
metasearchers
outperform
best
individual
engines
calculated
hypothetical
metasearcher
broadcast
queries
20
engines
study
achieve
score
0.9741
test
queries
used
ideal
merging
algorithm
16
precision
less
perfect
queries
total
number
relevant
pages
returned
engines
less
large
gap
actual
potential
performance
metasearchers
suggests
possibly
fruitful
avenue
improvement
search
engine
quality
given
metasearchers
inquirus
perform
merging
downloading
result
documents
reranking
basis
content
may
possible
find
merging
methods
capable
substantially
narrowing
gap
5.1
reliability
results
subject
search
engine
evaluations
vagaries
human
judgment
known
agreement
human
relevance
judges
less
perfect
voorhees
measuring
search
engine
quality
53
harman
1996
reported
71.7
rate
unanimous
agreement
three
assessors
14
968
documents
however
previously
noted
voorhees
1998
found
substituting
relevance
judgments
made
different
human
assessors
changed
magnitude
scores
almost
effect
rank
order
systems
5.2
representativeness
queries
three
potential
biases
affected
method
selecting
queries
section
3.3
200
000
queries
constituting
initial
pool
taken
query
logs
two
different
search
engines
may
biased
user
perceptions
characteristics
two
particular
engines
client
demographics
engines
fact
queries
cases
submitted
natural
language
interface
introduced
biases
excluding
adult-content
queries
allowing
single
judge
select
queries
felt
colleagues
able
judge
extent
biases
compatible
desirable
features
search
engine
evaluation
particularly
modification
andextension
figure
11
gordon
pathak
list
feature
can
reasonably
confident
judged
queries
submitted
result
real
information
need
apparently
flippant
queries
empty
incomplete
queries
occasionally
found
logs
obvious
examples
accepted
judging
queries
may
submitted
search
topics
representative
genuine
user
need
search
intermediary
third-party
relevance
judge
employed
primary
searcher
information
need
fully
captured
possible
transmitted
full
large
number
search
topics
used
purpose
study
enable
informed
consumer
choice
study
aim
include
major
search
engines
study
seeks
compare
maximal
opposed
typical
effectiveness
search
engines
appropriate
exploit
full
range
features
engine
may
require
use
skilled
search
intermediaries
search
topics
represent
full
range
information
needs
desired
draw
conclusions
respect
subject
type
results
wanted
see
type
categories
section
result
judging
appropriate
type
result
sought
see
section
judging
consistent
within
topic
judgments
topic
made
person
within
short
period
time
judging
blind
conducted
person
need
information
independent
judges
10
documents
presented
judging
way
seen
real
web
searcher
ie
rendered
browser
images
viewable
possible
follow
links
however
careful
instruction
may
necessary
ensure
judges
remain
task
waste
time
fruitless
link
following
11
general
comparisons
search
engines
dead
links
count
useless
answers
12
experiments
well
designed
conducted
figure
11
summary
desirable
features
future
web
search
evaluations
based
gordon
pathak
list
extended
modified
54
hawking
et
al
testing
purposes
study
proportion
almost
certainly
negligible
feature
suggests
queries
representative
full
range
information
needs
desired
draw
conclusions
respect
subject
type
results
wanted
can
seen
figure
queries
employed
covered
broad
range
subjects
including
politics
history
psychology
music
medicine
religion
humour
technology
geography
science
finance
however
queries
appear
general-knowledge
level
results
may
general
accurately
predict
performance
search
engines
queries
posed
evaluated
subject
experts
despite
fact
correlated
gordon
pathak
results
expert
queries
despite
selection
biases
identified
fairly
confident
results
predict
search
engine
performance
reasonably
well
general
non-adult-content
queries
provided
evaluation
methodology
employed
view
major
limitation
study
predecessors
lies
failure
represent
range
result
types
wanted
apply
appropriate
evaluation
different
types
performance
find
range
relevant
pages
task
may
predict
well
performance
find
homepage
task
issue
discussed
detail
5.3
effect
spelling
errors
noted
earlier
test
queries
contained
spelling
errors
errors
corrected
use
trec-8
large
web
something
departure
convention
trec
participants
trec
ad
hoc
topics
almost
free
errors
judges
looked
documents
satisfying
apparent
intent
query
rather
literal
matches
accordingly
systems
able
detect
correct
spelling
errors
may
small
advantage
relative
others
information
systems
employed
spelling
correction
future
web
search
evaluation
unfortunately
absence
standardised
web
test
collection
complete
relevance
judgments
willingness
search
engine
companies
use
little
prospect
reproducible
web
search
engine
evaluation
nonetheless
search
engine
effectiveness
evaluation
necessary
future
web
search
evaluations
adhere
sound
experimental
methods
blind
judging
statistical
significance
testing
improving
methodology
adopted
present
study
predecessors
passing
note
given
variation
effectiveness
across
web
crawlers
potential
effect
variation
search
result
quality
may
future
need
web
test
collection
constructed
way
enable
crawling
well
retrieval
evaluated
collection
obviously
comprise
set
linked
pages
initial
seed
list
may
difficult
construct
value
need
include
examples
known
crawler
hazards
mis-classified
file
types
subtle
self
reference
duplicate
pages
page
redirects
clickable
image
maps
framesets
measuring
search
engine
quality
55
collection
enable
testing
ability
crawling
algorithm
reach
pages
also
ability
fetch
useful
pages
ahead
less
useful
ones
attempted
commercial
systems
number
ways
future
web
search
evaluations
accurately
model
web
search
future
evaluations
recognise
retrieval
corresponding
different
types
information
need
require
different
evaluation
techniques
searcher
information
needs
may
broadly
classified
basis
type
answer
expected
short
eg
single
sentence
answer
question
example
melting
point
lead
210c
evaluation
techniques
type
information
need
considered
trec-8
question
answer
track
voorhees
harman
1999
various
papers
single
document
example
home
page
information
retrieval
journal
current
timetable
washington
metro
red
line
directory
accommodation
athens
greece
type
subsumes
traditional
known-item
search
however
web
searchers
often
deduce
particular
document
company
homepage
bus
timetable
exist
without
previously
seen
situation
accurately
described
suspected-item
search
often
page
important
searcher
seeking
point
start
browsing
selection
documents
documents
might
sought
research
purposes
example
range
documents
relating
us
policy
north
korea
order
access
on-line
services
example
on-line
auction
sites
sites
allow
download
recorded
music
every
document
matching
criterion
example
every
document
discusses
orbital
engines
evaluation
type
need
obviously
related
coverage
also
sophistication
engine
expanding
query
find
documents
literally
match
query
match
one
semantically
equivalent
example
sarich
engine
motor
developed
ralph
sarich
etc
another
complication
arises
expression
needs
terms
explicit
implicit
document
metadata
documents
authored
doug
engelbart
blair
maron
1985
discuss
retrieval
effectiveness
high-recall
legal
application
first
two
types
evaluation
requires
access
documents
type
relevance
even
strong
relevance
usually
sufficient
evaluation
must
based
asessment
whether
document
one
sought
cases
performance
can
evaluated
basis
position
desired
document
ranking
makes
little
sense
talk
relevance
illustrate
point
australian
national
university
intranet
contains
thousands
documents
relevant
topic
libraries
one
common
queries
submitted
search
engine
library
cases
submitter
query
looking
library
homepage
library
catalogue
ability
engine
retrieve
pages
merely
talk
libraries
unlikely
correlate
well
searcher
satisfaction
56
hawking
et
al
type
evaluation
may
limited
first
10
20
results
users
expect
find
information
require
fewer
number
documents
however
important
documents
presented
result
list
repeat
material
evaluation
methodology
type
information
need
take
account
evaluation
recall-oriented17
information
needs
type
difficult
given
limited
assessment
resources
must
inevitably
rely
sampling
techniques
classification
information
needs
difficult
four-way
classification
illustrates
need
range
evaluation
paradigms
still
gross
over-simplification
information
needs
highly
dynamic
conditioned
preliminary
results
example
someone
searching
complete
timetable
may
find
single
document
can
found
forced
seek
multiple
individual
timetables
together
provide
needed
information
type
search
single
homepage
may
may
transform
type
search
becomes
clear
multiple
home
pages
exist
within
types
may
need
range
judging
instructions
need
range
different
measures
case
type
research
needs
probably
preferable
use
multi-valued
relevance
judgments
gordon
pathak
may
possible
exploit
additional
relevance
information
note
however
gordon
pathak
report
results
relying
distinction
irrelevant
highly
irrelevant
also
convert
four-value
relevance
judgments
binary
order
compute
measures
contrast
case
type
services
needs
judgment
made
whether
page
relevant
rather
whether
page
allows
direct
access
service
right
type
example
whether
page
allows
downloading
mp3
files
opposed
discussing
topic
downloading
mp3
files
defect
present
study
treated
queries
though
corresponded
type
research
information
needs
problem
may
misinterpreted
intention
searchers
submitted
particular
queries
important
ability
search
engines
process
queries
types
evaluated
web
context
may
desirable
accord
least
partial
scores
retrieved
documents
contain
useful
content
link
indeed
pages
may
best
answers
searcher
seeking
point
browse
rather
particular
content
number
issues
indirect
relevance
canvassed
discussion
trec-8
small
web
task
hawking
et
al
1999
evaluations
carried
frequent
intervals
maintain
up-to-date
picture
relative
performance
smooth
performance
glitches
cost
evaluations
based
type
queries
largely
attributable
assessor
salaries
consequently
desirable
maximize
value
assessments
made
potentially
high
correlation
different
measures
might
used
limit
many
pages
per
topic
need
judged
may
greater
value
judging
fewer
documents
per
topic
larger
number
topics
particularly
measures
derived
top
ranking
may
best
predictors
user
satisfaction
certain
information
need
types
measuring
search
engine
quality
57
comparing
performance
one
evaluation
next
normalising
baseline
needed
median
performance
large
number
engines
used
role
unable
detect
general
increase
decline
performance
use
standard
set
queries
evaluation
solve
problem
variations
human
judgments
time
possibility
search
engine
companies
tune
results
queries
possibility
able
identify
involves
including
known
unchanging
engine
operated
evaluators
successive
evaluation
using
rejudged
performance
normalising
baseline
permit
fair
comparison
trec
systems
present
study
penalise
search
engines
returning
defunct
pages
results
list
future
evaluations
compare
trec
treat
dead
link
worthless
answer
however
may
considered
necessary
make
several
attempts
access
page
case
inaccessibility
temporary
considerable
care
needed
writing
scripts
automatically
posing
queries
search
engines
retrieving
results
format
result
pages
changes
time
time
may
cause
errors
thorough
sanity
checks
applied
results
obtained
automatic
means
presenting
documents
assessment
important
way
simulates
normal
web
search
see
point
10
figure
11
figure
11
summarises
features
believe
present
future
web
search
evaluations
conclusions
future
work
performed
web
search
engine
evaluation
using
appropriate
scientific
methodology
larger
scale
previously
published
studies
evaluation
shows
choice
search
engine
makes
difference
early
precision
significantly
correlated
index
coverage
best
search
engines
now
using
algorithms
approaching
effectiveness
relevance
based
tasks
used
trec-8
large
web
task
participants
found
unexpectedly
high
correlation
results
obtained
us
obtained
study
conducted
others
year
earlier
high
intercorrelations
four
different
measures
derivable
top
live
results
work
needed
refine
classification
information
need
types
web
search
identify
appropriate
evaluation
paradigms
type
user
studies
determine
effectiveness
measures
best
correlate
searcher
satisfaction
ratings
valuable
user
studies
will
also
required
determine
proportion
web
queries
derived
information
need
type
inspection
query
logs
frequently
fails
reveal
searchers
intentions
order
present
complete
picture
search
engine
performance
future
studies
include
queries
derived
range
commonly
expressed
information
need
types
use
appropriate
judgments
measures
type
reduce
multi-dimensional
results
study
single
index
effectiveness
will
require
dimension
weighted
frequency
occurrence
corresponding
information
need
type
58
hawking
et
al
notes
10
11
12
13
14
15
16
17
table
148
work
formally
published
1999
146
term
captures
intention
long-drawn-out
incomplete
nature
actual
crawls
item
accessible
via
web
conventionally
called
web
page
printed
web
page
may
cover
many
pages
just
lines
stopword
functional
word
like
don
know
chosen
rat
mode
relevance
documents
automatically
determined
using
concepts
criteria
evidence
supplied
judge
discrepancies
automatic
manual
judgments
result
alert
requires
judge
either
accept
automatic
judgment
override
record
reason
mode
used
present
experiments
nist
judges
working
documents
trec
collections
judge
several
hundred
documents
per
day
average
trec
average
precision
topic
based
precision
values
point
ranking
relevant
document
retrieved
average
precision
obtained
dividing
sum
values
number
relevant
documents
collection
unknown
many
relevant
documents
really
rankings
cut
rather
1000
accordingly
sum
divided
case
result
called
trec-style
average
precision
cutoff
tsap
average
precisions
unlike
true
trec
measure
include
recall
component
system
documents
retrieved
query
judged
relevant
score
1.0
measure
one
one
retrieved
document
relevant
score
49
depending
upon
position
relevant
document
ranking
note
although
individual
topic
tsap
scores
constant
multiple
trec
average
precision
cutoff
multiplier
varies
topic
topic
consequently
across-topic
averages
two
measures
simply
related
engines
requested
generous
number
results
single
page
engines
didn
know
necessary
url
syntax
requested
results
page
page
manova
repeated
factor
queries
independent
group
factor
search
engines
dependent
measure
multiple
rather
univariate
model
selected
latter
sensitive
violations
sphericity
common
repeated
measures
designs
related
samples
test
appropriate
query
processed
20
engines
cochran
test
non-parametric
test
determining
series
related
samples
differ
circumstances
data
based
nominal
dichotomised
ordinal
scale
measurement
data
latter
type
scores
individual
queries
must
either
related
samples
test
appropriate
query
sent
20
engines
mann-whitney
non-parametric
test
difference
two
independent
groups
nonparametric
test
selected
small
sample
size
trec
group
ideal
merging
algorithm
one
capable
producing
merged
list
relevant
documents
primary
results
lists
appear
first
note
high
precision
also
required
references
alta
vista
company
alta
vista
web
page
http://www.altavista.com/.
blair
dc
maron
1985
evaluation
retrieval
effectiveness
full-text
document-retrieval
system
communications
acm
28
289
299
buckley
voorhees
2000
evaluating
evaluation
measure
stability
proceedings
sigir
00
new
york
2000
pp
33
40
acm
press
measuring
search
engine
quality
59
cleverdon
1997
cranfield
tests
index
language
devices
jones
ks
willett
eds
readings
information
retrieval
morgan
kauffman
san
francisco
pp
47
59
reprinted
aslib
proceedings
19
173
192
ding
marchionini
1996
comparative
study
web
search
service
performance
proceedings
asis
1996
annual
conference
oct
1996
pp
136
142
eisenberg
barry
1998
order
effects
study
possible
influence
presentation
order
user
judgments
document
relevance
journal
american
society
information
science
39
293
300
electric
knowledge
llc
electric
monk
home
page
http://electricmonk.com/.
gordon
pathak
1999
finding
information
world
wide
web
retrieval
effectiveness
search
engines
information
processing
management
35
141
180
hawking
thistlewaite
1997
overview
trec-6
large
collection
track
voorhees
em
harman
dk
eds
proceedings
trec-6
gaithersburg
md
nov
1997
pp
93
106
nist
special
publication
500
240
http://trec.nist.gov.
hawking
thistlewaite
harman
1999
scaling
trec
collection
information
retrieval
115
137
hawking
voorhees
bailey
craswell
1999
overview
trec-8
web
track
proceedings
trec-8
gaithersburg
md
nov
1999
pp
131
150
nist
special
publication
500
246
http://trec.nist.gov.
koster
web
robots
pages
http://info.webcrawler.com/mak/projects/robots/robots.html.
lawrence
lee
giles
1999
accessibility
information
web
nature
400
107
109
leighton
hv
srivastava
1999
first
20
precision
among
world
wide
web
search
services
search
engines
journal
american
society
information
science
50
10
882
889
lynx
lynx
browser
home
page
http://lynx.browser.org.
salton
lesk
1997
computer
evaluation
indexing
text
processing
jones
ks
willett
eds
readings
information
retrieval
morgan
kauffman
san
francisco
pp
60
84
reprinted
journal
acm
15
36
silverstein
henzinger
marais
moricz
1999
analysis
large
web
search
engine
query
log
sigir
forum
33
12
previously
available
digital
systems
research
center
tr
1998
014
http://www.research.digital.com/src.
voorhees
em
harman
dk
1998
eds
proceedings
trec-7
gaithersburg
md
nov
1998
nist
special
publication
500
242
http://trec.nist.gov.
voorhees
em
harman
dk
1999
eds
proceedings
trec-8
gaithersburg
md
nov
1999
nist
special
publication
500
246
cm
http://trec.nist.gov.
voorhees
em
harman
dk
1996
overview
fifth
text
retrieval
conference
trec-5
voorhees
em
harman
dk
eds
proceedings
trec-5
gaithersburg
md
nov
1996
pp
28
nist
special
publication
500
238
http://trec.nist.gov.
voorhees
em
1998
variations
relevance
judgments
measurement
retrieval
effectiveness
croft
wb
moffat
van
rijsbergen
cj
wilkinson
zobel
eds
proceedings
sigir
98
melbourne
australia
august
1998
pp
315
323