cell
systems
commentary
fairshake
toolkit
to
evaluate
the
fairness
of
research
digital
resources
daniel
clarke
lily
wang
alex
jones
megan
wojciechowicz
denis
torre
kathleen
jagodnik
sherry
jenkins
peter
mcquilton
zachary
flamholz
moshe
silverstein
brian
schilder
kimberly
robasky
claris
castillo
ray
idaszak
stanley
ahalt
jason
williams
stephan
schurer
daniel
cooper
ricardo
de
miranda
azevedo
juergen
klenk
melissa
haendel
jared
nedzel
paul
avillach
10
mary
shimoyama
11
rayna
harris
12
meredith
gamble
13
rudy
poten
13
amanda
charbonneau
12
jennie
larkin
14
titus
brown
12
vivien
bonazzi
15
michel
dumontier
susanna-assunta
sansone
and
avi
ma
ayan1
1department
of
pharmacological
sciences
mount
sinai
center
for
bioinformatics
icahn
school
of
medicine
at
mount
sinai
new
york
ny
10029
usa
2deloitte
consulting
1919
lynn
st
arlington
va
22209
usa
3oxford
e-research
centre
department
of
engineering
science
university
of
oxford
oxford
ox1
3qg
uk
4renaissance
computing
institute
university
of
north
carolina
chapel
hill
usa
5cold
spring
harbor
laboratory
bungtown
rd
cold
spring
harbor
ny
11724
usa
6university
of
miami
pharmacology
1600
nw
10th
ave
miami
fl
33136
usa
7institute
of
data
science
maastricht
university
universiteitssingel
60
6229
er
maastricht
the
netherlands
8oregon
state
university
307
linus
pauling
science
center
2900
sw
campus
way
corvallis
or
9733
usa
9the
broad
institute
415
main
st
cambridge
ma
02142
usa
10harvard
medical
school
department
of
biomedical
informatics
10
shattuck
st
boston
ma
02115
usa
11medical
college
of
wisconsin
8701
watertown
plank
road
milwaukee
wi
53226
usa
12department
of
population
health
and
reproduction
school
of
veterinary
medicine
uc
davis
davis
ca
95616
usa
13curoverse
somerville
ma
02144
usa
14national
institute
of
diabetes
digestive
and
kidney
diseases
niddk
national
institutes
of
health
nih
6707
democracy
blvd
bethesda
md
20817
usa
15office
of
the
director
national
institutes
of
health
8600
rockville
pike
rm
2s-20
bethesda
md
20894
usa
correspondence
avi.maayan@mssm.edu
https://doi.org/10.1016/j.cels.2019.09.011
as
more
digital
resources
are
produced
by
the
research
community
it
is
becoming
increasingly
important
to
harmonize
and
organize
them
for
synergistic
utilization
the
findable
accessible
interoperable
and
reusable
fair
guiding
principles
have
prompted
many
stakeholders
to
consider
strategies
for
tackling
this
challenge
the
fairshake
toolkit
was
developed
to
enable
the
establishment
of
community-driven
fair
metrics
and
rubrics
paired
with
manual
and
automated
fair
assessments
fair
assessments
are
visualized
as
an
insignia
that
can
be
embedded
within
digital-resources-hosting
websites
using
fairshake
variety
of
biomedical
digital
resources
were
manually
and
automatically
evaluated
for
their
level
of
fairness
introduction
the
findable
accessible
interoperable
and
reusable
fair
guiding
principles
describe
an
urgent
need
to
improve
the
infrastructure
supporting
scholarly
data
reuse
and
outline
several
existing
resources
that
already
demonstrate
various
aspects
of
fair
and
associated
driving
technologies
wilkinson
et
al
2016
specific
emphasis
has
been
placed
on
ensuring
that
machines
can
exchange
interpretable
data
and
metadata
following
the
fair
principles
the
resource
description
framework
rdf
is
key
globally
accepted
framework
for
data
and
knowledge
representation
that
is
intended
to
be
read
and
interpreted
by
machines
critical
challenge
in
fulfilling
the
goals
outlined
by
the
fair
guiding
principles
is
the
lack
of
consensus
with
respect
to
agreement
on
using
certain
standards
in
an
effort
to
address
this
challenge
comprehensive
communitydriven
approach
was
taken
to
assemble
descriptions
of
standards
repositories
and
policies
and
make
them
easily
accessible
from
one
source
sansone
et
al
2019
by
collecting
community-accepted
elements
of
this
kind
fairsharing
can
reveal
domain-relevant
community
standards
with
respect
to
the
fair
principles
several
initiatives
have
begun
to
develop
their
own
understandings
of
fairness
and
developed
some
methods
of
assessing
fairness
by
self
and
peer-reviewed
manual
question-answer
approaches
cox
and
yu
2017
dillo
and
de
leeuw
2014
because
there
are
different
strategies
for
asserting
fairness
efforts
so
far
have
been
independent
of
one
another
and
as
such
not
comparable
while
the
biomedical
research
community
at
large
mostly
embraces
the
fair
guidelines
there
is
still
some
confusion
about
the
difference
between
being
fair
and
being
open
access
what
it
means
to
be
fair
and
how
the
fair
principles
compare
with
other
standards
hasnain
and
rebholz-schuhmann
2018
in
order
to
bring
the
fair
principles
into
practice
and
to
provide
more
clarity
about
their
meaning
template
was
created
for
constructing
fair
metrics
around
the
original
fair
guiding
principles
wilkinson
et
al
2018
the
publication
that
describes
the
fair
metrics
contains
self-evaluations
by
nine
organizations
while
the
fair
metrics
are
provided
on
github
so
the
community
can
contribute
to
their
development
the
original
authors
of
the
fair
metrics
claim
that
these
metrics
are
universal
and
aim
to
cover
all
types
of
digital
objects
for
all
organizations
in
the
publication
of
the
universal
fair
metrics
it
was
envisioned
that
framework
cell
systems
november
27
2019
2019
elsevier
inc
417
cell
systems
commentary
for
automated
evaluation
of
using
the
fairshake
interface
fairness
could
be
devised
and
accessing
fairshake
using
self-describing
and
programmatically
programmatically
executable
to
perform
and
visualize
metrics
this
was
followed
fair
assessments
with
fairby
an
initial
attempt
to
shake
users
must
follow
develop
system
that
evaluseveral
steps
table
first
ates
fair
maturity
level
users
are
required
to
sign
up
wilkinson
et
al
2019
sign
up
is
available
via
while
the
universal
fair
standard
registration
and
via
metrics
developed
by
some
oauth
implementation
of
of
the
original
authors
of
the
github
orcid
and
globus
fair
guiding
principles
pro
foster
and
kesselman
vide
concrete
guide
on
how
1997
next
users
are
required
to
assess
fairness
the
unito
create
project
projects
versal
fair
metrics
may
not
are
bundle
of
thematically
fit
all
domains
and
specific
rerelevant
digital
resources
quirements
for
example
project
descriptions
contain
recent
review
by
group
conminimal
information
for
identisisting
of
biopharma
refying
displaying
and
indexing
the
project
within
projects
searchers
and
representatives
figure
diagram
illustrating
fairshake
workflow
users
can
assess
the
fairsuggests
that
the
biopharma
digital
resources
from
various
projects
are
paired
with
fair
metrics
and
ness
of
an
arbitrary
collection
community
has
unique
rerubrics
to
perform
assessments
that
are
visualized
with
the
fair
insignia
of
digital
resources
project
quirements
so
being
fair
for
analytics
are
available
to
help
them
may
mean
different
thing
compared
with
other
digital
object
the
fairness
of
thousands
of
digital
re
user
better
understand
the
overall
fairness
of
the
digital
resources
contained
producers
wise
et
al
2019
sources
for
numerous
projects
within
the
project
next
users
need
to
in
order
to
facilitate
digital
resource
associate
the
digital
objects
in
their
proproducers
to
define
assess
and
implejects
with
rubrics
and
metrics
fair
metment
their
own
fairness
criteria
for
their
the
fairshake
framework
specialized
specific
projects
we
devel
overall
fairshake
provides
mechanisms
rics
are
questions
that
assess
whether
oped
fairshake
fairshake
enables
the
to
associate
digital
objects
with
rubrics
digital
object
complies
with
specific
community
to
develop
new
standards
or
and
metrics
to
perform
fair
assessments
aspect
of
fair
fair
metric
is
directly
reuse
existing
standards
to
define
and
these
assessments
are
communicated
via
related
to
one
of
the
fair
guiding
princievaluate
fairness
thus
fairshake
the
fair
insignia
figure
the
fairshake
ples
in
order
to
make
fair
metrics
reusallows
the
co-existence
of
multiple
met
toolkit
is
composed
of
elements
that
able
fairshake
collects
information
rics
and
rubrics
enabling
the
community
include
full-stack
web-server
application
about
each
metric
and
when
users
to
develop
standards
more
democrati
containing
user
interface
with
search
attempt
to
associate
digital
resource
cally
fairshake
is
toolkit
that
enables
engine
backend
database
and
an
appli
with
metrics
existing
metrics
are
prothe
systematic
assessment
of
the
fair
cation-programming
interface
api
as
well
vided
as
first
choice
fair
metrics
ness
of
any
digital
resource
compared
as
chrome
extension
and
bookmarklet
represent
human-described
concept
with
previous
attempts
to
develop
fair
table
fairshake
also
contains
fair
that
may
or
may
not
be
automated
autoness
assessment
tooling
the
fairshake
analytics
modules
that
produce
statistical
mation
of
such
concepts
can
be
done
toolkit
has
more
features
it
contains
reports
about
collections
of
assessments
independently
by
linking
actual
source
database
that
enlists
users
projects
dig
for
specific
project
in
an
effort
to
make
code
to
reference
persistent
identifier
ital
resources
metrics
rubrics
and
as
fairshake
adhere
to
the
fair
guidelines
of
that
metric
semantic
without
linked
sessments
figure
it
is
full-stack
the
fairshake
endpoint-rest
api
is
ma
code
metrics
are
simply
questions
that
application
with
user
interface
and
it
chine
readable
with
documentations
for
can
be
answered
manually
fairshake
comes
with
browser
extension
and
smartapi
swagger
openapi
https
defines
several
categorical
answer
types
bookmarklet
to
enable
viewing
and
sub
swagger
io
and
coreapi
https://www.
to
fair
metrics
when
manually
assessed
mitting
assessments
from
any
website
coreapi
org
the
api
can
be
accessed
that
are
ultimately
quantified
to
value
in
the
fair
assessment
results
are
visual
via
the
human-friendly
counterparts
of
range
between
zero
and
one
or
take
ized
as
an
insignia
that
represents
the
these
specifications
with
the
rest
frame
the
property
of
undefined
programmatifair
score
in
compact
grid
of
squares
work
api
explorer
https://www.django-
cally
metric
code
can
quantify
the
satiscolored
in
red
blue
and
purple
below
rest-framework
org
topics
browsable-api
faction
of
given
fair
metric
within
this
we
briefly
describe
the
various
compo
swagger
ui
https://swagger.io/tools/
same
range
the
concept
of
metric
is
nents
of
fairshake
how
they
are
related
swagger-ui
and
coreapi
ui
jupyter
supplemented
with
that
of
fair
rubric
to
each
other
and
how
the
fairshake
notebook
and
youtube
tutorials
are
avail
fair
rubric
is
collection
of
fair
metsystem
has
been
already
used
to
assess
able
to
guide
users
through
the
process
of
rics
an
assessment
of
digital
resource
418
cell
systems
november
27
2019
cell
systems
commentary
table
the
major
components
of
the
fairshake
toolkit
feature
description
url
search
engine
the
fairshake
search
engine
can
be
used
to
identify
project
digital
objects
rubric
and
metrics
https://fairshake.cloud/
open
source
code
the
fairshake
project
is
open
source
and
available
from
github
https://github.com/maayanlab/
fairshake
swagger
api
the
fairshake
api
is
documented
in
swagger
https://fairshake.cloud/swagger/
youtube
tutorials
there
are
several
video
tutorials
on
youtube
that
describe
how
to
use
fairshake
https://www.youtube.com/watch?
7u0c4-yzxga
list
fair
analytics
example
fair
analytics
stats
applied
to
agr
resources
https://fairshake.cloud/project/
10
stats
jupyter
notebook
tutorial
there
is
jupyter
notebook
tutorial
that
guides
users
on
how
to
use
fairshake
programmatically
https://fairshake.cloud/
documentation
bookmarklet
users
can
install
bookmarklet
that
enables
fair
evaluations
of
digital
objects
listed
on
any
website
https://fairshake.cloud/
bookmarklet
browser
extension
users
can
install
browser
that
enables
fair
evaluations
of
digital
objects
listed
on
any
website
https://fairshake.cloud/
chrome_extension
is
performed
using
specific
rubric
by
obtaining
answers
to
the
metrics
within
the
rubric
the
use
of
fair
rubric
makes
it
possible
to
establish
relevant
and
applicable
group
of
metrics
for
large
number
of
digital
resources
typically
under
the
umbrella
of
specific
project
while
enabling
reuse
of
metrics
both
for
comparisons
across
different
projects
and
for
automation
linking
rubrics
to
digital
resources
by
association
helps
users
understand
the
context
of
the
fair
metrics
that
are
best
suited
to
assess
the
digital
resources
in
their
projects
fair
assessments
can
be
performed
manually
or
automatically
on
digital
resource
that
is
associated
with
rubric
leveraging
rdf
fairshake
automatically
extracts
rdf-expressed
schema
org
metadata
from
urls
with
extruct
ter
table
steps
to
perform
and
visualize
fair
assessments
with
fairshake
step
instructions
sign
up
fill
in
registration
form
log
in
enter
user
name
and
password
start
project
fill
out
form
that
describes
the
project
register
digital
objects
register
digital
objects
in
fairshake
and
associate
them
with
the
project
add
fair
metric
fill
out
form
to
set
up
the
fair
metric
question
and
possible
answers
add
fair
rubric
associate
collection
of
fair
metrics
with
new
rubric
associate
rubrics
with
digital
objects
associate
each
registered
digital
object
from
the
project
with
registered
rubric
perform
assessments
answer
each
fair
metric
question
to
fill
in
the
fair
evaluation
questionnaire
visualize
the
fair
results
with
an
insignia
hosting
websites
can
use
javascript
library
to
visualize
fair
assessments
of
the
digital
objects
they
host
alternatively
the
insignia
can
be
visualized
via
browser
extension
or
bookmarklet
mehchy
and
winslett
2010
library
for
extracting
embedded
metadata
from
html
markup
this
approach
is
utilized
by
major
search
engines
to
index
websites
and
bind
information
together
using
this
rdf-expressed
metadata
alone
some
fair
metrics
are
automatically
resolved
including
those
designed
with
rdf
in
mind
as
schema
org
expands
its
vocabulary
through
initiatives
such
as
bioschemas
garcia
et
al
2017
rdf
will
enable
more
automated
assessments
adopting
other
non-rdf
based
standards
has
also
been
accomplished
with
fairshake
in
summary
any
assessment
of
digital
resource
within
fairshake
attempts
to
obtain
answers
automatically
the
newly
assessed
digital
resource
will
now
have
an
associated
insignia
that
reflects
the
results
of
the
fair
assessment
the
fairshake
insignia
uses
color
gradient
from
blue
satisfactory
to
red
unsatisfactory
visualizing
how
well
digital
resource
satisfied
the
fair
metrics
of
the
chosen
rubric
because
the
same
digital
resources
can
be
assessed
by
different
rubrics
composed
of
different
metrics
the
insignia
dynamically
expands
to
fit
all
assessments
if
answers
to
the
rubric
are
missing
the
squares
associated
with
these
metrics
will
be
colored
in
gray
developers
of
data
and
tool
portals
can
visualize
fairshake
insignias
on
their
site
standalone
javascript
library
for
generating
the
insignias
at
any
hosting
website
with
few
lines
of
code
is
provided
alternatively
through
this
library
browser
extension
and
bookmarklet
were
developed
for
rendering
the
visualization
of
fair
insignias
on
any
website
without
the
need
of
the
hosting
site
to
modify
their
website
source
code
fairshake
was
already
applied
to
assess
the
fairness
of
many
digital
objects
that
belong
to
various
high-profile
projects
table
the
first
use
of
fairshake
involved
the
manual
assessment
of
150
tools
and
datasets
developed
by
the
alliance
of
genome
resources
agr
https://www.alliancegenome.org/).
detailed
results
and
breakdown
of
these
assessments
were
captured
in
an
html
table
and
associated
jupyter
notebooks
that
are
available
at
https://maayanlab.
github
io
agr-fair-website
overall
we
observed
that
the
examined
agr
tools
and
datasets
scored
well
in
regard
to
providing
data
for
download
use
of
ontologies
and
providing
contact
information
cell
systems
november
27
2019
419
cell
systems
commentary
table
case
studies
where
fairshake
was
utilized
to
perform
fair
assessment
to
evaluate
various
collections
of
digital
objects
number
of
digital
objects
url
case
study
resource
manual
assessment
of
agr
datasets
and
bioinformatics
tools
agr
150
https://www.alliancegenome.org/
https://fairshake.cloud/
project
10
automated
assessment
fairsharing
of
the
resources
https://fairsharing.org/
listed
on
fairsharing
176
https://fairshake.cloud/
project
14
automated
assessment
dbgap
of
topmed
studies
ftp
ftp
ncbi
nlm
nih
gov
on
dbgap
dbgap
studies
27
https://fairshake.cloud/
project
61
automated
assessment
smartapi
https://smart-api.info/
of
apis
listed
on
smartapi
35
https://fairshake.cloud/
project
53
automated
assessment
ncbi
of
ncbi
tool
and
https://www.ncbi.nlm.nih.gov/
databases
227
https://fairshake.cloud/
project
71
automated
assessment
nih
common
fund
of
common
fund
https://commonfund.nih.gov/
programs
datasets
31282
https://fairshake.cloud/
project
87
while
most
agr
tools
and
datasets
did
not
provide
the
source
code
versioning
information
or
api
access
figure
limitations
and
challenges
the
fairshake
platform
is
complex
before
beginning
to
use
fairshake
users
must
have
some
training
about
concepts
like
fair
metrics
and
rubrics
associating
digital
object
with
the
right
rubric
is
not
trivial
while
the
co-existence
of
multiple
rubrics
provides
flexibility
and
freedom
in
the
choice
of
how
one
may
define
fair
this
approach
has
the
risk
of
having
too
many
different
interpretations
of
the
guidelines
with
undesired
partial
redundancy
that
is
not
consolidated
into
shared
standard
we
hope
that
with
increasing
use
of
fairshake
users
will
be
able
to
reuse
metrics
without
the
need
to
create
new
ones
this
can
potentially
enable
the
development
of
grassroots
eventually
widely
accepted
standard
incentivizing
users
with
carrots
and
sticks
when
community
standards
are
developed
global
adoption
is
needed
in
order
to
facilitate
their
true
enabling
poten
figure
fair
assessment
of
agr
tools
distribution
of
average
fair
scores
for
132
agr
tools
assessed
with
an
initial
set
of
fair
metrics
420
cell
systems
november
27
2019
tial
community
adoption
of
fairnessendorsed
standards
is
challenging
because
digital
object
producers
do
not
always
see
the
added
benefit
in
spending
the
time
effort
and
resources
to
fairify
their
digital
products
in
most
cases
digital
object
producers
will
use
the
excuse
that
they
do
not
have
the
required
resources
to
spend
on
fairification
thus
there
are
currently
few
incentives
for
them
to
make
their
products
fairer
such
incentives
can
be
nurtured
specifically
these
incentives
can
be
divided
into
carrots
and
sticks
if
more
fairenabled
resources
become
used
by
the
community
for
example
if
researchers
will
begin
using
resources
such
as
google
datasets
halevy
et
al
2016
more
frequently
for
their
research
digital
object
producers
will
want
to
be
listed
there
if
data
citations
begin
to
soar
digital
object
producers
will
have
the
incentive
to
participate
these
are
carrot
incentives
for
fairification
at
the
same
time
funders
and
journals
can
demand
that
published
data
meet
certain
communityaccepted
standards
before
they
are
accepted
for
publication
or
become
eligible
for
funding
this
is
achieved
for
example
when
gene
expression
data
are
deposited
into
the
gene
expression
omnibus
geo
or
when
solved
protein
structure
coordinates
are
deposited
into
the
protein
data
bank
pdb
funders
and
journals
requiring
researchers
to
take
the
needed
steps
in
order
to
ensure
the
fairness
of
the
digital
resources
they
produce
is
stick
approach
however
convicting
funders
and
journals
to
enforce
new
rules
is
often
difficult
due
to
possible
backlash
from
the
researchers
who
will
simply
go
somewhere
else
ultimately
fairification
benefits
all
the
digital
object
producers
the
journals
the
funders
and
the
users
who
are
the
real
consumers
of
these
digital
resources
the
question
and
challenge
is
simply
determining
who
is
responsible
for
performing
the
fairification
task
who
will
pay
for
it
and
what
it
means
to
do
it
and
perhaps
overdo
it
the
concept
of
digital
objects
needs
to
be
born
fair
suggests
that
this
activity
needs
to
be
done
by
the
data
producers
at
an
early
stage
discussion
fairshake
was
developed
as
toolkit
to
promote
the
fairification
of
digital
objects
cell
systems
commentary
produced
by
research
projects
fairshake
is
not
intended
to
judge
or
penalize
digital
resource
producers
but
rather
to
promote
the
awareness
about
standards
the
purpose
of
fairshake
is
to
guide
digital
object
producers
to
implement
community-accepted
best
practices
for
their
own
benefit
of
attracting
retaining
and
enabling
more
engagement
with
the
digital
objects
they
produce
there
is
common
confusion
between
assessing
the
quality
of
resource
and
assessing
its
fairness
it
should
be
made
clear
that
fairshake
was
designed
to
assess
fairness
and
low
fair
score
does
not
mean
that
digital
resource
is
lacking
quality
usefulness
user
friendliness
or
innovation
another
aspect
of
confusion
about
fair
is
the
association
of
fairness
with
openness
being
fair
does
not
entail
making
data
source
code
tools
or
any
other
digital
resource
free
and
openly
available
rather
the
fair
guidelines
only
require
that
access
and
usage
policies
are
provided
and
stated
clearly
haendel
et
al
2016
mons
et
al
2017
by
facilitating
the
creation
of
both
manual
and
automated
fair
assessments
and
enabling
fair
metric
findability
fairshake
promotes
the
involvement
of
more
stakeholders
starting
with
the
process
of
manual
fair
assessments
the
capacity
for
automation
is
expected
to
further
expand
as
more
adoption
is
realized
the
findability
of
fair
metrics
within
fairshake
makes
it
possible
to
design
community-adopted
metrics
that
can
be
customized
for
specific
purposes
but
at
the
same
time
for
general
and
generic
uses
fairshake
strives
to
evolve
with
the
community
adding
new
features
to
accommodate
community
demands
as
they
arise
while
facilitating
more
assessments
with
its
feature
of
enabling
the
development
of
fair
metrics
and
rubrics
by
any
user
the
assessment
of
digital
resources
can
happen
before
the
community
agrees
on
the
definition
of
what
it
means
to
be
fair
fairshake
facilitates
dynamic
metric
re-use
and
it
provides
analytical
tools
to
understand
the
global
and
relative
performance
of
resources
and
metrics
with
transparency
fairshake
enables
the
community
to
study
the
fairness
of
the
resources
they
produce
and
use
fairshake
was
developed
to
meet
the
demands
of
the
biomedical
research
community
with
integration
of
number
of
community-accepted
standards
including
rdf
dats
smartapi
and
schema
org
fairshake
is
already
capable
of
facilitating
fair
assessments
of
diverse
set
of
digital
objects
including
datasets
tools
repositories
and
apis
throughout
our
initial
assessments
it
has
become
clear
that
many
established
community
standards
are
not
being
employed
within
the
biomedical
research
community
largely
due
to
lack
of
awareness
as
the
community
continues
to
evolve
toward
better
defining
fairness
the
fair
metrics
are
expected
to
converge
and
the
fair
assessments
are
likely
to
become
more
automated
fairshake
will
continue
to
evolve
with
community
demand
continued
improvements
to
the
clarity
usability
and
fairness
of
fairshake
are
planned
similarly
through
integration
with
existing
fair-embracing
resources
such
as
fairsharing
fairshake
will
enable
the
display
of
assessments
on
digital
resource
landing
pages
so
that
broader
community
of
users
will
become
more
aware
of
fairshake
the
fairshake
platform
codebase
can
be
reused
for
the
assessment
of
other
digital
and
physical
products
such
as
publications
events
books
and
courses
however
such
assessments
may
not
be
relevant
to
the
fair
guiding
principles
nevertheless
the
fairshake
platform
is
flexible
enough
that
it
can
facilitate
other
related
applications
even
potentially
repurposing
fairshake
as
platform
for
scientific
peer
review
availability
the
primary
interface
to
fairshake
is
at
https://fairshake.cloud.
the
fairshake
chrome
extension
is
available
from
https://chrome.google.
com
webstore
detail
fairshake
pihohcec
piomegpagadljmdifpbkhnjn
hl
en-us
the
fairshake
source
code
is
available
from
github
at
https://github.com/
maayanlab
fairshake
dillo
and
de
leeuw
2014
data
seal
of
approval
certification
for
sustainable
and
trusted
data
repositories
the
hague
data
archiving
and
networked
services
dans
20
foster
and
kesselman
1997
globus
metacomputing
infrastructure
toolkit
the
international
journal
of
supercomputer
applications
and
high
performance
computing
11
115
128
garcia
giraldo
garcia
and
dumontier
2017
bioschemas
schema
org
for
the
life
sciences
proceedings
of
swat4ls
haendel
su
mcmurry
chute
mungall
good
wu
mcweeney
hochheiser
and
robinson
2016
metrics
to
assess
value
of
biomedical
digital
repositories
response
to
rfi
not-od-16-133
zenodo
halevy
korn
noy
olston
polyzotis
roy
and
whang
2016
proceedings
of
the
2016
international
conference
on
management
of
data
acm
san
francisco
california
usa
pp
795
806
hasnain
and
rebholz-schuhmann
2018
assessing
fair
data
principles
against
the
star
open
data
principles
in
the
semantic
web
eswc
2018
satellite
events
springer
international
publishing
pp
469
477
mons
neylon
velterop
dumontier
da
silva
santos
and
wilkinson
2017
cloudy
increasingly
fair
revisiting
the
fair
data
guiding
principles
for
the
european
open
science
cloud
inf
serv
use
37
49
56
sansone
mcquilton
rocca-serra
gonzalez-beltran
izzo
lister
and
thurston
fairsharing
community
2019
fairsharing
as
community
approach
to
standards
repositories
and
policies
nat
biotechnol
37
358
367
termehchy
and
winslett
2010
extruct
using
deep
structural
information
in
xml
keyword
search
proceedings
vldb
endowment
1593
1596
wilkinson
dumontier
aalbersberg
appleton
axton
baak
blomberg
boiten
da
silva
santos
bourne
et
al
2016
the
fair
guiding
principles
for
scientific
data
management
and
stewardship
sci
data
160018
wilkinson
sansone
schultes
doorn
bonino
da
silva
santos
and
dumontier
2018
design
framework
and
exemplar
metrics
for
fairness
sci
data
180118
acknowledgments
this
work
was
partially
supported
by
the
national
institutes
of
health
united
states
grant
numbers
ot3-od025467
ot3-od025459
and
u54hl127624
references
cox
and
yu
2017
oznome
star
tool
rating
system
for
making
data
fair
and
trustable
eresearch
australasia
2017
wilkinson
dumontier
sansone
bonino
da
silva
santos
prieto
batista
mcquilton
kuhn
rocca-serra
crosas
and
schultes
2019
evaluating
fair
maturity
through
scalable
automated
community-governed
framework
sci
data
174
wise
de
barron
splendiani
balalimood
vasant
little
mellino
harrow
smith
taubert
et
al
2019
implementation
and
relevance
of
fair
data
principles
in
biopharmaceutical
drug
discov
today
24
933
938
cell
systems
november
27
2019
421