thirty-sixth
aaai
conference
artificial
intelligence
aaai-22
ceo
gender
bias
really
fixed
adversarial
attacking
improving
gender
fairness
image
search
yunhe
feng
chirag
shah
information
school
university
washington
yunhe@uw.edu
chirags@uw.edu
abstract
gender
bias
one
common
well-studied
demographic
biases
information
retrieval
general
ai
systems
discovering
reporting
gender
bias
certain
professions
change
searchers
worldviews
mainstreaming
image
search
engines
google
quickly
took
action
correct
fix
bias
however
given
nature
systems
viz
opaque
unclear
addressed
unequal
gender
representation
gender
stereotypes
image
search
results
systematically
sustainable
way
paper
propose
adversarial
attack
queries
composed
professions
countries
ceo
united
states
investigate
whether
gender
bias
thoroughly
mitigated
image
search
engines
experiments
google
baidu
naver
yandex
image
search
show
proposed
attack
can
trigger
high
levels
gender
bias
image
search
results
effectively
defend
attacks
mitigate
gender
bias
design
implement
three
novel
re-ranking
algorithms
epsilon-greedy
algorithm
relevance-aware
swapping
algorithm
fairness-greedy
algorithm
re-rank
returned
images
given
image
queries
experiments
simulated
three
typical
gender
distributions
real-world
datasets
demonstrate
proposed
algorithms
can
mitigate
gender
bias
effectively
introduction
web
biggest
image
search
engines
google
bing
provide
important
information-seeking
interface
people
explore
world
according
internet
live
stats1
google
processes
3.5
billion
queries
per
day
1.2
trillion
searches
per
year
google
image
searches
account
22.6
searches2
given
volume
importance
daily
lives
image
search
results
can
significantly
influence
people
perceive
view
world
images
often
useful
objects
information
provide
visual
representation
phenomenon
concept
perceived
reality
world
around
us
given
sufficient
assess
quality
image
search
results
using
relevance
metrics
also
need
consider
visual
information
carries
various
perceptions
prejudice
example
lam
et
al
2018
showed
searching
ceo
google
image
search
resulted
predominantly
white
males
query
web
search
provides
diverse
set
copyright
2022
association
advancement
artificial
intelligence
www.aaai.org).
rights
reserved
https://www.internetlivestats.com/google-search-statistics/
https://firstsiteguide.com/google-search-stats/
11882
information
objects
definition
wikipedia
article
questions
answers
image
search
results
mono-media
appeal
one
visual
perceptions
can
quickly
affect
worldview
hibbing
rankin-erickson
2003
results
carry
biases
shown
lam
et
al
2018
kay
matuszek
munson
2015
much
easier
perpetuate
regular
web
search
results
therefore
evaluating
image
search
results
need
look
beyond
relevance
must
also
look
inherent
disparity
biases
carried
among
different
types
image
biases
gender
bias
one
common
well-studied
demographic
biases
surprisingly
also
gets
scrutiny
attention
scholars
media
often
makes
service
providers
take
immediate
actions
fix
biases
ad
hoc
manner
example
work
described
kay
matuszek
munson
2015
received
lot
attention
google
shifted
gender
distributions
image
search
results
ceo
occupations
instance
famous
query
ceo
image
search
fixed
long
time
see
figure
figure
however
mozilla
recent
internet
health
report
mozilla
2021
points
default
internet
user
still
viewed
white
male
cisgender
big
tech
done
enough
fix
griffith
2021
one
way
gender
bias
problem
fixed
paper
revisit
gender
bias
image
search
results
professional
occupations
search
terms
ceo
gender
fairness
observed
image
search
results
image
search
engines
mitigated
gender
biases
search
results
systematically
illustrate
research
question
present
relevant
adversarial
attack
queries
ceo
google
bing
shown
figure
google
bing
image
search
engines
already
fixed
gender
stereotypes
occupation
ceo
however
gender
bias
resurfaces
appending
country
names
united
states
uk
original
keyword
ceo
finding
inspires
us
dive
exploration
gender
fairness
image
search
engines
reveal
superficial
bias
mitigation
ten
occupations
also
investigated
kay
matuszek
munson
2015
seven
years
ago
chosen
image
search
terms
study
design
two
search
keywords
occupation
original
occupation
name
adversarial
attack
keyword
consists
occupation
name
country
name
united
states
latter
aims
trigger
gender
bias
image
search
results
keyword
retrieve
top
200
images
available
four
widely
ceo
google
ceo
google
ceo
uk
google
ceo
bing
ceo
bing
ceo
uk
bing
figure
image
search
results
ceo
ceo
united
states
almost
males
ceo
uk
males
google
bing
used
image
search
engines
namely
google
usa
baidu
china
naver
south
korea
yandex
russia
total
collected
18
000
images
image
retrieval
complete
attempt
leverage
image
gender
detection
apis
recognize
genders
people
images
specific
five
popular
gender
detection
apis
including
amazon
rekognition
luxand
face
microsoft
azure
facebook
deepface
selected
calculate
gender
distributions
returned
occupation
images
compared
gender
labels
detected
apis
human
annotations
found
amazon
rekognition
apis
acceptable
still
failed
handle
images
low
ratio
detected
faces
therefore
propose
hybrid
approach
detect
face
genders
search
images
combining
amazon
rekognition
results
crowdsourced
human
annotations
amazon
mechanical
turk
mitigate
gender
bias
present
three
generalized
reranking
algorithms
including
epsilon-greedy
algorithm
relevance-aware
swapping
algorithm
fairness-greedy
algorithm
balance
trade-off
gender
fairness
image
relevance
evaluations
proposed
gender
bias
mitigation
algorithms
simulated
real-world
datasets
demonstrated
feasible
advisable
address
bias
image
search
perhaps
types
search
well
systematic
meaningful
way
individual
query
fixes
ad
hoc
manner
contributions
summarized
follows
design
adversarial
attacks
regard
gender
bias
image
search
determine
gender
bias
fixed
systematically
search
engines
cirf
open-sourced
cross-search-engine
image
retrieval
framework
collect
images
multiple
search
engines
given
search
terms
developed
find
image
gender
detection
apis
always
perform
well
search
images
wild
hybrid
approach
combining
automatic
gender
detection
manual
annotation
presented
propose
validate
three
re-ranking
algorithms
mitigate
gender
bias
image
search
results
related
work
section
presents
importance
gender
fairness
image
search
results
summarizes
gender
bias-related
research
findings
multiple
perspectives
discusses
existing
approaches
mitigate
image
gender
biases
highlights
difference
existing
works
gender
fairness
biases
demonstrated
image
search
results
affect
people
perceptions
views
significantly
ellemers
2018
metaxa
et
al
2021
kay
matuszek
11883
munson
2015
one
first
investigate
gender
biases
professional
occupation
image
search
results
reported
image
search
results
occupations
slightly
exaggerate
gender
stereotypes
people
thought
image
search
results
better
agreed
stereotype
importantly
research
work
pointed
biased
representation
gender
image
search
results
shift
people
perceptions
real-world
distributions
otterbacher
bates
clough
2017
proposed
trait
adjective
checklist
inspired
method
identify
existence
gender
biases
image
search
found
images
men
often
retrieved
agentic
traits
whereas
warm
traits
demonstrated
photos
women
addition
photos
stereotype-incongruent
individuals
exhibited
backlash
effect
competent
women
less
likely
portrayed
positively
otterbacher
et
al
2018
measured
user
perception
gender
bias
image
search
perspective
sexism
found
search
engine
users
sexist
less
likely
perceive
gender
biases
also
exist
many
research
studies
exploring
gender
bias
different
types
images
detecting
gender
labels
photographs
members
congress
tweeted
images
schwemmer
et
al
2020
concluded
google
cloud
vision
gcv
produce
correct
biased
labels
time
subset
many
possible
true
labels
selectively
reported
wijnhoven
2021
found
gender
bias
toward
stereotypically
female
jobs
women
also
men
searching
jobs
via
google
search
engine
examining
four
professions
across
digital
platforms
singh
et
al
2020
concluded
gender
stereotypes
likely
challenged
users
acted
directly
create
curate
content
algorithmic
approaches
content
curation
showed
little
inclination
towards
breaking
stereotypes
makhortykh
urman
ulloa
2021
conducted
cross-engine
comparison
racial
gender
bias
visual
representation
search
term
artificial
intelligence
gender
representation
ai
diverse
racial
representation
hashemi
hall
2020
reported
gender
bias
identified
detecting
criminal
tendency
based
mugshot
images
arrested
individuals
last
couple
years
many
approaches
proposed
detect
mitigate
gender
bias
images
training
deep
learning
models
wang
et
al
2020
xu
et
al
2020
hwang
et
al
2020
adeli
et
al
2021
example
serna
et
al
2021
showed
bias
face
images
impacted
activations
gender
detection
models
developed
insidebias
detect
biased
models
reduce
gender
bias
deep
image
representations
adversarial
method
removal
features
associated
protected
variable
gender
0.0
0.2
0.4
0.6
0.8
1.0
ratio
images
containing
faces
amazon
rekognition
0.0
0.2
0.4
0.6
0.8
1.0
ratio
images
containing
faces
engineer
engineer
nurse
nurse
police
officer
police
officer
0.0
0.2
0.4
0.6
0.8
1.0
ratio
images
containing
faces
luxand
face
primary
school
teacher
primary
school
teacher
0.0
0.2
0.4
0.6
0.8
1.0
ratio
images
containing
faces
microsoft
azure
software
developer
software
developer
normalized
difference
cook
cook
normalized
difference
computer
programmer
computer
programmer
normalized
difference
chief
executive
officer
chief
executive
officer
normalized
difference
normalized
difference
biologist
biologist
truck
driver
truck
driver
0.0
0.2
0.4
0.6
0.8
1.0
ratio
images
containing
faces
facebook
deepface
figure
normalized
female
ratio
difference
compared
mturk
results
vs
ratio
detected
faces
images
intermediate
convolutional
neural
network
based
representations
presented
wang
et
al
2019
many
image
gender
bias
mitigation
approaches
posterior
regularization
based
gender
de-biasing
framework
jia
et
al
2020
fairness-aware
disentangling
variational
autoencoder
fd-vae
park
et
al
2021
adversarial
gender
de-biasing
algorithm
agenda
dhar
et
al
2020
also
proposed
besides
post-processing
bias
mitigation
methods
fa
ir
zehlike
et
al
2017
multi-task
learning
fair
regression
zhao
chen
2019
proposed
study
adds
literature
exploring
gender
bias
image
search
results
following
ways
first
similar
kay
matuszek
munson
2015
investigate
gender
distribution
professional
occupation
image
results
still
also
design
adversarial
search
attack
adding
country
information
occupation
search
terms
find
evidence
image
search
engines
fix
reported
gender
bias
search
results
systematically
second
examine
performance
five
popular
image
gender
detection
apis
also
propose
hybrid
approach
combines
automatic
detection
amazon
rekognition
services
manual
annotations
amazon
mechanical
turk
improve
gender
distribution
estimation
finally
develop
three
re-ranking
algorithms
epsilon-greedy
relevanceaware
swapping
fairness-greedy
methods
mitigate
gender
biases
image
search
results
image
retrieval
gender
detection
source
lnms
tbm
isch
url
template
google
image
search
keyword
placeholder
search
terms
cirf
able
handle
multiple
search
engines
also
design
similar
url
templates
popular
search
engines
including
baidu
china
naver
south
korea
yandex
russia
keyword
can
written
language
browsers
will
encode
utf-8
format
data
downloader
collect
two
types
search
image
data
based
built
urls
web
page
html
file
captures
layout
names
images
returned
search
engines
ii
individual
image
files
embedded
image
gallery
cirf
adopts
web
framework
selenium
webdriver
open
urls
chrome
browser
incognito
mode
display
cache
search
images
cirf
scrolls
web
page
sending
page_up
page_down
commands
html
entities
cirf
leverages
pyautogui
cross-platform
gui
automation
module
save
web
page
html
file
supplementary
materials
including
images
image
parser
component
responsible
extracting
images
orders
downloaded
html
file
general
three
types
images
collected
standard
images
base64
encoded
images
image
urls
latter
two
types
images
cirf
decodes
standard
images
retrieves
images
via
urls
respectively
images
ready
cirf
renames
according
orders
html
file
analysis
gender
detection
section
describe
build
image
search
datasets
examine
performance
image
based
gender
detection
apis
propose
hybrid
approach
strike
balance
detection
accuracy
efficiency
search
image
retrieval
propose
develop
open-sourced
cross-searchengine
image
retrieval
framework
cirf
automatically
collect
images
multiple
search
engines
given
search
terms
cirf
mainly
consists
three
components
url
builder
data
downloader
image
parser
url
builder
enable
automatic
data
download
first
construct
image
search
urls
based
search-enginespecific
url
templates
given
search
terms
example
use
https://www.google.com/search?q=keyword&
image-based
gender
detection
widely
adopted
diverse
domains
many
commercial
open-sourced
gender
detection
apis
developed
released
considering
scalability
efficiency
intended
rely
available
tools
label
search
images
automatically
evaluate
performance
randomly
selected
searched
ten
occupations
corresponding
adversarial
attack
search
terms
appending
united
states
google
image
search
conducted
irb-approved
user
study
recruit
participants
amazon
mechanical
turk
mturk
build
ground
truth
genders
paid
participant
0.5
annotating
50
images
image
assigned
three
workers
five
popular
gender
detection
apis
including
amazon
rekognition
luxand
face
microsoft
azure
facebook
deepface
chosen
https://github.com/yunhefeng/cirf
11884
https://www.selenium.dev/documentation/webdriver/
https://pyautogui.readthedocs.io/
calculate
gender
distributions
top
200
google
search
images
given
search
term
figure
demonstrates
normalized
female
ratio
difference
mturk
results
face
gender
detection
apis
general
amazon
rekognition
outperforms
rest
apis
terms
face
detection
ratios
see
x-axis
female
ratio
errors
see
y-axis
face
detection
ratio
0.5
normalized
difference
amazon
rekognition
15
therefore
amazon
rekognition
chosen
identify
genders
people
images
thus
propose
two-step
hybrid
method
annotate
image
gender
labels
use
amazon
rekognition
detect
image
genders
search
terms
suffer
low
face
detection
ratio
0.5
still
rely
mturk
manually
label
exploring
unsystematic
gender
bias
fixing
investigate
whether
gender
bias
image
search
results
systematically
fixed
designing
adversarial
search
attacks
measuring
degree
gender
fairness
adversarial
search
attack
design
mentioned
motivated
investigate
whether
image
search
engines
fix
gender
bias
different
occupation
queries
systematically
therefore
follow
occupation
list
bureau
labor
statistics
choose
occupation
names
baseline
search
keywords
constructing
adversarial
searches
append
country
name
united
states
occupation
name
build
attacking
search
term
baseline
attacking
searches
demonstrate
difference
gender
distribution
ground
truth
one
occupation
think
search
engines
mitigate
gender
bias
systematically
occupation
otherwise
argue
fixes
mitigation
gender
bias
just
hit-or-miss
previously
existing
gender
biases
image
search
queries
ceo
drew
huge
attention
public
academia
mainstream
search
engines
already
mitigated
biases
accordingly
however
analytics
show
gender
biases
crossing
occupations
fixed
systematic
way
gender
bias
measurement
intuitive
straightforward
compare
normalized
difference
gender
probability
distribution
image
search
results
ground
truth
gender
probability
occupation
top
images
returned
search
engines
calculate
kullback-leibler
divergence
dkl
images
ground
truth
average
kullback-leibler
divergence
used
represent
existing
bias
pn
dkl
epsilon-greedy
algorithm
inspired
exploitation
exploration
trade-off
idea
reinforcement
learning
berry
fristedt
1985
sutton
barto
2018
re-ranking
gao
shah
2020
propose
epsilon-greedy
re-ranking
algorithm
swaps
items
image
rank
list
controllable
degree
randomness
randomized
swapping
breaks
original
gender
distributions
might
improve
fairness
especially
items
attribution
values
gathered
together
densely
male
ceo
images
fully
occupy
top
20
ceo
image
search
results
algorithm
two
main
advantages
simplicity
generalizability
straightforward
simple
randomly
shuffle
items
without
considering
factors
addition
prior
knowledge
optimal
gender
distribution
required
apply
algorithm
proposed
epsilon-greedy
algorithm
randomness
specified
parameter
representing
probability
swapping
two
items
item
probability
exchange
positions
random
item
follows
larger
introduces
randomness
leading
re-ranked
list
different
original
list
relevance-aware
swapping
algorithm
normally
items
large
relevance
weights
ranked
top
search
engines
returned
image
list
unrelated
less
related
images
ranked
high
harms
user
experience
utility
epsilon-greedy
algorithm
straightforward
simple
ignores
relevance
search
items
re-ranking
therefore
propose
relevance-aware
swapping
algorithm
consider
randomness
relevance
weight
image
items
re-rank
image
list
keep
utility
re-ranked
list
image
larger
relevance
weight
less
likely
swapped
image
item
follows
relevance
weight
modeling
grade
image
relevance
weight
based
index
image
list
returned
search
engines
similar
mean
reciprocal
rank
mrr
voorhees
et
al
1999
relevance
weight
image
rank
index
can
modeled
reciprocal
rank
1i
however
relevance
weight
decreases
fast
growth
rank
index
instead
model
relevance
weight
distribution
linear
manner
suppose
image
list
containing
images
linear
relevance
weight
ith
image
estimated
inspired
discounted
cumulative
gain
dcg
järvelin
kekäläinen
2002
introduce
discount
factor
log2
smooth
decay
relevance
weights
bottom
images
finally
relevance
weight
image
li
expressed
wi
log2
algorithms
mitigate
gender
bias
propose
three
interpretable
lightweight
re-ranking
algorithms
mitigate
gender
biases
image
search
results
https://www.bls.gov/oes/current/oes_nat.htm#00-0000
11885
swapping
probability
swapping
probability
image
li
determined
relevance
weight
wi
ensure
image
high
relevance
weight
less
likely
swapped
can
use
wi
represent
swapping
algorithm
relevance-aware
swapping
algorithm
algorithm
fairness-greedy
algorithm
input
original
image
list
sensitivity
swapping
two
items
output
re-ranked
image
list
initialize
empty
input
original
image
list
ground
truth
gender
distribution
set
gender
features
output
re-ranked
image
list
l1
initialize
l1
gender
distribution
gr1
gri
lag
alse
xmin
one
underrep
feat
set
checked
features
lag
alse
10
dmin
11
add
xmin
update
select
underrep
feature
12
13
px
tx
diff
feat
14
dmin
15
xmin
underrep
feat
16
end
find
1st
item
underrep
feat
17
18
glj
xmin
find
item
19
temp
lj
save
lj
20
21
lk
lk
move
22
end
23
li
temp
update
li
24
append
li
update
25
lag
rue
find
item
26
break
27
end
28
end
29
end
30
return
10
11
12
13
14
15
16
17
wi
log
relevance
weight
random
number
wi
swap
items
temp
li
random
number
li
lj
lj
temp
append
li
add
swapped
item
else
keep
original
item
append
li
add
unswapped
item
end
end
return
probability
image
li
addition
design
coefficient
control
swapping
sensitivity
swapping
probability
image
li
expressed
wi
detailed
implementation
illustrated
algorithm
fairness-greedy
algorithm
considering
90
users
go
past
first
page
google
search
results
sharma
et
al
2019
first
three
items
displayed
amazon
search
results
account
64
clicks
baker
2018
think
great
significance
ensure
gender
fairness
images
ranked
top
search
results
therefore
propose
fairness-greedy
algorithm
guarantee
gender
fairness
first
pages
high
priority
accordingly
gender
distribution
images
displayed
last
pages
users
pay
lesser
attention
given
less
consideration
main
idea
fairness-greedy
algorithm
narrow
difference
gender
distributions
top-ranked
images
ground
truth
moving
images
unlike
epsilon-greedy
relevance-aware
swapping
algorithms
fairness-greedy
algorithm
needs
know
ground
truth
gender
distribution
search
terms
real
life
list
gender
labels
returned
images
search
engines
ground
truth
searched
profession
usually
available
open
data
census
data
image
gender
labels
can
estimated
available
computer
vision
based
gender
apis
required
calculate
gender
distribution
top-ranked
images
detailed
implementation
fairness-greedy
algorithm
shown
algorithm
make
algorithm
general
use
represent
involved
features
gender
features
female
male
note
fairnessgreedy
algorithm
capable
handling
two
different
features
keep
first
item
original
rank
list
beginning
see
line
starting
second
item
calculate
gender
distribution
latest
re-ranked
list
px
represents
ratio
feature
11886
tx
ground
truth
feature
real
world
next
take
two-step
re-ranking
method
mitigate
feature
biases
step
identify
underrepresented
feature
xmin
comparing
difference
px
tx
see
line
12
16
step
find
first
item
lj
feature
xmin
glj
xmin
li
move
forward
new
li
see
line
17
27
item
lj
exist
exclude
feature
xmin
adding
checked
feature
set
continue
re-ranking
see
line
11
experiments
evaluation
section
presents
evaluations
three
proposed
bias
mitigation
approaches
synthetic
real
datasets
evaluation
synthetic
data
generated
three
synthetic
datasets
different
gender
distribution
patterns
uniform
dataset
female
male
items
distributed
evenly
across
whole
list
heavyheaded
dataset
female
items
aggregated
top
list
heavy-tailed
dataset
female
items
aggregated
bottom
list
experiments
created
list
length
200
set
female
ratio
0.5
100
items
labeled
female
heavy-headed
heavy-tailed
datasets
100
female
items
distributed
computer
programmer
0.4
0.25
50
100
top
150
200
nurse
nurse
truck
driver
1.0
0.8
0.8
0.8
0.6
0.4
0.2
0.0
google
50
100
top
150
200
female
ratio
0.50
engineer
1.0
0.6
0.4
0.2
0.0
baidu
50
100
top
150
200
naver
truck
driver
0.6
0.4
0.2
0.0
50
100
top
150
200
yandex
0.2
0.1
0.0
0.1
0.2
0.3
50
100
top
biologist
150
google
naver
baidu
yandex
200
chief
executive
computer
officer
programmer
cook
engineer
nurse
police
officer
primary
school
teacher
software
developer
truck
driver
difference
female
ratio
image
search
results
united
states
search
terms
ground
truth
figure
gender
distributions
ten
occupations
google
baidu
naver
yandex
image
search
engines
evaluation
real-world
data
conducted
adversarial
attacks
gender
fairness
four
major
image
search
engines
various
gender
distributions
observed
search
term
also
found
image
search
engines
sensitive
search
term
variants
convey
semantics
finally
evaluated
performances
three
proposed
bias
mitigated
algorithms
collected
dataset
subsection
presents
details
evaluations
gender
bias
cross-culture
search
engines
besides
google
image
search
engine
evaluated
occupation
terms
baidu
china
naver
south
korea
yandex
russia
using
hybrid
image
gender
detection
method
see
subsection
gender
detection
similar
google
three
image
search
engines
deemed
gender
bias
search
terms
include
united
states
see
figure
positive
value
indicates
over-representing
females
neg11887
ative
value
indicates
under-representing
females
effectiveness
proposed
adversarial
attack
approach
cross-culture
search
engines
demonstrated
figure
figure
difference
female
ratios
search
terms
without
united
states
evident
especially
among
top
50
items
can
also
observe
distinct
occupations
demonstrate
different
gender
distribution
patterns
search
engine
occupation
may
demonstrate
different
patterns
across
search
engines
findings
led
us
consider
gender
bias
exists
across
cultures
needs
attention
globally
diff
ratio
top
50
bottom
50
list
respectively
set
ground
truth
gender
distribution
emale
0.5
male
0.5
bias
mitigation
performance
three
proposed
algorithms
1000
runs
widely
used
fair
top-k
ranking
algorithm
named
fa
ir
zehlike
et
al
2017
shown
table
recall
used
equation
measure
bias
expected
neither
epsilon-greedy
relevanceaware
swapping
algorithms
can
mitigate
bias
introducing
randomness
uniform
dataset
original
list
already
randomized
entirely
reason
fa
ir
also
fails
improve
fairness
uniform
dataset
heavy-headed
heavy-tailed
datasets
randomness
introduced
larger
epsilon-greedy
algorithm
larger
relevance-aware
swapping
algorithm
bias
mitigated
fa
ir
also
reduces
gender
bias
significantly
fairness-greedy
algorithm
performs
best
three
datasets
female
ratio
0.0
0.75
0.00
0.6
0.2
female
ratio
female
ratio
0.8
diff
btw
ground
truth
female
ratio
1.0
engineer
1.0
female
ratio
computer
programmer
1.00
0.3
0.2
0.1
ceo
chief
executive
officer
ceo
chief
executive
officer
50
100
top
150
200
0.0
0.2
ceo
chief
executive
officer
ceo
chief
executive
officer
50
100
top
150
200
ceo
vs
chief
exec
officer
difference
female
ratio
figure
sensitive
variant
search
terms
sensitive
variant
search
terms
another
evidence
unsystematic
mitigation
gender
bias
image
search
engines
sensitive
variant
search
terms
shown
figure
female
ratios
image
search
results
ceo
chief
executive
officer
significantly
different
especially
search
terms
include
united
states
however
increase
top
difference
female
ratio
demonstrates
trend
become
stable
small
especially
search
terms
containing
united
states
see
figure
gender
bias
mitigation
deployed
three
proposed
algorithms
image
search
datasets
collected
google
baidu
naver
yandex
illustrate
proposed
algorithms
work
take
epsilon-greedy
algorithm
example
show
dynamic
fairness
achievements
biologist
datasets
shown
figure
increases
original
uniform
heavy-headed
heavy-tailed
0.066
2.046
2.046
relevance-aware
swapping
epsilon-greedy
0.2
0.4
0.6
0.2
0.4
fair-greedy
0.6
fa
ir
0.5
0.1
0.059
0.019
0.055
0.025
0.052
0.028
0.065
0.013
0.064
0.018
0.063
0.022
0.426
0.189
0.203
0.107
0.105
0.063
0.553
0.222
0.316
0.143
0.198
0.095
0.423
0.199
0.194
0.096
0.102
0.061
0.548
0.219
0.312
0.136
0.198
0.098
0.020
0.020
0.020
0.066
0.142
0.142
table
bias
mitigation
performance
synthetic
datasets
bias
value
table
measured
equation
original
biologist
ceo
comp
programmer
cook
engineer
nurse
police
officer
prim
school
teacher
software
developer
truck
driver
0.138
0.172
0.114
0.149
0.04
0.115
0.049
0.135
0.189
0.056
relevance-aware
swapping
epsilon-greedy
0.2
0.4
0.6
0.2
0.4
0.6
0.102
0.044
0.175
0.055
0.119
0.027
0.131
0.051
0.044
0.011
0.119
0.011
0.053
0.015
0.136
0.007
0.193
0.066
0.067
0.044
0.087
0.046
0.160
0.082
0.120
0.030
0.109
0.064
0.053
0.019
0.119
0.015
0.054
0.016
0.136
0.010
0.171
0.078
0.088
0.062
0.071
0.049
0.144
0.087
0.135
0.062
0.101
0.070
0.063
0.036
0.128
0.023
0.055
0.018
0.137
0.011
0.156
0.082
0.088
0.067
0.128
0.032
0.169
0.048
0.113
0.021
0.148
0.049
0.045
0.022
0.118
0.009
0.048
0.008
0.137
0.006
0.193
0.035
0.070
0.044
0.108
0.046
0.167
0.052
0.114
0.030
0.133
0.052
0.048
0.016
0.121
0.015
0.047
0.011
0.136
0.008
0.180
0.061
0.074
0.048
0.114
0.046
0.160
0.054
0.120
0.035
0.128
0.064
0.052
0.022
0.124
0.017
0.046
0.013
0.137
0.009
0.184
0.067
0.087
0.064
fair-greedy
fa
ir
0.5
0.1
0.018
0.021
0.034
0.017
0.02
0.066
0.015
0.1
0.055
0.007
0.072
0.084
0.071
0.102
0.027
0.076
0.088
0.085
0.094
0.02
table
bias
mitigation
performance
google
occupation
image
datasets
bias
value
measured
equation
randomness
introduced
gender
distribution
re-ranked
list
becomes
likely
different
original
one
see
shaded
range
implying
fairness
will
achieved
raw
image
search
list
suffers
severe
gender
bias
increase
top
female
ratio
becomes
stable
finally
converges
top
reaches
200
0.0
100
top
200
2.5
0.0
0.0
yandex
orig
yandex
greedy
1.0
0.5
epsilon
0.2
5.0
naver
orig
naver
greedy
1.0
0.5
female
ratio
7.5
1.0
female
ratio
0.0
baidu
orig
baidu
greedy
female
ratio
google
orig
google
greedy
0.5
100
top
200
epsilon
0.4
0.0
100
top
200
epsilon
0.6
figure
performance
epsilon-greedy
algorithm
google
baidu
naver
yandex
biologist
datasets
similar
evaluations
synthetic
datasets
explored
performance
algorithms
fa
ir
zehlike
200
et
al
2017
100
real-world
datasets
table
illustrates
genk
der
mitigation
top
performance
algorithm
10
google
image
datasets
collected
search
keywords
10
occupations
plus
united
states
original
bias
larger
0.1
biologist
united
states
gender
bias
normally
decreases
along
increase
epsilon-greedy
algorithm
relevance-aware
swapping
algorithm
however
original
bias
small
engineer
united
states
epsilon-greedy
algorithm
relevance-aware
swapping
algorithm
mitigate
gender
bias
can
observe
fairness-greedy
algorithm
consistently
achieves
low
bias
gives
highest
priority
fairness
re-ranking
fa
ir
also
demonstrates
stable
good
performance
regardless
original
bias
addition
comparing
result
columns
original
11888
fairness-greedy
table
can
tell
degree
gender
bias
hidden
original
image
list
conclusion
limitation
bias
ai
systems
become
increasingly
prevalent
complex
issue
address
often
system
developers
fix
problem
creating
superfluous
solution
without
addressing
underlying
issue
paper
used
adversarial
query
attack
method
appending
additional
information
like
country
names
trigger
potential
gender
bias
image
search
open-sourced
cross-search-engine
image
retrieval
framework
cirf
developed
retrieve
data
google
baidu
naver
yandex
recognize
gender
people
photos
five
popular
image
gender
detection
apis
namely
amazon
rekognition
luxand
face
microsoft
azure
facebook
deepface
evaluated
although
apis
endorsed
ai
giants
always
handle
images
wild
high
accuracy
therefore
hybrid
method
combining
automatic
gender
detection
apis
crowdsourced
human
workforce
designed
label
image
genders
mitigate
gender
bias
proposed
three
lightweight
interpretable
re-ranking
algorithms
evaluated
performance
synthetic
real-world
datasets
results
demonstrated
possible
advisable
address
bias
image
search
perhaps
types
search
well
systematic
sustainable
meaningful
way
individual
query
fixes
ad
hoc
fashion
paper
treated
gender
binary
attribute
inferred
either
gender
apis
humans
however
acknowledge
gender
different
biological
sex
non-binary
also
something
third-party
human
program
always
position
detect
genders
correctly
reliance
binary
gender
norm
third-party
annotation
limitation
research
references
adeli
zhao
pfefferbaum
sullivan
fei-fei
niebles
pohl
2021
representation
learning
statistical
independence
mitigate
bias
proceedings
ieee
cvf
winter
conference
applications
computer
vision
2513
2523
baker
2018
amazon
search
engine
ranking
algorithm
marketers
need
know
https://www.searchenginejournal.com/amazon-searchengine-ranking-algorithm-explained/265173/.
accessed
2022
02
10
berry
fristedt
1985
bandit
problems
sequential
allocation
experiments
monographs
statistics
applied
probability
london
chapman
hall
71
87
dhar
gleason
souri
castillo
chellappa
2020
towards
gender-neutral
face
descriptors
mitigating
bias
face
recognition
arxiv
preprint
arxiv
2006.07845
ellemers
2018
gender
stereotypes
annual
review
psychology
69
275
298
gao
shah
2020
toward
creating
fairer
ranking
search
engine
results
information
processing
management
57
102138
griffith
2021
algorithms
still
bias
problem
big
tech
isn
enough
fix
https://www.pcmag.com/news/algorithms-still-have-abias-problem-and-big-tech-isnt-doing-enough-to.
accessed
2022
02
10
hashemi
hall
2020
retracted
article
criminal
tendency
detection
facial
images
gender
bias
effect
journal
big
data
16
hibbing
rankin-erickson
2003
picture
worth
thousand
words
using
visual
images
improve
comprehension
middle
school
struggling
readers
reading
teacher
56
758
770
hwang
park
kim
byun
2020
fairfacegan
fairness-aware
facial
image-to-image
translation
arxiv
preprint
arxiv
2012.00282
järvelin
kekäläinen
2002
cumulated
gain-based
evaluation
ir
techniques
acm
transactions
information
systems
tois
20
422
446
jia
meng
zhao
chang
2020
mitigating
gender
bias
amplification
distribution
posterior
regularization
arxiv
preprint
arxiv
2005.06251
kay
matuszek
munson
2015
unequal
representation
gender
stereotypes
image
search
results
occupations
proceedings
33rd
annual
acm
conference
human
factors
computing
systems
lam
broderick
wojcik
hughes
2018
gender
jobs
online
image
searches
pew
social
trends
retrieved
march
14
2020
makhortykh
urman
ulloa
2021
detecting
race
gender
bias
visual
representation
ai
web
search
engines
international
workshop
algorithmic
bias
search
recommendation
36
50
springer
11889
metaxa
gan
goh
hancock
landay
2021
image
society
gender
racial
representation
impact
image
search
results
occupations
proceedings
acm
human-computer
interaction
cscw1
23
mozilla
2021
internet
health
report
2020
https
creativecommons
org
licenses
4.0
accessed
2021
0915
otterbacher
bates
clough
2017
competent
men
warm
women
gender
stereotypes
backlash
image
search
results
proceedings
2017
chi
conference
human
factors
computing
systems
otterbacher
checco
demartini
clough
2018
investigating
user
perception
gender
bias
image
search
role
sexism
41st
international
acm
sigir
conference
research
development
information
retrieval
933
936
park
hwang
kim
byun
2021
learning
disentangled
representation
fair
facial
attribute
classification
via
fairness-aware
information
alignment
proceedings
aaai
conference
artificial
intelligence
volume
35
2403
2411
schwemmer
knight
bello-pardo
oklobdzija
schoonvelde
lockhart
2020
diagnosing
gender
bias
image
recognition
systems
socius
2378023120967171
serna
peña
morales
fierrez
2021
insidebias
measuring
bias
deep
networks
application
face
gender
biometrics
2020
25th
international
conference
pattern
recognition
icpr
3720
3727
ieee
sharma
shukla
giri
kumar
2019
brief
review
search
engine
optimization
2019
9th
international
conference
cloud
computing
data
science
engineering
confluence
687
692
ieee
singh
chayko
inamdar
floegel
2020
female
librarians
male
computer
programmers
gender
bias
occupational
images
digital
media
platforms
journal
association
information
science
technology
71
11
1281
1294
sutton
barto
2018
reinforcement
learning
introduction
mit
press
voorhees
et
al
1999
trec-8
question
answering
track
report
trec
volume
99
77
82
citeseer
wang
zhao
yatskar
chang
ordonez
2019
balanced
datasets
enough
estimating
mitigating
gender
bias
deep
image
representations
proceedings
ieee
cvf
international
conference
computer
vision
5310
5319
wang
qinami
karakozis
genova
nair
hata
russakovsky
2020
towards
fairness
visual
recognition
effective
strategies
bias
mitigation
proceedings
ieee
cvf
conference
computer
vision
pattern
recognition
8919
8928
wijnhoven
2021
search
engine
gender
bias
frontiers
big
data
29
xu
white
kalkan
gunes
2020
investigating
bias
fairness
facial
expression
recognition
european
conference
computer
vision
506
523
springer
zehlike
bonchi
castillo
hajian
megahed
baeza-yates
2017
fa
ir
fair
top-k
ranking
algorithm
proceedings
2017
acm
conference
information
knowledge
management
1569
1578
zhao
chen
2019
rank-based
multi-task
learning
fair
regression
2019
ieee
international
conference
data
mining
icdm
916
925
ieee
11890